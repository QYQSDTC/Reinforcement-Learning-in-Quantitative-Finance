{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FinRL: 强化学习在量化金融中的应用](https://github.com/QYQSDTC/FinRL)\n",
    "*注：本文不构成任何投资建议，入市有风险，投资需谨慎。*\n",
    "\n",
    "## 目标\n",
    "- 了解强化学习在量化金融中的应用\n",
    "- 通过强化学习的方法，实现一个简单的量化交易策略\n",
    "- 比较不同的强化学习算法在量化金融中的表现\n",
    "\n",
    "## 用到的Package\n",
    "- [FinRL](https://github.com/AI4Finance-Foundation/FinRL): 一个强化学习在量化金融中的应用的开源库\n",
    "- [Tushare](https://tushare.pro/): 一个免费的金融数据接口\n",
    "- [Quantopian Pyfolio](https://github.com/quantopian/pyfolio): 一个自动化回测工具包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42ac7297"
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:23.449076Z",
     "start_time": "2022-10-12T10:28:21.587829Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fluid-taylor",
    "outputId": "30383d78-b504-4216-e338-addc1689c3c3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100, 'display.min_rows', 50,'display.max_columns', 100)\n",
    "from IPython import display\n",
    "import tushare as ts\n",
    "display.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "from meta import config\n",
    "from meta.data_processors.tushare import Tushare, ReturnPlotter\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import StockTradingEnv\n",
    "from agents.stablebaselines3_models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "import datetime\n",
    "    \n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb601f4a"
   },
   "source": [
    "## Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:23.466632Z",
     "start_time": "2022-10-12T10:28:23.462467Z"
    },
    "collapsed": true,
    "id": "339ab411"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./datasets\" ):\n",
    "    os.makedirs(\"./datasets\" )\n",
    "if not os.path.exists(\"./trained_models\"):\n",
    "    os.makedirs(\"./trained_models\" )\n",
    "if not os.path.exists(\"./tensorboard_log\"):\n",
    "    os.makedirs(\"./tensorboard_log\" )\n",
    "if not os.path.exists(\"./results\" ):\n",
    "    os.makedirs(\"./results\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ad0a26"
   },
   "source": [
    "## Data preparation: download, cleansing and feature engineering\n",
    "我们用Tushare获取了A股市场近10年的数据 (2012/01/01 -- 2022/09/28)，包括开盘价、收盘价、最高价、最低价、成交量、成交额、涨跌幅等信息。我们用这些数据来训练我们的强化学习模型。\n",
    "### 个股的选择\n",
    "因为本项目的主要目的是研究强化学习在量化金融中的应用，所以个股的选择我们就简单的从上证50中选取了5只权重股，包括：贵州茅台，万华化学，中国平安，中国中免，恒瑞医药。\n",
    "\n",
    "如果想要更好的收益，可以用量化因子选股或者其它的一些量化方法，但是这不在本项目的讨论范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:25.166286Z",
     "start_time": "2022-10-12T10:28:25.160526Z"
    },
    "collapsed": true,
    "id": "transsexual-crack"
   },
   "outputs": [],
   "source": [
    "train_start_date='2012-01-01'\n",
    "train_stop_date='2020-01-01'\n",
    "trade_start_date='2020-01-01'\n",
    "trade_stop_date='2022-09-30'\n",
    "\n",
    "# token='27080ec403c0218f96f388bca1b1d85329d563c91a43672239619ef5'\n",
    "token='829a1fbce8eb0e34f05ab19906d0e08227c6f64261a81272aa078ccd'\n",
    "\n",
    "pro = ts.pro_api(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-11T11:09:45.032197Z",
     "start_time": "2022-10-11T11:09:44.912264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_code</th>\n",
       "      <th>con_code</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601012.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>4.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600745.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600104.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600690.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601088.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600028.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600809.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601995.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600519.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>18.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601919.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601166.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>3.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601668.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601601.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600436.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601066.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601318.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>6.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600030.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600588.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600276.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600438.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600570.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603501.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600837.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603288.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603986.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601688.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600036.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>6.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601857.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600196.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603799.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600887.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600111.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600031.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600048.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600905.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601398.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601633.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601288.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600893.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601628.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600010.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600585.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600900.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>3.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>603259.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601899.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>1.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601888.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600346.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601728.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>601211.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>600309.SH</td>\n",
       "      <td>20220930</td>\n",
       "      <td>2.220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_code   con_code trade_date  weight\n",
       "0   000016.SH  601012.SH   20220930   4.460\n",
       "1   000016.SH  600745.SH   20220930   0.547\n",
       "2   000016.SH  600104.SH   20220930   1.026\n",
       "3   000016.SH  600690.SH   20220930   1.440\n",
       "4   000016.SH  601088.SH   20220930   1.602\n",
       "5   000016.SH  600028.SH   20220930   0.881\n",
       "6   000016.SH  600809.SH   20220930   2.270\n",
       "7   000016.SH  601995.SH   20220930   0.309\n",
       "8   000016.SH  600519.SH   20220930  18.058\n",
       "9   000016.SH  601919.SH   20220930   1.071\n",
       "10  000016.SH  601166.SH   20220930   3.718\n",
       "11  000016.SH  601668.SH   20220930   1.658\n",
       "12  000016.SH  601601.SH   20220930   1.068\n",
       "13  000016.SH  600436.SH   20220930   1.236\n",
       "14  000016.SH  601066.SH   20220930   0.462\n",
       "15  000016.SH  601318.SH   20220930   6.916\n",
       "16  000016.SH  600030.SH   20220930   2.611\n",
       "17  000016.SH  600588.SH   20220930   0.464\n",
       "18  000016.SH  600276.SH   20220930   2.406\n",
       "19  000016.SH  600438.SH   20220930   1.947\n",
       "20  000016.SH  600570.SH   20220930   0.791\n",
       "21  000016.SH  603501.SH   20220930   0.874\n",
       "22  000016.SH  600837.SH   20220930   1.284\n",
       "23  000016.SH  603288.SH   20220930   1.768\n",
       "24  000016.SH  603986.SH   20220930   0.961\n",
       "25  000016.SH  601688.SH   20220930   1.095\n",
       "26  000016.SH  600036.SH   20220930   6.395\n",
       "27  000016.SH  601857.SH   20220930   0.765\n",
       "28  000016.SH  600196.SH   20220930   0.577\n",
       "29  000016.SH  603799.SH   20220930   1.255\n",
       "30  000016.SH  600887.SH   20220930   2.593\n",
       "31  000016.SH  600111.SH   20220930   0.889\n",
       "32  000016.SH  600031.SH   20220930   1.267\n",
       "33  000016.SH  600048.SH   20220930   1.985\n",
       "34  000016.SH  600905.SH   20220930   0.742\n",
       "35  000016.SH  601398.SH   20220930   2.341\n",
       "36  000016.SH  601633.SH   20220930   0.526\n",
       "37  000016.SH  601288.SH   20220930   1.402\n",
       "38  000016.SH  600893.SH   20220930   0.858\n",
       "39  000016.SH  601628.SH   20220930   0.809\n",
       "40  000016.SH  600010.SH   20220930   0.644\n",
       "41  000016.SH  600585.SH   20220930   1.062\n",
       "42  000016.SH  600900.SH   20220930   3.970\n",
       "43  000016.SH  603259.SH   20220930   2.258\n",
       "44  000016.SH  601899.SH   20220930   1.735\n",
       "45  000016.SH  601888.SH   20220930   2.972\n",
       "46  000016.SH  600346.SH   20220930   0.549\n",
       "47  000016.SH  601728.SH   20220930   0.320\n",
       "48  000016.SH  601211.SH   20220930   0.946\n",
       "49  000016.SH  600309.SH   20220930   2.220"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro.index_weight(index_code = '000016.SH', start_date = '20220901')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:26:21.637035Z",
     "start_time": "2022-10-12T02:26:21.457615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks: 50, stocks: ['601012.SH', '600745.SH', '600104.SH', '600690.SH', '601088.SH', '600028.SH', '600809.SH', '601995.SH', '600519.SH', '601919.SH', '601166.SH', '601668.SH', '601601.SH', '600436.SH', '601066.SH', '601318.SH', '600030.SH', '600588.SH', '600276.SH', '600438.SH', '600570.SH', '603501.SH', '600837.SH', '603288.SH', '603986.SH', '601688.SH', '600036.SH', '601857.SH', '600196.SH', '603799.SH', '600887.SH', '600111.SH', '600031.SH', '600048.SH', '600905.SH', '601398.SH', '601633.SH', '601288.SH', '600893.SH', '601628.SH', '600010.SH', '600585.SH', '600900.SH', '603259.SH', '601899.SH', '601888.SH', '600346.SH', '601728.SH', '601211.SH', '600309.SH']\n"
     ]
    }
   ],
   "source": [
    "# ticket_list=['600519.SH', '600309.SH', '601318.SH', '601888.SH', '600276.SH']\n",
    "# take 上证50成分股\n",
    "ticker_list = pro.index_weight(index_code = '000016.SH', start_date = '20220901').con_code.unique().tolist()\n",
    "ticker_list\n",
    "print(f'Number of stocks: {len(ticker_list)}, stocks: {ticker_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:32.806106Z",
     "start_time": "2022-10-12T10:28:32.799771Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "preceding-selling",
    "outputId": "8b88552b-da4a-476f-d3a4-8ea79019819e"
   },
   "outputs": [],
   "source": [
    "# download and clean\n",
    "ts_processor = Tushare(data_source=\"tushare\", \n",
    "                                   start_date=train_start_date,\n",
    "                                   end_date=trade_stop_date,\n",
    "                                   time_interval=\"1d\",\n",
    "                                   token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:00.374815Z",
     "start_time": "2022-10-12T02:26:26.066772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:34<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (113660, 8)\n"
     ]
    }
   ],
   "source": [
    "ts_processor.download_data(ticker_list=ticker_list)\n",
    "ts_processor.dataframe.to_csv('./datasets/A_stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:01.564972Z",
     "start_time": "2022-10-12T02:27:01.447768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/A_stock.csv')\n",
    "len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:04.953291Z",
     "start_time": "2022-10-12T02:27:04.668086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tic</th>\n",
       "      <th>600010.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600048.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600111.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600346.SH</th>\n",
       "      <th>600436.SH</th>\n",
       "      <th>600438.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "      <th>600585.SH</th>\n",
       "      <th>600588.SH</th>\n",
       "      <th>600690.SH</th>\n",
       "      <th>600745.SH</th>\n",
       "      <th>600809.SH</th>\n",
       "      <th>600837.SH</th>\n",
       "      <th>600887.SH</th>\n",
       "      <th>600893.SH</th>\n",
       "      <th>600900.SH</th>\n",
       "      <th>600905.SH</th>\n",
       "      <th>601012.SH</th>\n",
       "      <th>601066.SH</th>\n",
       "      <th>601088.SH</th>\n",
       "      <th>601166.SH</th>\n",
       "      <th>601211.SH</th>\n",
       "      <th>601288.SH</th>\n",
       "      <th>601318.SH</th>\n",
       "      <th>601398.SH</th>\n",
       "      <th>601601.SH</th>\n",
       "      <th>601628.SH</th>\n",
       "      <th>601633.SH</th>\n",
       "      <th>601668.SH</th>\n",
       "      <th>601688.SH</th>\n",
       "      <th>601728.SH</th>\n",
       "      <th>601857.SH</th>\n",
       "      <th>601888.SH</th>\n",
       "      <th>601899.SH</th>\n",
       "      <th>601919.SH</th>\n",
       "      <th>601995.SH</th>\n",
       "      <th>603259.SH</th>\n",
       "      <th>603288.SH</th>\n",
       "      <th>603501.SH</th>\n",
       "      <th>603799.SH</th>\n",
       "      <th>603986.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>4.15</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.56</td>\n",
       "      <td>12.09</td>\n",
       "      <td>11.67</td>\n",
       "      <td>10.05</td>\n",
       "      <td>14.16</td>\n",
       "      <td>37.61</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>7.07</td>\n",
       "      <td>73.03</td>\n",
       "      <td>4.85</td>\n",
       "      <td>185.27</td>\n",
       "      <td>11.50</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.90</td>\n",
       "      <td>8.78</td>\n",
       "      <td>5.79</td>\n",
       "      <td>57.79</td>\n",
       "      <td>7.12</td>\n",
       "      <td>19.73</td>\n",
       "      <td>13.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.60</td>\n",
       "      <td>12.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.60</td>\n",
       "      <td>33.90</td>\n",
       "      <td>4.22</td>\n",
       "      <td>19.04</td>\n",
       "      <td>17.46</td>\n",
       "      <td>11.87</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.75</td>\n",
       "      <td>25.59</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>4.10</td>\n",
       "      <td>7.42</td>\n",
       "      <td>9.29</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.91</td>\n",
       "      <td>9.80</td>\n",
       "      <td>14.39</td>\n",
       "      <td>35.64</td>\n",
       "      <td>8.25</td>\n",
       "      <td>27.00</td>\n",
       "      <td>12.10</td>\n",
       "      <td>6.86</td>\n",
       "      <td>70.50</td>\n",
       "      <td>4.66</td>\n",
       "      <td>183.15</td>\n",
       "      <td>10.70</td>\n",
       "      <td>14.92</td>\n",
       "      <td>16.48</td>\n",
       "      <td>8.73</td>\n",
       "      <td>5.54</td>\n",
       "      <td>55.04</td>\n",
       "      <td>7.08</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.66</td>\n",
       "      <td>6.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.29</td>\n",
       "      <td>12.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.65</td>\n",
       "      <td>33.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.12</td>\n",
       "      <td>16.58</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.80</td>\n",
       "      <td>24.17</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>4.34</td>\n",
       "      <td>7.48</td>\n",
       "      <td>9.39</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.99</td>\n",
       "      <td>9.71</td>\n",
       "      <td>14.20</td>\n",
       "      <td>36.32</td>\n",
       "      <td>8.08</td>\n",
       "      <td>26.55</td>\n",
       "      <td>12.06</td>\n",
       "      <td>6.40</td>\n",
       "      <td>70.08</td>\n",
       "      <td>4.72</td>\n",
       "      <td>186.64</td>\n",
       "      <td>10.67</td>\n",
       "      <td>14.72</td>\n",
       "      <td>16.23</td>\n",
       "      <td>8.79</td>\n",
       "      <td>5.76</td>\n",
       "      <td>53.69</td>\n",
       "      <td>7.30</td>\n",
       "      <td>19.66</td>\n",
       "      <td>12.95</td>\n",
       "      <td>6.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.27</td>\n",
       "      <td>12.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.66</td>\n",
       "      <td>33.85</td>\n",
       "      <td>4.28</td>\n",
       "      <td>19.23</td>\n",
       "      <td>16.73</td>\n",
       "      <td>11.81</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.96</td>\n",
       "      <td>23.61</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>4.48</td>\n",
       "      <td>7.75</td>\n",
       "      <td>9.75</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.38</td>\n",
       "      <td>10.17</td>\n",
       "      <td>14.90</td>\n",
       "      <td>39.02</td>\n",
       "      <td>8.34</td>\n",
       "      <td>27.40</td>\n",
       "      <td>12.47</td>\n",
       "      <td>6.64</td>\n",
       "      <td>70.10</td>\n",
       "      <td>4.89</td>\n",
       "      <td>188.01</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>16.58</td>\n",
       "      <td>9.07</td>\n",
       "      <td>6.00</td>\n",
       "      <td>54.59</td>\n",
       "      <td>7.62</td>\n",
       "      <td>20.13</td>\n",
       "      <td>13.39</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.01</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "      <td>34.73</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.73</td>\n",
       "      <td>17.28</td>\n",
       "      <td>12.26</td>\n",
       "      <td>2.93</td>\n",
       "      <td>7.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.03</td>\n",
       "      <td>24.41</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>4.54</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.12</td>\n",
       "      <td>13.31</td>\n",
       "      <td>12.56</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.25</td>\n",
       "      <td>40.39</td>\n",
       "      <td>8.66</td>\n",
       "      <td>27.75</td>\n",
       "      <td>13.21</td>\n",
       "      <td>7.02</td>\n",
       "      <td>72.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>194.48</td>\n",
       "      <td>11.34</td>\n",
       "      <td>16.59</td>\n",
       "      <td>17.02</td>\n",
       "      <td>9.42</td>\n",
       "      <td>6.21</td>\n",
       "      <td>57.00</td>\n",
       "      <td>7.93</td>\n",
       "      <td>20.58</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.76</td>\n",
       "      <td>13.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>36.29</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.40</td>\n",
       "      <td>18.23</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.12</td>\n",
       "      <td>25.60</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-11</th>\n",
       "      <td>4.79</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.08</td>\n",
       "      <td>13.13</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.31</td>\n",
       "      <td>15.10</td>\n",
       "      <td>42.63</td>\n",
       "      <td>8.63</td>\n",
       "      <td>27.70</td>\n",
       "      <td>13.25</td>\n",
       "      <td>7.14</td>\n",
       "      <td>72.85</td>\n",
       "      <td>5.06</td>\n",
       "      <td>189.68</td>\n",
       "      <td>11.25</td>\n",
       "      <td>16.38</td>\n",
       "      <td>17.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>6.13</td>\n",
       "      <td>57.67</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.61</td>\n",
       "      <td>13.72</td>\n",
       "      <td>6.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.67</td>\n",
       "      <td>35.83</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.20</td>\n",
       "      <td>18.22</td>\n",
       "      <td>12.41</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.04</td>\n",
       "      <td>25.95</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-12</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.03</td>\n",
       "      <td>13.22</td>\n",
       "      <td>12.62</td>\n",
       "      <td>10.39</td>\n",
       "      <td>15.29</td>\n",
       "      <td>43.46</td>\n",
       "      <td>8.58</td>\n",
       "      <td>27.37</td>\n",
       "      <td>13.31</td>\n",
       "      <td>7.07</td>\n",
       "      <td>73.99</td>\n",
       "      <td>5.03</td>\n",
       "      <td>190.35</td>\n",
       "      <td>11.05</td>\n",
       "      <td>16.51</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.23</td>\n",
       "      <td>6.28</td>\n",
       "      <td>55.89</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.50</td>\n",
       "      <td>14.10</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.03</td>\n",
       "      <td>18.30</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.04</td>\n",
       "      <td>7.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.06</td>\n",
       "      <td>25.47</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-13</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.80</td>\n",
       "      <td>12.92</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.28</td>\n",
       "      <td>14.69</td>\n",
       "      <td>44.96</td>\n",
       "      <td>8.31</td>\n",
       "      <td>26.80</td>\n",
       "      <td>12.83</td>\n",
       "      <td>6.81</td>\n",
       "      <td>71.73</td>\n",
       "      <td>4.87</td>\n",
       "      <td>188.69</td>\n",
       "      <td>10.49</td>\n",
       "      <td>15.75</td>\n",
       "      <td>16.51</td>\n",
       "      <td>8.83</td>\n",
       "      <td>6.50</td>\n",
       "      <td>53.98</td>\n",
       "      <td>7.71</td>\n",
       "      <td>20.22</td>\n",
       "      <td>13.26</td>\n",
       "      <td>6.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.33</td>\n",
       "      <td>13.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.95</td>\n",
       "      <td>17.89</td>\n",
       "      <td>12.26</td>\n",
       "      <td>3.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.20</td>\n",
       "      <td>24.93</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-16</th>\n",
       "      <td>4.32</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.83</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.39</td>\n",
       "      <td>9.93</td>\n",
       "      <td>14.39</td>\n",
       "      <td>41.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>26.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>6.52</td>\n",
       "      <td>69.15</td>\n",
       "      <td>4.76</td>\n",
       "      <td>177.41</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.03</td>\n",
       "      <td>8.70</td>\n",
       "      <td>5.91</td>\n",
       "      <td>50.77</td>\n",
       "      <td>7.64</td>\n",
       "      <td>19.01</td>\n",
       "      <td>12.89</td>\n",
       "      <td>6.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.59</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.85</td>\n",
       "      <td>17.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.98</td>\n",
       "      <td>7.73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>23.59</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-17</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.74</td>\n",
       "      <td>10.51</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.78</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.33</td>\n",
       "      <td>45.19</td>\n",
       "      <td>8.61</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.90</td>\n",
       "      <td>5.03</td>\n",
       "      <td>180.44</td>\n",
       "      <td>10.60</td>\n",
       "      <td>16.43</td>\n",
       "      <td>16.73</td>\n",
       "      <td>9.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>52.66</td>\n",
       "      <td>8.15</td>\n",
       "      <td>19.87</td>\n",
       "      <td>13.55</td>\n",
       "      <td>6.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.38</td>\n",
       "      <td>13.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.82</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.68</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.32</td>\n",
       "      <td>24.72</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-18</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.52</td>\n",
       "      <td>10.12</td>\n",
       "      <td>15.21</td>\n",
       "      <td>45.46</td>\n",
       "      <td>8.47</td>\n",
       "      <td>24.66</td>\n",
       "      <td>13.26</td>\n",
       "      <td>6.77</td>\n",
       "      <td>63.81</td>\n",
       "      <td>4.93</td>\n",
       "      <td>177.38</td>\n",
       "      <td>10.48</td>\n",
       "      <td>16.82</td>\n",
       "      <td>16.49</td>\n",
       "      <td>9.08</td>\n",
       "      <td>6.19</td>\n",
       "      <td>51.61</td>\n",
       "      <td>8.07</td>\n",
       "      <td>19.14</td>\n",
       "      <td>13.32</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.88</td>\n",
       "      <td>13.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.45</td>\n",
       "      <td>4.31</td>\n",
       "      <td>20.50</td>\n",
       "      <td>18.45</td>\n",
       "      <td>12.77</td>\n",
       "      <td>3.05</td>\n",
       "      <td>8.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.01</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-19</th>\n",
       "      <td>4.78</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.81</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.67</td>\n",
       "      <td>15.46</td>\n",
       "      <td>46.58</td>\n",
       "      <td>8.62</td>\n",
       "      <td>25.20</td>\n",
       "      <td>13.76</td>\n",
       "      <td>6.79</td>\n",
       "      <td>64.29</td>\n",
       "      <td>5.01</td>\n",
       "      <td>180.70</td>\n",
       "      <td>10.33</td>\n",
       "      <td>17.15</td>\n",
       "      <td>16.19</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>52.84</td>\n",
       "      <td>8.38</td>\n",
       "      <td>19.98</td>\n",
       "      <td>13.20</td>\n",
       "      <td>6.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.10</td>\n",
       "      <td>13.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.51</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.22</td>\n",
       "      <td>19.00</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>24.41</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-20</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.01</td>\n",
       "      <td>13.99</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.94</td>\n",
       "      <td>15.52</td>\n",
       "      <td>45.62</td>\n",
       "      <td>8.80</td>\n",
       "      <td>26.68</td>\n",
       "      <td>14.09</td>\n",
       "      <td>6.84</td>\n",
       "      <td>65.74</td>\n",
       "      <td>5.10</td>\n",
       "      <td>185.97</td>\n",
       "      <td>10.41</td>\n",
       "      <td>17.79</td>\n",
       "      <td>16.48</td>\n",
       "      <td>9.51</td>\n",
       "      <td>6.26</td>\n",
       "      <td>54.34</td>\n",
       "      <td>8.60</td>\n",
       "      <td>20.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.48</td>\n",
       "      <td>14.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.72</td>\n",
       "      <td>39.10</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.84</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.14</td>\n",
       "      <td>8.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-30</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.43</td>\n",
       "      <td>15.48</td>\n",
       "      <td>46.06</td>\n",
       "      <td>8.63</td>\n",
       "      <td>26.19</td>\n",
       "      <td>13.67</td>\n",
       "      <td>7.14</td>\n",
       "      <td>64.87</td>\n",
       "      <td>5.04</td>\n",
       "      <td>183.80</td>\n",
       "      <td>10.37</td>\n",
       "      <td>17.38</td>\n",
       "      <td>16.23</td>\n",
       "      <td>9.24</td>\n",
       "      <td>6.29</td>\n",
       "      <td>53.30</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.33</td>\n",
       "      <td>13.49</td>\n",
       "      <td>6.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.68</td>\n",
       "      <td>13.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "      <td>38.60</td>\n",
       "      <td>4.27</td>\n",
       "      <td>21.11</td>\n",
       "      <td>18.90</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.13</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.49</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>4.87</td>\n",
       "      <td>7.76</td>\n",
       "      <td>10.69</td>\n",
       "      <td>14.21</td>\n",
       "      <td>12.65</td>\n",
       "      <td>10.50</td>\n",
       "      <td>15.09</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.22</td>\n",
       "      <td>65.93</td>\n",
       "      <td>5.08</td>\n",
       "      <td>186.41</td>\n",
       "      <td>10.39</td>\n",
       "      <td>17.37</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.21</td>\n",
       "      <td>6.38</td>\n",
       "      <td>54.97</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.44</td>\n",
       "      <td>13.48</td>\n",
       "      <td>6.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.85</td>\n",
       "      <td>13.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.34</td>\n",
       "      <td>4.30</td>\n",
       "      <td>21.01</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.21</td>\n",
       "      <td>24.73</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.80</td>\n",
       "      <td>12.47</td>\n",
       "      <td>10.31</td>\n",
       "      <td>14.93</td>\n",
       "      <td>44.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>25.86</td>\n",
       "      <td>13.78</td>\n",
       "      <td>7.16</td>\n",
       "      <td>66.52</td>\n",
       "      <td>5.05</td>\n",
       "      <td>186.15</td>\n",
       "      <td>10.64</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.68</td>\n",
       "      <td>9.10</td>\n",
       "      <td>6.23</td>\n",
       "      <td>54.98</td>\n",
       "      <td>8.10</td>\n",
       "      <td>20.60</td>\n",
       "      <td>13.12</td>\n",
       "      <td>6.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.57</td>\n",
       "      <td>13.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.41</td>\n",
       "      <td>4.28</td>\n",
       "      <td>20.65</td>\n",
       "      <td>18.34</td>\n",
       "      <td>12.40</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.18</td>\n",
       "      <td>24.71</td>\n",
       "      <td>4.37</td>\n",
       "      <td>5.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-02</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.86</td>\n",
       "      <td>10.80</td>\n",
       "      <td>14.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.22</td>\n",
       "      <td>45.57</td>\n",
       "      <td>8.64</td>\n",
       "      <td>26.24</td>\n",
       "      <td>14.05</td>\n",
       "      <td>7.19</td>\n",
       "      <td>66.67</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.43</td>\n",
       "      <td>10.77</td>\n",
       "      <td>16.90</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.19</td>\n",
       "      <td>6.33</td>\n",
       "      <td>55.72</td>\n",
       "      <td>8.53</td>\n",
       "      <td>20.92</td>\n",
       "      <td>13.31</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.24</td>\n",
       "      <td>14.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.64</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.41</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.21</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-03</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.81</td>\n",
       "      <td>10.90</td>\n",
       "      <td>13.94</td>\n",
       "      <td>12.98</td>\n",
       "      <td>10.68</td>\n",
       "      <td>15.40</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.76</td>\n",
       "      <td>26.39</td>\n",
       "      <td>14.42</td>\n",
       "      <td>7.37</td>\n",
       "      <td>66.89</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.48</td>\n",
       "      <td>11.00</td>\n",
       "      <td>16.72</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.17</td>\n",
       "      <td>6.40</td>\n",
       "      <td>57.00</td>\n",
       "      <td>8.47</td>\n",
       "      <td>20.90</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>40.15</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.86</td>\n",
       "      <td>19.30</td>\n",
       "      <td>12.54</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.89</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-06</th>\n",
       "      <td>4.82</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.89</td>\n",
       "      <td>12.86</td>\n",
       "      <td>10.45</td>\n",
       "      <td>15.25</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.79</td>\n",
       "      <td>27.05</td>\n",
       "      <td>14.59</td>\n",
       "      <td>7.36</td>\n",
       "      <td>68.41</td>\n",
       "      <td>5.27</td>\n",
       "      <td>188.54</td>\n",
       "      <td>11.00</td>\n",
       "      <td>17.07</td>\n",
       "      <td>17.93</td>\n",
       "      <td>9.27</td>\n",
       "      <td>6.50</td>\n",
       "      <td>58.59</td>\n",
       "      <td>8.45</td>\n",
       "      <td>21.56</td>\n",
       "      <td>13.68</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>39.62</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.36</td>\n",
       "      <td>18.92</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.23</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-07</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.52</td>\n",
       "      <td>13.54</td>\n",
       "      <td>12.73</td>\n",
       "      <td>10.13</td>\n",
       "      <td>15.22</td>\n",
       "      <td>44.55</td>\n",
       "      <td>8.60</td>\n",
       "      <td>26.53</td>\n",
       "      <td>14.26</td>\n",
       "      <td>7.17</td>\n",
       "      <td>68.22</td>\n",
       "      <td>5.09</td>\n",
       "      <td>185.86</td>\n",
       "      <td>10.75</td>\n",
       "      <td>16.52</td>\n",
       "      <td>17.46</td>\n",
       "      <td>9.07</td>\n",
       "      <td>6.37</td>\n",
       "      <td>57.61</td>\n",
       "      <td>8.21</td>\n",
       "      <td>21.50</td>\n",
       "      <td>14.74</td>\n",
       "      <td>6.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.72</td>\n",
       "      <td>38.91</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.79</td>\n",
       "      <td>18.50</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.01</td>\n",
       "      <td>8.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.09</td>\n",
       "      <td>25.42</td>\n",
       "      <td>4.35</td>\n",
       "      <td>5.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-08</th>\n",
       "      <td>4.90</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.42</td>\n",
       "      <td>15.59</td>\n",
       "      <td>48.51</td>\n",
       "      <td>8.79</td>\n",
       "      <td>26.59</td>\n",
       "      <td>14.81</td>\n",
       "      <td>7.38</td>\n",
       "      <td>68.80</td>\n",
       "      <td>5.20</td>\n",
       "      <td>188.29</td>\n",
       "      <td>11.04</td>\n",
       "      <td>17.15</td>\n",
       "      <td>17.90</td>\n",
       "      <td>9.28</td>\n",
       "      <td>6.76</td>\n",
       "      <td>59.17</td>\n",
       "      <td>8.67</td>\n",
       "      <td>21.80</td>\n",
       "      <td>15.24</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.63</td>\n",
       "      <td>14.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.75</td>\n",
       "      <td>19.24</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.87</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-09</th>\n",
       "      <td>4.88</td>\n",
       "      <td>7.69</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.49</td>\n",
       "      <td>47.57</td>\n",
       "      <td>8.87</td>\n",
       "      <td>26.93</td>\n",
       "      <td>14.91</td>\n",
       "      <td>7.55</td>\n",
       "      <td>68.77</td>\n",
       "      <td>5.26</td>\n",
       "      <td>190.75</td>\n",
       "      <td>11.11</td>\n",
       "      <td>17.40</td>\n",
       "      <td>17.98</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.67</td>\n",
       "      <td>59.40</td>\n",
       "      <td>8.57</td>\n",
       "      <td>21.32</td>\n",
       "      <td>15.13</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.53</td>\n",
       "      <td>14.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.88</td>\n",
       "      <td>4.42</td>\n",
       "      <td>21.26</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.29</td>\n",
       "      <td>25.77</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-10</th>\n",
       "      <td>5.08</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.97</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.89</td>\n",
       "      <td>10.91</td>\n",
       "      <td>15.45</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>26.63</td>\n",
       "      <td>14.66</td>\n",
       "      <td>7.68</td>\n",
       "      <td>68.61</td>\n",
       "      <td>5.32</td>\n",
       "      <td>190.51</td>\n",
       "      <td>11.06</td>\n",
       "      <td>17.51</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.68</td>\n",
       "      <td>59.00</td>\n",
       "      <td>8.65</td>\n",
       "      <td>21.76</td>\n",
       "      <td>15.29</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.45</td>\n",
       "      <td>14.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.72</td>\n",
       "      <td>40.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.61</td>\n",
       "      <td>18.93</td>\n",
       "      <td>13.03</td>\n",
       "      <td>3.21</td>\n",
       "      <td>8.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.31</td>\n",
       "      <td>25.91</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-13</th>\n",
       "      <td>5.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.84</td>\n",
       "      <td>12.69</td>\n",
       "      <td>10.57</td>\n",
       "      <td>15.76</td>\n",
       "      <td>47.65</td>\n",
       "      <td>8.84</td>\n",
       "      <td>26.99</td>\n",
       "      <td>14.58</td>\n",
       "      <td>7.82</td>\n",
       "      <td>68.67</td>\n",
       "      <td>5.37</td>\n",
       "      <td>193.42</td>\n",
       "      <td>11.21</td>\n",
       "      <td>17.25</td>\n",
       "      <td>18.36</td>\n",
       "      <td>9.28</td>\n",
       "      <td>6.64</td>\n",
       "      <td>59.85</td>\n",
       "      <td>8.55</td>\n",
       "      <td>22.11</td>\n",
       "      <td>15.57</td>\n",
       "      <td>6.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.71</td>\n",
       "      <td>40.28</td>\n",
       "      <td>4.37</td>\n",
       "      <td>21.41</td>\n",
       "      <td>18.64</td>\n",
       "      <td>13.41</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.26</td>\n",
       "      <td>26.08</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-14</th>\n",
       "      <td>5.01</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.66</td>\n",
       "      <td>10.62</td>\n",
       "      <td>15.52</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.89</td>\n",
       "      <td>26.87</td>\n",
       "      <td>14.31</td>\n",
       "      <td>7.89</td>\n",
       "      <td>69.29</td>\n",
       "      <td>5.38</td>\n",
       "      <td>193.82</td>\n",
       "      <td>11.27</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.06</td>\n",
       "      <td>9.24</td>\n",
       "      <td>6.78</td>\n",
       "      <td>60.71</td>\n",
       "      <td>8.49</td>\n",
       "      <td>22.09</td>\n",
       "      <td>15.42</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>39.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.83</td>\n",
       "      <td>18.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.24</td>\n",
       "      <td>26.03</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>2.09</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.40</td>\n",
       "      <td>15.52</td>\n",
       "      <td>33.70</td>\n",
       "      <td>16.68</td>\n",
       "      <td>15.88</td>\n",
       "      <td>30.84</td>\n",
       "      <td>40.93</td>\n",
       "      <td>34.77</td>\n",
       "      <td>88.67</td>\n",
       "      <td>19.33</td>\n",
       "      <td>294.00</td>\n",
       "      <td>56.43</td>\n",
       "      <td>1898.00</td>\n",
       "      <td>32.44</td>\n",
       "      <td>31.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>24.33</td>\n",
       "      <td>62.51</td>\n",
       "      <td>286.93</td>\n",
       "      <td>9.51</td>\n",
       "      <td>36.19</td>\n",
       "      <td>48.17</td>\n",
       "      <td>23.39</td>\n",
       "      <td>6.28</td>\n",
       "      <td>53.06</td>\n",
       "      <td>25.88</td>\n",
       "      <td>31.26</td>\n",
       "      <td>17.88</td>\n",
       "      <td>14.72</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.12</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.29</td>\n",
       "      <td>29.44</td>\n",
       "      <td>35.35</td>\n",
       "      <td>5.01</td>\n",
       "      <td>13.13</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.44</td>\n",
       "      <td>192.41</td>\n",
       "      <td>9.15</td>\n",
       "      <td>13.78</td>\n",
       "      <td>41.81</td>\n",
       "      <td>89.55</td>\n",
       "      <td>79.16</td>\n",
       "      <td>92.10</td>\n",
       "      <td>80.15</td>\n",
       "      <td>114.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>2.07</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.56</td>\n",
       "      <td>33.28</td>\n",
       "      <td>16.61</td>\n",
       "      <td>15.50</td>\n",
       "      <td>30.59</td>\n",
       "      <td>40.61</td>\n",
       "      <td>34.23</td>\n",
       "      <td>87.80</td>\n",
       "      <td>19.29</td>\n",
       "      <td>291.09</td>\n",
       "      <td>56.78</td>\n",
       "      <td>1878.82</td>\n",
       "      <td>32.70</td>\n",
       "      <td>31.42</td>\n",
       "      <td>19.29</td>\n",
       "      <td>24.57</td>\n",
       "      <td>64.60</td>\n",
       "      <td>285.30</td>\n",
       "      <td>9.45</td>\n",
       "      <td>35.95</td>\n",
       "      <td>49.91</td>\n",
       "      <td>23.30</td>\n",
       "      <td>6.29</td>\n",
       "      <td>53.41</td>\n",
       "      <td>25.71</td>\n",
       "      <td>31.88</td>\n",
       "      <td>16.93</td>\n",
       "      <td>14.68</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.07</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.17</td>\n",
       "      <td>29.02</td>\n",
       "      <td>33.96</td>\n",
       "      <td>5.04</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.48</td>\n",
       "      <td>192.25</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.60</td>\n",
       "      <td>41.69</td>\n",
       "      <td>88.52</td>\n",
       "      <td>78.57</td>\n",
       "      <td>91.62</td>\n",
       "      <td>78.04</td>\n",
       "      <td>114.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.29</td>\n",
       "      <td>19.25</td>\n",
       "      <td>15.58</td>\n",
       "      <td>33.79</td>\n",
       "      <td>16.95</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.37</td>\n",
       "      <td>40.08</td>\n",
       "      <td>33.67</td>\n",
       "      <td>88.45</td>\n",
       "      <td>19.14</td>\n",
       "      <td>288.36</td>\n",
       "      <td>55.56</td>\n",
       "      <td>1870.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>30.99</td>\n",
       "      <td>20.07</td>\n",
       "      <td>25.40</td>\n",
       "      <td>64.96</td>\n",
       "      <td>284.09</td>\n",
       "      <td>9.41</td>\n",
       "      <td>36.13</td>\n",
       "      <td>47.88</td>\n",
       "      <td>23.28</td>\n",
       "      <td>6.21</td>\n",
       "      <td>52.80</td>\n",
       "      <td>25.60</td>\n",
       "      <td>30.52</td>\n",
       "      <td>16.82</td>\n",
       "      <td>14.68</td>\n",
       "      <td>2.82</td>\n",
       "      <td>42.89</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.47</td>\n",
       "      <td>29.50</td>\n",
       "      <td>34.20</td>\n",
       "      <td>5.07</td>\n",
       "      <td>13.11</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.47</td>\n",
       "      <td>190.40</td>\n",
       "      <td>8.90</td>\n",
       "      <td>14.41</td>\n",
       "      <td>41.51</td>\n",
       "      <td>87.35</td>\n",
       "      <td>78.25</td>\n",
       "      <td>93.26</td>\n",
       "      <td>77.72</td>\n",
       "      <td>112.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>2.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>19.52</td>\n",
       "      <td>15.75</td>\n",
       "      <td>35.05</td>\n",
       "      <td>17.30</td>\n",
       "      <td>15.47</td>\n",
       "      <td>30.14</td>\n",
       "      <td>40.36</td>\n",
       "      <td>34.66</td>\n",
       "      <td>88.57</td>\n",
       "      <td>19.20</td>\n",
       "      <td>300.99</td>\n",
       "      <td>52.88</td>\n",
       "      <td>1924.00</td>\n",
       "      <td>33.64</td>\n",
       "      <td>31.92</td>\n",
       "      <td>20.09</td>\n",
       "      <td>25.87</td>\n",
       "      <td>64.60</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.48</td>\n",
       "      <td>35.74</td>\n",
       "      <td>45.97</td>\n",
       "      <td>23.98</td>\n",
       "      <td>6.10</td>\n",
       "      <td>51.20</td>\n",
       "      <td>26.64</td>\n",
       "      <td>30.34</td>\n",
       "      <td>17.11</td>\n",
       "      <td>14.79</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.97</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.46</td>\n",
       "      <td>5.14</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.34</td>\n",
       "      <td>195.50</td>\n",
       "      <td>8.80</td>\n",
       "      <td>14.20</td>\n",
       "      <td>41.70</td>\n",
       "      <td>89.65</td>\n",
       "      <td>80.56</td>\n",
       "      <td>93.74</td>\n",
       "      <td>74.74</td>\n",
       "      <td>115.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.23</td>\n",
       "      <td>19.30</td>\n",
       "      <td>15.85</td>\n",
       "      <td>34.50</td>\n",
       "      <td>17.31</td>\n",
       "      <td>15.30</td>\n",
       "      <td>30.09</td>\n",
       "      <td>40.90</td>\n",
       "      <td>34.34</td>\n",
       "      <td>88.11</td>\n",
       "      <td>19.21</td>\n",
       "      <td>298.30</td>\n",
       "      <td>52.82</td>\n",
       "      <td>1880.89</td>\n",
       "      <td>34.50</td>\n",
       "      <td>31.60</td>\n",
       "      <td>20.37</td>\n",
       "      <td>26.21</td>\n",
       "      <td>62.71</td>\n",
       "      <td>292.58</td>\n",
       "      <td>9.39</td>\n",
       "      <td>34.55</td>\n",
       "      <td>45.88</td>\n",
       "      <td>23.91</td>\n",
       "      <td>6.00</td>\n",
       "      <td>51.65</td>\n",
       "      <td>26.80</td>\n",
       "      <td>31.11</td>\n",
       "      <td>17.11</td>\n",
       "      <td>14.73</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.82</td>\n",
       "      <td>30.45</td>\n",
       "      <td>32.25</td>\n",
       "      <td>5.15</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.76</td>\n",
       "      <td>5.36</td>\n",
       "      <td>186.80</td>\n",
       "      <td>8.65</td>\n",
       "      <td>13.70</td>\n",
       "      <td>41.17</td>\n",
       "      <td>87.75</td>\n",
       "      <td>78.61</td>\n",
       "      <td>90.58</td>\n",
       "      <td>74.86</td>\n",
       "      <td>112.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.24</td>\n",
       "      <td>15.61</td>\n",
       "      <td>34.32</td>\n",
       "      <td>17.02</td>\n",
       "      <td>15.26</td>\n",
       "      <td>30.16</td>\n",
       "      <td>40.21</td>\n",
       "      <td>33.90</td>\n",
       "      <td>86.95</td>\n",
       "      <td>19.15</td>\n",
       "      <td>296.11</td>\n",
       "      <td>52.21</td>\n",
       "      <td>1875.00</td>\n",
       "      <td>34.37</td>\n",
       "      <td>31.17</td>\n",
       "      <td>20.15</td>\n",
       "      <td>25.63</td>\n",
       "      <td>63.25</td>\n",
       "      <td>288.53</td>\n",
       "      <td>9.32</td>\n",
       "      <td>33.90</td>\n",
       "      <td>45.22</td>\n",
       "      <td>23.82</td>\n",
       "      <td>6.02</td>\n",
       "      <td>50.95</td>\n",
       "      <td>26.89</td>\n",
       "      <td>30.66</td>\n",
       "      <td>17.03</td>\n",
       "      <td>14.62</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.75</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.65</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.92</td>\n",
       "      <td>3.79</td>\n",
       "      <td>5.42</td>\n",
       "      <td>180.31</td>\n",
       "      <td>8.52</td>\n",
       "      <td>13.33</td>\n",
       "      <td>41.55</td>\n",
       "      <td>86.25</td>\n",
       "      <td>78.00</td>\n",
       "      <td>89.87</td>\n",
       "      <td>74.51</td>\n",
       "      <td>113.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05</th>\n",
       "      <td>2.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.27</td>\n",
       "      <td>15.45</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.22</td>\n",
       "      <td>15.21</td>\n",
       "      <td>30.08</td>\n",
       "      <td>36.19</td>\n",
       "      <td>33.73</td>\n",
       "      <td>88.65</td>\n",
       "      <td>19.12</td>\n",
       "      <td>294.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>1835.00</td>\n",
       "      <td>33.73</td>\n",
       "      <td>31.01</td>\n",
       "      <td>19.79</td>\n",
       "      <td>25.58</td>\n",
       "      <td>62.27</td>\n",
       "      <td>282.78</td>\n",
       "      <td>9.40</td>\n",
       "      <td>33.37</td>\n",
       "      <td>45.77</td>\n",
       "      <td>23.82</td>\n",
       "      <td>6.07</td>\n",
       "      <td>50.49</td>\n",
       "      <td>27.31</td>\n",
       "      <td>32.56</td>\n",
       "      <td>17.08</td>\n",
       "      <td>14.84</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.80</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.90</td>\n",
       "      <td>29.86</td>\n",
       "      <td>31.19</td>\n",
       "      <td>5.17</td>\n",
       "      <td>13.05</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.56</td>\n",
       "      <td>180.10</td>\n",
       "      <td>8.59</td>\n",
       "      <td>13.24</td>\n",
       "      <td>41.74</td>\n",
       "      <td>83.80</td>\n",
       "      <td>76.25</td>\n",
       "      <td>88.52</td>\n",
       "      <td>73.20</td>\n",
       "      <td>111.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.48</td>\n",
       "      <td>15.73</td>\n",
       "      <td>33.62</td>\n",
       "      <td>17.63</td>\n",
       "      <td>15.42</td>\n",
       "      <td>30.85</td>\n",
       "      <td>35.42</td>\n",
       "      <td>33.88</td>\n",
       "      <td>91.50</td>\n",
       "      <td>19.58</td>\n",
       "      <td>294.02</td>\n",
       "      <td>56.87</td>\n",
       "      <td>1845.00</td>\n",
       "      <td>33.66</td>\n",
       "      <td>31.00</td>\n",
       "      <td>19.71</td>\n",
       "      <td>25.69</td>\n",
       "      <td>61.53</td>\n",
       "      <td>286.02</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.63</td>\n",
       "      <td>47.14</td>\n",
       "      <td>23.75</td>\n",
       "      <td>6.12</td>\n",
       "      <td>53.16</td>\n",
       "      <td>27.55</td>\n",
       "      <td>32.88</td>\n",
       "      <td>17.06</td>\n",
       "      <td>14.92</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.90</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.08</td>\n",
       "      <td>30.34</td>\n",
       "      <td>31.84</td>\n",
       "      <td>5.24</td>\n",
       "      <td>13.18</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.61</td>\n",
       "      <td>182.72</td>\n",
       "      <td>8.84</td>\n",
       "      <td>13.39</td>\n",
       "      <td>42.56</td>\n",
       "      <td>84.21</td>\n",
       "      <td>76.32</td>\n",
       "      <td>88.87</td>\n",
       "      <td>74.99</td>\n",
       "      <td>112.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.60</td>\n",
       "      <td>33.38</td>\n",
       "      <td>17.55</td>\n",
       "      <td>15.40</td>\n",
       "      <td>30.79</td>\n",
       "      <td>35.55</td>\n",
       "      <td>33.43</td>\n",
       "      <td>90.52</td>\n",
       "      <td>19.76</td>\n",
       "      <td>291.48</td>\n",
       "      <td>56.69</td>\n",
       "      <td>1818.01</td>\n",
       "      <td>33.59</td>\n",
       "      <td>30.41</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.80</td>\n",
       "      <td>61.67</td>\n",
       "      <td>278.12</td>\n",
       "      <td>9.47</td>\n",
       "      <td>33.22</td>\n",
       "      <td>47.24</td>\n",
       "      <td>23.57</td>\n",
       "      <td>6.13</td>\n",
       "      <td>53.46</td>\n",
       "      <td>26.94</td>\n",
       "      <td>32.61</td>\n",
       "      <td>17.09</td>\n",
       "      <td>14.88</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.60</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.98</td>\n",
       "      <td>30.25</td>\n",
       "      <td>32.09</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.58</td>\n",
       "      <td>183.95</td>\n",
       "      <td>8.94</td>\n",
       "      <td>13.44</td>\n",
       "      <td>42.73</td>\n",
       "      <td>84.24</td>\n",
       "      <td>75.65</td>\n",
       "      <td>89.00</td>\n",
       "      <td>75.36</td>\n",
       "      <td>116.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.31</td>\n",
       "      <td>15.75</td>\n",
       "      <td>33.30</td>\n",
       "      <td>17.58</td>\n",
       "      <td>15.35</td>\n",
       "      <td>30.29</td>\n",
       "      <td>33.96</td>\n",
       "      <td>33.73</td>\n",
       "      <td>92.01</td>\n",
       "      <td>19.70</td>\n",
       "      <td>293.75</td>\n",
       "      <td>56.50</td>\n",
       "      <td>1815.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>30.20</td>\n",
       "      <td>19.33</td>\n",
       "      <td>25.88</td>\n",
       "      <td>60.41</td>\n",
       "      <td>285.59</td>\n",
       "      <td>9.44</td>\n",
       "      <td>33.27</td>\n",
       "      <td>47.76</td>\n",
       "      <td>23.65</td>\n",
       "      <td>6.07</td>\n",
       "      <td>53.39</td>\n",
       "      <td>26.82</td>\n",
       "      <td>32.30</td>\n",
       "      <td>17.01</td>\n",
       "      <td>14.84</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.95</td>\n",
       "      <td>30.76</td>\n",
       "      <td>30.98</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.53</td>\n",
       "      <td>186.00</td>\n",
       "      <td>9.06</td>\n",
       "      <td>13.26</td>\n",
       "      <td>42.18</td>\n",
       "      <td>82.74</td>\n",
       "      <td>75.80</td>\n",
       "      <td>87.70</td>\n",
       "      <td>73.00</td>\n",
       "      <td>115.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.45</td>\n",
       "      <td>19.78</td>\n",
       "      <td>16.26</td>\n",
       "      <td>34.50</td>\n",
       "      <td>18.47</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.68</td>\n",
       "      <td>35.00</td>\n",
       "      <td>34.78</td>\n",
       "      <td>95.61</td>\n",
       "      <td>20.06</td>\n",
       "      <td>298.11</td>\n",
       "      <td>54.56</td>\n",
       "      <td>1844.79</td>\n",
       "      <td>35.30</td>\n",
       "      <td>31.37</td>\n",
       "      <td>19.54</td>\n",
       "      <td>26.50</td>\n",
       "      <td>60.70</td>\n",
       "      <td>291.21</td>\n",
       "      <td>9.54</td>\n",
       "      <td>33.70</td>\n",
       "      <td>48.03</td>\n",
       "      <td>23.91</td>\n",
       "      <td>6.08</td>\n",
       "      <td>53.18</td>\n",
       "      <td>27.49</td>\n",
       "      <td>32.73</td>\n",
       "      <td>17.38</td>\n",
       "      <td>15.07</td>\n",
       "      <td>2.84</td>\n",
       "      <td>44.69</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.47</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.31</td>\n",
       "      <td>5.36</td>\n",
       "      <td>13.28</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.59</td>\n",
       "      <td>191.09</td>\n",
       "      <td>9.19</td>\n",
       "      <td>13.29</td>\n",
       "      <td>42.70</td>\n",
       "      <td>84.83</td>\n",
       "      <td>79.40</td>\n",
       "      <td>88.92</td>\n",
       "      <td>76.98</td>\n",
       "      <td>114.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.43</td>\n",
       "      <td>19.83</td>\n",
       "      <td>16.30</td>\n",
       "      <td>35.35</td>\n",
       "      <td>18.09</td>\n",
       "      <td>15.65</td>\n",
       "      <td>31.47</td>\n",
       "      <td>34.44</td>\n",
       "      <td>35.52</td>\n",
       "      <td>93.00</td>\n",
       "      <td>20.03</td>\n",
       "      <td>302.00</td>\n",
       "      <td>54.99</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>31.96</td>\n",
       "      <td>19.58</td>\n",
       "      <td>26.48</td>\n",
       "      <td>60.12</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>33.74</td>\n",
       "      <td>49.00</td>\n",
       "      <td>23.79</td>\n",
       "      <td>6.02</td>\n",
       "      <td>53.27</td>\n",
       "      <td>27.32</td>\n",
       "      <td>32.45</td>\n",
       "      <td>17.59</td>\n",
       "      <td>14.97</td>\n",
       "      <td>2.85</td>\n",
       "      <td>45.06</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.52</td>\n",
       "      <td>31.46</td>\n",
       "      <td>32.00</td>\n",
       "      <td>5.32</td>\n",
       "      <td>13.24</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.55</td>\n",
       "      <td>192.47</td>\n",
       "      <td>9.29</td>\n",
       "      <td>13.26</td>\n",
       "      <td>42.95</td>\n",
       "      <td>76.35</td>\n",
       "      <td>81.01</td>\n",
       "      <td>89.10</td>\n",
       "      <td>76.94</td>\n",
       "      <td>114.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>2.02</td>\n",
       "      <td>4.38</td>\n",
       "      <td>19.58</td>\n",
       "      <td>16.15</td>\n",
       "      <td>34.86</td>\n",
       "      <td>18.14</td>\n",
       "      <td>15.44</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.76</td>\n",
       "      <td>35.68</td>\n",
       "      <td>91.36</td>\n",
       "      <td>19.84</td>\n",
       "      <td>300.29</td>\n",
       "      <td>53.73</td>\n",
       "      <td>1869.00</td>\n",
       "      <td>36.30</td>\n",
       "      <td>31.59</td>\n",
       "      <td>19.71</td>\n",
       "      <td>26.49</td>\n",
       "      <td>59.67</td>\n",
       "      <td>292.30</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.60</td>\n",
       "      <td>49.23</td>\n",
       "      <td>23.70</td>\n",
       "      <td>5.94</td>\n",
       "      <td>52.55</td>\n",
       "      <td>26.81</td>\n",
       "      <td>32.35</td>\n",
       "      <td>17.38</td>\n",
       "      <td>14.81</td>\n",
       "      <td>2.85</td>\n",
       "      <td>44.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.26</td>\n",
       "      <td>31.63</td>\n",
       "      <td>31.74</td>\n",
       "      <td>5.26</td>\n",
       "      <td>13.11</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.52</td>\n",
       "      <td>191.55</td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.12</td>\n",
       "      <td>39.00</td>\n",
       "      <td>75.32</td>\n",
       "      <td>81.90</td>\n",
       "      <td>88.34</td>\n",
       "      <td>76.26</td>\n",
       "      <td>112.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>19.53</td>\n",
       "      <td>16.20</td>\n",
       "      <td>36.01</td>\n",
       "      <td>18.85</td>\n",
       "      <td>15.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>33.04</td>\n",
       "      <td>35.49</td>\n",
       "      <td>91.50</td>\n",
       "      <td>19.46</td>\n",
       "      <td>298.56</td>\n",
       "      <td>51.30</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>35.71</td>\n",
       "      <td>32.23</td>\n",
       "      <td>19.45</td>\n",
       "      <td>26.88</td>\n",
       "      <td>58.54</td>\n",
       "      <td>296.00</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.69</td>\n",
       "      <td>47.20</td>\n",
       "      <td>23.72</td>\n",
       "      <td>5.87</td>\n",
       "      <td>48.66</td>\n",
       "      <td>26.85</td>\n",
       "      <td>32.39</td>\n",
       "      <td>17.69</td>\n",
       "      <td>14.87</td>\n",
       "      <td>2.87</td>\n",
       "      <td>45.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.31</td>\n",
       "      <td>31.74</td>\n",
       "      <td>30.57</td>\n",
       "      <td>5.37</td>\n",
       "      <td>13.08</td>\n",
       "      <td>3.78</td>\n",
       "      <td>5.54</td>\n",
       "      <td>191.35</td>\n",
       "      <td>8.95</td>\n",
       "      <td>12.93</td>\n",
       "      <td>38.80</td>\n",
       "      <td>76.81</td>\n",
       "      <td>81.60</td>\n",
       "      <td>86.74</td>\n",
       "      <td>72.96</td>\n",
       "      <td>108.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.30</td>\n",
       "      <td>18.42</td>\n",
       "      <td>15.60</td>\n",
       "      <td>34.95</td>\n",
       "      <td>18.05</td>\n",
       "      <td>15.02</td>\n",
       "      <td>28.80</td>\n",
       "      <td>32.17</td>\n",
       "      <td>34.83</td>\n",
       "      <td>90.38</td>\n",
       "      <td>19.03</td>\n",
       "      <td>293.20</td>\n",
       "      <td>49.52</td>\n",
       "      <td>1859.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>31.19</td>\n",
       "      <td>19.53</td>\n",
       "      <td>26.06</td>\n",
       "      <td>55.60</td>\n",
       "      <td>289.50</td>\n",
       "      <td>9.05</td>\n",
       "      <td>32.88</td>\n",
       "      <td>46.88</td>\n",
       "      <td>23.46</td>\n",
       "      <td>5.68</td>\n",
       "      <td>48.30</td>\n",
       "      <td>24.97</td>\n",
       "      <td>30.96</td>\n",
       "      <td>17.22</td>\n",
       "      <td>14.12</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.88</td>\n",
       "      <td>31.06</td>\n",
       "      <td>28.88</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.41</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.37</td>\n",
       "      <td>188.51</td>\n",
       "      <td>8.68</td>\n",
       "      <td>12.56</td>\n",
       "      <td>37.45</td>\n",
       "      <td>73.74</td>\n",
       "      <td>80.94</td>\n",
       "      <td>83.70</td>\n",
       "      <td>71.47</td>\n",
       "      <td>106.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.18</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.97</td>\n",
       "      <td>35.09</td>\n",
       "      <td>18.44</td>\n",
       "      <td>15.01</td>\n",
       "      <td>28.34</td>\n",
       "      <td>32.19</td>\n",
       "      <td>34.69</td>\n",
       "      <td>91.36</td>\n",
       "      <td>18.82</td>\n",
       "      <td>289.50</td>\n",
       "      <td>49.87</td>\n",
       "      <td>1871.64</td>\n",
       "      <td>33.69</td>\n",
       "      <td>30.45</td>\n",
       "      <td>18.03</td>\n",
       "      <td>26.16</td>\n",
       "      <td>54.30</td>\n",
       "      <td>293.75</td>\n",
       "      <td>9.06</td>\n",
       "      <td>32.90</td>\n",
       "      <td>46.01</td>\n",
       "      <td>23.48</td>\n",
       "      <td>5.64</td>\n",
       "      <td>48.12</td>\n",
       "      <td>24.96</td>\n",
       "      <td>31.50</td>\n",
       "      <td>17.34</td>\n",
       "      <td>14.11</td>\n",
       "      <td>2.87</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.42</td>\n",
       "      <td>30.86</td>\n",
       "      <td>29.98</td>\n",
       "      <td>5.24</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.35</td>\n",
       "      <td>188.45</td>\n",
       "      <td>8.62</td>\n",
       "      <td>12.13</td>\n",
       "      <td>37.31</td>\n",
       "      <td>73.60</td>\n",
       "      <td>81.47</td>\n",
       "      <td>86.20</td>\n",
       "      <td>72.40</td>\n",
       "      <td>104.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>1.95</td>\n",
       "      <td>4.22</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.96</td>\n",
       "      <td>34.54</td>\n",
       "      <td>17.64</td>\n",
       "      <td>14.89</td>\n",
       "      <td>29.01</td>\n",
       "      <td>32.27</td>\n",
       "      <td>34.13</td>\n",
       "      <td>89.55</td>\n",
       "      <td>19.00</td>\n",
       "      <td>289.35</td>\n",
       "      <td>50.30</td>\n",
       "      <td>1878.00</td>\n",
       "      <td>32.77</td>\n",
       "      <td>29.58</td>\n",
       "      <td>18.19</td>\n",
       "      <td>25.87</td>\n",
       "      <td>52.96</td>\n",
       "      <td>296.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>32.66</td>\n",
       "      <td>45.75</td>\n",
       "      <td>23.42</td>\n",
       "      <td>5.69</td>\n",
       "      <td>50.04</td>\n",
       "      <td>24.85</td>\n",
       "      <td>31.35</td>\n",
       "      <td>17.08</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.24</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.10</td>\n",
       "      <td>29.84</td>\n",
       "      <td>29.83</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.33</td>\n",
       "      <td>3.73</td>\n",
       "      <td>5.16</td>\n",
       "      <td>194.23</td>\n",
       "      <td>8.70</td>\n",
       "      <td>12.22</td>\n",
       "      <td>37.30</td>\n",
       "      <td>74.05</td>\n",
       "      <td>80.78</td>\n",
       "      <td>85.84</td>\n",
       "      <td>74.60</td>\n",
       "      <td>105.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>1.98</td>\n",
       "      <td>4.25</td>\n",
       "      <td>18.43</td>\n",
       "      <td>15.06</td>\n",
       "      <td>34.41</td>\n",
       "      <td>17.83</td>\n",
       "      <td>14.92</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.70</td>\n",
       "      <td>33.43</td>\n",
       "      <td>87.94</td>\n",
       "      <td>18.43</td>\n",
       "      <td>281.08</td>\n",
       "      <td>50.09</td>\n",
       "      <td>1848.00</td>\n",
       "      <td>32.74</td>\n",
       "      <td>29.18</td>\n",
       "      <td>18.29</td>\n",
       "      <td>25.19</td>\n",
       "      <td>51.93</td>\n",
       "      <td>292.15</td>\n",
       "      <td>9.07</td>\n",
       "      <td>32.48</td>\n",
       "      <td>44.80</td>\n",
       "      <td>23.43</td>\n",
       "      <td>5.69</td>\n",
       "      <td>49.19</td>\n",
       "      <td>24.30</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.15</td>\n",
       "      <td>14.21</td>\n",
       "      <td>2.86</td>\n",
       "      <td>43.15</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.25</td>\n",
       "      <td>29.82</td>\n",
       "      <td>29.44</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.33</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.23</td>\n",
       "      <td>185.54</td>\n",
       "      <td>8.71</td>\n",
       "      <td>12.41</td>\n",
       "      <td>36.65</td>\n",
       "      <td>71.90</td>\n",
       "      <td>79.06</td>\n",
       "      <td>85.00</td>\n",
       "      <td>74.57</td>\n",
       "      <td>102.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.39</td>\n",
       "      <td>18.39</td>\n",
       "      <td>14.69</td>\n",
       "      <td>34.17</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.81</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.99</td>\n",
       "      <td>32.64</td>\n",
       "      <td>88.05</td>\n",
       "      <td>18.35</td>\n",
       "      <td>260.85</td>\n",
       "      <td>49.12</td>\n",
       "      <td>1820.81</td>\n",
       "      <td>32.80</td>\n",
       "      <td>28.73</td>\n",
       "      <td>18.49</td>\n",
       "      <td>24.56</td>\n",
       "      <td>51.93</td>\n",
       "      <td>292.44</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.00</td>\n",
       "      <td>46.60</td>\n",
       "      <td>23.42</td>\n",
       "      <td>5.69</td>\n",
       "      <td>49.18</td>\n",
       "      <td>24.37</td>\n",
       "      <td>31.99</td>\n",
       "      <td>17.05</td>\n",
       "      <td>14.25</td>\n",
       "      <td>2.86</td>\n",
       "      <td>42.48</td>\n",
       "      <td>4.39</td>\n",
       "      <td>20.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>28.63</td>\n",
       "      <td>5.12</td>\n",
       "      <td>12.33</td>\n",
       "      <td>3.76</td>\n",
       "      <td>5.34</td>\n",
       "      <td>187.10</td>\n",
       "      <td>8.65</td>\n",
       "      <td>12.27</td>\n",
       "      <td>36.48</td>\n",
       "      <td>70.15</td>\n",
       "      <td>78.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>73.07</td>\n",
       "      <td>101.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-23</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.47</td>\n",
       "      <td>18.36</td>\n",
       "      <td>14.42</td>\n",
       "      <td>34.36</td>\n",
       "      <td>17.55</td>\n",
       "      <td>14.77</td>\n",
       "      <td>28.73</td>\n",
       "      <td>30.48</td>\n",
       "      <td>32.93</td>\n",
       "      <td>87.76</td>\n",
       "      <td>18.26</td>\n",
       "      <td>252.69</td>\n",
       "      <td>49.30</td>\n",
       "      <td>1834.43</td>\n",
       "      <td>32.52</td>\n",
       "      <td>28.66</td>\n",
       "      <td>18.05</td>\n",
       "      <td>24.50</td>\n",
       "      <td>50.48</td>\n",
       "      <td>291.89</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.45</td>\n",
       "      <td>46.74</td>\n",
       "      <td>23.33</td>\n",
       "      <td>5.62</td>\n",
       "      <td>48.54</td>\n",
       "      <td>24.40</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.10</td>\n",
       "      <td>14.25</td>\n",
       "      <td>2.88</td>\n",
       "      <td>43.02</td>\n",
       "      <td>4.40</td>\n",
       "      <td>20.39</td>\n",
       "      <td>30.88</td>\n",
       "      <td>28.49</td>\n",
       "      <td>5.22</td>\n",
       "      <td>12.44</td>\n",
       "      <td>3.86</td>\n",
       "      <td>5.44</td>\n",
       "      <td>185.41</td>\n",
       "      <td>8.53</td>\n",
       "      <td>11.97</td>\n",
       "      <td>36.34</td>\n",
       "      <td>69.42</td>\n",
       "      <td>77.96</td>\n",
       "      <td>82.00</td>\n",
       "      <td>72.10</td>\n",
       "      <td>98.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-26</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.27</td>\n",
       "      <td>18.02</td>\n",
       "      <td>14.05</td>\n",
       "      <td>33.95</td>\n",
       "      <td>17.69</td>\n",
       "      <td>14.55</td>\n",
       "      <td>28.10</td>\n",
       "      <td>30.09</td>\n",
       "      <td>31.90</td>\n",
       "      <td>87.28</td>\n",
       "      <td>17.35</td>\n",
       "      <td>246.79</td>\n",
       "      <td>48.68</td>\n",
       "      <td>1863.00</td>\n",
       "      <td>32.04</td>\n",
       "      <td>28.33</td>\n",
       "      <td>17.76</td>\n",
       "      <td>24.95</td>\n",
       "      <td>50.52</td>\n",
       "      <td>299.65</td>\n",
       "      <td>8.97</td>\n",
       "      <td>32.36</td>\n",
       "      <td>45.29</td>\n",
       "      <td>23.05</td>\n",
       "      <td>5.45</td>\n",
       "      <td>48.80</td>\n",
       "      <td>23.75</td>\n",
       "      <td>30.36</td>\n",
       "      <td>16.75</td>\n",
       "      <td>14.01</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.49</td>\n",
       "      <td>4.35</td>\n",
       "      <td>19.90</td>\n",
       "      <td>30.82</td>\n",
       "      <td>28.70</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>5.11</td>\n",
       "      <td>194.51</td>\n",
       "      <td>7.82</td>\n",
       "      <td>11.26</td>\n",
       "      <td>35.67</td>\n",
       "      <td>70.47</td>\n",
       "      <td>79.70</td>\n",
       "      <td>83.55</td>\n",
       "      <td>73.45</td>\n",
       "      <td>98.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-27</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.28</td>\n",
       "      <td>18.07</td>\n",
       "      <td>14.37</td>\n",
       "      <td>33.90</td>\n",
       "      <td>17.67</td>\n",
       "      <td>14.65</td>\n",
       "      <td>28.30</td>\n",
       "      <td>30.45</td>\n",
       "      <td>33.65</td>\n",
       "      <td>87.66</td>\n",
       "      <td>17.74</td>\n",
       "      <td>264.07</td>\n",
       "      <td>49.32</td>\n",
       "      <td>1888.00</td>\n",
       "      <td>33.67</td>\n",
       "      <td>28.61</td>\n",
       "      <td>18.11</td>\n",
       "      <td>25.60</td>\n",
       "      <td>51.38</td>\n",
       "      <td>308.18</td>\n",
       "      <td>8.98</td>\n",
       "      <td>33.22</td>\n",
       "      <td>46.47</td>\n",
       "      <td>22.70</td>\n",
       "      <td>5.64</td>\n",
       "      <td>48.99</td>\n",
       "      <td>24.01</td>\n",
       "      <td>30.40</td>\n",
       "      <td>16.81</td>\n",
       "      <td>13.99</td>\n",
       "      <td>2.83</td>\n",
       "      <td>42.44</td>\n",
       "      <td>4.34</td>\n",
       "      <td>20.03</td>\n",
       "      <td>31.10</td>\n",
       "      <td>29.39</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.85</td>\n",
       "      <td>5.10</td>\n",
       "      <td>202.45</td>\n",
       "      <td>7.85</td>\n",
       "      <td>11.34</td>\n",
       "      <td>36.15</td>\n",
       "      <td>72.24</td>\n",
       "      <td>81.89</td>\n",
       "      <td>84.90</td>\n",
       "      <td>72.67</td>\n",
       "      <td>99.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17.72</td>\n",
       "      <td>14.09</td>\n",
       "      <td>33.67</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.49</td>\n",
       "      <td>27.01</td>\n",
       "      <td>29.56</td>\n",
       "      <td>33.47</td>\n",
       "      <td>87.08</td>\n",
       "      <td>17.41</td>\n",
       "      <td>261.50</td>\n",
       "      <td>46.90</td>\n",
       "      <td>1883.00</td>\n",
       "      <td>33.51</td>\n",
       "      <td>28.30</td>\n",
       "      <td>17.84</td>\n",
       "      <td>25.30</td>\n",
       "      <td>49.32</td>\n",
       "      <td>306.85</td>\n",
       "      <td>8.82</td>\n",
       "      <td>33.26</td>\n",
       "      <td>43.98</td>\n",
       "      <td>22.46</td>\n",
       "      <td>5.55</td>\n",
       "      <td>47.90</td>\n",
       "      <td>23.42</td>\n",
       "      <td>30.64</td>\n",
       "      <td>16.84</td>\n",
       "      <td>13.86</td>\n",
       "      <td>2.85</td>\n",
       "      <td>41.89</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.08</td>\n",
       "      <td>31.48</td>\n",
       "      <td>28.11</td>\n",
       "      <td>5.10</td>\n",
       "      <td>12.26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5.07</td>\n",
       "      <td>202.48</td>\n",
       "      <td>7.48</td>\n",
       "      <td>11.05</td>\n",
       "      <td>35.83</td>\n",
       "      <td>70.80</td>\n",
       "      <td>83.00</td>\n",
       "      <td>82.63</td>\n",
       "      <td>65.40</td>\n",
       "      <td>97.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.26</td>\n",
       "      <td>17.40</td>\n",
       "      <td>13.85</td>\n",
       "      <td>33.15</td>\n",
       "      <td>17.28</td>\n",
       "      <td>14.27</td>\n",
       "      <td>26.97</td>\n",
       "      <td>29.61</td>\n",
       "      <td>34.97</td>\n",
       "      <td>89.49</td>\n",
       "      <td>17.15</td>\n",
       "      <td>266.10</td>\n",
       "      <td>47.98</td>\n",
       "      <td>1880.35</td>\n",
       "      <td>33.52</td>\n",
       "      <td>28.11</td>\n",
       "      <td>17.80</td>\n",
       "      <td>24.94</td>\n",
       "      <td>49.11</td>\n",
       "      <td>304.28</td>\n",
       "      <td>8.58</td>\n",
       "      <td>33.30</td>\n",
       "      <td>43.38</td>\n",
       "      <td>22.40</td>\n",
       "      <td>5.54</td>\n",
       "      <td>50.08</td>\n",
       "      <td>23.15</td>\n",
       "      <td>31.41</td>\n",
       "      <td>16.54</td>\n",
       "      <td>13.58</td>\n",
       "      <td>2.82</td>\n",
       "      <td>41.32</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.81</td>\n",
       "      <td>31.77</td>\n",
       "      <td>28.10</td>\n",
       "      <td>5.01</td>\n",
       "      <td>12.18</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.11</td>\n",
       "      <td>197.25</td>\n",
       "      <td>7.70</td>\n",
       "      <td>11.08</td>\n",
       "      <td>34.74</td>\n",
       "      <td>72.55</td>\n",
       "      <td>84.00</td>\n",
       "      <td>81.48</td>\n",
       "      <td>65.48</td>\n",
       "      <td>96.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.29</td>\n",
       "      <td>17.42</td>\n",
       "      <td>13.88</td>\n",
       "      <td>33.65</td>\n",
       "      <td>18.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>26.56</td>\n",
       "      <td>29.56</td>\n",
       "      <td>35.10</td>\n",
       "      <td>92.10</td>\n",
       "      <td>16.92</td>\n",
       "      <td>266.80</td>\n",
       "      <td>46.96</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>33.89</td>\n",
       "      <td>28.81</td>\n",
       "      <td>17.60</td>\n",
       "      <td>24.77</td>\n",
       "      <td>47.67</td>\n",
       "      <td>302.89</td>\n",
       "      <td>8.66</td>\n",
       "      <td>32.98</td>\n",
       "      <td>41.95</td>\n",
       "      <td>22.74</td>\n",
       "      <td>5.63</td>\n",
       "      <td>47.91</td>\n",
       "      <td>23.17</td>\n",
       "      <td>31.64</td>\n",
       "      <td>16.65</td>\n",
       "      <td>13.67</td>\n",
       "      <td>2.86</td>\n",
       "      <td>41.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.33</td>\n",
       "      <td>31.63</td>\n",
       "      <td>27.80</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.12</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5.13</td>\n",
       "      <td>198.25</td>\n",
       "      <td>7.84</td>\n",
       "      <td>11.02</td>\n",
       "      <td>34.41</td>\n",
       "      <td>71.69</td>\n",
       "      <td>82.82</td>\n",
       "      <td>80.13</td>\n",
       "      <td>64.34</td>\n",
       "      <td>93.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tic         600010.SH  600028.SH  600030.SH  600031.SH  600036.SH  600048.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       4.15       7.36       9.56      12.09      11.67      10.05   \n",
       "2012-01-05       4.10       7.42       9.29      12.06      11.91       9.80   \n",
       "2012-01-06       4.34       7.48       9.39      12.06      11.99       9.71   \n",
       "2012-01-09       4.48       7.75       9.75      12.55      12.38      10.17   \n",
       "2012-01-10       4.54       7.79      10.12      13.31      12.56      10.35   \n",
       "2012-01-11       4.79       7.70      10.08      13.13      12.49      10.31   \n",
       "2012-01-12       4.77       7.66      10.03      13.22      12.62      10.39   \n",
       "2012-01-13       4.69       7.62       9.80      12.92      12.49      10.28   \n",
       "2012-01-16       4.32       7.54       9.83      13.06      12.39       9.93   \n",
       "2012-01-17       4.75       7.74      10.51      13.77      12.78      10.35   \n",
       "2012-01-18       4.73       7.58      10.47      13.69      12.52      10.12   \n",
       "2012-01-19       4.78       7.66      10.84      13.81      12.70      10.67   \n",
       "2012-01-20       4.77       7.74      11.01      13.99      13.00      10.94   \n",
       "2012-01-30       4.75       7.70      10.68        NaN      12.70      10.43   \n",
       "2012-01-31       4.87       7.76      10.69      14.21      12.65      10.50   \n",
       "2012-02-01       4.73       7.79      10.47      13.80      12.47      10.31   \n",
       "2012-02-02       4.83       7.86      10.80      14.06      12.87      10.56   \n",
       "2012-02-03       4.83       7.81      10.90      13.94      12.98      10.68   \n",
       "2012-02-06       4.82       7.78      10.84      13.89      12.86      10.45   \n",
       "2012-02-07       4.69       7.65      10.52      13.54      12.73      10.13   \n",
       "2012-02-08       4.90       7.78      10.95      13.88      12.99      10.42   \n",
       "2012-02-09       4.88       7.69      10.87      13.77      12.99      10.56   \n",
       "2012-02-10       5.08       7.67      10.97      13.88      12.89      10.91   \n",
       "2012-02-13       5.04       7.65      10.95      13.84      12.69      10.57   \n",
       "2012-02-14       5.01       7.66      10.87      13.69      12.66      10.62   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26       2.09       4.25      19.40      15.52      33.70      16.68   \n",
       "2022-08-29       2.07       4.26      19.37      15.56      33.28      16.61   \n",
       "2022-08-30       2.04       4.29      19.25      15.58      33.79      16.95   \n",
       "2022-08-31       2.01       4.27      19.52      15.75      35.05      17.30   \n",
       "2022-09-01       2.00       4.23      19.30      15.85      34.50      17.31   \n",
       "2022-09-02       2.00       4.26      19.24      15.61      34.32      17.02   \n",
       "2022-09-05       2.03       4.34      19.27      15.45      34.23      17.22   \n",
       "2022-09-06       2.05       4.41      19.48      15.73      33.62      17.63   \n",
       "2022-09-07       2.06       4.41      19.37      15.60      33.38      17.55   \n",
       "2022-09-08       2.04       4.41      19.31      15.75      33.30      17.58   \n",
       "2022-09-09       2.06       4.45      19.78      16.26      34.50      18.47   \n",
       "2022-09-13       2.05       4.43      19.83      16.30      35.35      18.09   \n",
       "2022-09-14       2.02       4.38      19.58      16.15      34.86      18.14   \n",
       "2022-09-15       2.00       4.40      19.53      16.20      36.01      18.85   \n",
       "2022-09-16       1.96       4.30      18.42      15.60      34.95      18.05   \n",
       "2022-09-19       1.91       4.18      18.42      14.97      35.09      18.44   \n",
       "2022-09-20       1.95       4.22      18.42      14.96      34.54      17.64   \n",
       "2022-09-21       1.98       4.25      18.43      15.06      34.41      17.83   \n",
       "2022-09-22       1.96       4.39      18.39      14.69      34.17      17.52   \n",
       "2022-09-23       1.96       4.47      18.36      14.42      34.36      17.55   \n",
       "2022-09-26       1.91       4.27      18.02      14.05      33.95      17.69   \n",
       "2022-09-27       1.91       4.28      18.07      14.37      33.90      17.67   \n",
       "2022-09-28       1.84       4.25      17.72      14.09      33.67      17.52   \n",
       "2022-09-29       1.84       4.26      17.40      13.85      33.15      17.28   \n",
       "2022-09-30       1.84       4.29      17.42      13.88      33.65      18.00   \n",
       "\n",
       "tic         600104.SH  600111.SH  600196.SH  600276.SH  600309.SH  600346.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      14.16      37.61       8.34      28.45      12.50       7.07   \n",
       "2012-01-05      14.39      35.64       8.25      27.00      12.10       6.86   \n",
       "2012-01-06      14.20      36.32       8.08      26.55      12.06       6.40   \n",
       "2012-01-09      14.90      39.02       8.34      27.40      12.47       6.64   \n",
       "2012-01-10      15.25      40.39       8.66      27.75      13.21       7.02   \n",
       "2012-01-11      15.10      42.63       8.63      27.70      13.25       7.14   \n",
       "2012-01-12      15.29      43.46       8.58      27.37      13.31       7.07   \n",
       "2012-01-13      14.69      44.96       8.31      26.80      12.83       6.81   \n",
       "2012-01-16      14.39      41.08       8.17      26.00      12.50       6.52   \n",
       "2012-01-17      15.33      45.19       8.61      26.02      13.39        NaN   \n",
       "2012-01-18      15.21      45.46       8.47      24.66      13.26       6.77   \n",
       "2012-01-19      15.46      46.58       8.62      25.20      13.76       6.79   \n",
       "2012-01-20      15.52      45.62       8.80      26.68      14.09       6.84   \n",
       "2012-01-30      15.48      46.06       8.63      26.19      13.67       7.14   \n",
       "2012-01-31      15.09      46.56        NaN      26.00        NaN       7.22   \n",
       "2012-02-01      14.93      44.73       8.51      25.86      13.78       7.16   \n",
       "2012-02-02      15.22      45.57       8.64      26.24      14.05       7.19   \n",
       "2012-02-03      15.40      45.61       8.76      26.39      14.42       7.37   \n",
       "2012-02-06      15.25      45.61       8.79      27.05      14.59       7.36   \n",
       "2012-02-07      15.22      44.55       8.60      26.53      14.26       7.17   \n",
       "2012-02-08      15.59      48.51       8.79      26.59      14.81       7.38   \n",
       "2012-02-09      15.49      47.57       8.87      26.93      14.91       7.55   \n",
       "2012-02-10      15.45      47.50       8.90      26.63      14.66       7.68   \n",
       "2012-02-13      15.76      47.65       8.84      26.99      14.58       7.82   \n",
       "2012-02-14      15.52      47.50       8.89      26.87      14.31       7.89   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      15.88      30.84      40.93      34.77      88.67      19.33   \n",
       "2022-08-29      15.50      30.59      40.61      34.23      87.80      19.29   \n",
       "2022-08-30      15.48      30.37      40.08      33.67      88.45      19.14   \n",
       "2022-08-31      15.47      30.14      40.36      34.66      88.57      19.20   \n",
       "2022-09-01      15.30      30.09      40.90      34.34      88.11      19.21   \n",
       "2022-09-02      15.26      30.16      40.21      33.90      86.95      19.15   \n",
       "2022-09-05      15.21      30.08      36.19      33.73      88.65      19.12   \n",
       "2022-09-06      15.42      30.85      35.42      33.88      91.50      19.58   \n",
       "2022-09-07      15.40      30.79      35.55      33.43      90.52      19.76   \n",
       "2022-09-08      15.35      30.29      33.96      33.73      92.01      19.70   \n",
       "2022-09-09      15.48      30.68      35.00      34.78      95.61      20.06   \n",
       "2022-09-13      15.65      31.47      34.44      35.52      93.00      20.03   \n",
       "2022-09-14      15.44      30.70      33.76      35.68      91.36      19.84   \n",
       "2022-09-15      15.34      30.01      33.04      35.49      91.50      19.46   \n",
       "2022-09-16      15.02      28.80      32.17      34.83      90.38      19.03   \n",
       "2022-09-19      15.01      28.34      32.19      34.69      91.36      18.82   \n",
       "2022-09-20      14.89      29.01      32.27      34.13      89.55      19.00   \n",
       "2022-09-21      14.92      30.48      31.70      33.43      87.94      18.43   \n",
       "2022-09-22      14.81      29.39      30.99      32.64      88.05      18.35   \n",
       "2022-09-23      14.77      28.73      30.48      32.93      87.76      18.26   \n",
       "2022-09-26      14.55      28.10      30.09      31.90      87.28      17.35   \n",
       "2022-09-27      14.65      28.30      30.45      33.65      87.66      17.74   \n",
       "2022-09-28      14.49      27.01      29.56      33.47      87.08      17.41   \n",
       "2022-09-29      14.27      26.97      29.61      34.97      89.49      17.15   \n",
       "2022-09-30      14.30      26.56      29.56      35.10      92.10      16.92   \n",
       "\n",
       "tic         600436.SH  600438.SH  600519.SH  600570.SH  600585.SH  600588.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      73.03       4.85     185.27      11.50      15.28      16.90   \n",
       "2012-01-05      70.50       4.66     183.15      10.70      14.92      16.48   \n",
       "2012-01-06      70.08       4.72     186.64      10.67      14.72      16.23   \n",
       "2012-01-09      70.10       4.89     188.01      11.00      15.55      16.58   \n",
       "2012-01-10      72.00       5.10     194.48      11.34      16.59      17.02   \n",
       "2012-01-11      72.85       5.06     189.68      11.25      16.38      17.79   \n",
       "2012-01-12      73.99       5.03     190.35      11.05      16.51      17.14   \n",
       "2012-01-13      71.73       4.87     188.69      10.49      15.75      16.51   \n",
       "2012-01-16      69.15       4.76     177.41      10.30      15.28      16.03   \n",
       "2012-01-17      70.90       5.03     180.44      10.60      16.43      16.73   \n",
       "2012-01-18      63.81       4.93     177.38      10.48      16.82      16.49   \n",
       "2012-01-19      64.29       5.01     180.70      10.33      17.15      16.19   \n",
       "2012-01-20      65.74       5.10     185.97      10.41      17.79      16.48   \n",
       "2012-01-30      64.87       5.04     183.80      10.37      17.38      16.23   \n",
       "2012-01-31      65.93       5.08     186.41      10.39      17.37      16.45   \n",
       "2012-02-01      66.52       5.05     186.15      10.64      16.54      16.68   \n",
       "2012-02-02      66.67       5.25     186.43      10.77      16.90      17.14   \n",
       "2012-02-03      66.89       5.25     186.48      11.00      16.72      17.70   \n",
       "2012-02-06      68.41       5.27     188.54      11.00      17.07      17.93   \n",
       "2012-02-07      68.22       5.09     185.86      10.75      16.52      17.46   \n",
       "2012-02-08      68.80       5.20     188.29      11.04      17.15      17.90   \n",
       "2012-02-09      68.77       5.26     190.75      11.11      17.40      17.98   \n",
       "2012-02-10      68.61       5.32     190.51      11.06      17.51      17.70   \n",
       "2012-02-13      68.67       5.37     193.42      11.21      17.25      18.36   \n",
       "2012-02-14      69.29       5.38     193.82      11.27      17.10      18.06   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26     294.00      56.43    1898.00      32.44      31.81      20.00   \n",
       "2022-08-29     291.09      56.78    1878.82      32.70      31.42      19.29   \n",
       "2022-08-30     288.36      55.56    1870.00      33.33      30.99      20.07   \n",
       "2022-08-31     300.99      52.88    1924.00      33.64      31.92      20.09   \n",
       "2022-09-01     298.30      52.82    1880.89      34.50      31.60      20.37   \n",
       "2022-09-02     296.11      52.21    1875.00      34.37      31.17      20.15   \n",
       "2022-09-05     294.00      52.45    1835.00      33.73      31.01      19.79   \n",
       "2022-09-06     294.02      56.87    1845.00      33.66      31.00      19.71   \n",
       "2022-09-07     291.48      56.69    1818.01      33.59      30.41      19.62   \n",
       "2022-09-08     293.75      56.50    1815.00      33.99      30.20      19.33   \n",
       "2022-09-09     298.11      54.56    1844.79      35.30      31.37      19.54   \n",
       "2022-09-13     302.00      54.99    1879.00      36.15      31.96      19.58   \n",
       "2022-09-14     300.29      53.73    1869.00      36.30      31.59      19.71   \n",
       "2022-09-15     298.56      51.30    1880.00      35.71      32.23      19.45   \n",
       "2022-09-16     293.20      49.52    1859.00      33.99      31.19      19.53   \n",
       "2022-09-19     289.50      49.87    1871.64      33.69      30.45      18.03   \n",
       "2022-09-20     289.35      50.30    1878.00      32.77      29.58      18.19   \n",
       "2022-09-21     281.08      50.09    1848.00      32.74      29.18      18.29   \n",
       "2022-09-22     260.85      49.12    1820.81      32.80      28.73      18.49   \n",
       "2022-09-23     252.69      49.30    1834.43      32.52      28.66      18.05   \n",
       "2022-09-26     246.79      48.68    1863.00      32.04      28.33      17.76   \n",
       "2022-09-27     264.07      49.32    1888.00      33.67      28.61      18.11   \n",
       "2022-09-28     261.50      46.90    1883.00      33.51      28.30      17.84   \n",
       "2022-09-29     266.10      47.98    1880.35      33.52      28.11      17.80   \n",
       "2022-09-30     266.80      46.96    1872.50      33.89      28.81      17.60   \n",
       "\n",
       "tic         600690.SH  600745.SH  600809.SH  600837.SH  600887.SH  600893.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       8.78       5.79      57.79       7.12      19.73      13.29   \n",
       "2012-01-05       8.73       5.54      55.04       7.08      19.33      12.66   \n",
       "2012-01-06       8.79       5.76      53.69       7.30      19.66      12.95   \n",
       "2012-01-09       9.07       6.00      54.59       7.62      20.13      13.39   \n",
       "2012-01-10       9.42       6.21      57.00       7.93      20.58      13.79   \n",
       "2012-01-11       9.26       6.13      57.67       7.85      20.61      13.72   \n",
       "2012-01-12       9.23       6.28      55.89       7.85      20.50      14.10   \n",
       "2012-01-13       8.83       6.50      53.98       7.71      20.22      13.26   \n",
       "2012-01-16       8.70       5.91      50.77       7.64      19.01      12.89   \n",
       "2012-01-17       9.29       6.29      52.66       8.15      19.87      13.55   \n",
       "2012-01-18       9.08       6.19      51.61       8.07      19.14      13.32   \n",
       "2012-01-19       9.40       6.25      52.84       8.38      19.98      13.20   \n",
       "2012-01-20       9.51       6.26      54.34       8.60      20.54        NaN   \n",
       "2012-01-30       9.24       6.29      53.30       8.36      20.33      13.49   \n",
       "2012-01-31       9.21       6.38      54.97       8.36      20.44      13.48   \n",
       "2012-02-01       9.10       6.23      54.98       8.10      20.60      13.12   \n",
       "2012-02-02       9.19       6.33      55.72       8.53      20.92      13.31   \n",
       "2012-02-03       9.17       6.40      57.00       8.47      20.90      13.79   \n",
       "2012-02-06       9.27       6.50      58.59       8.45      21.56      13.68   \n",
       "2012-02-07       9.07       6.37      57.61       8.21      21.50      14.74   \n",
       "2012-02-08       9.28       6.76      59.17       8.67      21.80      15.24   \n",
       "2012-02-09       9.33       6.67      59.40       8.57      21.32      15.13   \n",
       "2012-02-10       9.33       6.68      59.00       8.65      21.76      15.29   \n",
       "2012-02-13       9.28       6.64      59.85       8.55      22.11      15.57   \n",
       "2012-02-14       9.24       6.78      60.71       8.49      22.09      15.42   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      24.33      62.51     286.93       9.51      36.19      48.17   \n",
       "2022-08-29      24.57      64.60     285.30       9.45      35.95      49.91   \n",
       "2022-08-30      25.40      64.96     284.09       9.41      36.13      47.88   \n",
       "2022-08-31      25.87      64.60     293.00       9.48      35.74      45.97   \n",
       "2022-09-01      26.21      62.71     292.58       9.39      34.55      45.88   \n",
       "2022-09-02      25.63      63.25     288.53       9.32      33.90      45.22   \n",
       "2022-09-05      25.58      62.27     282.78       9.40      33.37      45.77   \n",
       "2022-09-06      25.69      61.53     286.02       9.46      33.63      47.14   \n",
       "2022-09-07      25.80      61.67     278.12       9.47      33.22      47.24   \n",
       "2022-09-08      25.88      60.41     285.59       9.44      33.27      47.76   \n",
       "2022-09-09      26.50      60.70     291.21       9.54      33.70      48.03   \n",
       "2022-09-13      26.48      60.12     293.00       9.52      33.74      49.00   \n",
       "2022-09-14      26.49      59.67     292.30       9.46      33.60      49.23   \n",
       "2022-09-15      26.88      58.54     296.00       9.46      33.69      47.20   \n",
       "2022-09-16      26.06      55.60     289.50       9.05      32.88      46.88   \n",
       "2022-09-19      26.16      54.30     293.75       9.06      32.90      46.01   \n",
       "2022-09-20      25.87      52.96     296.09       9.09      32.66      45.75   \n",
       "2022-09-21      25.19      51.93     292.15       9.07      32.48      44.80   \n",
       "2022-09-22      24.56      51.93     292.44       9.12      32.00      46.60   \n",
       "2022-09-23      24.50      50.48     291.89       9.12      32.45      46.74   \n",
       "2022-09-26      24.95      50.52     299.65       8.97      32.36      45.29   \n",
       "2022-09-27      25.60      51.38     308.18       8.98      33.22      46.47   \n",
       "2022-09-28      25.30      49.32     306.85       8.82      33.26      43.98   \n",
       "2022-09-29      24.94      49.11     304.28       8.58      33.30      43.38   \n",
       "2022-09-30      24.77      47.67     302.89       8.66      32.98      41.95   \n",
       "\n",
       "tic         600900.SH  600905.SH  601012.SH  601066.SH  601088.SH  601166.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       6.29        NaN        NaN        NaN      24.60      12.50   \n",
       "2012-01-05       6.24        NaN        NaN        NaN      24.29      12.71   \n",
       "2012-01-06       6.22        NaN        NaN        NaN      24.27      12.79   \n",
       "2012-01-09       6.29        NaN        NaN        NaN      26.01      13.04   \n",
       "2012-01-10       6.40        NaN        NaN        NaN      26.76      13.15   \n",
       "2012-01-11       6.38        NaN        NaN        NaN      26.49      13.02   \n",
       "2012-01-12       6.41        NaN        NaN        NaN      26.49      13.30   \n",
       "2012-01-13       6.35        NaN        NaN        NaN      26.33      13.28   \n",
       "2012-01-16       6.36        NaN        NaN        NaN      26.02      13.32   \n",
       "2012-01-17       6.53        NaN        NaN        NaN      27.38      13.60   \n",
       "2012-01-18       6.48        NaN        NaN        NaN      26.88      13.43   \n",
       "2012-01-19       6.56        NaN        NaN        NaN      27.10      13.78   \n",
       "2012-01-20       6.57        NaN        NaN        NaN      27.48      14.05   \n",
       "2012-01-30       6.45        NaN        NaN        NaN      26.68      13.83   \n",
       "2012-01-31       6.49        NaN        NaN        NaN      26.85      13.86   \n",
       "2012-02-01       6.44        NaN        NaN        NaN      26.57      13.56   \n",
       "2012-02-02       6.48        NaN        NaN        NaN      27.24      14.15   \n",
       "2012-02-03       6.52        NaN        NaN        NaN      27.35      14.18   \n",
       "2012-02-06       6.47        NaN        NaN        NaN      27.35      14.17   \n",
       "2012-02-07       6.33        NaN        NaN        NaN      26.89      14.02   \n",
       "2012-02-08       6.47        NaN        NaN        NaN      27.63      14.43   \n",
       "2012-02-09       6.41        NaN        NaN        NaN      27.53      14.42   \n",
       "2012-02-10       6.40        NaN        NaN        NaN      27.45      14.24   \n",
       "2012-02-13       6.39        NaN        NaN        NaN      27.14      14.13   \n",
       "2012-02-14       6.40        NaN        NaN        NaN      27.14      14.08   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      23.39       6.28      53.06      25.88      31.26      17.88   \n",
       "2022-08-29      23.30       6.29      53.41      25.71      31.88      16.93   \n",
       "2022-08-30      23.28       6.21      52.80      25.60      30.52      16.82   \n",
       "2022-08-31      23.98       6.10      51.20      26.64      30.34      17.11   \n",
       "2022-09-01      23.91       6.00      51.65      26.80      31.11      17.11   \n",
       "2022-09-02      23.82       6.02      50.95      26.89      30.66      17.03   \n",
       "2022-09-05      23.82       6.07      50.49      27.31      32.56      17.08   \n",
       "2022-09-06      23.75       6.12      53.16      27.55      32.88      17.06   \n",
       "2022-09-07      23.57       6.13      53.46      26.94      32.61      17.09   \n",
       "2022-09-08      23.65       6.07      53.39      26.82      32.30      17.01   \n",
       "2022-09-09      23.91       6.08      53.18      27.49      32.73      17.38   \n",
       "2022-09-13      23.79       6.02      53.27      27.32      32.45      17.59   \n",
       "2022-09-14      23.70       5.94      52.55      26.81      32.35      17.38   \n",
       "2022-09-15      23.72       5.87      48.66      26.85      32.39      17.69   \n",
       "2022-09-16      23.46       5.68      48.30      24.97      30.96      17.22   \n",
       "2022-09-19      23.48       5.64      48.12      24.96      31.50      17.34   \n",
       "2022-09-20      23.42       5.69      50.04      24.85      31.35      17.08   \n",
       "2022-09-21      23.43       5.69      49.19      24.30      31.18      17.15   \n",
       "2022-09-22      23.42       5.69      49.18      24.37      31.99      17.05   \n",
       "2022-09-23      23.33       5.62      48.54      24.40      31.18      17.10   \n",
       "2022-09-26      23.05       5.45      48.80      23.75      30.36      16.75   \n",
       "2022-09-27      22.70       5.64      48.99      24.01      30.40      16.81   \n",
       "2022-09-28      22.46       5.55      47.90      23.42      30.64      16.84   \n",
       "2022-09-29      22.40       5.54      50.08      23.15      31.41      16.54   \n",
       "2022-09-30      22.74       5.63      47.91      23.17      31.64      16.65   \n",
       "\n",
       "tic         601211.SH  601288.SH  601318.SH  601398.SH  601601.SH  601628.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04        NaN       2.60      33.90       4.22      19.04      17.46   \n",
       "2012-01-05        NaN       2.65      33.93       4.25      19.12      16.58   \n",
       "2012-01-06        NaN       2.66      33.85       4.28      19.23      16.73   \n",
       "2012-01-09        NaN       2.68      34.73       4.31      19.73      17.28   \n",
       "2012-01-10        NaN       2.69      36.29       4.35      20.40      18.23   \n",
       "2012-01-11        NaN       2.67      35.83       4.35      20.20      18.22   \n",
       "2012-01-12        NaN       2.65      36.37       4.33      20.03      18.30   \n",
       "2012-01-13        NaN       2.65      36.03       4.34      19.95      17.89   \n",
       "2012-01-16        NaN        NaN      35.59       4.31      19.85      17.81   \n",
       "2012-01-17        NaN       2.69      37.82       4.36      20.68      18.78   \n",
       "2012-01-18        NaN       2.69      37.45       4.31      20.50      18.45   \n",
       "2012-01-19        NaN       2.70      38.51       4.36      21.22      19.00   \n",
       "2012-01-20        NaN       2.72      39.10       4.36      21.84      19.33   \n",
       "2012-01-30        NaN       2.68      38.60       4.27      21.11      18.90   \n",
       "2012-01-31        NaN       2.70      38.34       4.30      21.01      18.78   \n",
       "2012-02-01        NaN       2.68      37.41       4.28      20.65      18.34   \n",
       "2012-02-02        NaN       2.73      39.64       4.38      21.41      19.07   \n",
       "2012-02-03        NaN       2.75      40.15       4.41      21.86      19.30   \n",
       "2012-02-06        NaN       2.75      39.62       4.41      21.36      18.92   \n",
       "2012-02-07        NaN       2.72      38.91       4.33      20.79      18.50   \n",
       "2012-02-08        NaN       2.75        NaN       4.41      21.75      19.24   \n",
       "2012-02-09        NaN       2.73      39.88       4.42      21.26      19.07   \n",
       "2012-02-10        NaN       2.72      40.09       4.39      21.61      18.93   \n",
       "2012-02-13        NaN       2.71      40.28       4.37      21.41      18.64   \n",
       "2012-02-14        NaN       2.70      39.58       4.35      20.83      18.39   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      14.72       2.82      43.12       4.35      20.29      29.44   \n",
       "2022-08-29      14.68       2.82      43.07       4.33      20.17      29.02   \n",
       "2022-08-30      14.68       2.82      42.89       4.36      20.47      29.50   \n",
       "2022-08-31      14.79       2.85      43.84       4.38      20.97      30.70   \n",
       "2022-09-01      14.73       2.83      43.65       4.36      20.82      30.45   \n",
       "2022-09-02      14.62       2.83      43.70       4.35      20.75      29.70   \n",
       "2022-09-05      14.84       2.84      43.80       4.36      20.90      29.86   \n",
       "2022-09-06      14.92       2.84      43.90       4.36      21.08      30.34   \n",
       "2022-09-07      14.88       2.83      43.60       4.35      20.98      30.25   \n",
       "2022-09-08      14.84       2.83      43.84       4.35      20.95      30.76   \n",
       "2022-09-09      15.07       2.84      44.69       4.36      21.47      31.50   \n",
       "2022-09-13      14.97       2.85      45.06       4.38      21.52      31.46   \n",
       "2022-09-14      14.81       2.85      44.65       4.36      21.26      31.63   \n",
       "2022-09-15      14.87       2.87      45.09       4.39      21.31      31.74   \n",
       "2022-09-16      14.12       2.85      43.93       4.36      20.88      31.06   \n",
       "2022-09-19      14.11       2.87      43.93       4.38      20.42      30.86   \n",
       "2022-09-20      14.18       2.84      43.24       4.37      20.10      29.84   \n",
       "2022-09-21      14.21       2.86      43.15       4.37      20.25      29.82   \n",
       "2022-09-22      14.25       2.86      42.48       4.39      20.26      29.91   \n",
       "2022-09-23      14.25       2.88      43.02       4.40      20.39      30.88   \n",
       "2022-09-26      14.01       2.85      42.49       4.35      19.90      30.82   \n",
       "2022-09-27      13.99       2.83      42.44       4.34      20.03      31.10   \n",
       "2022-09-28      13.86       2.85      41.89       4.35      20.08      31.48   \n",
       "2022-09-29      13.58       2.82      41.32       4.33      19.81      31.77   \n",
       "2022-09-30      13.67       2.86      41.58       4.35      20.33      31.63   \n",
       "\n",
       "tic         601633.SH  601668.SH  601688.SH  601728.SH  601857.SH  601888.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      11.87       2.86       7.62        NaN       9.75      25.59   \n",
       "2012-01-05      12.10       2.87       7.36        NaN       9.80      24.17   \n",
       "2012-01-06      11.81       2.87       7.49        NaN       9.96      23.61   \n",
       "2012-01-09      12.26       2.93       7.79        NaN      10.03      24.41   \n",
       "2012-01-10      12.46       3.08       8.13        NaN      10.12      25.60   \n",
       "2012-01-11      12.41       3.04       8.00        NaN      10.04      25.95   \n",
       "2012-01-12      12.65       3.04       7.93        NaN      10.06      25.47   \n",
       "2012-01-13      12.26       3.01       7.87        NaN      10.20      24.93   \n",
       "2012-01-16        NaN       2.98       7.73        NaN      10.09      23.59   \n",
       "2012-01-17      12.99       3.10       8.19        NaN      10.32      24.72   \n",
       "2012-01-18      12.77       3.05       8.22        NaN      10.22      24.01   \n",
       "2012-01-19      12.88       3.09       8.48        NaN      10.26      24.41   \n",
       "2012-01-20      12.99       3.14       8.50        NaN      10.26      25.01   \n",
       "2012-01-30      12.73       3.07       8.20        NaN      10.13      25.10   \n",
       "2012-01-31      12.57       3.07       8.33        NaN      10.21      24.73   \n",
       "2012-02-01      12.40       3.04       8.16        NaN      10.18      24.71   \n",
       "2012-02-02      12.65       3.10       8.36        NaN      10.21      25.10   \n",
       "2012-02-03      12.54       3.10       8.35        NaN      10.22      24.89   \n",
       "2012-02-06      12.73       3.07       8.26        NaN      10.23      25.01   \n",
       "2012-02-07      12.65       3.01       8.05        NaN      10.09      25.42   \n",
       "2012-02-08      12.98       3.09       8.36        NaN      10.26      25.87   \n",
       "2012-02-09      12.98       3.08       8.27        NaN      10.29      25.77   \n",
       "2012-02-10      13.03       3.21       8.32        NaN      10.31      25.91   \n",
       "2012-02-13      13.41       3.16       8.37        NaN      10.26      26.08   \n",
       "2012-02-14      13.38       3.16       8.37        NaN      10.24      26.03   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      35.35       5.01      13.13       3.74       5.44     192.41   \n",
       "2022-08-29      33.96       5.04      13.02       3.74       5.48     192.25   \n",
       "2022-08-30      34.20       5.07      13.11       3.74       5.47     190.40   \n",
       "2022-08-31      33.46       5.14      13.14       3.75       5.34     195.50   \n",
       "2022-09-01      32.25       5.15      13.00       3.76       5.36     186.80   \n",
       "2022-09-02      31.65       5.11      12.92       3.79       5.42     180.31   \n",
       "2022-09-05      31.19       5.17      13.05       3.82       5.56     180.10   \n",
       "2022-09-06      31.84       5.24      13.18       3.81       5.61     182.72   \n",
       "2022-09-07      32.09       5.23      13.14       3.82       5.58     183.95   \n",
       "2022-09-08      30.98       5.23      13.14       3.75       5.53     186.00   \n",
       "2022-09-09      31.31       5.36      13.28       3.80       5.59     191.09   \n",
       "2022-09-13      32.00       5.32      13.24       3.81       5.55     192.47   \n",
       "2022-09-14      31.74       5.26      13.11       3.81       5.52     191.55   \n",
       "2022-09-15      30.57       5.37      13.08       3.78       5.54     191.35   \n",
       "2022-09-16      28.88       5.15      12.41       3.75       5.37     188.51   \n",
       "2022-09-19      29.98       5.24      12.35       3.74       5.35     188.45   \n",
       "2022-09-20      29.83       5.11      12.33       3.73       5.16     194.23   \n",
       "2022-09-21      29.44       5.15      12.33       3.74       5.23     185.54   \n",
       "2022-09-22      28.63       5.12      12.33       3.76       5.34     187.10   \n",
       "2022-09-23      28.49       5.22      12.44       3.86       5.44     185.41   \n",
       "2022-09-26      28.70       5.15      12.21       3.82       5.11     194.51   \n",
       "2022-09-27      29.39       5.15      12.35       3.85       5.10     202.45   \n",
       "2022-09-28      28.11       5.10      12.26       3.83       5.07     202.48   \n",
       "2022-09-29      28.10       5.01      12.18       3.81       5.11     197.25   \n",
       "2022-09-30      27.80       5.15      12.12       3.83       5.13     198.25   \n",
       "\n",
       "tic         601899.SH  601919.SH  601995.SH  603259.SH  603288.SH  603501.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       3.81       4.50        NaN        NaN        NaN        NaN   \n",
       "2012-01-05       3.78       4.30        NaN        NaN        NaN        NaN   \n",
       "2012-01-06       3.80       4.32        NaN        NaN        NaN        NaN   \n",
       "2012-01-09       3.93       4.47        NaN        NaN        NaN        NaN   \n",
       "2012-01-10       4.12       4.68        NaN        NaN        NaN        NaN   \n",
       "2012-01-11       4.16       4.63        NaN        NaN        NaN        NaN   \n",
       "2012-01-12       4.15       4.69        NaN        NaN        NaN        NaN   \n",
       "2012-01-13       4.06       4.48        NaN        NaN        NaN        NaN   \n",
       "2012-01-16       3.96       4.38        NaN        NaN        NaN        NaN   \n",
       "2012-01-17       4.36       4.82        NaN        NaN        NaN        NaN   \n",
       "2012-01-18       4.29       5.10        NaN        NaN        NaN        NaN   \n",
       "2012-01-19       4.48       5.08        NaN        NaN        NaN        NaN   \n",
       "2012-01-20       4.47       5.05        NaN        NaN        NaN        NaN   \n",
       "2012-01-30       4.49       5.00        NaN        NaN        NaN        NaN   \n",
       "2012-01-31       4.44       5.08        NaN        NaN        NaN        NaN   \n",
       "2012-02-01       4.37       5.10        NaN        NaN        NaN        NaN   \n",
       "2012-02-02       4.46       5.33        NaN        NaN        NaN        NaN   \n",
       "2012-02-03       4.50       5.31        NaN        NaN        NaN        NaN   \n",
       "2012-02-06       4.45       5.30        NaN        NaN        NaN        NaN   \n",
       "2012-02-07       4.35       5.28        NaN        NaN        NaN        NaN   \n",
       "2012-02-08       4.53       5.37        NaN        NaN        NaN        NaN   \n",
       "2012-02-09       4.50       5.41        NaN        NaN        NaN        NaN   \n",
       "2012-02-10       4.50       5.47        NaN        NaN        NaN        NaN   \n",
       "2012-02-13       4.53       5.43        NaN        NaN        NaN        NaN   \n",
       "2012-02-14       4.48       5.39        NaN        NaN        NaN        NaN   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26       9.15      13.78      41.81      89.55      79.16      92.10   \n",
       "2022-08-29       9.02      13.60      41.69      88.52      78.57      91.62   \n",
       "2022-08-30       8.90      14.41      41.51      87.35      78.25      93.26   \n",
       "2022-08-31       8.80      14.20      41.70      89.65      80.56      93.74   \n",
       "2022-09-01       8.65      13.70      41.17      87.75      78.61      90.58   \n",
       "2022-09-02       8.52      13.33      41.55      86.25      78.00      89.87   \n",
       "2022-09-05       8.59      13.24      41.74      83.80      76.25      88.52   \n",
       "2022-09-06       8.84      13.39      42.56      84.21      76.32      88.87   \n",
       "2022-09-07       8.94      13.44      42.73      84.24      75.65      89.00   \n",
       "2022-09-08       9.06      13.26      42.18      82.74      75.80      87.70   \n",
       "2022-09-09       9.19      13.29      42.70      84.83      79.40      88.92   \n",
       "2022-09-13       9.29      13.26      42.95      76.35      81.01      89.10   \n",
       "2022-09-14       9.00      13.12      39.00      75.32      81.90      88.34   \n",
       "2022-09-15       8.95      12.93      38.80      76.81      81.60      86.74   \n",
       "2022-09-16       8.68      12.56      37.45      73.74      80.94      83.70   \n",
       "2022-09-19       8.62      12.13      37.31      73.60      81.47      86.20   \n",
       "2022-09-20       8.70      12.22      37.30      74.05      80.78      85.84   \n",
       "2022-09-21       8.71      12.41      36.65      71.90      79.06      85.00   \n",
       "2022-09-22       8.65      12.27      36.48      70.15      78.00      83.00   \n",
       "2022-09-23       8.53      11.97      36.34      69.42      77.96      82.00   \n",
       "2022-09-26       7.82      11.26      35.67      70.47      79.70      83.55   \n",
       "2022-09-27       7.85      11.34      36.15      72.24      81.89      84.90   \n",
       "2022-09-28       7.48      11.05      35.83      70.80      83.00      82.63   \n",
       "2022-09-29       7.70      11.08      34.74      72.55      84.00      81.48   \n",
       "2022-09-30       7.84      11.02      34.41      71.69      82.82      80.13   \n",
       "\n",
       "tic         603799.SH  603986.SH  \n",
       "date                              \n",
       "2012-01-04        NaN        NaN  \n",
       "2012-01-05        NaN        NaN  \n",
       "2012-01-06        NaN        NaN  \n",
       "2012-01-09        NaN        NaN  \n",
       "2012-01-10        NaN        NaN  \n",
       "2012-01-11        NaN        NaN  \n",
       "2012-01-12        NaN        NaN  \n",
       "2012-01-13        NaN        NaN  \n",
       "2012-01-16        NaN        NaN  \n",
       "2012-01-17        NaN        NaN  \n",
       "2012-01-18        NaN        NaN  \n",
       "2012-01-19        NaN        NaN  \n",
       "2012-01-20        NaN        NaN  \n",
       "2012-01-30        NaN        NaN  \n",
       "2012-01-31        NaN        NaN  \n",
       "2012-02-01        NaN        NaN  \n",
       "2012-02-02        NaN        NaN  \n",
       "2012-02-03        NaN        NaN  \n",
       "2012-02-06        NaN        NaN  \n",
       "2012-02-07        NaN        NaN  \n",
       "2012-02-08        NaN        NaN  \n",
       "2012-02-09        NaN        NaN  \n",
       "2012-02-10        NaN        NaN  \n",
       "2012-02-13        NaN        NaN  \n",
       "2012-02-14        NaN        NaN  \n",
       "...               ...        ...  \n",
       "2022-08-26      80.15     114.90  \n",
       "2022-08-29      78.04     114.49  \n",
       "2022-08-30      77.72     112.52  \n",
       "2022-08-31      74.74     115.97  \n",
       "2022-09-01      74.86     112.95  \n",
       "2022-09-02      74.51     113.25  \n",
       "2022-09-05      73.20     111.22  \n",
       "2022-09-06      74.99     112.71  \n",
       "2022-09-07      75.36     116.63  \n",
       "2022-09-08      73.00     115.30  \n",
       "2022-09-09      76.98     114.92  \n",
       "2022-09-13      76.94     114.19  \n",
       "2022-09-14      76.26     112.42  \n",
       "2022-09-15      72.96     108.60  \n",
       "2022-09-16      71.47     106.21  \n",
       "2022-09-19      72.40     104.55  \n",
       "2022-09-20      74.60     105.44  \n",
       "2022-09-21      74.57     102.30  \n",
       "2022-09-22      73.07     101.06  \n",
       "2022-09-23      72.10      98.24  \n",
       "2022-09-26      73.45      98.35  \n",
       "2022-09-27      72.67      99.91  \n",
       "2022-09-28      65.40      97.40  \n",
       "2022-09-29      65.48      96.24  \n",
       "2022-09-30      64.34      93.75  \n",
       "\n",
       "[2613 rows x 50 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "merged_closes = df.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "merged_closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:07.928699Z",
     "start_time": "2022-10-12T02:27:07.811836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tic</th>\n",
       "      <th>600010.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600048.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600111.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600436.SH</th>\n",
       "      <th>600438.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "      <th>600585.SH</th>\n",
       "      <th>600588.SH</th>\n",
       "      <th>600690.SH</th>\n",
       "      <th>600809.SH</th>\n",
       "      <th>600837.SH</th>\n",
       "      <th>600887.SH</th>\n",
       "      <th>600893.SH</th>\n",
       "      <th>600900.SH</th>\n",
       "      <th>601012.SH</th>\n",
       "      <th>601088.SH</th>\n",
       "      <th>601166.SH</th>\n",
       "      <th>601288.SH</th>\n",
       "      <th>601318.SH</th>\n",
       "      <th>601398.SH</th>\n",
       "      <th>601601.SH</th>\n",
       "      <th>601628.SH</th>\n",
       "      <th>601633.SH</th>\n",
       "      <th>601668.SH</th>\n",
       "      <th>601688.SH</th>\n",
       "      <th>601857.SH</th>\n",
       "      <th>601888.SH</th>\n",
       "      <th>601899.SH</th>\n",
       "      <th>601919.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>4.15</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.56</td>\n",
       "      <td>12.09</td>\n",
       "      <td>11.67</td>\n",
       "      <td>10.05</td>\n",
       "      <td>14.16</td>\n",
       "      <td>37.61</td>\n",
       "      <td>8.34</td>\n",
       "      <td>28.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>73.03</td>\n",
       "      <td>4.85</td>\n",
       "      <td>185.27</td>\n",
       "      <td>11.50</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.90</td>\n",
       "      <td>8.78</td>\n",
       "      <td>57.79</td>\n",
       "      <td>7.12</td>\n",
       "      <td>19.73</td>\n",
       "      <td>13.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.60</td>\n",
       "      <td>12.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>33.90</td>\n",
       "      <td>4.22</td>\n",
       "      <td>19.04</td>\n",
       "      <td>17.46</td>\n",
       "      <td>11.87</td>\n",
       "      <td>2.86</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.75</td>\n",
       "      <td>25.59</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>4.10</td>\n",
       "      <td>7.42</td>\n",
       "      <td>9.29</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.91</td>\n",
       "      <td>9.80</td>\n",
       "      <td>14.39</td>\n",
       "      <td>35.64</td>\n",
       "      <td>8.25</td>\n",
       "      <td>27.00</td>\n",
       "      <td>12.10</td>\n",
       "      <td>70.50</td>\n",
       "      <td>4.66</td>\n",
       "      <td>183.15</td>\n",
       "      <td>10.70</td>\n",
       "      <td>14.92</td>\n",
       "      <td>16.48</td>\n",
       "      <td>8.73</td>\n",
       "      <td>55.04</td>\n",
       "      <td>7.08</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.66</td>\n",
       "      <td>6.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.29</td>\n",
       "      <td>12.71</td>\n",
       "      <td>2.65</td>\n",
       "      <td>33.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.12</td>\n",
       "      <td>16.58</td>\n",
       "      <td>12.10</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.36</td>\n",
       "      <td>9.80</td>\n",
       "      <td>24.17</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>4.34</td>\n",
       "      <td>7.48</td>\n",
       "      <td>9.39</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.99</td>\n",
       "      <td>9.71</td>\n",
       "      <td>14.20</td>\n",
       "      <td>36.32</td>\n",
       "      <td>8.08</td>\n",
       "      <td>26.55</td>\n",
       "      <td>12.06</td>\n",
       "      <td>70.08</td>\n",
       "      <td>4.72</td>\n",
       "      <td>186.64</td>\n",
       "      <td>10.67</td>\n",
       "      <td>14.72</td>\n",
       "      <td>16.23</td>\n",
       "      <td>8.79</td>\n",
       "      <td>53.69</td>\n",
       "      <td>7.30</td>\n",
       "      <td>19.66</td>\n",
       "      <td>12.95</td>\n",
       "      <td>6.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.27</td>\n",
       "      <td>12.79</td>\n",
       "      <td>2.66</td>\n",
       "      <td>33.85</td>\n",
       "      <td>4.28</td>\n",
       "      <td>19.23</td>\n",
       "      <td>16.73</td>\n",
       "      <td>11.81</td>\n",
       "      <td>2.87</td>\n",
       "      <td>7.49</td>\n",
       "      <td>9.96</td>\n",
       "      <td>23.61</td>\n",
       "      <td>3.80</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>4.48</td>\n",
       "      <td>7.75</td>\n",
       "      <td>9.75</td>\n",
       "      <td>12.55</td>\n",
       "      <td>12.38</td>\n",
       "      <td>10.17</td>\n",
       "      <td>14.90</td>\n",
       "      <td>39.02</td>\n",
       "      <td>8.34</td>\n",
       "      <td>27.40</td>\n",
       "      <td>12.47</td>\n",
       "      <td>70.10</td>\n",
       "      <td>4.89</td>\n",
       "      <td>188.01</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>16.58</td>\n",
       "      <td>9.07</td>\n",
       "      <td>54.59</td>\n",
       "      <td>7.62</td>\n",
       "      <td>20.13</td>\n",
       "      <td>13.39</td>\n",
       "      <td>6.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.01</td>\n",
       "      <td>13.04</td>\n",
       "      <td>2.68</td>\n",
       "      <td>34.73</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.73</td>\n",
       "      <td>17.28</td>\n",
       "      <td>12.26</td>\n",
       "      <td>2.93</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.03</td>\n",
       "      <td>24.41</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-10</th>\n",
       "      <td>4.54</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.12</td>\n",
       "      <td>13.31</td>\n",
       "      <td>12.56</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.25</td>\n",
       "      <td>40.39</td>\n",
       "      <td>8.66</td>\n",
       "      <td>27.75</td>\n",
       "      <td>13.21</td>\n",
       "      <td>72.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>194.48</td>\n",
       "      <td>11.34</td>\n",
       "      <td>16.59</td>\n",
       "      <td>17.02</td>\n",
       "      <td>9.42</td>\n",
       "      <td>57.00</td>\n",
       "      <td>7.93</td>\n",
       "      <td>20.58</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.76</td>\n",
       "      <td>13.15</td>\n",
       "      <td>2.69</td>\n",
       "      <td>36.29</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.40</td>\n",
       "      <td>18.23</td>\n",
       "      <td>12.46</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.13</td>\n",
       "      <td>10.12</td>\n",
       "      <td>25.60</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-11</th>\n",
       "      <td>4.79</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.08</td>\n",
       "      <td>13.13</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.31</td>\n",
       "      <td>15.10</td>\n",
       "      <td>42.63</td>\n",
       "      <td>8.63</td>\n",
       "      <td>27.70</td>\n",
       "      <td>13.25</td>\n",
       "      <td>72.85</td>\n",
       "      <td>5.06</td>\n",
       "      <td>189.68</td>\n",
       "      <td>11.25</td>\n",
       "      <td>16.38</td>\n",
       "      <td>17.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>57.67</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.61</td>\n",
       "      <td>13.72</td>\n",
       "      <td>6.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.02</td>\n",
       "      <td>2.67</td>\n",
       "      <td>35.83</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.20</td>\n",
       "      <td>18.22</td>\n",
       "      <td>12.41</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.04</td>\n",
       "      <td>25.95</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-12</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.03</td>\n",
       "      <td>13.22</td>\n",
       "      <td>12.62</td>\n",
       "      <td>10.39</td>\n",
       "      <td>15.29</td>\n",
       "      <td>43.46</td>\n",
       "      <td>8.58</td>\n",
       "      <td>27.37</td>\n",
       "      <td>13.31</td>\n",
       "      <td>73.99</td>\n",
       "      <td>5.03</td>\n",
       "      <td>190.35</td>\n",
       "      <td>11.05</td>\n",
       "      <td>16.51</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.23</td>\n",
       "      <td>55.89</td>\n",
       "      <td>7.85</td>\n",
       "      <td>20.50</td>\n",
       "      <td>14.10</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.49</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.03</td>\n",
       "      <td>18.30</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.04</td>\n",
       "      <td>7.93</td>\n",
       "      <td>10.06</td>\n",
       "      <td>25.47</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-13</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.80</td>\n",
       "      <td>12.92</td>\n",
       "      <td>12.49</td>\n",
       "      <td>10.28</td>\n",
       "      <td>14.69</td>\n",
       "      <td>44.96</td>\n",
       "      <td>8.31</td>\n",
       "      <td>26.80</td>\n",
       "      <td>12.83</td>\n",
       "      <td>71.73</td>\n",
       "      <td>4.87</td>\n",
       "      <td>188.69</td>\n",
       "      <td>10.49</td>\n",
       "      <td>15.75</td>\n",
       "      <td>16.51</td>\n",
       "      <td>8.83</td>\n",
       "      <td>53.98</td>\n",
       "      <td>7.71</td>\n",
       "      <td>20.22</td>\n",
       "      <td>13.26</td>\n",
       "      <td>6.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.33</td>\n",
       "      <td>13.28</td>\n",
       "      <td>2.65</td>\n",
       "      <td>36.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.95</td>\n",
       "      <td>17.89</td>\n",
       "      <td>12.26</td>\n",
       "      <td>3.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>10.20</td>\n",
       "      <td>24.93</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-16</th>\n",
       "      <td>4.32</td>\n",
       "      <td>7.54</td>\n",
       "      <td>9.83</td>\n",
       "      <td>13.06</td>\n",
       "      <td>12.39</td>\n",
       "      <td>9.93</td>\n",
       "      <td>14.39</td>\n",
       "      <td>41.08</td>\n",
       "      <td>8.17</td>\n",
       "      <td>26.00</td>\n",
       "      <td>12.50</td>\n",
       "      <td>69.15</td>\n",
       "      <td>4.76</td>\n",
       "      <td>177.41</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.28</td>\n",
       "      <td>16.03</td>\n",
       "      <td>8.70</td>\n",
       "      <td>50.77</td>\n",
       "      <td>7.64</td>\n",
       "      <td>19.01</td>\n",
       "      <td>12.89</td>\n",
       "      <td>6.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.59</td>\n",
       "      <td>4.31</td>\n",
       "      <td>19.85</td>\n",
       "      <td>17.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.98</td>\n",
       "      <td>7.73</td>\n",
       "      <td>10.09</td>\n",
       "      <td>23.59</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-17</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.74</td>\n",
       "      <td>10.51</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.78</td>\n",
       "      <td>10.35</td>\n",
       "      <td>15.33</td>\n",
       "      <td>45.19</td>\n",
       "      <td>8.61</td>\n",
       "      <td>26.02</td>\n",
       "      <td>13.39</td>\n",
       "      <td>70.90</td>\n",
       "      <td>5.03</td>\n",
       "      <td>180.44</td>\n",
       "      <td>10.60</td>\n",
       "      <td>16.43</td>\n",
       "      <td>16.73</td>\n",
       "      <td>9.29</td>\n",
       "      <td>52.66</td>\n",
       "      <td>8.15</td>\n",
       "      <td>19.87</td>\n",
       "      <td>13.55</td>\n",
       "      <td>6.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.38</td>\n",
       "      <td>13.60</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.82</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.68</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.32</td>\n",
       "      <td>24.72</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-18</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.58</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.52</td>\n",
       "      <td>10.12</td>\n",
       "      <td>15.21</td>\n",
       "      <td>45.46</td>\n",
       "      <td>8.47</td>\n",
       "      <td>24.66</td>\n",
       "      <td>13.26</td>\n",
       "      <td>63.81</td>\n",
       "      <td>4.93</td>\n",
       "      <td>177.38</td>\n",
       "      <td>10.48</td>\n",
       "      <td>16.82</td>\n",
       "      <td>16.49</td>\n",
       "      <td>9.08</td>\n",
       "      <td>51.61</td>\n",
       "      <td>8.07</td>\n",
       "      <td>19.14</td>\n",
       "      <td>13.32</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.88</td>\n",
       "      <td>13.43</td>\n",
       "      <td>2.69</td>\n",
       "      <td>37.45</td>\n",
       "      <td>4.31</td>\n",
       "      <td>20.50</td>\n",
       "      <td>18.45</td>\n",
       "      <td>12.77</td>\n",
       "      <td>3.05</td>\n",
       "      <td>8.22</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.01</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-19</th>\n",
       "      <td>4.78</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.81</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.67</td>\n",
       "      <td>15.46</td>\n",
       "      <td>46.58</td>\n",
       "      <td>8.62</td>\n",
       "      <td>25.20</td>\n",
       "      <td>13.76</td>\n",
       "      <td>64.29</td>\n",
       "      <td>5.01</td>\n",
       "      <td>180.70</td>\n",
       "      <td>10.33</td>\n",
       "      <td>17.15</td>\n",
       "      <td>16.19</td>\n",
       "      <td>9.40</td>\n",
       "      <td>52.84</td>\n",
       "      <td>8.38</td>\n",
       "      <td>19.98</td>\n",
       "      <td>13.20</td>\n",
       "      <td>6.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.10</td>\n",
       "      <td>13.78</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.51</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.22</td>\n",
       "      <td>19.00</td>\n",
       "      <td>12.88</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.48</td>\n",
       "      <td>10.26</td>\n",
       "      <td>24.41</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-20</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.74</td>\n",
       "      <td>11.01</td>\n",
       "      <td>13.99</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.94</td>\n",
       "      <td>15.52</td>\n",
       "      <td>45.62</td>\n",
       "      <td>8.80</td>\n",
       "      <td>26.68</td>\n",
       "      <td>14.09</td>\n",
       "      <td>65.74</td>\n",
       "      <td>5.10</td>\n",
       "      <td>185.97</td>\n",
       "      <td>10.41</td>\n",
       "      <td>17.79</td>\n",
       "      <td>16.48</td>\n",
       "      <td>9.51</td>\n",
       "      <td>54.34</td>\n",
       "      <td>8.60</td>\n",
       "      <td>20.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.48</td>\n",
       "      <td>14.05</td>\n",
       "      <td>2.72</td>\n",
       "      <td>39.10</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.84</td>\n",
       "      <td>19.33</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3.14</td>\n",
       "      <td>8.50</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-30</th>\n",
       "      <td>4.75</td>\n",
       "      <td>7.70</td>\n",
       "      <td>10.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.70</td>\n",
       "      <td>10.43</td>\n",
       "      <td>15.48</td>\n",
       "      <td>46.06</td>\n",
       "      <td>8.63</td>\n",
       "      <td>26.19</td>\n",
       "      <td>13.67</td>\n",
       "      <td>64.87</td>\n",
       "      <td>5.04</td>\n",
       "      <td>183.80</td>\n",
       "      <td>10.37</td>\n",
       "      <td>17.38</td>\n",
       "      <td>16.23</td>\n",
       "      <td>9.24</td>\n",
       "      <td>53.30</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.33</td>\n",
       "      <td>13.49</td>\n",
       "      <td>6.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.68</td>\n",
       "      <td>13.83</td>\n",
       "      <td>2.68</td>\n",
       "      <td>38.60</td>\n",
       "      <td>4.27</td>\n",
       "      <td>21.11</td>\n",
       "      <td>18.90</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.13</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.49</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-31</th>\n",
       "      <td>4.87</td>\n",
       "      <td>7.76</td>\n",
       "      <td>10.69</td>\n",
       "      <td>14.21</td>\n",
       "      <td>12.65</td>\n",
       "      <td>10.50</td>\n",
       "      <td>15.09</td>\n",
       "      <td>46.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.93</td>\n",
       "      <td>5.08</td>\n",
       "      <td>186.41</td>\n",
       "      <td>10.39</td>\n",
       "      <td>17.37</td>\n",
       "      <td>16.45</td>\n",
       "      <td>9.21</td>\n",
       "      <td>54.97</td>\n",
       "      <td>8.36</td>\n",
       "      <td>20.44</td>\n",
       "      <td>13.48</td>\n",
       "      <td>6.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.85</td>\n",
       "      <td>13.86</td>\n",
       "      <td>2.70</td>\n",
       "      <td>38.34</td>\n",
       "      <td>4.30</td>\n",
       "      <td>21.01</td>\n",
       "      <td>18.78</td>\n",
       "      <td>12.57</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.33</td>\n",
       "      <td>10.21</td>\n",
       "      <td>24.73</td>\n",
       "      <td>4.44</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>4.73</td>\n",
       "      <td>7.79</td>\n",
       "      <td>10.47</td>\n",
       "      <td>13.80</td>\n",
       "      <td>12.47</td>\n",
       "      <td>10.31</td>\n",
       "      <td>14.93</td>\n",
       "      <td>44.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>25.86</td>\n",
       "      <td>13.78</td>\n",
       "      <td>66.52</td>\n",
       "      <td>5.05</td>\n",
       "      <td>186.15</td>\n",
       "      <td>10.64</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.68</td>\n",
       "      <td>9.10</td>\n",
       "      <td>54.98</td>\n",
       "      <td>8.10</td>\n",
       "      <td>20.60</td>\n",
       "      <td>13.12</td>\n",
       "      <td>6.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.57</td>\n",
       "      <td>13.56</td>\n",
       "      <td>2.68</td>\n",
       "      <td>37.41</td>\n",
       "      <td>4.28</td>\n",
       "      <td>20.65</td>\n",
       "      <td>18.34</td>\n",
       "      <td>12.40</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.16</td>\n",
       "      <td>10.18</td>\n",
       "      <td>24.71</td>\n",
       "      <td>4.37</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-02</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.86</td>\n",
       "      <td>10.80</td>\n",
       "      <td>14.06</td>\n",
       "      <td>12.87</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.22</td>\n",
       "      <td>45.57</td>\n",
       "      <td>8.64</td>\n",
       "      <td>26.24</td>\n",
       "      <td>14.05</td>\n",
       "      <td>66.67</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.43</td>\n",
       "      <td>10.77</td>\n",
       "      <td>16.90</td>\n",
       "      <td>17.14</td>\n",
       "      <td>9.19</td>\n",
       "      <td>55.72</td>\n",
       "      <td>8.53</td>\n",
       "      <td>20.92</td>\n",
       "      <td>13.31</td>\n",
       "      <td>6.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.24</td>\n",
       "      <td>14.15</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.64</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.41</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.36</td>\n",
       "      <td>10.21</td>\n",
       "      <td>25.10</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-03</th>\n",
       "      <td>4.83</td>\n",
       "      <td>7.81</td>\n",
       "      <td>10.90</td>\n",
       "      <td>13.94</td>\n",
       "      <td>12.98</td>\n",
       "      <td>10.68</td>\n",
       "      <td>15.40</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.76</td>\n",
       "      <td>26.39</td>\n",
       "      <td>14.42</td>\n",
       "      <td>66.89</td>\n",
       "      <td>5.25</td>\n",
       "      <td>186.48</td>\n",
       "      <td>11.00</td>\n",
       "      <td>16.72</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.17</td>\n",
       "      <td>57.00</td>\n",
       "      <td>8.47</td>\n",
       "      <td>20.90</td>\n",
       "      <td>13.79</td>\n",
       "      <td>6.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.18</td>\n",
       "      <td>2.75</td>\n",
       "      <td>40.15</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.86</td>\n",
       "      <td>19.30</td>\n",
       "      <td>12.54</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>10.22</td>\n",
       "      <td>24.89</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-06</th>\n",
       "      <td>4.82</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.84</td>\n",
       "      <td>13.89</td>\n",
       "      <td>12.86</td>\n",
       "      <td>10.45</td>\n",
       "      <td>15.25</td>\n",
       "      <td>45.61</td>\n",
       "      <td>8.79</td>\n",
       "      <td>27.05</td>\n",
       "      <td>14.59</td>\n",
       "      <td>68.41</td>\n",
       "      <td>5.27</td>\n",
       "      <td>188.54</td>\n",
       "      <td>11.00</td>\n",
       "      <td>17.07</td>\n",
       "      <td>17.93</td>\n",
       "      <td>9.27</td>\n",
       "      <td>58.59</td>\n",
       "      <td>8.45</td>\n",
       "      <td>21.56</td>\n",
       "      <td>13.68</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>14.17</td>\n",
       "      <td>2.75</td>\n",
       "      <td>39.62</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.36</td>\n",
       "      <td>18.92</td>\n",
       "      <td>12.73</td>\n",
       "      <td>3.07</td>\n",
       "      <td>8.26</td>\n",
       "      <td>10.23</td>\n",
       "      <td>25.01</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-07</th>\n",
       "      <td>4.69</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.52</td>\n",
       "      <td>13.54</td>\n",
       "      <td>12.73</td>\n",
       "      <td>10.13</td>\n",
       "      <td>15.22</td>\n",
       "      <td>44.55</td>\n",
       "      <td>8.60</td>\n",
       "      <td>26.53</td>\n",
       "      <td>14.26</td>\n",
       "      <td>68.22</td>\n",
       "      <td>5.09</td>\n",
       "      <td>185.86</td>\n",
       "      <td>10.75</td>\n",
       "      <td>16.52</td>\n",
       "      <td>17.46</td>\n",
       "      <td>9.07</td>\n",
       "      <td>57.61</td>\n",
       "      <td>8.21</td>\n",
       "      <td>21.50</td>\n",
       "      <td>14.74</td>\n",
       "      <td>6.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>2.72</td>\n",
       "      <td>38.91</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.79</td>\n",
       "      <td>18.50</td>\n",
       "      <td>12.65</td>\n",
       "      <td>3.01</td>\n",
       "      <td>8.05</td>\n",
       "      <td>10.09</td>\n",
       "      <td>25.42</td>\n",
       "      <td>4.35</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-08</th>\n",
       "      <td>4.90</td>\n",
       "      <td>7.78</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.42</td>\n",
       "      <td>15.59</td>\n",
       "      <td>48.51</td>\n",
       "      <td>8.79</td>\n",
       "      <td>26.59</td>\n",
       "      <td>14.81</td>\n",
       "      <td>68.80</td>\n",
       "      <td>5.20</td>\n",
       "      <td>188.29</td>\n",
       "      <td>11.04</td>\n",
       "      <td>17.15</td>\n",
       "      <td>17.90</td>\n",
       "      <td>9.28</td>\n",
       "      <td>59.17</td>\n",
       "      <td>8.67</td>\n",
       "      <td>21.80</td>\n",
       "      <td>15.24</td>\n",
       "      <td>6.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.63</td>\n",
       "      <td>14.43</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.41</td>\n",
       "      <td>21.75</td>\n",
       "      <td>19.24</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.09</td>\n",
       "      <td>8.36</td>\n",
       "      <td>10.26</td>\n",
       "      <td>25.87</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-09</th>\n",
       "      <td>4.88</td>\n",
       "      <td>7.69</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.77</td>\n",
       "      <td>12.99</td>\n",
       "      <td>10.56</td>\n",
       "      <td>15.49</td>\n",
       "      <td>47.57</td>\n",
       "      <td>8.87</td>\n",
       "      <td>26.93</td>\n",
       "      <td>14.91</td>\n",
       "      <td>68.77</td>\n",
       "      <td>5.26</td>\n",
       "      <td>190.75</td>\n",
       "      <td>11.11</td>\n",
       "      <td>17.40</td>\n",
       "      <td>17.98</td>\n",
       "      <td>9.33</td>\n",
       "      <td>59.40</td>\n",
       "      <td>8.57</td>\n",
       "      <td>21.32</td>\n",
       "      <td>15.13</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.53</td>\n",
       "      <td>14.42</td>\n",
       "      <td>2.73</td>\n",
       "      <td>39.88</td>\n",
       "      <td>4.42</td>\n",
       "      <td>21.26</td>\n",
       "      <td>19.07</td>\n",
       "      <td>12.98</td>\n",
       "      <td>3.08</td>\n",
       "      <td>8.27</td>\n",
       "      <td>10.29</td>\n",
       "      <td>25.77</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-10</th>\n",
       "      <td>5.08</td>\n",
       "      <td>7.67</td>\n",
       "      <td>10.97</td>\n",
       "      <td>13.88</td>\n",
       "      <td>12.89</td>\n",
       "      <td>10.91</td>\n",
       "      <td>15.45</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.90</td>\n",
       "      <td>26.63</td>\n",
       "      <td>14.66</td>\n",
       "      <td>68.61</td>\n",
       "      <td>5.32</td>\n",
       "      <td>190.51</td>\n",
       "      <td>11.06</td>\n",
       "      <td>17.51</td>\n",
       "      <td>17.70</td>\n",
       "      <td>9.33</td>\n",
       "      <td>59.00</td>\n",
       "      <td>8.65</td>\n",
       "      <td>21.76</td>\n",
       "      <td>15.29</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.45</td>\n",
       "      <td>14.24</td>\n",
       "      <td>2.72</td>\n",
       "      <td>40.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.61</td>\n",
       "      <td>18.93</td>\n",
       "      <td>13.03</td>\n",
       "      <td>3.21</td>\n",
       "      <td>8.32</td>\n",
       "      <td>10.31</td>\n",
       "      <td>25.91</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-13</th>\n",
       "      <td>5.04</td>\n",
       "      <td>7.65</td>\n",
       "      <td>10.95</td>\n",
       "      <td>13.84</td>\n",
       "      <td>12.69</td>\n",
       "      <td>10.57</td>\n",
       "      <td>15.76</td>\n",
       "      <td>47.65</td>\n",
       "      <td>8.84</td>\n",
       "      <td>26.99</td>\n",
       "      <td>14.58</td>\n",
       "      <td>68.67</td>\n",
       "      <td>5.37</td>\n",
       "      <td>193.42</td>\n",
       "      <td>11.21</td>\n",
       "      <td>17.25</td>\n",
       "      <td>18.36</td>\n",
       "      <td>9.28</td>\n",
       "      <td>59.85</td>\n",
       "      <td>8.55</td>\n",
       "      <td>22.11</td>\n",
       "      <td>15.57</td>\n",
       "      <td>6.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.13</td>\n",
       "      <td>2.71</td>\n",
       "      <td>40.28</td>\n",
       "      <td>4.37</td>\n",
       "      <td>21.41</td>\n",
       "      <td>18.64</td>\n",
       "      <td>13.41</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>10.26</td>\n",
       "      <td>26.08</td>\n",
       "      <td>4.53</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-14</th>\n",
       "      <td>5.01</td>\n",
       "      <td>7.66</td>\n",
       "      <td>10.87</td>\n",
       "      <td>13.69</td>\n",
       "      <td>12.66</td>\n",
       "      <td>10.62</td>\n",
       "      <td>15.52</td>\n",
       "      <td>47.50</td>\n",
       "      <td>8.89</td>\n",
       "      <td>26.87</td>\n",
       "      <td>14.31</td>\n",
       "      <td>69.29</td>\n",
       "      <td>5.38</td>\n",
       "      <td>193.82</td>\n",
       "      <td>11.27</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.06</td>\n",
       "      <td>9.24</td>\n",
       "      <td>60.71</td>\n",
       "      <td>8.49</td>\n",
       "      <td>22.09</td>\n",
       "      <td>15.42</td>\n",
       "      <td>6.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>14.08</td>\n",
       "      <td>2.70</td>\n",
       "      <td>39.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.83</td>\n",
       "      <td>18.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.37</td>\n",
       "      <td>10.24</td>\n",
       "      <td>26.03</td>\n",
       "      <td>4.48</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>2.09</td>\n",
       "      <td>4.25</td>\n",
       "      <td>19.40</td>\n",
       "      <td>15.52</td>\n",
       "      <td>33.70</td>\n",
       "      <td>16.68</td>\n",
       "      <td>15.88</td>\n",
       "      <td>30.84</td>\n",
       "      <td>40.93</td>\n",
       "      <td>34.77</td>\n",
       "      <td>88.67</td>\n",
       "      <td>294.00</td>\n",
       "      <td>56.43</td>\n",
       "      <td>1898.00</td>\n",
       "      <td>32.44</td>\n",
       "      <td>31.81</td>\n",
       "      <td>20.00</td>\n",
       "      <td>24.33</td>\n",
       "      <td>286.93</td>\n",
       "      <td>9.51</td>\n",
       "      <td>36.19</td>\n",
       "      <td>48.17</td>\n",
       "      <td>23.39</td>\n",
       "      <td>53.06</td>\n",
       "      <td>31.26</td>\n",
       "      <td>17.88</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.12</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.29</td>\n",
       "      <td>29.44</td>\n",
       "      <td>35.35</td>\n",
       "      <td>5.01</td>\n",
       "      <td>13.13</td>\n",
       "      <td>5.44</td>\n",
       "      <td>192.41</td>\n",
       "      <td>9.15</td>\n",
       "      <td>13.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>2.07</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.56</td>\n",
       "      <td>33.28</td>\n",
       "      <td>16.61</td>\n",
       "      <td>15.50</td>\n",
       "      <td>30.59</td>\n",
       "      <td>40.61</td>\n",
       "      <td>34.23</td>\n",
       "      <td>87.80</td>\n",
       "      <td>291.09</td>\n",
       "      <td>56.78</td>\n",
       "      <td>1878.82</td>\n",
       "      <td>32.70</td>\n",
       "      <td>31.42</td>\n",
       "      <td>19.29</td>\n",
       "      <td>24.57</td>\n",
       "      <td>285.30</td>\n",
       "      <td>9.45</td>\n",
       "      <td>35.95</td>\n",
       "      <td>49.91</td>\n",
       "      <td>23.30</td>\n",
       "      <td>53.41</td>\n",
       "      <td>31.88</td>\n",
       "      <td>16.93</td>\n",
       "      <td>2.82</td>\n",
       "      <td>43.07</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.17</td>\n",
       "      <td>29.02</td>\n",
       "      <td>33.96</td>\n",
       "      <td>5.04</td>\n",
       "      <td>13.02</td>\n",
       "      <td>5.48</td>\n",
       "      <td>192.25</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.29</td>\n",
       "      <td>19.25</td>\n",
       "      <td>15.58</td>\n",
       "      <td>33.79</td>\n",
       "      <td>16.95</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.37</td>\n",
       "      <td>40.08</td>\n",
       "      <td>33.67</td>\n",
       "      <td>88.45</td>\n",
       "      <td>288.36</td>\n",
       "      <td>55.56</td>\n",
       "      <td>1870.00</td>\n",
       "      <td>33.33</td>\n",
       "      <td>30.99</td>\n",
       "      <td>20.07</td>\n",
       "      <td>25.40</td>\n",
       "      <td>284.09</td>\n",
       "      <td>9.41</td>\n",
       "      <td>36.13</td>\n",
       "      <td>47.88</td>\n",
       "      <td>23.28</td>\n",
       "      <td>52.80</td>\n",
       "      <td>30.52</td>\n",
       "      <td>16.82</td>\n",
       "      <td>2.82</td>\n",
       "      <td>42.89</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.47</td>\n",
       "      <td>29.50</td>\n",
       "      <td>34.20</td>\n",
       "      <td>5.07</td>\n",
       "      <td>13.11</td>\n",
       "      <td>5.47</td>\n",
       "      <td>190.40</td>\n",
       "      <td>8.90</td>\n",
       "      <td>14.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>2.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>19.52</td>\n",
       "      <td>15.75</td>\n",
       "      <td>35.05</td>\n",
       "      <td>17.30</td>\n",
       "      <td>15.47</td>\n",
       "      <td>30.14</td>\n",
       "      <td>40.36</td>\n",
       "      <td>34.66</td>\n",
       "      <td>88.57</td>\n",
       "      <td>300.99</td>\n",
       "      <td>52.88</td>\n",
       "      <td>1924.00</td>\n",
       "      <td>33.64</td>\n",
       "      <td>31.92</td>\n",
       "      <td>20.09</td>\n",
       "      <td>25.87</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.48</td>\n",
       "      <td>35.74</td>\n",
       "      <td>45.97</td>\n",
       "      <td>23.98</td>\n",
       "      <td>51.20</td>\n",
       "      <td>30.34</td>\n",
       "      <td>17.11</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.97</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.46</td>\n",
       "      <td>5.14</td>\n",
       "      <td>13.14</td>\n",
       "      <td>5.34</td>\n",
       "      <td>195.50</td>\n",
       "      <td>8.80</td>\n",
       "      <td>14.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.23</td>\n",
       "      <td>19.30</td>\n",
       "      <td>15.85</td>\n",
       "      <td>34.50</td>\n",
       "      <td>17.31</td>\n",
       "      <td>15.30</td>\n",
       "      <td>30.09</td>\n",
       "      <td>40.90</td>\n",
       "      <td>34.34</td>\n",
       "      <td>88.11</td>\n",
       "      <td>298.30</td>\n",
       "      <td>52.82</td>\n",
       "      <td>1880.89</td>\n",
       "      <td>34.50</td>\n",
       "      <td>31.60</td>\n",
       "      <td>20.37</td>\n",
       "      <td>26.21</td>\n",
       "      <td>292.58</td>\n",
       "      <td>9.39</td>\n",
       "      <td>34.55</td>\n",
       "      <td>45.88</td>\n",
       "      <td>23.91</td>\n",
       "      <td>51.65</td>\n",
       "      <td>31.11</td>\n",
       "      <td>17.11</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.82</td>\n",
       "      <td>30.45</td>\n",
       "      <td>32.25</td>\n",
       "      <td>5.15</td>\n",
       "      <td>13.00</td>\n",
       "      <td>5.36</td>\n",
       "      <td>186.80</td>\n",
       "      <td>8.65</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.26</td>\n",
       "      <td>19.24</td>\n",
       "      <td>15.61</td>\n",
       "      <td>34.32</td>\n",
       "      <td>17.02</td>\n",
       "      <td>15.26</td>\n",
       "      <td>30.16</td>\n",
       "      <td>40.21</td>\n",
       "      <td>33.90</td>\n",
       "      <td>86.95</td>\n",
       "      <td>296.11</td>\n",
       "      <td>52.21</td>\n",
       "      <td>1875.00</td>\n",
       "      <td>34.37</td>\n",
       "      <td>31.17</td>\n",
       "      <td>20.15</td>\n",
       "      <td>25.63</td>\n",
       "      <td>288.53</td>\n",
       "      <td>9.32</td>\n",
       "      <td>33.90</td>\n",
       "      <td>45.22</td>\n",
       "      <td>23.82</td>\n",
       "      <td>50.95</td>\n",
       "      <td>30.66</td>\n",
       "      <td>17.03</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.70</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.75</td>\n",
       "      <td>29.70</td>\n",
       "      <td>31.65</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.92</td>\n",
       "      <td>5.42</td>\n",
       "      <td>180.31</td>\n",
       "      <td>8.52</td>\n",
       "      <td>13.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05</th>\n",
       "      <td>2.03</td>\n",
       "      <td>4.34</td>\n",
       "      <td>19.27</td>\n",
       "      <td>15.45</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.22</td>\n",
       "      <td>15.21</td>\n",
       "      <td>30.08</td>\n",
       "      <td>36.19</td>\n",
       "      <td>33.73</td>\n",
       "      <td>88.65</td>\n",
       "      <td>294.00</td>\n",
       "      <td>52.45</td>\n",
       "      <td>1835.00</td>\n",
       "      <td>33.73</td>\n",
       "      <td>31.01</td>\n",
       "      <td>19.79</td>\n",
       "      <td>25.58</td>\n",
       "      <td>282.78</td>\n",
       "      <td>9.40</td>\n",
       "      <td>33.37</td>\n",
       "      <td>45.77</td>\n",
       "      <td>23.82</td>\n",
       "      <td>50.49</td>\n",
       "      <td>32.56</td>\n",
       "      <td>17.08</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.80</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.90</td>\n",
       "      <td>29.86</td>\n",
       "      <td>31.19</td>\n",
       "      <td>5.17</td>\n",
       "      <td>13.05</td>\n",
       "      <td>5.56</td>\n",
       "      <td>180.10</td>\n",
       "      <td>8.59</td>\n",
       "      <td>13.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.48</td>\n",
       "      <td>15.73</td>\n",
       "      <td>33.62</td>\n",
       "      <td>17.63</td>\n",
       "      <td>15.42</td>\n",
       "      <td>30.85</td>\n",
       "      <td>35.42</td>\n",
       "      <td>33.88</td>\n",
       "      <td>91.50</td>\n",
       "      <td>294.02</td>\n",
       "      <td>56.87</td>\n",
       "      <td>1845.00</td>\n",
       "      <td>33.66</td>\n",
       "      <td>31.00</td>\n",
       "      <td>19.71</td>\n",
       "      <td>25.69</td>\n",
       "      <td>286.02</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.63</td>\n",
       "      <td>47.14</td>\n",
       "      <td>23.75</td>\n",
       "      <td>53.16</td>\n",
       "      <td>32.88</td>\n",
       "      <td>17.06</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.90</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.08</td>\n",
       "      <td>30.34</td>\n",
       "      <td>31.84</td>\n",
       "      <td>5.24</td>\n",
       "      <td>13.18</td>\n",
       "      <td>5.61</td>\n",
       "      <td>182.72</td>\n",
       "      <td>8.84</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.37</td>\n",
       "      <td>15.60</td>\n",
       "      <td>33.38</td>\n",
       "      <td>17.55</td>\n",
       "      <td>15.40</td>\n",
       "      <td>30.79</td>\n",
       "      <td>35.55</td>\n",
       "      <td>33.43</td>\n",
       "      <td>90.52</td>\n",
       "      <td>291.48</td>\n",
       "      <td>56.69</td>\n",
       "      <td>1818.01</td>\n",
       "      <td>33.59</td>\n",
       "      <td>30.41</td>\n",
       "      <td>19.62</td>\n",
       "      <td>25.80</td>\n",
       "      <td>278.12</td>\n",
       "      <td>9.47</td>\n",
       "      <td>33.22</td>\n",
       "      <td>47.24</td>\n",
       "      <td>23.57</td>\n",
       "      <td>53.46</td>\n",
       "      <td>32.61</td>\n",
       "      <td>17.09</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.60</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.98</td>\n",
       "      <td>30.25</td>\n",
       "      <td>32.09</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>5.58</td>\n",
       "      <td>183.95</td>\n",
       "      <td>8.94</td>\n",
       "      <td>13.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>2.04</td>\n",
       "      <td>4.41</td>\n",
       "      <td>19.31</td>\n",
       "      <td>15.75</td>\n",
       "      <td>33.30</td>\n",
       "      <td>17.58</td>\n",
       "      <td>15.35</td>\n",
       "      <td>30.29</td>\n",
       "      <td>33.96</td>\n",
       "      <td>33.73</td>\n",
       "      <td>92.01</td>\n",
       "      <td>293.75</td>\n",
       "      <td>56.50</td>\n",
       "      <td>1815.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>30.20</td>\n",
       "      <td>19.33</td>\n",
       "      <td>25.88</td>\n",
       "      <td>285.59</td>\n",
       "      <td>9.44</td>\n",
       "      <td>33.27</td>\n",
       "      <td>47.76</td>\n",
       "      <td>23.65</td>\n",
       "      <td>53.39</td>\n",
       "      <td>32.30</td>\n",
       "      <td>17.01</td>\n",
       "      <td>2.83</td>\n",
       "      <td>43.84</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.95</td>\n",
       "      <td>30.76</td>\n",
       "      <td>30.98</td>\n",
       "      <td>5.23</td>\n",
       "      <td>13.14</td>\n",
       "      <td>5.53</td>\n",
       "      <td>186.00</td>\n",
       "      <td>9.06</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.45</td>\n",
       "      <td>19.78</td>\n",
       "      <td>16.26</td>\n",
       "      <td>34.50</td>\n",
       "      <td>18.47</td>\n",
       "      <td>15.48</td>\n",
       "      <td>30.68</td>\n",
       "      <td>35.00</td>\n",
       "      <td>34.78</td>\n",
       "      <td>95.61</td>\n",
       "      <td>298.11</td>\n",
       "      <td>54.56</td>\n",
       "      <td>1844.79</td>\n",
       "      <td>35.30</td>\n",
       "      <td>31.37</td>\n",
       "      <td>19.54</td>\n",
       "      <td>26.50</td>\n",
       "      <td>291.21</td>\n",
       "      <td>9.54</td>\n",
       "      <td>33.70</td>\n",
       "      <td>48.03</td>\n",
       "      <td>23.91</td>\n",
       "      <td>53.18</td>\n",
       "      <td>32.73</td>\n",
       "      <td>17.38</td>\n",
       "      <td>2.84</td>\n",
       "      <td>44.69</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.47</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.31</td>\n",
       "      <td>5.36</td>\n",
       "      <td>13.28</td>\n",
       "      <td>5.59</td>\n",
       "      <td>191.09</td>\n",
       "      <td>9.19</td>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>2.05</td>\n",
       "      <td>4.43</td>\n",
       "      <td>19.83</td>\n",
       "      <td>16.30</td>\n",
       "      <td>35.35</td>\n",
       "      <td>18.09</td>\n",
       "      <td>15.65</td>\n",
       "      <td>31.47</td>\n",
       "      <td>34.44</td>\n",
       "      <td>35.52</td>\n",
       "      <td>93.00</td>\n",
       "      <td>302.00</td>\n",
       "      <td>54.99</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>36.15</td>\n",
       "      <td>31.96</td>\n",
       "      <td>19.58</td>\n",
       "      <td>26.48</td>\n",
       "      <td>293.00</td>\n",
       "      <td>9.52</td>\n",
       "      <td>33.74</td>\n",
       "      <td>49.00</td>\n",
       "      <td>23.79</td>\n",
       "      <td>53.27</td>\n",
       "      <td>32.45</td>\n",
       "      <td>17.59</td>\n",
       "      <td>2.85</td>\n",
       "      <td>45.06</td>\n",
       "      <td>4.38</td>\n",
       "      <td>21.52</td>\n",
       "      <td>31.46</td>\n",
       "      <td>32.00</td>\n",
       "      <td>5.32</td>\n",
       "      <td>13.24</td>\n",
       "      <td>5.55</td>\n",
       "      <td>192.47</td>\n",
       "      <td>9.29</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>2.02</td>\n",
       "      <td>4.38</td>\n",
       "      <td>19.58</td>\n",
       "      <td>16.15</td>\n",
       "      <td>34.86</td>\n",
       "      <td>18.14</td>\n",
       "      <td>15.44</td>\n",
       "      <td>30.70</td>\n",
       "      <td>33.76</td>\n",
       "      <td>35.68</td>\n",
       "      <td>91.36</td>\n",
       "      <td>300.29</td>\n",
       "      <td>53.73</td>\n",
       "      <td>1869.00</td>\n",
       "      <td>36.30</td>\n",
       "      <td>31.59</td>\n",
       "      <td>19.71</td>\n",
       "      <td>26.49</td>\n",
       "      <td>292.30</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.60</td>\n",
       "      <td>49.23</td>\n",
       "      <td>23.70</td>\n",
       "      <td>52.55</td>\n",
       "      <td>32.35</td>\n",
       "      <td>17.38</td>\n",
       "      <td>2.85</td>\n",
       "      <td>44.65</td>\n",
       "      <td>4.36</td>\n",
       "      <td>21.26</td>\n",
       "      <td>31.63</td>\n",
       "      <td>31.74</td>\n",
       "      <td>5.26</td>\n",
       "      <td>13.11</td>\n",
       "      <td>5.52</td>\n",
       "      <td>191.55</td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>2.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>19.53</td>\n",
       "      <td>16.20</td>\n",
       "      <td>36.01</td>\n",
       "      <td>18.85</td>\n",
       "      <td>15.34</td>\n",
       "      <td>30.01</td>\n",
       "      <td>33.04</td>\n",
       "      <td>35.49</td>\n",
       "      <td>91.50</td>\n",
       "      <td>298.56</td>\n",
       "      <td>51.30</td>\n",
       "      <td>1880.00</td>\n",
       "      <td>35.71</td>\n",
       "      <td>32.23</td>\n",
       "      <td>19.45</td>\n",
       "      <td>26.88</td>\n",
       "      <td>296.00</td>\n",
       "      <td>9.46</td>\n",
       "      <td>33.69</td>\n",
       "      <td>47.20</td>\n",
       "      <td>23.72</td>\n",
       "      <td>48.66</td>\n",
       "      <td>32.39</td>\n",
       "      <td>17.69</td>\n",
       "      <td>2.87</td>\n",
       "      <td>45.09</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.31</td>\n",
       "      <td>31.74</td>\n",
       "      <td>30.57</td>\n",
       "      <td>5.37</td>\n",
       "      <td>13.08</td>\n",
       "      <td>5.54</td>\n",
       "      <td>191.35</td>\n",
       "      <td>8.95</td>\n",
       "      <td>12.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.30</td>\n",
       "      <td>18.42</td>\n",
       "      <td>15.60</td>\n",
       "      <td>34.95</td>\n",
       "      <td>18.05</td>\n",
       "      <td>15.02</td>\n",
       "      <td>28.80</td>\n",
       "      <td>32.17</td>\n",
       "      <td>34.83</td>\n",
       "      <td>90.38</td>\n",
       "      <td>293.20</td>\n",
       "      <td>49.52</td>\n",
       "      <td>1859.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>31.19</td>\n",
       "      <td>19.53</td>\n",
       "      <td>26.06</td>\n",
       "      <td>289.50</td>\n",
       "      <td>9.05</td>\n",
       "      <td>32.88</td>\n",
       "      <td>46.88</td>\n",
       "      <td>23.46</td>\n",
       "      <td>48.30</td>\n",
       "      <td>30.96</td>\n",
       "      <td>17.22</td>\n",
       "      <td>2.85</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.36</td>\n",
       "      <td>20.88</td>\n",
       "      <td>31.06</td>\n",
       "      <td>28.88</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.41</td>\n",
       "      <td>5.37</td>\n",
       "      <td>188.51</td>\n",
       "      <td>8.68</td>\n",
       "      <td>12.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.18</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.97</td>\n",
       "      <td>35.09</td>\n",
       "      <td>18.44</td>\n",
       "      <td>15.01</td>\n",
       "      <td>28.34</td>\n",
       "      <td>32.19</td>\n",
       "      <td>34.69</td>\n",
       "      <td>91.36</td>\n",
       "      <td>289.50</td>\n",
       "      <td>49.87</td>\n",
       "      <td>1871.64</td>\n",
       "      <td>33.69</td>\n",
       "      <td>30.45</td>\n",
       "      <td>18.03</td>\n",
       "      <td>26.16</td>\n",
       "      <td>293.75</td>\n",
       "      <td>9.06</td>\n",
       "      <td>32.90</td>\n",
       "      <td>46.01</td>\n",
       "      <td>23.48</td>\n",
       "      <td>48.12</td>\n",
       "      <td>31.50</td>\n",
       "      <td>17.34</td>\n",
       "      <td>2.87</td>\n",
       "      <td>43.93</td>\n",
       "      <td>4.38</td>\n",
       "      <td>20.42</td>\n",
       "      <td>30.86</td>\n",
       "      <td>29.98</td>\n",
       "      <td>5.24</td>\n",
       "      <td>12.35</td>\n",
       "      <td>5.35</td>\n",
       "      <td>188.45</td>\n",
       "      <td>8.62</td>\n",
       "      <td>12.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>1.95</td>\n",
       "      <td>4.22</td>\n",
       "      <td>18.42</td>\n",
       "      <td>14.96</td>\n",
       "      <td>34.54</td>\n",
       "      <td>17.64</td>\n",
       "      <td>14.89</td>\n",
       "      <td>29.01</td>\n",
       "      <td>32.27</td>\n",
       "      <td>34.13</td>\n",
       "      <td>89.55</td>\n",
       "      <td>289.35</td>\n",
       "      <td>50.30</td>\n",
       "      <td>1878.00</td>\n",
       "      <td>32.77</td>\n",
       "      <td>29.58</td>\n",
       "      <td>18.19</td>\n",
       "      <td>25.87</td>\n",
       "      <td>296.09</td>\n",
       "      <td>9.09</td>\n",
       "      <td>32.66</td>\n",
       "      <td>45.75</td>\n",
       "      <td>23.42</td>\n",
       "      <td>50.04</td>\n",
       "      <td>31.35</td>\n",
       "      <td>17.08</td>\n",
       "      <td>2.84</td>\n",
       "      <td>43.24</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.10</td>\n",
       "      <td>29.84</td>\n",
       "      <td>29.83</td>\n",
       "      <td>5.11</td>\n",
       "      <td>12.33</td>\n",
       "      <td>5.16</td>\n",
       "      <td>194.23</td>\n",
       "      <td>8.70</td>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>1.98</td>\n",
       "      <td>4.25</td>\n",
       "      <td>18.43</td>\n",
       "      <td>15.06</td>\n",
       "      <td>34.41</td>\n",
       "      <td>17.83</td>\n",
       "      <td>14.92</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.70</td>\n",
       "      <td>33.43</td>\n",
       "      <td>87.94</td>\n",
       "      <td>281.08</td>\n",
       "      <td>50.09</td>\n",
       "      <td>1848.00</td>\n",
       "      <td>32.74</td>\n",
       "      <td>29.18</td>\n",
       "      <td>18.29</td>\n",
       "      <td>25.19</td>\n",
       "      <td>292.15</td>\n",
       "      <td>9.07</td>\n",
       "      <td>32.48</td>\n",
       "      <td>44.80</td>\n",
       "      <td>23.43</td>\n",
       "      <td>49.19</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.15</td>\n",
       "      <td>2.86</td>\n",
       "      <td>43.15</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20.25</td>\n",
       "      <td>29.82</td>\n",
       "      <td>29.44</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.33</td>\n",
       "      <td>5.23</td>\n",
       "      <td>185.54</td>\n",
       "      <td>8.71</td>\n",
       "      <td>12.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.39</td>\n",
       "      <td>18.39</td>\n",
       "      <td>14.69</td>\n",
       "      <td>34.17</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.81</td>\n",
       "      <td>29.39</td>\n",
       "      <td>30.99</td>\n",
       "      <td>32.64</td>\n",
       "      <td>88.05</td>\n",
       "      <td>260.85</td>\n",
       "      <td>49.12</td>\n",
       "      <td>1820.81</td>\n",
       "      <td>32.80</td>\n",
       "      <td>28.73</td>\n",
       "      <td>18.49</td>\n",
       "      <td>24.56</td>\n",
       "      <td>292.44</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.00</td>\n",
       "      <td>46.60</td>\n",
       "      <td>23.42</td>\n",
       "      <td>49.18</td>\n",
       "      <td>31.99</td>\n",
       "      <td>17.05</td>\n",
       "      <td>2.86</td>\n",
       "      <td>42.48</td>\n",
       "      <td>4.39</td>\n",
       "      <td>20.26</td>\n",
       "      <td>29.91</td>\n",
       "      <td>28.63</td>\n",
       "      <td>5.12</td>\n",
       "      <td>12.33</td>\n",
       "      <td>5.34</td>\n",
       "      <td>187.10</td>\n",
       "      <td>8.65</td>\n",
       "      <td>12.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-23</th>\n",
       "      <td>1.96</td>\n",
       "      <td>4.47</td>\n",
       "      <td>18.36</td>\n",
       "      <td>14.42</td>\n",
       "      <td>34.36</td>\n",
       "      <td>17.55</td>\n",
       "      <td>14.77</td>\n",
       "      <td>28.73</td>\n",
       "      <td>30.48</td>\n",
       "      <td>32.93</td>\n",
       "      <td>87.76</td>\n",
       "      <td>252.69</td>\n",
       "      <td>49.30</td>\n",
       "      <td>1834.43</td>\n",
       "      <td>32.52</td>\n",
       "      <td>28.66</td>\n",
       "      <td>18.05</td>\n",
       "      <td>24.50</td>\n",
       "      <td>291.89</td>\n",
       "      <td>9.12</td>\n",
       "      <td>32.45</td>\n",
       "      <td>46.74</td>\n",
       "      <td>23.33</td>\n",
       "      <td>48.54</td>\n",
       "      <td>31.18</td>\n",
       "      <td>17.10</td>\n",
       "      <td>2.88</td>\n",
       "      <td>43.02</td>\n",
       "      <td>4.40</td>\n",
       "      <td>20.39</td>\n",
       "      <td>30.88</td>\n",
       "      <td>28.49</td>\n",
       "      <td>5.22</td>\n",
       "      <td>12.44</td>\n",
       "      <td>5.44</td>\n",
       "      <td>185.41</td>\n",
       "      <td>8.53</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-26</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.27</td>\n",
       "      <td>18.02</td>\n",
       "      <td>14.05</td>\n",
       "      <td>33.95</td>\n",
       "      <td>17.69</td>\n",
       "      <td>14.55</td>\n",
       "      <td>28.10</td>\n",
       "      <td>30.09</td>\n",
       "      <td>31.90</td>\n",
       "      <td>87.28</td>\n",
       "      <td>246.79</td>\n",
       "      <td>48.68</td>\n",
       "      <td>1863.00</td>\n",
       "      <td>32.04</td>\n",
       "      <td>28.33</td>\n",
       "      <td>17.76</td>\n",
       "      <td>24.95</td>\n",
       "      <td>299.65</td>\n",
       "      <td>8.97</td>\n",
       "      <td>32.36</td>\n",
       "      <td>45.29</td>\n",
       "      <td>23.05</td>\n",
       "      <td>48.80</td>\n",
       "      <td>30.36</td>\n",
       "      <td>16.75</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.49</td>\n",
       "      <td>4.35</td>\n",
       "      <td>19.90</td>\n",
       "      <td>30.82</td>\n",
       "      <td>28.70</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.21</td>\n",
       "      <td>5.11</td>\n",
       "      <td>194.51</td>\n",
       "      <td>7.82</td>\n",
       "      <td>11.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-27</th>\n",
       "      <td>1.91</td>\n",
       "      <td>4.28</td>\n",
       "      <td>18.07</td>\n",
       "      <td>14.37</td>\n",
       "      <td>33.90</td>\n",
       "      <td>17.67</td>\n",
       "      <td>14.65</td>\n",
       "      <td>28.30</td>\n",
       "      <td>30.45</td>\n",
       "      <td>33.65</td>\n",
       "      <td>87.66</td>\n",
       "      <td>264.07</td>\n",
       "      <td>49.32</td>\n",
       "      <td>1888.00</td>\n",
       "      <td>33.67</td>\n",
       "      <td>28.61</td>\n",
       "      <td>18.11</td>\n",
       "      <td>25.60</td>\n",
       "      <td>308.18</td>\n",
       "      <td>8.98</td>\n",
       "      <td>33.22</td>\n",
       "      <td>46.47</td>\n",
       "      <td>22.70</td>\n",
       "      <td>48.99</td>\n",
       "      <td>30.40</td>\n",
       "      <td>16.81</td>\n",
       "      <td>2.83</td>\n",
       "      <td>42.44</td>\n",
       "      <td>4.34</td>\n",
       "      <td>20.03</td>\n",
       "      <td>31.10</td>\n",
       "      <td>29.39</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.35</td>\n",
       "      <td>5.10</td>\n",
       "      <td>202.45</td>\n",
       "      <td>7.85</td>\n",
       "      <td>11.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17.72</td>\n",
       "      <td>14.09</td>\n",
       "      <td>33.67</td>\n",
       "      <td>17.52</td>\n",
       "      <td>14.49</td>\n",
       "      <td>27.01</td>\n",
       "      <td>29.56</td>\n",
       "      <td>33.47</td>\n",
       "      <td>87.08</td>\n",
       "      <td>261.50</td>\n",
       "      <td>46.90</td>\n",
       "      <td>1883.00</td>\n",
       "      <td>33.51</td>\n",
       "      <td>28.30</td>\n",
       "      <td>17.84</td>\n",
       "      <td>25.30</td>\n",
       "      <td>306.85</td>\n",
       "      <td>8.82</td>\n",
       "      <td>33.26</td>\n",
       "      <td>43.98</td>\n",
       "      <td>22.46</td>\n",
       "      <td>47.90</td>\n",
       "      <td>30.64</td>\n",
       "      <td>16.84</td>\n",
       "      <td>2.85</td>\n",
       "      <td>41.89</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.08</td>\n",
       "      <td>31.48</td>\n",
       "      <td>28.11</td>\n",
       "      <td>5.10</td>\n",
       "      <td>12.26</td>\n",
       "      <td>5.07</td>\n",
       "      <td>202.48</td>\n",
       "      <td>7.48</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.26</td>\n",
       "      <td>17.40</td>\n",
       "      <td>13.85</td>\n",
       "      <td>33.15</td>\n",
       "      <td>17.28</td>\n",
       "      <td>14.27</td>\n",
       "      <td>26.97</td>\n",
       "      <td>29.61</td>\n",
       "      <td>34.97</td>\n",
       "      <td>89.49</td>\n",
       "      <td>266.10</td>\n",
       "      <td>47.98</td>\n",
       "      <td>1880.35</td>\n",
       "      <td>33.52</td>\n",
       "      <td>28.11</td>\n",
       "      <td>17.80</td>\n",
       "      <td>24.94</td>\n",
       "      <td>304.28</td>\n",
       "      <td>8.58</td>\n",
       "      <td>33.30</td>\n",
       "      <td>43.38</td>\n",
       "      <td>22.40</td>\n",
       "      <td>50.08</td>\n",
       "      <td>31.41</td>\n",
       "      <td>16.54</td>\n",
       "      <td>2.82</td>\n",
       "      <td>41.32</td>\n",
       "      <td>4.33</td>\n",
       "      <td>19.81</td>\n",
       "      <td>31.77</td>\n",
       "      <td>28.10</td>\n",
       "      <td>5.01</td>\n",
       "      <td>12.18</td>\n",
       "      <td>5.11</td>\n",
       "      <td>197.25</td>\n",
       "      <td>7.70</td>\n",
       "      <td>11.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>1.84</td>\n",
       "      <td>4.29</td>\n",
       "      <td>17.42</td>\n",
       "      <td>13.88</td>\n",
       "      <td>33.65</td>\n",
       "      <td>18.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>26.56</td>\n",
       "      <td>29.56</td>\n",
       "      <td>35.10</td>\n",
       "      <td>92.10</td>\n",
       "      <td>266.80</td>\n",
       "      <td>46.96</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>33.89</td>\n",
       "      <td>28.81</td>\n",
       "      <td>17.60</td>\n",
       "      <td>24.77</td>\n",
       "      <td>302.89</td>\n",
       "      <td>8.66</td>\n",
       "      <td>32.98</td>\n",
       "      <td>41.95</td>\n",
       "      <td>22.74</td>\n",
       "      <td>47.91</td>\n",
       "      <td>31.64</td>\n",
       "      <td>16.65</td>\n",
       "      <td>2.86</td>\n",
       "      <td>41.58</td>\n",
       "      <td>4.35</td>\n",
       "      <td>20.33</td>\n",
       "      <td>31.63</td>\n",
       "      <td>27.80</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.12</td>\n",
       "      <td>5.13</td>\n",
       "      <td>198.25</td>\n",
       "      <td>7.84</td>\n",
       "      <td>11.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2613 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "tic         600010.SH  600028.SH  600030.SH  600031.SH  600036.SH  600048.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       4.15       7.36       9.56      12.09      11.67      10.05   \n",
       "2012-01-05       4.10       7.42       9.29      12.06      11.91       9.80   \n",
       "2012-01-06       4.34       7.48       9.39      12.06      11.99       9.71   \n",
       "2012-01-09       4.48       7.75       9.75      12.55      12.38      10.17   \n",
       "2012-01-10       4.54       7.79      10.12      13.31      12.56      10.35   \n",
       "2012-01-11       4.79       7.70      10.08      13.13      12.49      10.31   \n",
       "2012-01-12       4.77       7.66      10.03      13.22      12.62      10.39   \n",
       "2012-01-13       4.69       7.62       9.80      12.92      12.49      10.28   \n",
       "2012-01-16       4.32       7.54       9.83      13.06      12.39       9.93   \n",
       "2012-01-17       4.75       7.74      10.51      13.77      12.78      10.35   \n",
       "2012-01-18       4.73       7.58      10.47      13.69      12.52      10.12   \n",
       "2012-01-19       4.78       7.66      10.84      13.81      12.70      10.67   \n",
       "2012-01-20       4.77       7.74      11.01      13.99      13.00      10.94   \n",
       "2012-01-30       4.75       7.70      10.68        NaN      12.70      10.43   \n",
       "2012-01-31       4.87       7.76      10.69      14.21      12.65      10.50   \n",
       "2012-02-01       4.73       7.79      10.47      13.80      12.47      10.31   \n",
       "2012-02-02       4.83       7.86      10.80      14.06      12.87      10.56   \n",
       "2012-02-03       4.83       7.81      10.90      13.94      12.98      10.68   \n",
       "2012-02-06       4.82       7.78      10.84      13.89      12.86      10.45   \n",
       "2012-02-07       4.69       7.65      10.52      13.54      12.73      10.13   \n",
       "2012-02-08       4.90       7.78      10.95      13.88      12.99      10.42   \n",
       "2012-02-09       4.88       7.69      10.87      13.77      12.99      10.56   \n",
       "2012-02-10       5.08       7.67      10.97      13.88      12.89      10.91   \n",
       "2012-02-13       5.04       7.65      10.95      13.84      12.69      10.57   \n",
       "2012-02-14       5.01       7.66      10.87      13.69      12.66      10.62   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26       2.09       4.25      19.40      15.52      33.70      16.68   \n",
       "2022-08-29       2.07       4.26      19.37      15.56      33.28      16.61   \n",
       "2022-08-30       2.04       4.29      19.25      15.58      33.79      16.95   \n",
       "2022-08-31       2.01       4.27      19.52      15.75      35.05      17.30   \n",
       "2022-09-01       2.00       4.23      19.30      15.85      34.50      17.31   \n",
       "2022-09-02       2.00       4.26      19.24      15.61      34.32      17.02   \n",
       "2022-09-05       2.03       4.34      19.27      15.45      34.23      17.22   \n",
       "2022-09-06       2.05       4.41      19.48      15.73      33.62      17.63   \n",
       "2022-09-07       2.06       4.41      19.37      15.60      33.38      17.55   \n",
       "2022-09-08       2.04       4.41      19.31      15.75      33.30      17.58   \n",
       "2022-09-09       2.06       4.45      19.78      16.26      34.50      18.47   \n",
       "2022-09-13       2.05       4.43      19.83      16.30      35.35      18.09   \n",
       "2022-09-14       2.02       4.38      19.58      16.15      34.86      18.14   \n",
       "2022-09-15       2.00       4.40      19.53      16.20      36.01      18.85   \n",
       "2022-09-16       1.96       4.30      18.42      15.60      34.95      18.05   \n",
       "2022-09-19       1.91       4.18      18.42      14.97      35.09      18.44   \n",
       "2022-09-20       1.95       4.22      18.42      14.96      34.54      17.64   \n",
       "2022-09-21       1.98       4.25      18.43      15.06      34.41      17.83   \n",
       "2022-09-22       1.96       4.39      18.39      14.69      34.17      17.52   \n",
       "2022-09-23       1.96       4.47      18.36      14.42      34.36      17.55   \n",
       "2022-09-26       1.91       4.27      18.02      14.05      33.95      17.69   \n",
       "2022-09-27       1.91       4.28      18.07      14.37      33.90      17.67   \n",
       "2022-09-28       1.84       4.25      17.72      14.09      33.67      17.52   \n",
       "2022-09-29       1.84       4.26      17.40      13.85      33.15      17.28   \n",
       "2022-09-30       1.84       4.29      17.42      13.88      33.65      18.00   \n",
       "\n",
       "tic         600104.SH  600111.SH  600196.SH  600276.SH  600309.SH  600436.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      14.16      37.61       8.34      28.45      12.50      73.03   \n",
       "2012-01-05      14.39      35.64       8.25      27.00      12.10      70.50   \n",
       "2012-01-06      14.20      36.32       8.08      26.55      12.06      70.08   \n",
       "2012-01-09      14.90      39.02       8.34      27.40      12.47      70.10   \n",
       "2012-01-10      15.25      40.39       8.66      27.75      13.21      72.00   \n",
       "2012-01-11      15.10      42.63       8.63      27.70      13.25      72.85   \n",
       "2012-01-12      15.29      43.46       8.58      27.37      13.31      73.99   \n",
       "2012-01-13      14.69      44.96       8.31      26.80      12.83      71.73   \n",
       "2012-01-16      14.39      41.08       8.17      26.00      12.50      69.15   \n",
       "2012-01-17      15.33      45.19       8.61      26.02      13.39      70.90   \n",
       "2012-01-18      15.21      45.46       8.47      24.66      13.26      63.81   \n",
       "2012-01-19      15.46      46.58       8.62      25.20      13.76      64.29   \n",
       "2012-01-20      15.52      45.62       8.80      26.68      14.09      65.74   \n",
       "2012-01-30      15.48      46.06       8.63      26.19      13.67      64.87   \n",
       "2012-01-31      15.09      46.56        NaN      26.00        NaN      65.93   \n",
       "2012-02-01      14.93      44.73       8.51      25.86      13.78      66.52   \n",
       "2012-02-02      15.22      45.57       8.64      26.24      14.05      66.67   \n",
       "2012-02-03      15.40      45.61       8.76      26.39      14.42      66.89   \n",
       "2012-02-06      15.25      45.61       8.79      27.05      14.59      68.41   \n",
       "2012-02-07      15.22      44.55       8.60      26.53      14.26      68.22   \n",
       "2012-02-08      15.59      48.51       8.79      26.59      14.81      68.80   \n",
       "2012-02-09      15.49      47.57       8.87      26.93      14.91      68.77   \n",
       "2012-02-10      15.45      47.50       8.90      26.63      14.66      68.61   \n",
       "2012-02-13      15.76      47.65       8.84      26.99      14.58      68.67   \n",
       "2012-02-14      15.52      47.50       8.89      26.87      14.31      69.29   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      15.88      30.84      40.93      34.77      88.67     294.00   \n",
       "2022-08-29      15.50      30.59      40.61      34.23      87.80     291.09   \n",
       "2022-08-30      15.48      30.37      40.08      33.67      88.45     288.36   \n",
       "2022-08-31      15.47      30.14      40.36      34.66      88.57     300.99   \n",
       "2022-09-01      15.30      30.09      40.90      34.34      88.11     298.30   \n",
       "2022-09-02      15.26      30.16      40.21      33.90      86.95     296.11   \n",
       "2022-09-05      15.21      30.08      36.19      33.73      88.65     294.00   \n",
       "2022-09-06      15.42      30.85      35.42      33.88      91.50     294.02   \n",
       "2022-09-07      15.40      30.79      35.55      33.43      90.52     291.48   \n",
       "2022-09-08      15.35      30.29      33.96      33.73      92.01     293.75   \n",
       "2022-09-09      15.48      30.68      35.00      34.78      95.61     298.11   \n",
       "2022-09-13      15.65      31.47      34.44      35.52      93.00     302.00   \n",
       "2022-09-14      15.44      30.70      33.76      35.68      91.36     300.29   \n",
       "2022-09-15      15.34      30.01      33.04      35.49      91.50     298.56   \n",
       "2022-09-16      15.02      28.80      32.17      34.83      90.38     293.20   \n",
       "2022-09-19      15.01      28.34      32.19      34.69      91.36     289.50   \n",
       "2022-09-20      14.89      29.01      32.27      34.13      89.55     289.35   \n",
       "2022-09-21      14.92      30.48      31.70      33.43      87.94     281.08   \n",
       "2022-09-22      14.81      29.39      30.99      32.64      88.05     260.85   \n",
       "2022-09-23      14.77      28.73      30.48      32.93      87.76     252.69   \n",
       "2022-09-26      14.55      28.10      30.09      31.90      87.28     246.79   \n",
       "2022-09-27      14.65      28.30      30.45      33.65      87.66     264.07   \n",
       "2022-09-28      14.49      27.01      29.56      33.47      87.08     261.50   \n",
       "2022-09-29      14.27      26.97      29.61      34.97      89.49     266.10   \n",
       "2022-09-30      14.30      26.56      29.56      35.10      92.10     266.80   \n",
       "\n",
       "tic         600438.SH  600519.SH  600570.SH  600585.SH  600588.SH  600690.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04       4.85     185.27      11.50      15.28      16.90       8.78   \n",
       "2012-01-05       4.66     183.15      10.70      14.92      16.48       8.73   \n",
       "2012-01-06       4.72     186.64      10.67      14.72      16.23       8.79   \n",
       "2012-01-09       4.89     188.01      11.00      15.55      16.58       9.07   \n",
       "2012-01-10       5.10     194.48      11.34      16.59      17.02       9.42   \n",
       "2012-01-11       5.06     189.68      11.25      16.38      17.79       9.26   \n",
       "2012-01-12       5.03     190.35      11.05      16.51      17.14       9.23   \n",
       "2012-01-13       4.87     188.69      10.49      15.75      16.51       8.83   \n",
       "2012-01-16       4.76     177.41      10.30      15.28      16.03       8.70   \n",
       "2012-01-17       5.03     180.44      10.60      16.43      16.73       9.29   \n",
       "2012-01-18       4.93     177.38      10.48      16.82      16.49       9.08   \n",
       "2012-01-19       5.01     180.70      10.33      17.15      16.19       9.40   \n",
       "2012-01-20       5.10     185.97      10.41      17.79      16.48       9.51   \n",
       "2012-01-30       5.04     183.80      10.37      17.38      16.23       9.24   \n",
       "2012-01-31       5.08     186.41      10.39      17.37      16.45       9.21   \n",
       "2012-02-01       5.05     186.15      10.64      16.54      16.68       9.10   \n",
       "2012-02-02       5.25     186.43      10.77      16.90      17.14       9.19   \n",
       "2012-02-03       5.25     186.48      11.00      16.72      17.70       9.17   \n",
       "2012-02-06       5.27     188.54      11.00      17.07      17.93       9.27   \n",
       "2012-02-07       5.09     185.86      10.75      16.52      17.46       9.07   \n",
       "2012-02-08       5.20     188.29      11.04      17.15      17.90       9.28   \n",
       "2012-02-09       5.26     190.75      11.11      17.40      17.98       9.33   \n",
       "2012-02-10       5.32     190.51      11.06      17.51      17.70       9.33   \n",
       "2012-02-13       5.37     193.42      11.21      17.25      18.36       9.28   \n",
       "2012-02-14       5.38     193.82      11.27      17.10      18.06       9.24   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      56.43    1898.00      32.44      31.81      20.00      24.33   \n",
       "2022-08-29      56.78    1878.82      32.70      31.42      19.29      24.57   \n",
       "2022-08-30      55.56    1870.00      33.33      30.99      20.07      25.40   \n",
       "2022-08-31      52.88    1924.00      33.64      31.92      20.09      25.87   \n",
       "2022-09-01      52.82    1880.89      34.50      31.60      20.37      26.21   \n",
       "2022-09-02      52.21    1875.00      34.37      31.17      20.15      25.63   \n",
       "2022-09-05      52.45    1835.00      33.73      31.01      19.79      25.58   \n",
       "2022-09-06      56.87    1845.00      33.66      31.00      19.71      25.69   \n",
       "2022-09-07      56.69    1818.01      33.59      30.41      19.62      25.80   \n",
       "2022-09-08      56.50    1815.00      33.99      30.20      19.33      25.88   \n",
       "2022-09-09      54.56    1844.79      35.30      31.37      19.54      26.50   \n",
       "2022-09-13      54.99    1879.00      36.15      31.96      19.58      26.48   \n",
       "2022-09-14      53.73    1869.00      36.30      31.59      19.71      26.49   \n",
       "2022-09-15      51.30    1880.00      35.71      32.23      19.45      26.88   \n",
       "2022-09-16      49.52    1859.00      33.99      31.19      19.53      26.06   \n",
       "2022-09-19      49.87    1871.64      33.69      30.45      18.03      26.16   \n",
       "2022-09-20      50.30    1878.00      32.77      29.58      18.19      25.87   \n",
       "2022-09-21      50.09    1848.00      32.74      29.18      18.29      25.19   \n",
       "2022-09-22      49.12    1820.81      32.80      28.73      18.49      24.56   \n",
       "2022-09-23      49.30    1834.43      32.52      28.66      18.05      24.50   \n",
       "2022-09-26      48.68    1863.00      32.04      28.33      17.76      24.95   \n",
       "2022-09-27      49.32    1888.00      33.67      28.61      18.11      25.60   \n",
       "2022-09-28      46.90    1883.00      33.51      28.30      17.84      25.30   \n",
       "2022-09-29      47.98    1880.35      33.52      28.11      17.80      24.94   \n",
       "2022-09-30      46.96    1872.50      33.89      28.81      17.60      24.77   \n",
       "\n",
       "tic         600809.SH  600837.SH  600887.SH  600893.SH  600900.SH  601012.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      57.79       7.12      19.73      13.29       6.29        NaN   \n",
       "2012-01-05      55.04       7.08      19.33      12.66       6.24        NaN   \n",
       "2012-01-06      53.69       7.30      19.66      12.95       6.22        NaN   \n",
       "2012-01-09      54.59       7.62      20.13      13.39       6.29        NaN   \n",
       "2012-01-10      57.00       7.93      20.58      13.79       6.40        NaN   \n",
       "2012-01-11      57.67       7.85      20.61      13.72       6.38        NaN   \n",
       "2012-01-12      55.89       7.85      20.50      14.10       6.41        NaN   \n",
       "2012-01-13      53.98       7.71      20.22      13.26       6.35        NaN   \n",
       "2012-01-16      50.77       7.64      19.01      12.89       6.36        NaN   \n",
       "2012-01-17      52.66       8.15      19.87      13.55       6.53        NaN   \n",
       "2012-01-18      51.61       8.07      19.14      13.32       6.48        NaN   \n",
       "2012-01-19      52.84       8.38      19.98      13.20       6.56        NaN   \n",
       "2012-01-20      54.34       8.60      20.54        NaN       6.57        NaN   \n",
       "2012-01-30      53.30       8.36      20.33      13.49       6.45        NaN   \n",
       "2012-01-31      54.97       8.36      20.44      13.48       6.49        NaN   \n",
       "2012-02-01      54.98       8.10      20.60      13.12       6.44        NaN   \n",
       "2012-02-02      55.72       8.53      20.92      13.31       6.48        NaN   \n",
       "2012-02-03      57.00       8.47      20.90      13.79       6.52        NaN   \n",
       "2012-02-06      58.59       8.45      21.56      13.68       6.47        NaN   \n",
       "2012-02-07      57.61       8.21      21.50      14.74       6.33        NaN   \n",
       "2012-02-08      59.17       8.67      21.80      15.24       6.47        NaN   \n",
       "2012-02-09      59.40       8.57      21.32      15.13       6.41        NaN   \n",
       "2012-02-10      59.00       8.65      21.76      15.29       6.40        NaN   \n",
       "2012-02-13      59.85       8.55      22.11      15.57       6.39        NaN   \n",
       "2012-02-14      60.71       8.49      22.09      15.42       6.40        NaN   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26     286.93       9.51      36.19      48.17      23.39      53.06   \n",
       "2022-08-29     285.30       9.45      35.95      49.91      23.30      53.41   \n",
       "2022-08-30     284.09       9.41      36.13      47.88      23.28      52.80   \n",
       "2022-08-31     293.00       9.48      35.74      45.97      23.98      51.20   \n",
       "2022-09-01     292.58       9.39      34.55      45.88      23.91      51.65   \n",
       "2022-09-02     288.53       9.32      33.90      45.22      23.82      50.95   \n",
       "2022-09-05     282.78       9.40      33.37      45.77      23.82      50.49   \n",
       "2022-09-06     286.02       9.46      33.63      47.14      23.75      53.16   \n",
       "2022-09-07     278.12       9.47      33.22      47.24      23.57      53.46   \n",
       "2022-09-08     285.59       9.44      33.27      47.76      23.65      53.39   \n",
       "2022-09-09     291.21       9.54      33.70      48.03      23.91      53.18   \n",
       "2022-09-13     293.00       9.52      33.74      49.00      23.79      53.27   \n",
       "2022-09-14     292.30       9.46      33.60      49.23      23.70      52.55   \n",
       "2022-09-15     296.00       9.46      33.69      47.20      23.72      48.66   \n",
       "2022-09-16     289.50       9.05      32.88      46.88      23.46      48.30   \n",
       "2022-09-19     293.75       9.06      32.90      46.01      23.48      48.12   \n",
       "2022-09-20     296.09       9.09      32.66      45.75      23.42      50.04   \n",
       "2022-09-21     292.15       9.07      32.48      44.80      23.43      49.19   \n",
       "2022-09-22     292.44       9.12      32.00      46.60      23.42      49.18   \n",
       "2022-09-23     291.89       9.12      32.45      46.74      23.33      48.54   \n",
       "2022-09-26     299.65       8.97      32.36      45.29      23.05      48.80   \n",
       "2022-09-27     308.18       8.98      33.22      46.47      22.70      48.99   \n",
       "2022-09-28     306.85       8.82      33.26      43.98      22.46      47.90   \n",
       "2022-09-29     304.28       8.58      33.30      43.38      22.40      50.08   \n",
       "2022-09-30     302.89       8.66      32.98      41.95      22.74      47.91   \n",
       "\n",
       "tic         601088.SH  601166.SH  601288.SH  601318.SH  601398.SH  601601.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      24.60      12.50       2.60      33.90       4.22      19.04   \n",
       "2012-01-05      24.29      12.71       2.65      33.93       4.25      19.12   \n",
       "2012-01-06      24.27      12.79       2.66      33.85       4.28      19.23   \n",
       "2012-01-09      26.01      13.04       2.68      34.73       4.31      19.73   \n",
       "2012-01-10      26.76      13.15       2.69      36.29       4.35      20.40   \n",
       "2012-01-11      26.49      13.02       2.67      35.83       4.35      20.20   \n",
       "2012-01-12      26.49      13.30       2.65      36.37       4.33      20.03   \n",
       "2012-01-13      26.33      13.28       2.65      36.03       4.34      19.95   \n",
       "2012-01-16      26.02      13.32        NaN      35.59       4.31      19.85   \n",
       "2012-01-17      27.38      13.60       2.69      37.82       4.36      20.68   \n",
       "2012-01-18      26.88      13.43       2.69      37.45       4.31      20.50   \n",
       "2012-01-19      27.10      13.78       2.70      38.51       4.36      21.22   \n",
       "2012-01-20      27.48      14.05       2.72      39.10       4.36      21.84   \n",
       "2012-01-30      26.68      13.83       2.68      38.60       4.27      21.11   \n",
       "2012-01-31      26.85      13.86       2.70      38.34       4.30      21.01   \n",
       "2012-02-01      26.57      13.56       2.68      37.41       4.28      20.65   \n",
       "2012-02-02      27.24      14.15       2.73      39.64       4.38      21.41   \n",
       "2012-02-03      27.35      14.18       2.75      40.15       4.41      21.86   \n",
       "2012-02-06      27.35      14.17       2.75      39.62       4.41      21.36   \n",
       "2012-02-07      26.89      14.02       2.72      38.91       4.33      20.79   \n",
       "2012-02-08      27.63      14.43       2.75        NaN       4.41      21.75   \n",
       "2012-02-09      27.53      14.42       2.73      39.88       4.42      21.26   \n",
       "2012-02-10      27.45      14.24       2.72      40.09       4.39      21.61   \n",
       "2012-02-13      27.14      14.13       2.71      40.28       4.37      21.41   \n",
       "2012-02-14      27.14      14.08       2.70      39.58       4.35      20.83   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      31.26      17.88       2.82      43.12       4.35      20.29   \n",
       "2022-08-29      31.88      16.93       2.82      43.07       4.33      20.17   \n",
       "2022-08-30      30.52      16.82       2.82      42.89       4.36      20.47   \n",
       "2022-08-31      30.34      17.11       2.85      43.84       4.38      20.97   \n",
       "2022-09-01      31.11      17.11       2.83      43.65       4.36      20.82   \n",
       "2022-09-02      30.66      17.03       2.83      43.70       4.35      20.75   \n",
       "2022-09-05      32.56      17.08       2.84      43.80       4.36      20.90   \n",
       "2022-09-06      32.88      17.06       2.84      43.90       4.36      21.08   \n",
       "2022-09-07      32.61      17.09       2.83      43.60       4.35      20.98   \n",
       "2022-09-08      32.30      17.01       2.83      43.84       4.35      20.95   \n",
       "2022-09-09      32.73      17.38       2.84      44.69       4.36      21.47   \n",
       "2022-09-13      32.45      17.59       2.85      45.06       4.38      21.52   \n",
       "2022-09-14      32.35      17.38       2.85      44.65       4.36      21.26   \n",
       "2022-09-15      32.39      17.69       2.87      45.09       4.39      21.31   \n",
       "2022-09-16      30.96      17.22       2.85      43.93       4.36      20.88   \n",
       "2022-09-19      31.50      17.34       2.87      43.93       4.38      20.42   \n",
       "2022-09-20      31.35      17.08       2.84      43.24       4.37      20.10   \n",
       "2022-09-21      31.18      17.15       2.86      43.15       4.37      20.25   \n",
       "2022-09-22      31.99      17.05       2.86      42.48       4.39      20.26   \n",
       "2022-09-23      31.18      17.10       2.88      43.02       4.40      20.39   \n",
       "2022-09-26      30.36      16.75       2.85      42.49       4.35      19.90   \n",
       "2022-09-27      30.40      16.81       2.83      42.44       4.34      20.03   \n",
       "2022-09-28      30.64      16.84       2.85      41.89       4.35      20.08   \n",
       "2022-09-29      31.41      16.54       2.82      41.32       4.33      19.81   \n",
       "2022-09-30      31.64      16.65       2.86      41.58       4.35      20.33   \n",
       "\n",
       "tic         601628.SH  601633.SH  601668.SH  601688.SH  601857.SH  601888.SH  \\\n",
       "date                                                                           \n",
       "2012-01-04      17.46      11.87       2.86       7.62       9.75      25.59   \n",
       "2012-01-05      16.58      12.10       2.87       7.36       9.80      24.17   \n",
       "2012-01-06      16.73      11.81       2.87       7.49       9.96      23.61   \n",
       "2012-01-09      17.28      12.26       2.93       7.79      10.03      24.41   \n",
       "2012-01-10      18.23      12.46       3.08       8.13      10.12      25.60   \n",
       "2012-01-11      18.22      12.41       3.04       8.00      10.04      25.95   \n",
       "2012-01-12      18.30      12.65       3.04       7.93      10.06      25.47   \n",
       "2012-01-13      17.89      12.26       3.01       7.87      10.20      24.93   \n",
       "2012-01-16      17.81        NaN       2.98       7.73      10.09      23.59   \n",
       "2012-01-17      18.78      12.99       3.10       8.19      10.32      24.72   \n",
       "2012-01-18      18.45      12.77       3.05       8.22      10.22      24.01   \n",
       "2012-01-19      19.00      12.88       3.09       8.48      10.26      24.41   \n",
       "2012-01-20      19.33      12.99       3.14       8.50      10.26      25.01   \n",
       "2012-01-30      18.90      12.73       3.07       8.20      10.13      25.10   \n",
       "2012-01-31      18.78      12.57       3.07       8.33      10.21      24.73   \n",
       "2012-02-01      18.34      12.40       3.04       8.16      10.18      24.71   \n",
       "2012-02-02      19.07      12.65       3.10       8.36      10.21      25.10   \n",
       "2012-02-03      19.30      12.54       3.10       8.35      10.22      24.89   \n",
       "2012-02-06      18.92      12.73       3.07       8.26      10.23      25.01   \n",
       "2012-02-07      18.50      12.65       3.01       8.05      10.09      25.42   \n",
       "2012-02-08      19.24      12.98       3.09       8.36      10.26      25.87   \n",
       "2012-02-09      19.07      12.98       3.08       8.27      10.29      25.77   \n",
       "2012-02-10      18.93      13.03       3.21       8.32      10.31      25.91   \n",
       "2012-02-13      18.64      13.41       3.16       8.37      10.26      26.08   \n",
       "2012-02-14      18.39      13.38       3.16       8.37      10.24      26.03   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-26      29.44      35.35       5.01      13.13       5.44     192.41   \n",
       "2022-08-29      29.02      33.96       5.04      13.02       5.48     192.25   \n",
       "2022-08-30      29.50      34.20       5.07      13.11       5.47     190.40   \n",
       "2022-08-31      30.70      33.46       5.14      13.14       5.34     195.50   \n",
       "2022-09-01      30.45      32.25       5.15      13.00       5.36     186.80   \n",
       "2022-09-02      29.70      31.65       5.11      12.92       5.42     180.31   \n",
       "2022-09-05      29.86      31.19       5.17      13.05       5.56     180.10   \n",
       "2022-09-06      30.34      31.84       5.24      13.18       5.61     182.72   \n",
       "2022-09-07      30.25      32.09       5.23      13.14       5.58     183.95   \n",
       "2022-09-08      30.76      30.98       5.23      13.14       5.53     186.00   \n",
       "2022-09-09      31.50      31.31       5.36      13.28       5.59     191.09   \n",
       "2022-09-13      31.46      32.00       5.32      13.24       5.55     192.47   \n",
       "2022-09-14      31.63      31.74       5.26      13.11       5.52     191.55   \n",
       "2022-09-15      31.74      30.57       5.37      13.08       5.54     191.35   \n",
       "2022-09-16      31.06      28.88       5.15      12.41       5.37     188.51   \n",
       "2022-09-19      30.86      29.98       5.24      12.35       5.35     188.45   \n",
       "2022-09-20      29.84      29.83       5.11      12.33       5.16     194.23   \n",
       "2022-09-21      29.82      29.44       5.15      12.33       5.23     185.54   \n",
       "2022-09-22      29.91      28.63       5.12      12.33       5.34     187.10   \n",
       "2022-09-23      30.88      28.49       5.22      12.44       5.44     185.41   \n",
       "2022-09-26      30.82      28.70       5.15      12.21       5.11     194.51   \n",
       "2022-09-27      31.10      29.39       5.15      12.35       5.10     202.45   \n",
       "2022-09-28      31.48      28.11       5.10      12.26       5.07     202.48   \n",
       "2022-09-29      31.77      28.10       5.01      12.18       5.11     197.25   \n",
       "2022-09-30      31.63      27.80       5.15      12.12       5.13     198.25   \n",
       "\n",
       "tic         601899.SH  601919.SH  \n",
       "date                              \n",
       "2012-01-04       3.81       4.50  \n",
       "2012-01-05       3.78       4.30  \n",
       "2012-01-06       3.80       4.32  \n",
       "2012-01-09       3.93       4.47  \n",
       "2012-01-10       4.12       4.68  \n",
       "2012-01-11       4.16       4.63  \n",
       "2012-01-12       4.15       4.69  \n",
       "2012-01-13       4.06       4.48  \n",
       "2012-01-16       3.96       4.38  \n",
       "2012-01-17       4.36       4.82  \n",
       "2012-01-18       4.29       5.10  \n",
       "2012-01-19       4.48       5.08  \n",
       "2012-01-20       4.47       5.05  \n",
       "2012-01-30       4.49       5.00  \n",
       "2012-01-31       4.44       5.08  \n",
       "2012-02-01       4.37       5.10  \n",
       "2012-02-02       4.46       5.33  \n",
       "2012-02-03       4.50       5.31  \n",
       "2012-02-06       4.45       5.30  \n",
       "2012-02-07       4.35       5.28  \n",
       "2012-02-08       4.53       5.37  \n",
       "2012-02-09       4.50       5.41  \n",
       "2012-02-10       4.50       5.47  \n",
       "2012-02-13       4.53       5.43  \n",
       "2012-02-14       4.48       5.39  \n",
       "...               ...        ...  \n",
       "2022-08-26       9.15      13.78  \n",
       "2022-08-29       9.02      13.60  \n",
       "2022-08-30       8.90      14.41  \n",
       "2022-08-31       8.80      14.20  \n",
       "2022-09-01       8.65      13.70  \n",
       "2022-09-02       8.52      13.33  \n",
       "2022-09-05       8.59      13.24  \n",
       "2022-09-06       8.84      13.39  \n",
       "2022-09-07       8.94      13.44  \n",
       "2022-09-08       9.06      13.26  \n",
       "2022-09-09       9.19      13.29  \n",
       "2022-09-13       9.29      13.26  \n",
       "2022-09-14       9.00      13.12  \n",
       "2022-09-15       8.95      12.93  \n",
       "2022-09-16       8.68      12.56  \n",
       "2022-09-19       8.62      12.13  \n",
       "2022-09-20       8.70      12.22  \n",
       "2022-09-21       8.71      12.41  \n",
       "2022-09-22       8.65      12.27  \n",
       "2022-09-23       8.53      11.97  \n",
       "2022-09-26       7.82      11.26  \n",
       "2022-09-27       7.85      11.34  \n",
       "2022-09-28       7.48      11.05  \n",
       "2022-09-29       7.70      11.08  \n",
       "2022-09-30       7.84      11.02  \n",
       "\n",
       "[2613 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_length = len(merged_closes)\n",
    "merged_closes.dropna(axis=1, thresh = int(0.9*data_length), inplace=True)\n",
    "merged_closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:10.255616Z",
     "start_time": "2022-10-12T02:27:10.210341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>672559.53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.36</td>\n",
       "      <td>528181.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.56</td>\n",
       "      <td>9.56</td>\n",
       "      <td>354005.33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.09</td>\n",
       "      <td>235312.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>11.95</td>\n",
       "      <td>12.10</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.67</td>\n",
       "      <td>522606.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>10.01</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.05</td>\n",
       "      <td>341555.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>14.28</td>\n",
       "      <td>14.53</td>\n",
       "      <td>13.92</td>\n",
       "      <td>14.16</td>\n",
       "      <td>272418.21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>37.90</td>\n",
       "      <td>38.20</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.61</td>\n",
       "      <td>160533.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8.34</td>\n",
       "      <td>36465.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>29.50</td>\n",
       "      <td>29.75</td>\n",
       "      <td>28.40</td>\n",
       "      <td>28.45</td>\n",
       "      <td>11847.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.97</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>96092.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>75.02</td>\n",
       "      <td>75.30</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.03</td>\n",
       "      <td>3099.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.85</td>\n",
       "      <td>17962.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>191.50</td>\n",
       "      <td>192.77</td>\n",
       "      <td>185.00</td>\n",
       "      <td>185.27</td>\n",
       "      <td>33878.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.25</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.50</td>\n",
       "      <td>18070.26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>15.81</td>\n",
       "      <td>15.90</td>\n",
       "      <td>15.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>207915.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.19</td>\n",
       "      <td>16.88</td>\n",
       "      <td>16.90</td>\n",
       "      <td>25973.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.17</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.78</td>\n",
       "      <td>142288.41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.03</td>\n",
       "      <td>57.36</td>\n",
       "      <td>57.79</td>\n",
       "      <td>28902.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>291690.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>20.59</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.48</td>\n",
       "      <td>19.73</td>\n",
       "      <td>102000.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>13.77</td>\n",
       "      <td>13.95</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.29</td>\n",
       "      <td>34955.58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>130363.57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>25.48</td>\n",
       "      <td>25.62</td>\n",
       "      <td>24.45</td>\n",
       "      <td>24.60</td>\n",
       "      <td>121256.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.68</td>\n",
       "      <td>12.48</td>\n",
       "      <td>12.50</td>\n",
       "      <td>405285.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113624</td>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113625</td>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113626</td>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113627</td>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113628</td>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113630</td>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113631</td>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113632</td>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113633</td>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113634</td>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113636</td>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113638</td>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113639</td>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113641</td>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113642</td>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113643</td>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113644</td>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113645</td>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113646</td>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113647</td>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113648</td>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113650</td>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113651</td>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113652</td>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>113653</td>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97902 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        tic        date     open     high      low    close  \\\n",
       "0              0  600010.SH  2012-01-04     4.15     4.28     4.09     4.15   \n",
       "0              1  600028.SH  2012-01-04     7.28     7.44     7.27     7.36   \n",
       "0              2  600030.SH  2012-01-04     9.79     9.85     9.56     9.56   \n",
       "0              3  600031.SH  2012-01-04    12.61    12.73    12.07    12.09   \n",
       "0              4  600036.SH  2012-01-04    11.95    12.10    11.63    11.67   \n",
       "0              5  600048.SH  2012-01-04    10.01    10.30     9.91    10.05   \n",
       "0              6  600104.SH  2012-01-04    14.28    14.53    13.92    14.16   \n",
       "0              7  600111.SH  2012-01-04    37.90    38.20    37.51    37.61   \n",
       "0              8  600196.SH  2012-01-04     8.60     8.68     8.30     8.34   \n",
       "0              9  600276.SH  2012-01-04    29.50    29.75    28.40    28.45   \n",
       "0             10  600309.SH  2012-01-04    12.97    13.10    12.45    12.50   \n",
       "0             12  600436.SH  2012-01-04    75.02    75.30    73.00    73.03   \n",
       "0             13  600438.SH  2012-01-04     5.02     5.06     4.84     4.85   \n",
       "0             14  600519.SH  2012-01-04   191.50   192.77   185.00   185.27   \n",
       "0             15  600570.SH  2012-01-04    12.24    12.25    11.46    11.50   \n",
       "0             16  600585.SH  2012-01-04    15.81    15.90    15.27    15.28   \n",
       "0             17  600588.SH  2012-01-04    18.00    18.19    16.88    16.90   \n",
       "0             18  600690.SH  2012-01-04     9.00     9.17     8.78     8.78   \n",
       "0             20  600809.SH  2012-01-04    63.00    63.03    57.36    57.79   \n",
       "0             21  600837.SH  2012-01-04     7.51     7.51     7.10     7.12   \n",
       "0             22  600887.SH  2012-01-04    20.59    20.60    19.48    19.73   \n",
       "0             23  600893.SH  2012-01-04    13.77    13.95    13.24    13.29   \n",
       "0             24  600900.SH  2012-01-04     6.36     6.40     6.29     6.29   \n",
       "0             25  601088.SH  2012-01-04    25.48    25.62    24.45    24.60   \n",
       "0             26  601166.SH  2012-01-04    12.65    12.68    12.48    12.50   \n",
       "...          ...        ...         ...      ...      ...      ...      ...   \n",
       "2612      113624  600519.SH  2022-09-30  1898.62  1901.99  1866.00  1872.50   \n",
       "2612      113625  600570.SH  2022-09-30    33.79    34.74    33.60    33.89   \n",
       "2612      113626  600585.SH  2022-09-30    28.18    29.15    28.18    28.81   \n",
       "2612      113627  600588.SH  2022-09-30    17.71    17.93    17.60    17.60   \n",
       "2612      113628  600690.SH  2022-09-30    25.00    25.19    24.65    24.77   \n",
       "2612      113630  600809.SH  2022-09-30   309.00   309.80   300.12   302.89   \n",
       "2612      113631  600837.SH  2022-09-30     8.51     8.73     8.51     8.66   \n",
       "2612      113632  600887.SH  2022-09-30    33.29    33.47    32.93    32.98   \n",
       "2612      113633  600893.SH  2022-09-30    43.56    43.64    41.84    41.95   \n",
       "2612      113634  600900.SH  2022-09-30    22.40    22.85    22.28    22.74   \n",
       "2612      113636  601012.SH  2022-09-30    49.78    50.15    47.80    47.91   \n",
       "2612      113638  601088.SH  2022-09-30    31.60    31.92    31.10    31.64   \n",
       "2612      113639  601166.SH  2022-09-30    16.57    16.77    16.54    16.65   \n",
       "2612      113641  601288.SH  2022-09-30     2.83     2.86     2.83     2.86   \n",
       "2612      113642  601318.SH  2022-09-30    41.35    41.98    41.35    41.58   \n",
       "2612      113643  601398.SH  2022-09-30     4.34     4.36     4.33     4.35   \n",
       "2612      113644  601601.SH  2022-09-30    19.83    20.45    19.83    20.33   \n",
       "2612      113645  601628.SH  2022-09-30    31.76    32.00    31.16    31.63   \n",
       "2612      113646  601633.SH  2022-09-30    28.05    28.35    27.68    27.80   \n",
       "2612      113647  601668.SH  2022-09-30     5.03     5.19     5.03     5.15   \n",
       "2612      113648  601688.SH  2022-09-30    12.19    12.29    12.10    12.12   \n",
       "2612      113650  601857.SH  2022-09-30     5.08     5.16     5.08     5.13   \n",
       "2612      113651  601888.SH  2022-09-30   198.24   200.50   195.71   198.25   \n",
       "2612      113652  601899.SH  2022-09-30     7.78     7.92     7.73     7.84   \n",
       "2612      113653  601919.SH  2022-09-30    11.00    11.14    10.92    11.02   \n",
       "\n",
       "          volume  day  \n",
       "0      672559.53    2  \n",
       "0      528181.38    2  \n",
       "0      354005.33    2  \n",
       "0      235312.56    2  \n",
       "0      522606.17    2  \n",
       "0      341555.93    2  \n",
       "0      272418.21    2  \n",
       "0      160533.19    2  \n",
       "0       36465.88    2  \n",
       "0       11847.13    2  \n",
       "0       96092.38    2  \n",
       "0        3099.31    2  \n",
       "0       17962.70    2  \n",
       "0       33878.28    2  \n",
       "0       18070.26    2  \n",
       "0      207915.93    2  \n",
       "0       25973.70    2  \n",
       "0      142288.41    2  \n",
       "0       28902.50    2  \n",
       "0      291690.79    2  \n",
       "0      102000.09    2  \n",
       "0       34955.58    2  \n",
       "0      130363.57    2  \n",
       "0      121256.25    2  \n",
       "0      405285.47    2  \n",
       "...          ...  ...  \n",
       "2612    21289.08    4  \n",
       "2612   101960.81    4  \n",
       "2612   284870.69    4  \n",
       "2612   124403.66    4  \n",
       "2612   267702.88    4  \n",
       "2612    32116.50    4  \n",
       "2612   220874.32    4  \n",
       "2612   264761.80    4  \n",
       "2612   161512.07    4  \n",
       "2612   423324.79    4  \n",
       "2612   682745.27    4  \n",
       "2612   219426.08    4  \n",
       "2612   470496.19    4  \n",
       "2612  2602100.09    4  \n",
       "2612   331619.40    4  \n",
       "2612  1578628.46    4  \n",
       "2612   195189.41    4  \n",
       "2612   111268.85    4  \n",
       "2612   151081.85    4  \n",
       "2612  2186913.38    4  \n",
       "2612   229982.43    4  \n",
       "2612   819572.30    4  \n",
       "2612    80998.33    4  \n",
       "2612  1988575.12    4  \n",
       "2612   625792.65    4  \n",
       "\n",
       "[97902 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the stocks with missing data less than 10%\n",
    "tics = merged_closes.columns\n",
    "df = df[df.tic.isin(tics)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:15.803830Z",
     "start_time": "2022-10-12T02:27:15.716342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>672559.53</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.36</td>\n",
       "      <td>528181.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.56</td>\n",
       "      <td>9.56</td>\n",
       "      <td>354005.33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.61</td>\n",
       "      <td>12.73</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.09</td>\n",
       "      <td>235312.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>11.95</td>\n",
       "      <td>12.10</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.67</td>\n",
       "      <td>522606.17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>10.01</td>\n",
       "      <td>10.30</td>\n",
       "      <td>9.91</td>\n",
       "      <td>10.05</td>\n",
       "      <td>341555.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>14.28</td>\n",
       "      <td>14.53</td>\n",
       "      <td>13.92</td>\n",
       "      <td>14.16</td>\n",
       "      <td>272418.21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>37.90</td>\n",
       "      <td>38.20</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.61</td>\n",
       "      <td>160533.19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.30</td>\n",
       "      <td>8.34</td>\n",
       "      <td>36465.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>29.50</td>\n",
       "      <td>29.75</td>\n",
       "      <td>28.40</td>\n",
       "      <td>28.45</td>\n",
       "      <td>11847.13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.97</td>\n",
       "      <td>13.10</td>\n",
       "      <td>12.45</td>\n",
       "      <td>12.50</td>\n",
       "      <td>96092.38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>75.02</td>\n",
       "      <td>75.30</td>\n",
       "      <td>73.00</td>\n",
       "      <td>73.03</td>\n",
       "      <td>3099.31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.06</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.85</td>\n",
       "      <td>17962.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>191.50</td>\n",
       "      <td>192.77</td>\n",
       "      <td>185.00</td>\n",
       "      <td>185.27</td>\n",
       "      <td>33878.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.24</td>\n",
       "      <td>12.25</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.50</td>\n",
       "      <td>18070.26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>15.81</td>\n",
       "      <td>15.90</td>\n",
       "      <td>15.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>207915.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>18.00</td>\n",
       "      <td>18.19</td>\n",
       "      <td>16.88</td>\n",
       "      <td>16.90</td>\n",
       "      <td>25973.70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.17</td>\n",
       "      <td>8.78</td>\n",
       "      <td>8.78</td>\n",
       "      <td>142288.41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>63.00</td>\n",
       "      <td>63.03</td>\n",
       "      <td>57.36</td>\n",
       "      <td>57.79</td>\n",
       "      <td>28902.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.12</td>\n",
       "      <td>291690.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>20.59</td>\n",
       "      <td>20.60</td>\n",
       "      <td>19.48</td>\n",
       "      <td>19.73</td>\n",
       "      <td>102000.09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>13.77</td>\n",
       "      <td>13.95</td>\n",
       "      <td>13.24</td>\n",
       "      <td>13.29</td>\n",
       "      <td>34955.58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>6.36</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.29</td>\n",
       "      <td>6.29</td>\n",
       "      <td>130363.57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>25.48</td>\n",
       "      <td>25.62</td>\n",
       "      <td>24.45</td>\n",
       "      <td>24.60</td>\n",
       "      <td>121256.25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>12.65</td>\n",
       "      <td>12.68</td>\n",
       "      <td>12.48</td>\n",
       "      <td>12.50</td>\n",
       "      <td>405285.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97902 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tic        date     open     high      low    close      volume  \\\n",
       "0     600010.SH  2012-01-04     4.15     4.28     4.09     4.15   672559.53   \n",
       "0     600028.SH  2012-01-04     7.28     7.44     7.27     7.36   528181.38   \n",
       "0     600030.SH  2012-01-04     9.79     9.85     9.56     9.56   354005.33   \n",
       "0     600031.SH  2012-01-04    12.61    12.73    12.07    12.09   235312.56   \n",
       "0     600036.SH  2012-01-04    11.95    12.10    11.63    11.67   522606.17   \n",
       "0     600048.SH  2012-01-04    10.01    10.30     9.91    10.05   341555.93   \n",
       "0     600104.SH  2012-01-04    14.28    14.53    13.92    14.16   272418.21   \n",
       "0     600111.SH  2012-01-04    37.90    38.20    37.51    37.61   160533.19   \n",
       "0     600196.SH  2012-01-04     8.60     8.68     8.30     8.34    36465.88   \n",
       "0     600276.SH  2012-01-04    29.50    29.75    28.40    28.45    11847.13   \n",
       "0     600309.SH  2012-01-04    12.97    13.10    12.45    12.50    96092.38   \n",
       "0     600436.SH  2012-01-04    75.02    75.30    73.00    73.03     3099.31   \n",
       "0     600438.SH  2012-01-04     5.02     5.06     4.84     4.85    17962.70   \n",
       "0     600519.SH  2012-01-04   191.50   192.77   185.00   185.27    33878.28   \n",
       "0     600570.SH  2012-01-04    12.24    12.25    11.46    11.50    18070.26   \n",
       "0     600585.SH  2012-01-04    15.81    15.90    15.27    15.28   207915.93   \n",
       "0     600588.SH  2012-01-04    18.00    18.19    16.88    16.90    25973.70   \n",
       "0     600690.SH  2012-01-04     9.00     9.17     8.78     8.78   142288.41   \n",
       "0     600809.SH  2012-01-04    63.00    63.03    57.36    57.79    28902.50   \n",
       "0     600837.SH  2012-01-04     7.51     7.51     7.10     7.12   291690.79   \n",
       "0     600887.SH  2012-01-04    20.59    20.60    19.48    19.73   102000.09   \n",
       "0     600893.SH  2012-01-04    13.77    13.95    13.24    13.29    34955.58   \n",
       "0     600900.SH  2012-01-04     6.36     6.40     6.29     6.29   130363.57   \n",
       "0     601088.SH  2012-01-04    25.48    25.62    24.45    24.60   121256.25   \n",
       "0     601166.SH  2012-01-04    12.65    12.68    12.48    12.50   405285.47   \n",
       "...         ...         ...      ...      ...      ...      ...         ...   \n",
       "2612  600519.SH  2022-09-30  1898.62  1901.99  1866.00  1872.50    21289.08   \n",
       "2612  600570.SH  2022-09-30    33.79    34.74    33.60    33.89   101960.81   \n",
       "2612  600585.SH  2022-09-30    28.18    29.15    28.18    28.81   284870.69   \n",
       "2612  600588.SH  2022-09-30    17.71    17.93    17.60    17.60   124403.66   \n",
       "2612  600690.SH  2022-09-30    25.00    25.19    24.65    24.77   267702.88   \n",
       "2612  600809.SH  2022-09-30   309.00   309.80   300.12   302.89    32116.50   \n",
       "2612  600837.SH  2022-09-30     8.51     8.73     8.51     8.66   220874.32   \n",
       "2612  600887.SH  2022-09-30    33.29    33.47    32.93    32.98   264761.80   \n",
       "2612  600893.SH  2022-09-30    43.56    43.64    41.84    41.95   161512.07   \n",
       "2612  600900.SH  2022-09-30    22.40    22.85    22.28    22.74   423324.79   \n",
       "2612  601012.SH  2022-09-30    49.78    50.15    47.80    47.91   682745.27   \n",
       "2612  601088.SH  2022-09-30    31.60    31.92    31.10    31.64   219426.08   \n",
       "2612  601166.SH  2022-09-30    16.57    16.77    16.54    16.65   470496.19   \n",
       "2612  601288.SH  2022-09-30     2.83     2.86     2.83     2.86  2602100.09   \n",
       "2612  601318.SH  2022-09-30    41.35    41.98    41.35    41.58   331619.40   \n",
       "2612  601398.SH  2022-09-30     4.34     4.36     4.33     4.35  1578628.46   \n",
       "2612  601601.SH  2022-09-30    19.83    20.45    19.83    20.33   195189.41   \n",
       "2612  601628.SH  2022-09-30    31.76    32.00    31.16    31.63   111268.85   \n",
       "2612  601633.SH  2022-09-30    28.05    28.35    27.68    27.80   151081.85   \n",
       "2612  601668.SH  2022-09-30     5.03     5.19     5.03     5.15  2186913.38   \n",
       "2612  601688.SH  2022-09-30    12.19    12.29    12.10    12.12   229982.43   \n",
       "2612  601857.SH  2022-09-30     5.08     5.16     5.08     5.13   819572.30   \n",
       "2612  601888.SH  2022-09-30   198.24   200.50   195.71   198.25    80998.33   \n",
       "2612  601899.SH  2022-09-30     7.78     7.92     7.73     7.84  1988575.12   \n",
       "2612  601919.SH  2022-09-30    11.00    11.14    10.92    11.02   625792.65   \n",
       "\n",
       "      day  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "0       2  \n",
       "...   ...  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "2612    4  \n",
       "\n",
       "[97902 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# back fill missing data then front fill\n",
    "df = df.fillna(method = 'bfill').fillna(method = 'ffill')\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:27:51.621838Z",
     "start_time": "2022-10-12T02:27:20.606731Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "3e40b006",
    "outputId": "86eb6231-2bfa-4f04-bd37-9296d88102d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (99142, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.48</td>\n",
       "      <td>787406.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>4.618261</td>\n",
       "      <td>3.916739</td>\n",
       "      <td>88.841714</td>\n",
       "      <td>110.724638</td>\n",
       "      <td>48.821799</td>\n",
       "      <td>4.267500</td>\n",
       "      <td>4.267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.75</td>\n",
       "      <td>743960.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>7.846738</td>\n",
       "      <td>7.158262</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.502500</td>\n",
       "      <td>7.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.75</td>\n",
       "      <td>623061.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>9.901274</td>\n",
       "      <td>9.093726</td>\n",
       "      <td>64.412995</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>12.698092</td>\n",
       "      <td>9.497500</td>\n",
       "      <td>9.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.11</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.55</td>\n",
       "      <td>245945.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>12.670833</td>\n",
       "      <td>11.709167</td>\n",
       "      <td>94.588508</td>\n",
       "      <td>80.380952</td>\n",
       "      <td>26.343026</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>12.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.98</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.38</td>\n",
       "      <td>960020.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>12.577274</td>\n",
       "      <td>11.397726</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.987500</td>\n",
       "      <td>11.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>10.21</td>\n",
       "      <td>9.56</td>\n",
       "      <td>10.17</td>\n",
       "      <td>469341.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>10.360324</td>\n",
       "      <td>9.504676</td>\n",
       "      <td>58.928190</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.558436</td>\n",
       "      <td>9.932500</td>\n",
       "      <td>9.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.06</td>\n",
       "      <td>14.90</td>\n",
       "      <td>356606.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>15.092770</td>\n",
       "      <td>13.732230</td>\n",
       "      <td>83.281583</td>\n",
       "      <td>131.360947</td>\n",
       "      <td>43.366115</td>\n",
       "      <td>14.412500</td>\n",
       "      <td>14.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>39.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>39.02</td>\n",
       "      <td>263676.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067193</td>\n",
       "      <td>40.131340</td>\n",
       "      <td>34.163660</td>\n",
       "      <td>64.586597</td>\n",
       "      <td>77.199282</td>\n",
       "      <td>7.583484</td>\n",
       "      <td>37.147500</td>\n",
       "      <td>37.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.34</td>\n",
       "      <td>62208.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>8.497653</td>\n",
       "      <td>8.007347</td>\n",
       "      <td>51.137481</td>\n",
       "      <td>-14.245014</td>\n",
       "      <td>49.001351</td>\n",
       "      <td>8.252500</td>\n",
       "      <td>8.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.65</td>\n",
       "      <td>27.50</td>\n",
       "      <td>25.60</td>\n",
       "      <td>27.40</td>\n",
       "      <td>43085.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>28.972755</td>\n",
       "      <td>25.727245</td>\n",
       "      <td>32.197647</td>\n",
       "      <td>-56.144438</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.350000</td>\n",
       "      <td>27.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.08</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.84</td>\n",
       "      <td>12.47</td>\n",
       "      <td>151864.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>12.751932</td>\n",
       "      <td>11.813068</td>\n",
       "      <td>49.851392</td>\n",
       "      <td>-10.122921</td>\n",
       "      <td>35.172834</td>\n",
       "      <td>12.282500</td>\n",
       "      <td>12.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.60</td>\n",
       "      <td>68.89</td>\n",
       "      <td>70.10</td>\n",
       "      <td>10927.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095540</td>\n",
       "      <td>73.757406</td>\n",
       "      <td>68.097594</td>\n",
       "      <td>0.716809</td>\n",
       "      <td>-61.967145</td>\n",
       "      <td>95.185322</td>\n",
       "      <td>70.927500</td>\n",
       "      <td>70.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.89</td>\n",
       "      <td>24346.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>4.996025</td>\n",
       "      <td>4.563975</td>\n",
       "      <td>56.220718</td>\n",
       "      <td>30.529595</td>\n",
       "      <td>11.732573</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>4.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.00</td>\n",
       "      <td>188.09</td>\n",
       "      <td>181.77</td>\n",
       "      <td>188.01</td>\n",
       "      <td>26160.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139206</td>\n",
       "      <td>189.913000</td>\n",
       "      <td>181.622000</td>\n",
       "      <td>70.541058</td>\n",
       "      <td>16.931217</td>\n",
       "      <td>7.889720</td>\n",
       "      <td>185.767500</td>\n",
       "      <td>185.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.72</td>\n",
       "      <td>11.03</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15365.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013964</td>\n",
       "      <td>11.737500</td>\n",
       "      <td>10.197500</td>\n",
       "      <td>29.822271</td>\n",
       "      <td>-24.598512</td>\n",
       "      <td>57.180821</td>\n",
       "      <td>10.967500</td>\n",
       "      <td>10.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>15.60</td>\n",
       "      <td>14.56</td>\n",
       "      <td>15.55</td>\n",
       "      <td>311506.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>15.857297</td>\n",
       "      <td>14.377703</td>\n",
       "      <td>61.041381</td>\n",
       "      <td>33.106576</td>\n",
       "      <td>15.199647</td>\n",
       "      <td>15.117500</td>\n",
       "      <td>15.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.62</td>\n",
       "      <td>15.66</td>\n",
       "      <td>16.58</td>\n",
       "      <td>48522.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011340</td>\n",
       "      <td>17.102087</td>\n",
       "      <td>15.992913</td>\n",
       "      <td>35.564287</td>\n",
       "      <td>-32.037222</td>\n",
       "      <td>66.698547</td>\n",
       "      <td>16.547500</td>\n",
       "      <td>16.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8.68</td>\n",
       "      <td>9.07</td>\n",
       "      <td>160606.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>9.150342</td>\n",
       "      <td>8.534658</td>\n",
       "      <td>87.855596</td>\n",
       "      <td>80.341880</td>\n",
       "      <td>9.531850</td>\n",
       "      <td>8.842500</td>\n",
       "      <td>8.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.70</td>\n",
       "      <td>54.60</td>\n",
       "      <td>52.78</td>\n",
       "      <td>54.59</td>\n",
       "      <td>28933.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.111768</td>\n",
       "      <td>58.810558</td>\n",
       "      <td>51.744442</td>\n",
       "      <td>18.849264</td>\n",
       "      <td>-62.041431</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>55.277500</td>\n",
       "      <td>55.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.62</td>\n",
       "      <td>642922.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>7.772070</td>\n",
       "      <td>6.787930</td>\n",
       "      <td>93.443006</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>79.566052</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.67</td>\n",
       "      <td>20.20</td>\n",
       "      <td>19.08</td>\n",
       "      <td>20.13</td>\n",
       "      <td>118868.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>20.369437</td>\n",
       "      <td>19.055563</td>\n",
       "      <td>67.854754</td>\n",
       "      <td>46.840149</td>\n",
       "      <td>6.659267</td>\n",
       "      <td>19.712500</td>\n",
       "      <td>19.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>13.46</td>\n",
       "      <td>12.74</td>\n",
       "      <td>13.39</td>\n",
       "      <td>43936.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>13.739108</td>\n",
       "      <td>12.405892</td>\n",
       "      <td>55.027883</td>\n",
       "      <td>26.845638</td>\n",
       "      <td>27.847554</td>\n",
       "      <td>13.072500</td>\n",
       "      <td>13.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.29</td>\n",
       "      <td>203893.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>6.331181</td>\n",
       "      <td>6.188819</td>\n",
       "      <td>51.449571</td>\n",
       "      <td>-31.924883</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.260000</td>\n",
       "      <td>6.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>63.0</td>\n",
       "      <td>19.30</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.15</td>\n",
       "      <td>19.47</td>\n",
       "      <td>83715.18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>20.005980</td>\n",
       "      <td>19.214020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.610000</td>\n",
       "      <td>19.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.29</td>\n",
       "      <td>26.06</td>\n",
       "      <td>24.12</td>\n",
       "      <td>26.01</td>\n",
       "      <td>304669.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052423</td>\n",
       "      <td>26.443712</td>\n",
       "      <td>23.141288</td>\n",
       "      <td>84.919012</td>\n",
       "      <td>109.787234</td>\n",
       "      <td>66.693781</td>\n",
       "      <td>24.792500</td>\n",
       "      <td>24.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99117</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.205584</td>\n",
       "      <td>1905.084788</td>\n",
       "      <td>1810.868212</td>\n",
       "      <td>49.210286</td>\n",
       "      <td>43.354556</td>\n",
       "      <td>4.610511</td>\n",
       "      <td>1866.981333</td>\n",
       "      <td>1896.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99118</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.768929</td>\n",
       "      <td>36.239658</td>\n",
       "      <td>31.554342</td>\n",
       "      <td>44.196982</td>\n",
       "      <td>45.034429</td>\n",
       "      <td>8.461160</td>\n",
       "      <td>33.301667</td>\n",
       "      <td>37.428833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99119</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.951232</td>\n",
       "      <td>32.768742</td>\n",
       "      <td>27.320258</td>\n",
       "      <td>39.227171</td>\n",
       "      <td>-112.192998</td>\n",
       "      <td>23.395967</td>\n",
       "      <td>30.577000</td>\n",
       "      <td>31.911167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99120</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.686902</td>\n",
       "      <td>20.564209</td>\n",
       "      <td>17.092791</td>\n",
       "      <td>39.883637</td>\n",
       "      <td>-127.830776</td>\n",
       "      <td>23.497526</td>\n",
       "      <td>19.364000</td>\n",
       "      <td>20.070667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99121</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.032207</td>\n",
       "      <td>27.002850</td>\n",
       "      <td>24.280150</td>\n",
       "      <td>47.955669</td>\n",
       "      <td>-46.280992</td>\n",
       "      <td>8.286352</td>\n",
       "      <td>25.364667</td>\n",
       "      <td>24.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99122</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.770177</td>\n",
       "      <td>309.269051</td>\n",
       "      <td>277.852949</td>\n",
       "      <td>56.490877</td>\n",
       "      <td>118.397397</td>\n",
       "      <td>35.043245</td>\n",
       "      <td>288.141333</td>\n",
       "      <td>285.021333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99123</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.182558</td>\n",
       "      <td>9.760406</td>\n",
       "      <td>8.598594</td>\n",
       "      <td>36.582080</td>\n",
       "      <td>-194.604245</td>\n",
       "      <td>55.336652</td>\n",
       "      <td>9.272333</td>\n",
       "      <td>9.353333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99124</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.588198</td>\n",
       "      <td>34.189506</td>\n",
       "      <td>32.071494</td>\n",
       "      <td>40.677415</td>\n",
       "      <td>-51.402939</td>\n",
       "      <td>12.827832</td>\n",
       "      <td>33.973667</td>\n",
       "      <td>35.066833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99125</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.371672</td>\n",
       "      <td>49.830794</td>\n",
       "      <td>42.613206</td>\n",
       "      <td>40.822531</td>\n",
       "      <td>-203.113753</td>\n",
       "      <td>31.939610</td>\n",
       "      <td>46.967333</td>\n",
       "      <td>49.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99126</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.283151</td>\n",
       "      <td>24.311465</td>\n",
       "      <td>22.450535</td>\n",
       "      <td>42.647592</td>\n",
       "      <td>-185.556412</td>\n",
       "      <td>34.433872</td>\n",
       "      <td>23.417667</td>\n",
       "      <td>23.789333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99127</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.728189</td>\n",
       "      <td>54.486358</td>\n",
       "      <td>46.129642</td>\n",
       "      <td>38.786281</td>\n",
       "      <td>-94.845268</td>\n",
       "      <td>35.806177</td>\n",
       "      <td>51.251333</td>\n",
       "      <td>55.487333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99128</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.096078</td>\n",
       "      <td>33.327838</td>\n",
       "      <td>30.026162</td>\n",
       "      <td>52.556566</td>\n",
       "      <td>16.859864</td>\n",
       "      <td>10.223676</td>\n",
       "      <td>31.409333</td>\n",
       "      <td>30.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99129</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.215111</td>\n",
       "      <td>17.677171</td>\n",
       "      <td>16.506829</td>\n",
       "      <td>41.092287</td>\n",
       "      <td>-130.421549</td>\n",
       "      <td>21.408923</td>\n",
       "      <td>17.211333</td>\n",
       "      <td>17.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99130</th>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2.879206</td>\n",
       "      <td>2.815794</td>\n",
       "      <td>49.061725</td>\n",
       "      <td>44.937429</td>\n",
       "      <td>19.468989</td>\n",
       "      <td>2.840333</td>\n",
       "      <td>2.852167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99131</th>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.306936</td>\n",
       "      <td>45.584692</td>\n",
       "      <td>41.195308</td>\n",
       "      <td>43.493820</td>\n",
       "      <td>-103.476775</td>\n",
       "      <td>14.614106</td>\n",
       "      <td>43.064000</td>\n",
       "      <td>42.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99132</th>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>4.398556</td>\n",
       "      <td>4.326444</td>\n",
       "      <td>44.834511</td>\n",
       "      <td>-39.017341</td>\n",
       "      <td>4.027457</td>\n",
       "      <td>4.355667</td>\n",
       "      <td>4.379167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99133</th>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.136296</td>\n",
       "      <td>21.714986</td>\n",
       "      <td>19.552014</td>\n",
       "      <td>47.205933</td>\n",
       "      <td>-43.289347</td>\n",
       "      <td>3.763124</td>\n",
       "      <td>20.489333</td>\n",
       "      <td>20.457833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99134</th>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620124</td>\n",
       "      <td>32.273866</td>\n",
       "      <td>29.367134</td>\n",
       "      <td>59.040332</td>\n",
       "      <td>94.651333</td>\n",
       "      <td>30.245425</td>\n",
       "      <td>30.140667</td>\n",
       "      <td>28.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99135</th>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.220938</td>\n",
       "      <td>33.000132</td>\n",
       "      <td>27.071868</td>\n",
       "      <td>40.762729</td>\n",
       "      <td>-126.327626</td>\n",
       "      <td>38.764325</td>\n",
       "      <td>31.231667</td>\n",
       "      <td>32.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99136</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>5.374797</td>\n",
       "      <td>5.009203</td>\n",
       "      <td>49.362609</td>\n",
       "      <td>-8.448348</td>\n",
       "      <td>0.267188</td>\n",
       "      <td>5.138000</td>\n",
       "      <td>5.123167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99137</th>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.249653</td>\n",
       "      <td>13.538437</td>\n",
       "      <td>11.806563</td>\n",
       "      <td>36.813250</td>\n",
       "      <td>-122.198506</td>\n",
       "      <td>44.061683</td>\n",
       "      <td>12.812000</td>\n",
       "      <td>13.004333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99138</th>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.062860</td>\n",
       "      <td>5.755721</td>\n",
       "      <td>4.975279</td>\n",
       "      <td>45.564208</td>\n",
       "      <td>-113.679847</td>\n",
       "      <td>11.212406</td>\n",
       "      <td>5.364333</td>\n",
       "      <td>5.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99139</th>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.330810</td>\n",
       "      <td>203.420184</td>\n",
       "      <td>176.951816</td>\n",
       "      <td>51.954585</td>\n",
       "      <td>129.238562</td>\n",
       "      <td>17.738487</td>\n",
       "      <td>190.593667</td>\n",
       "      <td>197.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99140</th>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.303164</td>\n",
       "      <td>9.603624</td>\n",
       "      <td>7.492376</td>\n",
       "      <td>38.868903</td>\n",
       "      <td>-169.989876</td>\n",
       "      <td>41.678620</td>\n",
       "      <td>8.679333</td>\n",
       "      <td>8.751333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99141</th>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.651301</td>\n",
       "      <td>14.200318</td>\n",
       "      <td>10.656682</td>\n",
       "      <td>32.953801</td>\n",
       "      <td>-154.242342</td>\n",
       "      <td>49.177082</td>\n",
       "      <td>12.898333</td>\n",
       "      <td>13.367333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99142 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tic        date   index     open     high      low    close  \\\n",
       "0      600010.SH  2012-01-09     3.0     4.31     4.49     4.23     4.48   \n",
       "1      600028.SH  2012-01-09     3.0     7.50     7.80     7.41     7.75   \n",
       "2      600030.SH  2012-01-09     3.0     9.36     9.79     9.26     9.75   \n",
       "3      600031.SH  2012-01-09     3.0    12.11    12.58    11.94    12.55   \n",
       "4      600036.SH  2012-01-09     3.0    11.98    12.50    11.90    12.38   \n",
       "5      600048.SH  2012-01-09     3.0     9.66    10.21     9.56    10.17   \n",
       "6      600104.SH  2012-01-09     3.0    14.21    14.95    14.06    14.90   \n",
       "7      600111.SH  2012-01-09     3.0    36.33    39.40    35.78    39.02   \n",
       "8      600196.SH  2012-01-09     3.0     8.10     8.35     8.04     8.34   \n",
       "9      600276.SH  2012-01-09     3.0    26.65    27.50    25.60    27.40   \n",
       "10     600309.SH  2012-01-09     3.0    12.08    12.50    11.84    12.47   \n",
       "11     600436.SH  2012-01-09     3.0    70.08    70.60    68.89    70.10   \n",
       "12     600438.SH  2012-01-09     3.0     4.73     4.91     4.66     4.89   \n",
       "13     600519.SH  2012-01-09     3.0   186.00   188.09   181.77   188.01   \n",
       "14     600570.SH  2012-01-09     3.0    10.72    11.03    10.66    11.00   \n",
       "15     600585.SH  2012-01-09     3.0    14.82    15.60    14.56    15.55   \n",
       "16     600588.SH  2012-01-09     3.0    16.23    16.62    15.66    16.58   \n",
       "17     600690.SH  2012-01-09     3.0     8.88     9.10     8.68     9.07   \n",
       "18     600809.SH  2012-01-09     3.0    53.70    54.60    52.78    54.59   \n",
       "19     600837.SH  2012-01-09     3.0     7.30     7.64     7.24     7.62   \n",
       "20     600887.SH  2012-01-09     3.0    19.67    20.20    19.08    20.13   \n",
       "21     600893.SH  2012-01-09     3.0    12.92    13.46    12.74    13.39   \n",
       "22     600900.SH  2012-01-09     3.0     6.22     6.30     6.17     6.29   \n",
       "23     601012.SH  2012-01-09    63.0    19.30    19.60    19.15    19.47   \n",
       "24     601088.SH  2012-01-09     3.0    24.29    26.06    24.12    26.01   \n",
       "...          ...         ...     ...      ...      ...      ...      ...   \n",
       "99117  600519.SH  2022-09-30  2612.0  1898.62  1901.99  1866.00  1872.50   \n",
       "99118  600570.SH  2022-09-30  2612.0    33.79    34.74    33.60    33.89   \n",
       "99119  600585.SH  2022-09-30  2612.0    28.18    29.15    28.18    28.81   \n",
       "99120  600588.SH  2022-09-30  2612.0    17.71    17.93    17.60    17.60   \n",
       "99121  600690.SH  2022-09-30  2612.0    25.00    25.19    24.65    24.77   \n",
       "99122  600809.SH  2022-09-30  2612.0   309.00   309.80   300.12   302.89   \n",
       "99123  600837.SH  2022-09-30  2612.0     8.51     8.73     8.51     8.66   \n",
       "99124  600887.SH  2022-09-30  2612.0    33.29    33.47    32.93    32.98   \n",
       "99125  600893.SH  2022-09-30  2612.0    43.56    43.64    41.84    41.95   \n",
       "99126  600900.SH  2022-09-30  2612.0    22.40    22.85    22.28    22.74   \n",
       "99127  601012.SH  2022-09-30  2612.0    49.78    50.15    47.80    47.91   \n",
       "99128  601088.SH  2022-09-30  2612.0    31.60    31.92    31.10    31.64   \n",
       "99129  601166.SH  2022-09-30  2612.0    16.57    16.77    16.54    16.65   \n",
       "99130  601288.SH  2022-09-30  2612.0     2.83     2.86     2.83     2.86   \n",
       "99131  601318.SH  2022-09-30  2612.0    41.35    41.98    41.35    41.58   \n",
       "99132  601398.SH  2022-09-30  2612.0     4.34     4.36     4.33     4.35   \n",
       "99133  601601.SH  2022-09-30  2612.0    19.83    20.45    19.83    20.33   \n",
       "99134  601628.SH  2022-09-30  2612.0    31.76    32.00    31.16    31.63   \n",
       "99135  601633.SH  2022-09-30  2612.0    28.05    28.35    27.68    27.80   \n",
       "99136  601668.SH  2022-09-30  2612.0     5.03     5.19     5.03     5.15   \n",
       "99137  601688.SH  2022-09-30  2612.0    12.19    12.29    12.10    12.12   \n",
       "99138  601857.SH  2022-09-30  2612.0     5.08     5.16     5.08     5.13   \n",
       "99139  601888.SH  2022-09-30  2612.0   198.24   200.50   195.71   198.25   \n",
       "99140  601899.SH  2022-09-30  2612.0     7.78     7.92     7.73     7.84   \n",
       "99141  601919.SH  2022-09-30  2612.0    11.00    11.14    10.92    11.02   \n",
       "\n",
       "           volume  day      macd      boll_ub      boll_lb      rsi_30  \\\n",
       "0       787406.46  0.0  0.014165     4.618261     3.916739   88.841714   \n",
       "1       743960.15  0.0  0.014251     7.846738     7.158262  100.000000   \n",
       "2       623061.16  0.0  0.009148     9.901274     9.093726   64.412995   \n",
       "3       245945.25  0.0  0.016771    12.670833    11.709167   94.588508   \n",
       "4       960020.09  0.0  0.024994    12.577274    11.397726  100.000000   \n",
       "5       469341.00  0.0  0.004945    10.360324     9.504676   58.928190   \n",
       "6       356606.32  0.0  0.023904    15.092770    13.732230   83.281583   \n",
       "7       263676.19  0.0  0.067193    40.131340    34.163660   64.586597   \n",
       "8        62208.12  0.0 -0.000915     8.497653     8.007347   51.137481   \n",
       "9        43085.35  0.0 -0.033764    28.972755    25.727245   32.197647   \n",
       "10      151864.28  0.0  0.000755    12.751932    11.813068   49.851392   \n",
       "11       10927.68  0.0 -0.095540    73.757406    68.097594    0.716809   \n",
       "12       24346.27  0.0  0.002969     4.996025     4.563975   56.220718   \n",
       "13       26160.16  0.0  0.139206   189.913000   181.622000   70.541058   \n",
       "14       15365.29  0.0 -0.013964    11.737500    10.197500   29.822271   \n",
       "15      311506.05  0.0  0.010049    15.857297    14.377703   61.041381   \n",
       "16       48522.89  0.0 -0.011340    17.102087    15.992913   35.564287   \n",
       "17      160606.42  0.0  0.011236     9.150342     8.534658   87.855596   \n",
       "18       28933.49  0.0 -0.111768    58.810558    51.744442   18.849264   \n",
       "19      642922.60  0.0  0.020084     7.772070     6.787930   93.443006   \n",
       "20      118868.14  0.0  0.019332    20.369437    19.055563   67.854754   \n",
       "21       43936.61  0.0  0.009417    13.739108    12.405892   55.027883   \n",
       "22      203893.30  0.0  0.000106     6.331181     6.188819   51.449571   \n",
       "23       83715.18  3.0 -0.006282    20.005980    19.214020    0.000000   \n",
       "24      304669.62  0.0  0.052423    26.443712    23.141288   84.919012   \n",
       "...           ...  ...       ...          ...          ...         ...   \n",
       "99117    21289.08  4.0 -3.205584  1905.084788  1810.868212   49.210286   \n",
       "99118   101960.81  4.0 -0.768929    36.239658    31.554342   44.196982   \n",
       "99119   284870.69  4.0 -0.951232    32.768742    27.320258   39.227171   \n",
       "99120   124403.66  4.0 -0.686902    20.564209    17.092791   39.883637   \n",
       "99121   267702.88  4.0 -0.032207    27.002850    24.280150   47.955669   \n",
       "99122    32116.50  4.0  5.770177   309.269051   277.852949   56.490877   \n",
       "99123   220874.32  4.0 -0.182558     9.760406     8.598594   36.582080   \n",
       "99124   264761.80  4.0 -0.588198    34.189506    32.071494   40.677415   \n",
       "99125   161512.07  4.0 -1.371672    49.830794    42.613206   40.822531   \n",
       "99126   423324.79  4.0 -0.283151    24.311465    22.450535   42.647592   \n",
       "99127   682745.27  4.0 -1.728189    54.486358    46.129642   38.786281   \n",
       "99128   219426.08  4.0  0.096078    33.327838    30.026162   52.556566   \n",
       "99129   470496.19  4.0 -0.215111    17.677171    16.506829   41.092287   \n",
       "99130  2602100.09  4.0  0.000538     2.879206     2.815794   49.061725   \n",
       "99131   331619.40  4.0 -0.306936    45.584692    41.195308   43.493820   \n",
       "99132  1578628.46  4.0 -0.006202     4.398556     4.326444   44.834511   \n",
       "99133   195189.41  4.0 -0.136296    21.714986    19.552014   47.205933   \n",
       "99134   111268.85  4.0  0.620124    32.273866    29.367134   59.040332   \n",
       "99135   151081.85  4.0 -1.220938    33.000132    27.071868   40.762729   \n",
       "99136  2186913.38  4.0 -0.000079     5.374797     5.009203   49.362609   \n",
       "99137   229982.43  4.0 -0.249653    13.538437    11.806563   36.813250   \n",
       "99138   819572.30  4.0 -0.062860     5.755721     4.975279   45.564208   \n",
       "99139    80998.33  4.0  1.330810   203.420184   176.951816   51.954585   \n",
       "99140  1988575.12  4.0 -0.303164     9.603624     7.492376   38.868903   \n",
       "99141   625792.65  4.0 -0.651301    14.200318    10.656682   32.953801   \n",
       "\n",
       "           cci_30       dx_30  close_30_sma  close_60_sma  \n",
       "0      110.724638   48.821799      4.267500      4.267500  \n",
       "1      133.333333  100.000000      7.502500      7.502500  \n",
       "2       53.333333   12.698092      9.497500      9.497500  \n",
       "3       80.380952   26.343026     12.190000     12.190000  \n",
       "4      133.333333  100.000000     11.987500     11.987500  \n",
       "5       40.000000    3.558436      9.932500      9.932500  \n",
       "6      131.360947   43.366115     14.412500     14.412500  \n",
       "7       77.199282    7.583484     37.147500     37.147500  \n",
       "8      -14.245014   49.001351      8.252500      8.252500  \n",
       "9      -56.144438  100.000000     27.350000     27.350000  \n",
       "10     -10.122921   35.172834     12.282500     12.282500  \n",
       "11     -61.967145   95.185322     70.927500     70.927500  \n",
       "12      30.529595   11.732573      4.780000      4.780000  \n",
       "13      16.931217    7.889720    185.767500    185.767500  \n",
       "14     -24.598512   57.180821     10.967500     10.967500  \n",
       "15      33.106576   15.199647     15.117500     15.117500  \n",
       "16     -32.037222   66.698547     16.547500     16.547500  \n",
       "17      80.341880    9.531850      8.842500      8.842500  \n",
       "18     -62.041431  100.000000     55.277500     55.277500  \n",
       "19     133.333333   79.566052      7.280000      7.280000  \n",
       "20      46.840149    6.659267     19.712500     19.712500  \n",
       "21      26.845638   27.847554     13.072500     13.072500  \n",
       "22     -31.924883  100.000000      6.260000      6.260000  \n",
       "23     -66.666667  100.000000     19.610000     19.610000  \n",
       "24     109.787234   66.693781     24.792500     24.792500  \n",
       "...           ...         ...           ...           ...  \n",
       "99117   43.354556    4.610511   1866.981333   1896.708500  \n",
       "99118   45.034429    8.461160     33.301667     37.428833  \n",
       "99119 -112.192998   23.395967     30.577000     31.911167  \n",
       "99120 -127.830776   23.497526     19.364000     20.070667  \n",
       "99121  -46.280992    8.286352     25.364667     24.991000  \n",
       "99122  118.397397   35.043245    288.141333    285.021333  \n",
       "99123 -194.604245   55.336652      9.272333      9.353333  \n",
       "99124  -51.402939   12.827832     33.973667     35.066833  \n",
       "99125 -203.113753   31.939610     46.967333     49.416500  \n",
       "99126 -185.556412   34.433872     23.417667     23.789333  \n",
       "99127  -94.845268   35.806177     51.251333     55.487333  \n",
       "99128   16.859864   10.223676     31.409333     30.179500  \n",
       "99129 -130.421549   21.408923     17.211333     17.523000  \n",
       "99130   44.937429   19.468989      2.840333      2.852167  \n",
       "99131 -103.476775   14.614106     43.064000     42.768500  \n",
       "99132  -39.017341    4.027457      4.355667      4.379167  \n",
       "99133  -43.289347    3.763124     20.489333     20.457833  \n",
       "99134   94.651333   30.245425     30.140667     28.998000  \n",
       "99135 -126.327626   38.764325     31.231667     32.385000  \n",
       "99136   -8.448348    0.267188      5.138000      5.123167  \n",
       "99137 -122.198506   44.061683     12.812000     13.004333  \n",
       "99138 -113.679847   11.212406      5.364333      5.258000  \n",
       "99139  129.238562   17.738487    190.593667    197.692000  \n",
       "99140 -169.989876   41.678620      8.679333      8.751333  \n",
       "99141 -154.242342   49.177082     12.898333     13.367333  \n",
       "\n",
       "[99142 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_technical_indicator\n",
    "ts_processor.dataframe = df\n",
    "ts_processor.add_technical_indicator(config.INDICATORS)\n",
    "ts_processor.clean_data()\n",
    "ts_processor.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T02:28:12.795734Z",
     "start_time": "2022-10-12T02:28:11.420578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_processor.dataframe.to_csv('./datasets/A_stock_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25fc2e45"
   },
   "source": [
    "### Split traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:51.378464Z",
     "start_time": "2022-10-12T10:28:51.122396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.48</td>\n",
       "      <td>787406.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>4.618261</td>\n",
       "      <td>3.916739</td>\n",
       "      <td>88.841714</td>\n",
       "      <td>110.724638</td>\n",
       "      <td>48.821799</td>\n",
       "      <td>4.267500</td>\n",
       "      <td>4.267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.75</td>\n",
       "      <td>743960.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>7.846738</td>\n",
       "      <td>7.158262</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.502500</td>\n",
       "      <td>7.502500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.75</td>\n",
       "      <td>623061.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>9.901274</td>\n",
       "      <td>9.093726</td>\n",
       "      <td>64.412995</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>12.698092</td>\n",
       "      <td>9.497500</td>\n",
       "      <td>9.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.11</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.55</td>\n",
       "      <td>245945.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>12.670833</td>\n",
       "      <td>11.709167</td>\n",
       "      <td>94.588508</td>\n",
       "      <td>80.380952</td>\n",
       "      <td>26.343026</td>\n",
       "      <td>12.190000</td>\n",
       "      <td>12.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.98</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.38</td>\n",
       "      <td>960020.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>12.577274</td>\n",
       "      <td>11.397726</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.987500</td>\n",
       "      <td>11.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600048.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>10.21</td>\n",
       "      <td>9.56</td>\n",
       "      <td>10.17</td>\n",
       "      <td>469341.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>10.360324</td>\n",
       "      <td>9.504676</td>\n",
       "      <td>58.928190</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.558436</td>\n",
       "      <td>9.932500</td>\n",
       "      <td>9.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600104.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.21</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.06</td>\n",
       "      <td>14.90</td>\n",
       "      <td>356606.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>15.092770</td>\n",
       "      <td>13.732230</td>\n",
       "      <td>83.281583</td>\n",
       "      <td>131.360947</td>\n",
       "      <td>43.366115</td>\n",
       "      <td>14.412500</td>\n",
       "      <td>14.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600111.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.33</td>\n",
       "      <td>39.40</td>\n",
       "      <td>35.78</td>\n",
       "      <td>39.02</td>\n",
       "      <td>263676.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067193</td>\n",
       "      <td>40.131340</td>\n",
       "      <td>34.163660</td>\n",
       "      <td>64.586597</td>\n",
       "      <td>77.199282</td>\n",
       "      <td>7.583484</td>\n",
       "      <td>37.147500</td>\n",
       "      <td>37.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>600196.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>8.35</td>\n",
       "      <td>8.04</td>\n",
       "      <td>8.34</td>\n",
       "      <td>62208.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>8.497653</td>\n",
       "      <td>8.007347</td>\n",
       "      <td>51.137481</td>\n",
       "      <td>-14.245014</td>\n",
       "      <td>49.001351</td>\n",
       "      <td>8.252500</td>\n",
       "      <td>8.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.65</td>\n",
       "      <td>27.50</td>\n",
       "      <td>25.60</td>\n",
       "      <td>27.40</td>\n",
       "      <td>43085.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>28.972755</td>\n",
       "      <td>25.727245</td>\n",
       "      <td>32.197647</td>\n",
       "      <td>-56.144438</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.350000</td>\n",
       "      <td>27.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.08</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.84</td>\n",
       "      <td>12.47</td>\n",
       "      <td>151864.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>12.751932</td>\n",
       "      <td>11.813068</td>\n",
       "      <td>49.851392</td>\n",
       "      <td>-10.122921</td>\n",
       "      <td>35.172834</td>\n",
       "      <td>12.282500</td>\n",
       "      <td>12.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600436.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.60</td>\n",
       "      <td>68.89</td>\n",
       "      <td>70.10</td>\n",
       "      <td>10927.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095540</td>\n",
       "      <td>73.757406</td>\n",
       "      <td>68.097594</td>\n",
       "      <td>0.716809</td>\n",
       "      <td>-61.967145</td>\n",
       "      <td>95.185322</td>\n",
       "      <td>70.927500</td>\n",
       "      <td>70.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>600438.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.89</td>\n",
       "      <td>24346.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>4.996025</td>\n",
       "      <td>4.563975</td>\n",
       "      <td>56.220718</td>\n",
       "      <td>30.529595</td>\n",
       "      <td>11.732573</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>4.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.00</td>\n",
       "      <td>188.09</td>\n",
       "      <td>181.77</td>\n",
       "      <td>188.01</td>\n",
       "      <td>26160.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139206</td>\n",
       "      <td>189.913000</td>\n",
       "      <td>181.622000</td>\n",
       "      <td>70.541058</td>\n",
       "      <td>16.931217</td>\n",
       "      <td>7.889720</td>\n",
       "      <td>185.767500</td>\n",
       "      <td>185.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.72</td>\n",
       "      <td>11.03</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.00</td>\n",
       "      <td>15365.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.013964</td>\n",
       "      <td>11.737500</td>\n",
       "      <td>10.197500</td>\n",
       "      <td>29.822271</td>\n",
       "      <td>-24.598512</td>\n",
       "      <td>57.180821</td>\n",
       "      <td>10.967500</td>\n",
       "      <td>10.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>15.60</td>\n",
       "      <td>14.56</td>\n",
       "      <td>15.55</td>\n",
       "      <td>311506.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010049</td>\n",
       "      <td>15.857297</td>\n",
       "      <td>14.377703</td>\n",
       "      <td>61.041381</td>\n",
       "      <td>33.106576</td>\n",
       "      <td>15.199647</td>\n",
       "      <td>15.117500</td>\n",
       "      <td>15.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.62</td>\n",
       "      <td>15.66</td>\n",
       "      <td>16.58</td>\n",
       "      <td>48522.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011340</td>\n",
       "      <td>17.102087</td>\n",
       "      <td>15.992913</td>\n",
       "      <td>35.564287</td>\n",
       "      <td>-32.037222</td>\n",
       "      <td>66.698547</td>\n",
       "      <td>16.547500</td>\n",
       "      <td>16.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.88</td>\n",
       "      <td>9.10</td>\n",
       "      <td>8.68</td>\n",
       "      <td>9.07</td>\n",
       "      <td>160606.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>9.150342</td>\n",
       "      <td>8.534658</td>\n",
       "      <td>87.855596</td>\n",
       "      <td>80.341880</td>\n",
       "      <td>9.531850</td>\n",
       "      <td>8.842500</td>\n",
       "      <td>8.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.70</td>\n",
       "      <td>54.60</td>\n",
       "      <td>52.78</td>\n",
       "      <td>54.59</td>\n",
       "      <td>28933.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.111768</td>\n",
       "      <td>58.810558</td>\n",
       "      <td>51.744442</td>\n",
       "      <td>18.849264</td>\n",
       "      <td>-62.041431</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>55.277500</td>\n",
       "      <td>55.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.62</td>\n",
       "      <td>642922.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020084</td>\n",
       "      <td>7.772070</td>\n",
       "      <td>6.787930</td>\n",
       "      <td>93.443006</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>79.566052</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>7.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.67</td>\n",
       "      <td>20.20</td>\n",
       "      <td>19.08</td>\n",
       "      <td>20.13</td>\n",
       "      <td>118868.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019332</td>\n",
       "      <td>20.369437</td>\n",
       "      <td>19.055563</td>\n",
       "      <td>67.854754</td>\n",
       "      <td>46.840149</td>\n",
       "      <td>6.659267</td>\n",
       "      <td>19.712500</td>\n",
       "      <td>19.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.92</td>\n",
       "      <td>13.46</td>\n",
       "      <td>12.74</td>\n",
       "      <td>13.39</td>\n",
       "      <td>43936.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>13.739108</td>\n",
       "      <td>12.405892</td>\n",
       "      <td>55.027883</td>\n",
       "      <td>26.845638</td>\n",
       "      <td>27.847554</td>\n",
       "      <td>13.072500</td>\n",
       "      <td>13.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.22</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.29</td>\n",
       "      <td>203893.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>6.331181</td>\n",
       "      <td>6.188819</td>\n",
       "      <td>51.449571</td>\n",
       "      <td>-31.924883</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6.260000</td>\n",
       "      <td>6.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>63.0</td>\n",
       "      <td>19.30</td>\n",
       "      <td>19.60</td>\n",
       "      <td>19.15</td>\n",
       "      <td>19.47</td>\n",
       "      <td>83715.18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.006282</td>\n",
       "      <td>20.005980</td>\n",
       "      <td>19.214020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>19.610000</td>\n",
       "      <td>19.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.29</td>\n",
       "      <td>26.06</td>\n",
       "      <td>24.12</td>\n",
       "      <td>26.01</td>\n",
       "      <td>304669.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052423</td>\n",
       "      <td>26.443712</td>\n",
       "      <td>23.141288</td>\n",
       "      <td>84.919012</td>\n",
       "      <td>109.787234</td>\n",
       "      <td>66.693781</td>\n",
       "      <td>24.792500</td>\n",
       "      <td>24.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99117</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>1898.62</td>\n",
       "      <td>1901.99</td>\n",
       "      <td>1866.00</td>\n",
       "      <td>1872.50</td>\n",
       "      <td>21289.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.205584</td>\n",
       "      <td>1905.084788</td>\n",
       "      <td>1810.868212</td>\n",
       "      <td>49.210286</td>\n",
       "      <td>43.354556</td>\n",
       "      <td>4.610511</td>\n",
       "      <td>1866.981333</td>\n",
       "      <td>1896.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99118</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.79</td>\n",
       "      <td>34.74</td>\n",
       "      <td>33.60</td>\n",
       "      <td>33.89</td>\n",
       "      <td>101960.81</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.768929</td>\n",
       "      <td>36.239658</td>\n",
       "      <td>31.554342</td>\n",
       "      <td>44.196982</td>\n",
       "      <td>45.034429</td>\n",
       "      <td>8.461160</td>\n",
       "      <td>33.301667</td>\n",
       "      <td>37.428833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99119</th>\n",
       "      <td>600585.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.18</td>\n",
       "      <td>29.15</td>\n",
       "      <td>28.18</td>\n",
       "      <td>28.81</td>\n",
       "      <td>284870.69</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.951232</td>\n",
       "      <td>32.768742</td>\n",
       "      <td>27.320258</td>\n",
       "      <td>39.227171</td>\n",
       "      <td>-112.192998</td>\n",
       "      <td>23.395967</td>\n",
       "      <td>30.577000</td>\n",
       "      <td>31.911167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99120</th>\n",
       "      <td>600588.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>17.71</td>\n",
       "      <td>17.93</td>\n",
       "      <td>17.60</td>\n",
       "      <td>17.60</td>\n",
       "      <td>124403.66</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.686902</td>\n",
       "      <td>20.564209</td>\n",
       "      <td>17.092791</td>\n",
       "      <td>39.883637</td>\n",
       "      <td>-127.830776</td>\n",
       "      <td>23.497526</td>\n",
       "      <td>19.364000</td>\n",
       "      <td>20.070667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99121</th>\n",
       "      <td>600690.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.19</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.77</td>\n",
       "      <td>267702.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.032207</td>\n",
       "      <td>27.002850</td>\n",
       "      <td>24.280150</td>\n",
       "      <td>47.955669</td>\n",
       "      <td>-46.280992</td>\n",
       "      <td>8.286352</td>\n",
       "      <td>25.364667</td>\n",
       "      <td>24.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99122</th>\n",
       "      <td>600809.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>309.00</td>\n",
       "      <td>309.80</td>\n",
       "      <td>300.12</td>\n",
       "      <td>302.89</td>\n",
       "      <td>32116.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.770177</td>\n",
       "      <td>309.269051</td>\n",
       "      <td>277.852949</td>\n",
       "      <td>56.490877</td>\n",
       "      <td>118.397397</td>\n",
       "      <td>35.043245</td>\n",
       "      <td>288.141333</td>\n",
       "      <td>285.021333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99123</th>\n",
       "      <td>600837.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.73</td>\n",
       "      <td>8.51</td>\n",
       "      <td>8.66</td>\n",
       "      <td>220874.32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.182558</td>\n",
       "      <td>9.760406</td>\n",
       "      <td>8.598594</td>\n",
       "      <td>36.582080</td>\n",
       "      <td>-194.604245</td>\n",
       "      <td>55.336652</td>\n",
       "      <td>9.272333</td>\n",
       "      <td>9.353333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99124</th>\n",
       "      <td>600887.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>33.29</td>\n",
       "      <td>33.47</td>\n",
       "      <td>32.93</td>\n",
       "      <td>32.98</td>\n",
       "      <td>264761.80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.588198</td>\n",
       "      <td>34.189506</td>\n",
       "      <td>32.071494</td>\n",
       "      <td>40.677415</td>\n",
       "      <td>-51.402939</td>\n",
       "      <td>12.827832</td>\n",
       "      <td>33.973667</td>\n",
       "      <td>35.066833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99125</th>\n",
       "      <td>600893.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>43.56</td>\n",
       "      <td>43.64</td>\n",
       "      <td>41.84</td>\n",
       "      <td>41.95</td>\n",
       "      <td>161512.07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.371672</td>\n",
       "      <td>49.830794</td>\n",
       "      <td>42.613206</td>\n",
       "      <td>40.822531</td>\n",
       "      <td>-203.113753</td>\n",
       "      <td>31.939610</td>\n",
       "      <td>46.967333</td>\n",
       "      <td>49.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99126</th>\n",
       "      <td>600900.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.85</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.74</td>\n",
       "      <td>423324.79</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.283151</td>\n",
       "      <td>24.311465</td>\n",
       "      <td>22.450535</td>\n",
       "      <td>42.647592</td>\n",
       "      <td>-185.556412</td>\n",
       "      <td>34.433872</td>\n",
       "      <td>23.417667</td>\n",
       "      <td>23.789333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99127</th>\n",
       "      <td>601012.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>49.78</td>\n",
       "      <td>50.15</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.91</td>\n",
       "      <td>682745.27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.728189</td>\n",
       "      <td>54.486358</td>\n",
       "      <td>46.129642</td>\n",
       "      <td>38.786281</td>\n",
       "      <td>-94.845268</td>\n",
       "      <td>35.806177</td>\n",
       "      <td>51.251333</td>\n",
       "      <td>55.487333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99128</th>\n",
       "      <td>601088.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.60</td>\n",
       "      <td>31.92</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.64</td>\n",
       "      <td>219426.08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.096078</td>\n",
       "      <td>33.327838</td>\n",
       "      <td>30.026162</td>\n",
       "      <td>52.556566</td>\n",
       "      <td>16.859864</td>\n",
       "      <td>10.223676</td>\n",
       "      <td>31.409333</td>\n",
       "      <td>30.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99129</th>\n",
       "      <td>601166.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>16.57</td>\n",
       "      <td>16.77</td>\n",
       "      <td>16.54</td>\n",
       "      <td>16.65</td>\n",
       "      <td>470496.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.215111</td>\n",
       "      <td>17.677171</td>\n",
       "      <td>16.506829</td>\n",
       "      <td>41.092287</td>\n",
       "      <td>-130.421549</td>\n",
       "      <td>21.408923</td>\n",
       "      <td>17.211333</td>\n",
       "      <td>17.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99130</th>\n",
       "      <td>601288.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2602100.09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>2.879206</td>\n",
       "      <td>2.815794</td>\n",
       "      <td>49.061725</td>\n",
       "      <td>44.937429</td>\n",
       "      <td>19.468989</td>\n",
       "      <td>2.840333</td>\n",
       "      <td>2.852167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99131</th>\n",
       "      <td>601318.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.98</td>\n",
       "      <td>41.35</td>\n",
       "      <td>41.58</td>\n",
       "      <td>331619.40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.306936</td>\n",
       "      <td>45.584692</td>\n",
       "      <td>41.195308</td>\n",
       "      <td>43.493820</td>\n",
       "      <td>-103.476775</td>\n",
       "      <td>14.614106</td>\n",
       "      <td>43.064000</td>\n",
       "      <td>42.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99132</th>\n",
       "      <td>601398.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1578628.46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>4.398556</td>\n",
       "      <td>4.326444</td>\n",
       "      <td>44.834511</td>\n",
       "      <td>-39.017341</td>\n",
       "      <td>4.027457</td>\n",
       "      <td>4.355667</td>\n",
       "      <td>4.379167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99133</th>\n",
       "      <td>601601.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.45</td>\n",
       "      <td>19.83</td>\n",
       "      <td>20.33</td>\n",
       "      <td>195189.41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.136296</td>\n",
       "      <td>21.714986</td>\n",
       "      <td>19.552014</td>\n",
       "      <td>47.205933</td>\n",
       "      <td>-43.289347</td>\n",
       "      <td>3.763124</td>\n",
       "      <td>20.489333</td>\n",
       "      <td>20.457833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99134</th>\n",
       "      <td>601628.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>31.76</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.16</td>\n",
       "      <td>31.63</td>\n",
       "      <td>111268.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620124</td>\n",
       "      <td>32.273866</td>\n",
       "      <td>29.367134</td>\n",
       "      <td>59.040332</td>\n",
       "      <td>94.651333</td>\n",
       "      <td>30.245425</td>\n",
       "      <td>30.140667</td>\n",
       "      <td>28.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99135</th>\n",
       "      <td>601633.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>28.05</td>\n",
       "      <td>28.35</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.80</td>\n",
       "      <td>151081.85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.220938</td>\n",
       "      <td>33.000132</td>\n",
       "      <td>27.071868</td>\n",
       "      <td>40.762729</td>\n",
       "      <td>-126.327626</td>\n",
       "      <td>38.764325</td>\n",
       "      <td>31.231667</td>\n",
       "      <td>32.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99136</th>\n",
       "      <td>601668.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2186913.38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>5.374797</td>\n",
       "      <td>5.009203</td>\n",
       "      <td>49.362609</td>\n",
       "      <td>-8.448348</td>\n",
       "      <td>0.267188</td>\n",
       "      <td>5.138000</td>\n",
       "      <td>5.123167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99137</th>\n",
       "      <td>601688.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>12.19</td>\n",
       "      <td>12.29</td>\n",
       "      <td>12.10</td>\n",
       "      <td>12.12</td>\n",
       "      <td>229982.43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.249653</td>\n",
       "      <td>13.538437</td>\n",
       "      <td>11.806563</td>\n",
       "      <td>36.813250</td>\n",
       "      <td>-122.198506</td>\n",
       "      <td>44.061683</td>\n",
       "      <td>12.812000</td>\n",
       "      <td>13.004333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99138</th>\n",
       "      <td>601857.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.13</td>\n",
       "      <td>819572.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.062860</td>\n",
       "      <td>5.755721</td>\n",
       "      <td>4.975279</td>\n",
       "      <td>45.564208</td>\n",
       "      <td>-113.679847</td>\n",
       "      <td>11.212406</td>\n",
       "      <td>5.364333</td>\n",
       "      <td>5.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99139</th>\n",
       "      <td>601888.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>198.24</td>\n",
       "      <td>200.50</td>\n",
       "      <td>195.71</td>\n",
       "      <td>198.25</td>\n",
       "      <td>80998.33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.330810</td>\n",
       "      <td>203.420184</td>\n",
       "      <td>176.951816</td>\n",
       "      <td>51.954585</td>\n",
       "      <td>129.238562</td>\n",
       "      <td>17.738487</td>\n",
       "      <td>190.593667</td>\n",
       "      <td>197.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99140</th>\n",
       "      <td>601899.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.84</td>\n",
       "      <td>1988575.12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.303164</td>\n",
       "      <td>9.603624</td>\n",
       "      <td>7.492376</td>\n",
       "      <td>38.868903</td>\n",
       "      <td>-169.989876</td>\n",
       "      <td>41.678620</td>\n",
       "      <td>8.679333</td>\n",
       "      <td>8.751333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99141</th>\n",
       "      <td>601919.SH</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>10.92</td>\n",
       "      <td>11.02</td>\n",
       "      <td>625792.65</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.651301</td>\n",
       "      <td>14.200318</td>\n",
       "      <td>10.656682</td>\n",
       "      <td>32.953801</td>\n",
       "      <td>-154.242342</td>\n",
       "      <td>49.177082</td>\n",
       "      <td>12.898333</td>\n",
       "      <td>13.367333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99142 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tic        date   index     open     high      low    close  \\\n",
       "0      600010.SH  2012-01-09     3.0     4.31     4.49     4.23     4.48   \n",
       "1      600028.SH  2012-01-09     3.0     7.50     7.80     7.41     7.75   \n",
       "2      600030.SH  2012-01-09     3.0     9.36     9.79     9.26     9.75   \n",
       "3      600031.SH  2012-01-09     3.0    12.11    12.58    11.94    12.55   \n",
       "4      600036.SH  2012-01-09     3.0    11.98    12.50    11.90    12.38   \n",
       "5      600048.SH  2012-01-09     3.0     9.66    10.21     9.56    10.17   \n",
       "6      600104.SH  2012-01-09     3.0    14.21    14.95    14.06    14.90   \n",
       "7      600111.SH  2012-01-09     3.0    36.33    39.40    35.78    39.02   \n",
       "8      600196.SH  2012-01-09     3.0     8.10     8.35     8.04     8.34   \n",
       "9      600276.SH  2012-01-09     3.0    26.65    27.50    25.60    27.40   \n",
       "10     600309.SH  2012-01-09     3.0    12.08    12.50    11.84    12.47   \n",
       "11     600436.SH  2012-01-09     3.0    70.08    70.60    68.89    70.10   \n",
       "12     600438.SH  2012-01-09     3.0     4.73     4.91     4.66     4.89   \n",
       "13     600519.SH  2012-01-09     3.0   186.00   188.09   181.77   188.01   \n",
       "14     600570.SH  2012-01-09     3.0    10.72    11.03    10.66    11.00   \n",
       "15     600585.SH  2012-01-09     3.0    14.82    15.60    14.56    15.55   \n",
       "16     600588.SH  2012-01-09     3.0    16.23    16.62    15.66    16.58   \n",
       "17     600690.SH  2012-01-09     3.0     8.88     9.10     8.68     9.07   \n",
       "18     600809.SH  2012-01-09     3.0    53.70    54.60    52.78    54.59   \n",
       "19     600837.SH  2012-01-09     3.0     7.30     7.64     7.24     7.62   \n",
       "20     600887.SH  2012-01-09     3.0    19.67    20.20    19.08    20.13   \n",
       "21     600893.SH  2012-01-09     3.0    12.92    13.46    12.74    13.39   \n",
       "22     600900.SH  2012-01-09     3.0     6.22     6.30     6.17     6.29   \n",
       "23     601012.SH  2012-01-09    63.0    19.30    19.60    19.15    19.47   \n",
       "24     601088.SH  2012-01-09     3.0    24.29    26.06    24.12    26.01   \n",
       "...          ...         ...     ...      ...      ...      ...      ...   \n",
       "99117  600519.SH  2022-09-30  2612.0  1898.62  1901.99  1866.00  1872.50   \n",
       "99118  600570.SH  2022-09-30  2612.0    33.79    34.74    33.60    33.89   \n",
       "99119  600585.SH  2022-09-30  2612.0    28.18    29.15    28.18    28.81   \n",
       "99120  600588.SH  2022-09-30  2612.0    17.71    17.93    17.60    17.60   \n",
       "99121  600690.SH  2022-09-30  2612.0    25.00    25.19    24.65    24.77   \n",
       "99122  600809.SH  2022-09-30  2612.0   309.00   309.80   300.12   302.89   \n",
       "99123  600837.SH  2022-09-30  2612.0     8.51     8.73     8.51     8.66   \n",
       "99124  600887.SH  2022-09-30  2612.0    33.29    33.47    32.93    32.98   \n",
       "99125  600893.SH  2022-09-30  2612.0    43.56    43.64    41.84    41.95   \n",
       "99126  600900.SH  2022-09-30  2612.0    22.40    22.85    22.28    22.74   \n",
       "99127  601012.SH  2022-09-30  2612.0    49.78    50.15    47.80    47.91   \n",
       "99128  601088.SH  2022-09-30  2612.0    31.60    31.92    31.10    31.64   \n",
       "99129  601166.SH  2022-09-30  2612.0    16.57    16.77    16.54    16.65   \n",
       "99130  601288.SH  2022-09-30  2612.0     2.83     2.86     2.83     2.86   \n",
       "99131  601318.SH  2022-09-30  2612.0    41.35    41.98    41.35    41.58   \n",
       "99132  601398.SH  2022-09-30  2612.0     4.34     4.36     4.33     4.35   \n",
       "99133  601601.SH  2022-09-30  2612.0    19.83    20.45    19.83    20.33   \n",
       "99134  601628.SH  2022-09-30  2612.0    31.76    32.00    31.16    31.63   \n",
       "99135  601633.SH  2022-09-30  2612.0    28.05    28.35    27.68    27.80   \n",
       "99136  601668.SH  2022-09-30  2612.0     5.03     5.19     5.03     5.15   \n",
       "99137  601688.SH  2022-09-30  2612.0    12.19    12.29    12.10    12.12   \n",
       "99138  601857.SH  2022-09-30  2612.0     5.08     5.16     5.08     5.13   \n",
       "99139  601888.SH  2022-09-30  2612.0   198.24   200.50   195.71   198.25   \n",
       "99140  601899.SH  2022-09-30  2612.0     7.78     7.92     7.73     7.84   \n",
       "99141  601919.SH  2022-09-30  2612.0    11.00    11.14    10.92    11.02   \n",
       "\n",
       "           volume  day      macd      boll_ub      boll_lb      rsi_30  \\\n",
       "0       787406.46  0.0  0.014165     4.618261     3.916739   88.841714   \n",
       "1       743960.15  0.0  0.014251     7.846738     7.158262  100.000000   \n",
       "2       623061.16  0.0  0.009148     9.901274     9.093726   64.412995   \n",
       "3       245945.25  0.0  0.016771    12.670833    11.709167   94.588508   \n",
       "4       960020.09  0.0  0.024994    12.577274    11.397726  100.000000   \n",
       "5       469341.00  0.0  0.004945    10.360324     9.504676   58.928190   \n",
       "6       356606.32  0.0  0.023904    15.092770    13.732230   83.281583   \n",
       "7       263676.19  0.0  0.067193    40.131340    34.163660   64.586597   \n",
       "8        62208.12  0.0 -0.000915     8.497653     8.007347   51.137481   \n",
       "9        43085.35  0.0 -0.033764    28.972755    25.727245   32.197647   \n",
       "10      151864.28  0.0  0.000755    12.751932    11.813068   49.851392   \n",
       "11       10927.68  0.0 -0.095540    73.757406    68.097594    0.716809   \n",
       "12       24346.27  0.0  0.002969     4.996025     4.563975   56.220718   \n",
       "13       26160.16  0.0  0.139206   189.913000   181.622000   70.541058   \n",
       "14       15365.29  0.0 -0.013964    11.737500    10.197500   29.822271   \n",
       "15      311506.05  0.0  0.010049    15.857297    14.377703   61.041381   \n",
       "16       48522.89  0.0 -0.011340    17.102087    15.992913   35.564287   \n",
       "17      160606.42  0.0  0.011236     9.150342     8.534658   87.855596   \n",
       "18       28933.49  0.0 -0.111768    58.810558    51.744442   18.849264   \n",
       "19      642922.60  0.0  0.020084     7.772070     6.787930   93.443006   \n",
       "20      118868.14  0.0  0.019332    20.369437    19.055563   67.854754   \n",
       "21       43936.61  0.0  0.009417    13.739108    12.405892   55.027883   \n",
       "22      203893.30  0.0  0.000106     6.331181     6.188819   51.449571   \n",
       "23       83715.18  3.0 -0.006282    20.005980    19.214020    0.000000   \n",
       "24      304669.62  0.0  0.052423    26.443712    23.141288   84.919012   \n",
       "...           ...  ...       ...          ...          ...         ...   \n",
       "99117    21289.08  4.0 -3.205584  1905.084788  1810.868212   49.210286   \n",
       "99118   101960.81  4.0 -0.768929    36.239658    31.554342   44.196982   \n",
       "99119   284870.69  4.0 -0.951232    32.768742    27.320258   39.227171   \n",
       "99120   124403.66  4.0 -0.686902    20.564209    17.092791   39.883637   \n",
       "99121   267702.88  4.0 -0.032207    27.002850    24.280150   47.955669   \n",
       "99122    32116.50  4.0  5.770177   309.269051   277.852949   56.490877   \n",
       "99123   220874.32  4.0 -0.182558     9.760406     8.598594   36.582080   \n",
       "99124   264761.80  4.0 -0.588198    34.189506    32.071494   40.677415   \n",
       "99125   161512.07  4.0 -1.371672    49.830794    42.613206   40.822531   \n",
       "99126   423324.79  4.0 -0.283151    24.311465    22.450535   42.647592   \n",
       "99127   682745.27  4.0 -1.728189    54.486358    46.129642   38.786281   \n",
       "99128   219426.08  4.0  0.096078    33.327838    30.026162   52.556566   \n",
       "99129   470496.19  4.0 -0.215111    17.677171    16.506829   41.092287   \n",
       "99130  2602100.09  4.0  0.000538     2.879206     2.815794   49.061725   \n",
       "99131   331619.40  4.0 -0.306936    45.584692    41.195308   43.493820   \n",
       "99132  1578628.46  4.0 -0.006202     4.398556     4.326444   44.834511   \n",
       "99133   195189.41  4.0 -0.136296    21.714986    19.552014   47.205933   \n",
       "99134   111268.85  4.0  0.620124    32.273866    29.367134   59.040332   \n",
       "99135   151081.85  4.0 -1.220938    33.000132    27.071868   40.762729   \n",
       "99136  2186913.38  4.0 -0.000079     5.374797     5.009203   49.362609   \n",
       "99137   229982.43  4.0 -0.249653    13.538437    11.806563   36.813250   \n",
       "99138   819572.30  4.0 -0.062860     5.755721     4.975279   45.564208   \n",
       "99139    80998.33  4.0  1.330810   203.420184   176.951816   51.954585   \n",
       "99140  1988575.12  4.0 -0.303164     9.603624     7.492376   38.868903   \n",
       "99141   625792.65  4.0 -0.651301    14.200318    10.656682   32.953801   \n",
       "\n",
       "           cci_30       dx_30  close_30_sma  close_60_sma  \n",
       "0      110.724638   48.821799      4.267500      4.267500  \n",
       "1      133.333333  100.000000      7.502500      7.502500  \n",
       "2       53.333333   12.698092      9.497500      9.497500  \n",
       "3       80.380952   26.343026     12.190000     12.190000  \n",
       "4      133.333333  100.000000     11.987500     11.987500  \n",
       "5       40.000000    3.558436      9.932500      9.932500  \n",
       "6      131.360947   43.366115     14.412500     14.412500  \n",
       "7       77.199282    7.583484     37.147500     37.147500  \n",
       "8      -14.245014   49.001351      8.252500      8.252500  \n",
       "9      -56.144438  100.000000     27.350000     27.350000  \n",
       "10     -10.122921   35.172834     12.282500     12.282500  \n",
       "11     -61.967145   95.185322     70.927500     70.927500  \n",
       "12      30.529595   11.732573      4.780000      4.780000  \n",
       "13      16.931217    7.889720    185.767500    185.767500  \n",
       "14     -24.598512   57.180821     10.967500     10.967500  \n",
       "15      33.106576   15.199647     15.117500     15.117500  \n",
       "16     -32.037222   66.698547     16.547500     16.547500  \n",
       "17      80.341880    9.531850      8.842500      8.842500  \n",
       "18     -62.041431  100.000000     55.277500     55.277500  \n",
       "19     133.333333   79.566052      7.280000      7.280000  \n",
       "20      46.840149    6.659267     19.712500     19.712500  \n",
       "21      26.845638   27.847554     13.072500     13.072500  \n",
       "22     -31.924883  100.000000      6.260000      6.260000  \n",
       "23     -66.666667  100.000000     19.610000     19.610000  \n",
       "24     109.787234   66.693781     24.792500     24.792500  \n",
       "...           ...         ...           ...           ...  \n",
       "99117   43.354556    4.610511   1866.981333   1896.708500  \n",
       "99118   45.034429    8.461160     33.301667     37.428833  \n",
       "99119 -112.192998   23.395967     30.577000     31.911167  \n",
       "99120 -127.830776   23.497526     19.364000     20.070667  \n",
       "99121  -46.280992    8.286352     25.364667     24.991000  \n",
       "99122  118.397397   35.043245    288.141333    285.021333  \n",
       "99123 -194.604245   55.336652      9.272333      9.353333  \n",
       "99124  -51.402939   12.827832     33.973667     35.066833  \n",
       "99125 -203.113753   31.939610     46.967333     49.416500  \n",
       "99126 -185.556412   34.433872     23.417667     23.789333  \n",
       "99127  -94.845268   35.806177     51.251333     55.487333  \n",
       "99128   16.859864   10.223676     31.409333     30.179500  \n",
       "99129 -130.421549   21.408923     17.211333     17.523000  \n",
       "99130   44.937429   19.468989      2.840333      2.852167  \n",
       "99131 -103.476775   14.614106     43.064000     42.768500  \n",
       "99132  -39.017341    4.027457      4.355667      4.379167  \n",
       "99133  -43.289347    3.763124     20.489333     20.457833  \n",
       "99134   94.651333   30.245425     30.140667     28.998000  \n",
       "99135 -126.327626   38.764325     31.231667     32.385000  \n",
       "99136   -8.448348    0.267188      5.138000      5.123167  \n",
       "99137 -122.198506   44.061683     12.812000     13.004333  \n",
       "99138 -113.679847   11.212406      5.364333      5.258000  \n",
       "99139  129.238562   17.738487    190.593667    197.692000  \n",
       "99140 -169.989876   41.678620      8.679333      8.751333  \n",
       "99141 -154.242342   49.177082     12.898333     13.367333  \n",
       "\n",
       "[99142 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_processor.dataframe = pd.read_csv('./datasets/A_stock_processed.csv', index_col=[0])\n",
    "ts_processor.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:53.420867Z",
     "start_time": "2022-10-12T10:28:53.350720Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pending-mother",
    "outputId": "87fb4ed5-6c51-4da4-b208-7a350a170c02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train =ts_processor.data_split(ts_processor.dataframe, train_start_date, train_stop_date)       \n",
    "len(train.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:53.687120Z",
     "start_time": "2022-10-12T10:28:53.671813Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "signal-rochester",
    "outputId": "68104252-5064-4e12-c674-b27b75061fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['600010.SH', '600028.SH', '600030.SH', '600031.SH', '600036.SH',\n",
       "       '600048.SH', '600104.SH', '600111.SH', '600196.SH', '600276.SH',\n",
       "       '600309.SH', '600436.SH', '600438.SH', '600519.SH', '600570.SH',\n",
       "       '600585.SH', '600588.SH', '600690.SH', '600809.SH', '600837.SH',\n",
       "       '600887.SH', '600893.SH', '600900.SH', '601012.SH', '601088.SH',\n",
       "       '601166.SH', '601288.SH', '601318.SH', '601398.SH', '601601.SH',\n",
       "       '601628.SH', '601633.SH', '601668.SH', '601688.SH', '601857.SH',\n",
       "       '601888.SH', '601899.SH', '601919.SH'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:54.163155Z",
     "start_time": "2022-10-12T10:28:54.133668Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "future-while",
    "outputId": "20d6734c-3206-4e18-bab9-ed340dd70151"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600010.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.48</td>\n",
       "      <td>787406.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>4.618261</td>\n",
       "      <td>3.916739</td>\n",
       "      <td>88.841714</td>\n",
       "      <td>110.724638</td>\n",
       "      <td>48.821799</td>\n",
       "      <td>4.2675</td>\n",
       "      <td>4.2675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.75</td>\n",
       "      <td>743960.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>7.846738</td>\n",
       "      <td>7.158262</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>7.5025</td>\n",
       "      <td>7.5025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.75</td>\n",
       "      <td>623061.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009148</td>\n",
       "      <td>9.901274</td>\n",
       "      <td>9.093726</td>\n",
       "      <td>64.412995</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>12.698092</td>\n",
       "      <td>9.4975</td>\n",
       "      <td>9.4975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600031.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.11</td>\n",
       "      <td>12.58</td>\n",
       "      <td>11.94</td>\n",
       "      <td>12.55</td>\n",
       "      <td>245945.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>12.670833</td>\n",
       "      <td>11.709167</td>\n",
       "      <td>94.588508</td>\n",
       "      <td>80.380952</td>\n",
       "      <td>26.343026</td>\n",
       "      <td>12.1900</td>\n",
       "      <td>12.1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600036.SH</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.98</td>\n",
       "      <td>12.50</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.38</td>\n",
       "      <td>960020.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024994</td>\n",
       "      <td>12.577274</td>\n",
       "      <td>11.397726</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>11.9875</td>\n",
       "      <td>11.9875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        date  index   open   high    low  close     volume  day  \\\n",
       "0  600010.SH  2012-01-09    3.0   4.31   4.49   4.23   4.48  787406.46  0.0   \n",
       "0  600028.SH  2012-01-09    3.0   7.50   7.80   7.41   7.75  743960.15  0.0   \n",
       "0  600030.SH  2012-01-09    3.0   9.36   9.79   9.26   9.75  623061.16  0.0   \n",
       "0  600031.SH  2012-01-09    3.0  12.11  12.58  11.94  12.55  245945.25  0.0   \n",
       "0  600036.SH  2012-01-09    3.0  11.98  12.50  11.90  12.38  960020.09  0.0   \n",
       "\n",
       "       macd    boll_ub    boll_lb      rsi_30      cci_30       dx_30  \\\n",
       "0  0.014165   4.618261   3.916739   88.841714  110.724638   48.821799   \n",
       "0  0.014251   7.846738   7.158262  100.000000  133.333333  100.000000   \n",
       "0  0.009148   9.901274   9.093726   64.412995   53.333333   12.698092   \n",
       "0  0.016771  12.670833  11.709167   94.588508   80.380952   26.343026   \n",
       "0  0.024994  12.577274  11.397726  100.000000  133.333333  100.000000   \n",
       "\n",
       "   close_30_sma  close_60_sma  \n",
       "0        4.2675        4.2675  \n",
       "0        7.5025        7.5025  \n",
       "0        9.4975        9.4975  \n",
       "0       12.1900       12.1900  \n",
       "0       11.9875       11.9875  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:54.660144Z",
     "start_time": "2022-10-12T10:28:54.652903Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72e9bcc2",
    "outputId": "2e7dbf8d-4792-4bea-d26d-0fab001dab7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73758, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T10:28:55.430002Z",
     "start_time": "2022-10-12T10:28:55.414986Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "provincial-wichita",
    "outputId": "81a0dbd5-02d8-4f6a-cfee-62490004bfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 38, State Space: 381\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension*(len(config.INDICATORS)+2)+1 # (indicators + close_price + shares) * num_stock + cash\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e90bbf93"
   },
   "source": [
    "# 构建金融仿真环境\n",
    "FinRL中为我们构建了一个和OpenAI Gym-style类似的金融仿真环境，通过agent和该环境互动，包括监测股价的变动，动作的采取和奖励的计算，agent最终可以学习到一个交易策略以期最大化收益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:25:14.185428Z",
     "start_time": "2022-10-12T11:25:14.161450Z"
    },
    "collapsed": true,
    "id": "dcb153fc"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1e7, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":2e-4,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\":True,\n",
    "    \"hundred_each_trade\":True,\n",
    "    \"model_name\":'ppo_agents',\n",
    "    \"mode\":'train',\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyat-FppWzZ_"
   },
   "source": [
    "## Train DRL Agents\n",
    "FinRL为我们提供了多种强化学习算法：DDPG，A2C，PPO，SAC，TD3，我们将比较不同的强化学习算法在量化金融中的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:25:15.288936Z",
     "start_time": "2022-10-12T11:25:15.267689Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loaded-modem",
    "outputId": "f6fab15a-ecff-46f1-bcb0-f3750cc751fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T11:25:15.932791Z",
     "start_time": "2022-10-12T11:25:15.882629Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thick-blackjack",
    "outputId": "d20ac9f8-f707-4fea-ac04-956270a8bd9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 256, 'buffer_size': 100000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      " 0.1 0.1])}\n",
      "Using cpu device\n",
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 30, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "{'n_steps': 20}\n",
      "Using cpu device\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to ./results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\n",
    "                \"batch_size\": 256, \n",
    "               \"buffer_size\": 100000, \n",
    "               \"learning_rate\": 0.0005,\n",
    "               \"action_noise\":\"normal\",\n",
    "                }\n",
    "\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 30,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "A2C_PARAMS = {\n",
    "    \"n_steps\": 20,\n",
    "}\n",
    "\n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "model_sac = agent.get_model(\"sac\", model_kwargs=SAC_PARAMS, policy_kwargs=POLICY_KWARGS)\n",
    "model_a2c = agent.get_model('a2c', model_kwargs=A2C_PARAMS)\n",
    "model_ppo = agent.get_model('ppo', model_kwargs=PPO_PARAMS)\n",
    "\n",
    "# set up logger\n",
    "tmp_path = './results/ppo'\n",
    "new_logger = configure(tmp_path, [\"stdout\", \"csv\"])\n",
    "# Set new logger\n",
    "# model_ddpg.set_logger(new_logger)\n",
    "# model_sac.set_logger(new_logger)\n",
    "# model_a2c.set_logger(new_logger)\n",
    "model_ppo.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-12T18:47:40.722780Z",
     "start_time": "2022-10-12T11:25:18.122949Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "growing-supplier",
    "outputId": "7eb00fa2-31d0-4217-8515-fc80db1ebbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 1940, episode: 2\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 20487615.96\n",
      "total_reward: 10487615.96\n",
      "total_cost: 167057.14\n",
      "total_trades: 73670\n",
      "Sharpe: 0.506\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 256       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | -9.114095 |\n",
      "----------------------------------\n",
      "Episode: 3\n",
      "day: 1940, episode: 3\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13499541.37\n",
      "total_reward: 3499541.37\n",
      "total_cost: 159192.63\n",
      "total_trades: 73661\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021269351 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54         |\n",
      "|    explained_variance   | -0.000389   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    reward               | -18.263706  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 4\n",
      "day: 1940, episode: 4\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15251210.01\n",
      "total_reward: 5251210.01\n",
      "total_cost: 152531.99\n",
      "total_trades: 73664\n",
      "Sharpe: 0.343\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020216007 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | -0.00125    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    reward               | -12.291031  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 5\n",
      "day: 1940, episode: 5\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12555392.12\n",
      "total_reward: 2555392.12\n",
      "total_cost: 154720.88\n",
      "total_trades: 73664\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016822074 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.1       |\n",
      "|    explained_variance   | 0.00169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.83e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    reward               | -5.5155845  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 6\n",
      "day: 1940, episode: 6\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14383917.18\n",
      "total_reward: 4383917.18\n",
      "total_cost: 154589.82\n",
      "total_trades: 73659\n",
      "Sharpe: 0.321\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016767122 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.2       |\n",
      "|    explained_variance   | -0.000432   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 955         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    reward               | 8.733643    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 7\n",
      "day: 1940, episode: 7\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13016576.50\n",
      "total_reward: 3016576.50\n",
      "total_cost: 155147.50\n",
      "total_trades: 73662\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 49         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01882789 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.3      |\n",
      "|    explained_variance   | 0.00125    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 780        |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0262    |\n",
      "|    reward               | 6.8077064  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.09e+03   |\n",
      "----------------------------------------\n",
      "Episode: 8\n",
      "day: 1940, episode: 8\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13460216.97\n",
      "total_reward: 3460216.97\n",
      "total_cost: 153836.03\n",
      "total_trades: 73668\n",
      "Sharpe: 0.284\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026995566 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.3       |\n",
      "|    explained_variance   | -0.00497    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.83e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    reward               | 11.089914   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 9\n",
      "day: 1940, episode: 9\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17005840.11\n",
      "total_reward: 7005840.11\n",
      "total_cost: 153248.89\n",
      "total_trades: 73665\n",
      "Sharpe: 0.404\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025710894 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.4       |\n",
      "|    explained_variance   | -0.0059     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.95e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    reward               | 8.745135    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 10\n",
      "day: 1940, episode: 10\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12194953.41\n",
      "total_reward: 2194953.41\n",
      "total_cost: 145632.59\n",
      "total_trades: 73664\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022190303 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.5       |\n",
      "|    explained_variance   | -0.00126    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.25e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    reward               | 8.872336    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 11\n",
      "day: 1940, episode: 11\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15157824.58\n",
      "total_reward: 5157824.58\n",
      "total_cost: 155117.42\n",
      "total_trades: 73662\n",
      "Sharpe: 0.341\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027621027 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.6       |\n",
      "|    explained_variance   | 2.09e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.23e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    reward               | 3.7886186   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 12\n",
      "day: 1940, episode: 12\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14126682.46\n",
      "total_reward: 4126682.46\n",
      "total_cost: 157982.54\n",
      "total_trades: 73674\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026465703 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.7       |\n",
      "|    explained_variance   | -0.00131    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | 1.057785    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 13\n",
      "day: 1940, episode: 13\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9251567.67\n",
      "total_reward: -748432.33\n",
      "total_cost: 148688.33\n",
      "total_trades: 73660\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034146965 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -54.8       |\n",
      "|    explained_variance   | -0.000513   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | -1.9424001  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.16e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 14\n",
      "day: 1940, episode: 14\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9353798.90\n",
      "total_reward: -646201.10\n",
      "total_cost: 140535.10\n",
      "total_trades: 73666\n",
      "Sharpe: 0.123\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 107        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03652366 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -54.9      |\n",
      "|    explained_variance   | 0.000536   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.16e+03   |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    reward               | -3.4830377 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.78e+03   |\n",
      "----------------------------------------\n",
      "Episode: 15\n",
      "day: 1940, episode: 15\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9601016.00\n",
      "total_reward: -398984.00\n",
      "total_cost: 152506.00\n",
      "total_trades: 73663\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048312426 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55         |\n",
      "|    explained_variance   | -0.000396   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 736         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | 3.0039563   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 16\n",
      "day: 1940, episode: 16\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11993271.55\n",
      "total_reward: 1993271.55\n",
      "total_cost: 151620.45\n",
      "total_trades: 73662\n",
      "Sharpe: 0.232\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 246        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 124        |\n",
      "|    total_timesteps      | 30720      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03765247 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.2      |\n",
      "|    explained_variance   | -0.00197   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 536        |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0239    |\n",
      "|    reward               | -20.920269 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 1.21e+03   |\n",
      "----------------------------------------\n",
      "Episode: 17\n",
      "day: 1940, episode: 17\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10982233.93\n",
      "total_reward: 982233.93\n",
      "total_cost: 136181.07\n",
      "total_trades: 73655\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024619486 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.3       |\n",
      "|    explained_variance   | -0.000219   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 875         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -2.3420258  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 18\n",
      "day: 1940, episode: 18\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13933072.82\n",
      "total_reward: 3933072.82\n",
      "total_cost: 153680.18\n",
      "total_trades: 73656\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026748443 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.4       |\n",
      "|    explained_variance   | 0.000256    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 849         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | 3.694409    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 19\n",
      "day: 1940, episode: 19\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10625802.35\n",
      "total_reward: 625802.35\n",
      "total_cost: 146810.65\n",
      "total_trades: 73666\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 148        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.027124   |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -55.5      |\n",
      "|    explained_variance   | 5.38e-05   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.83e+03   |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    reward               | -11.184267 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 3.19e+03   |\n",
      "----------------------------------------\n",
      "Episode: 20\n",
      "day: 1940, episode: 20\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13419043.85\n",
      "total_reward: 3419043.85\n",
      "total_cost: 153537.15\n",
      "total_trades: 73670\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "Episode: 21\n",
      "day: 1940, episode: 21\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11854200.19\n",
      "total_reward: 1854200.19\n",
      "total_cost: 149722.81\n",
      "total_trades: 73672\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 156       |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.03911   |\n",
      "|    clip_fraction        | 0.332     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -55.6     |\n",
      "|    explained_variance   | 0.000137  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 889       |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -0.0129   |\n",
      "|    reward               | 5.0910416 |\n",
      "|    std                  | 1.05      |\n",
      "|    value_loss           | 2.7e+03   |\n",
      "---------------------------------------\n",
      "Episode: 22\n",
      "day: 1940, episode: 22\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10382853.89\n",
      "total_reward: 382853.89\n",
      "total_cost: 146043.11\n",
      "total_trades: 73646\n",
      "Sharpe: 0.190\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029202387 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 3.84e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | 1.9847696   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 23\n",
      "day: 1940, episode: 23\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13011757.93\n",
      "total_reward: 3011757.93\n",
      "total_cost: 149498.07\n",
      "total_trades: 73665\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042260423 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.8       |\n",
      "|    explained_variance   | 3.23e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -3.5470421  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 2.14e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 24\n",
      "day: 1940, episode: 24\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11683134.96\n",
      "total_reward: 1683134.96\n",
      "total_cost: 147816.04\n",
      "total_trades: 73665\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038511455 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -55.9       |\n",
      "|    explained_variance   | 0.000146    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 881         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | -4.112955   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 2.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 25\n",
      "day: 1940, episode: 25\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15150759.36\n",
      "total_reward: 5150759.36\n",
      "total_cost: 158624.64\n",
      "total_trades: 73667\n",
      "Sharpe: 0.348\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022404674 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.00732     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | 3.4344554   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 26\n",
      "day: 1940, episode: 26\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16007275.48\n",
      "total_reward: 6007275.48\n",
      "total_cost: 156506.52\n",
      "total_trades: 73657\n",
      "Sharpe: 0.379\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 197         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027748372 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56         |\n",
      "|    explained_variance   | 0.00967     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    reward               | -2.8181818  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 27\n",
      "day: 1940, episode: 27\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14645993.60\n",
      "total_reward: 4645993.60\n",
      "total_cost: 159396.40\n",
      "total_trades: 73653\n",
      "Sharpe: 0.329\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023375295 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.1       |\n",
      "|    explained_variance   | 0.0138      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    reward               | 24.643652   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 28\n",
      "day: 1940, episode: 28\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13751369.86\n",
      "total_reward: 3751369.86\n",
      "total_cost: 136166.14\n",
      "total_trades: 73666\n",
      "Sharpe: 0.307\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019486595 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.2       |\n",
      "|    explained_variance   | -0.0138     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    reward               | -60.079365  |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 29\n",
      "day: 1940, episode: 29\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8730378.16\n",
      "total_reward: -1269621.84\n",
      "total_cost: 128961.84\n",
      "total_trades: 73676\n",
      "Sharpe: 0.101\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 222        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02194481 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.2      |\n",
      "|    explained_variance   | -0.00129   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.06e+03   |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0272    |\n",
      "|    reward               | -18.71268  |\n",
      "|    std                  | 1.06       |\n",
      "|    value_loss           | 2.25e+03   |\n",
      "----------------------------------------\n",
      "Episode: 30\n",
      "day: 1940, episode: 30\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14775877.62\n",
      "total_reward: 4775877.62\n",
      "total_cost: 166658.38\n",
      "total_trades: 73669\n",
      "Sharpe: 0.332\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024427857 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | -8.239256   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.58e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 31\n",
      "day: 1940, episode: 31\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15602000.72\n",
      "total_reward: 5602000.72\n",
      "total_cost: 171866.28\n",
      "total_trades: 73675\n",
      "Sharpe: 0.366\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023413112 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.3       |\n",
      "|    explained_variance   | 0.00547     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -5.331921   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 32\n",
      "day: 1940, episode: 32\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12605031.35\n",
      "total_reward: 2605031.35\n",
      "total_cost: 153660.65\n",
      "total_trades: 73667\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022428682 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.4       |\n",
      "|    explained_variance   | -0.0167     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    reward               | 8.315979    |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 33\n",
      "day: 1940, episode: 33\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14246904.41\n",
      "total_reward: 4246904.41\n",
      "total_cost: 165580.59\n",
      "total_trades: 73662\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040357172 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.5       |\n",
      "|    explained_variance   | 0.00641     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 937         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 1.4145216   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 34\n",
      "day: 1940, episode: 34\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9098558.96\n",
      "total_reward: -901441.04\n",
      "total_cost: 156037.04\n",
      "total_trades: 73671\n",
      "Sharpe: 0.116\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018683653 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 729         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    reward               | 32.521557   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 35\n",
      "day: 1940, episode: 35\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15168316.66\n",
      "total_reward: 5168316.66\n",
      "total_cost: 165867.34\n",
      "total_trades: 73658\n",
      "Sharpe: 0.345\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028177224 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.6       |\n",
      "|    explained_variance   | -0.00772    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -6.6333466  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 36\n",
      "day: 1940, episode: 36\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17967340.27\n",
      "total_reward: 7967340.27\n",
      "total_cost: 174599.73\n",
      "total_trades: 73658\n",
      "Sharpe: 0.447\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 280        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02293082 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -56.7      |\n",
      "|    explained_variance   | -0.000761  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.73e+03   |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    reward               | -6.7658653 |\n",
      "|    std                  | 1.08       |\n",
      "|    value_loss           | 2.81e+03   |\n",
      "----------------------------------------\n",
      "Episode: 37\n",
      "day: 1940, episode: 37\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11535940.10\n",
      "total_reward: 1535940.10\n",
      "total_cost: 161715.90\n",
      "total_trades: 73661\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033615917 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.8       |\n",
      "|    explained_variance   | 0.00457     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 918         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    reward               | -3.6644886  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 38\n",
      "day: 1940, episode: 38\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10513768.76\n",
      "total_reward: 513768.76\n",
      "total_cost: 164148.24\n",
      "total_trades: 73659\n",
      "Sharpe: 0.165\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034944143 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -56.9       |\n",
      "|    explained_variance   | -0.0118     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | -7.6625104  |\n",
      "|    std                  | 1.08        |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 39\n",
      "day: 1940, episode: 39\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10289717.25\n",
      "total_reward: 289717.25\n",
      "total_cost: 154939.75\n",
      "total_trades: 73647\n",
      "Sharpe: 0.177\n",
      "=================================\n",
      "Episode: 40\n",
      "day: 1940, episode: 40\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11139416.48\n",
      "total_reward: 1139416.48\n",
      "total_cost: 158003.52\n",
      "total_trades: 73660\n",
      "Sharpe: 0.195\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032729946 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57         |\n",
      "|    explained_variance   | -0.00425    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 751         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -5.1155577  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 41\n",
      "day: 1940, episode: 41\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11425566.05\n",
      "total_reward: 1425566.05\n",
      "total_cost: 160553.95\n",
      "total_trades: 73658\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025043696 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.1       |\n",
      "|    explained_variance   | 0.0068      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 629         |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    reward               | 2.7711024   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 42\n",
      "day: 1940, episode: 42\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10605652.45\n",
      "total_reward: 605652.45\n",
      "total_cost: 147535.55\n",
      "total_trades: 73673\n",
      "Sharpe: 0.164\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034972146 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.2       |\n",
      "|    explained_variance   | 0.00883     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 700         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    reward               | -4.575601   |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 43\n",
      "day: 1940, episode: 43\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9715581.86\n",
      "total_reward: -284418.14\n",
      "total_cost: 144246.14\n",
      "total_trades: 73674\n",
      "Sharpe: 0.128\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 328        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03598572 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.2      |\n",
      "|    explained_variance   | 0.00553    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    reward               | 11.859413  |\n",
      "|    std                  | 1.09       |\n",
      "|    value_loss           | 1.69e+03   |\n",
      "----------------------------------------\n",
      "Episode: 44\n",
      "day: 1940, episode: 44\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12670453.88\n",
      "total_reward: 2670453.88\n",
      "total_cost: 147873.12\n",
      "total_trades: 73678\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028505681 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.3       |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    reward               | -13.410485  |\n",
      "|    std                  | 1.09        |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 45\n",
      "day: 1940, episode: 45\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10685494.39\n",
      "total_reward: 685494.39\n",
      "total_cost: 138182.61\n",
      "total_trades: 73672\n",
      "Sharpe: 0.180\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 345        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02258339 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.4      |\n",
      "|    explained_variance   | 0.00872    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    reward               | 0.8866181  |\n",
      "|    std                  | 1.1        |\n",
      "|    value_loss           | 2.7e+03    |\n",
      "----------------------------------------\n",
      "Episode: 46\n",
      "day: 1940, episode: 46\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6916268.69\n",
      "total_reward: -3083731.31\n",
      "total_cost: 137970.31\n",
      "total_trades: 73671\n",
      "Sharpe: 0.009\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028693203 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.4       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 789         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | 12.375351   |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.25e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 47\n",
      "day: 1940, episode: 47\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9871327.63\n",
      "total_reward: -128672.37\n",
      "total_cost: 146660.37\n",
      "total_trades: 73667\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026980408 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.5       |\n",
      "|    explained_variance   | 0.00425     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 754         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    reward               | -23.289791  |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 1.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 48\n",
      "day: 1940, episode: 48\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13889287.60\n",
      "total_reward: 3889287.60\n",
      "total_cost: 158557.40\n",
      "total_trades: 73660\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03796683  |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.6       |\n",
      "|    explained_variance   | -0.016      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 970         |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | -0.96535295 |\n",
      "|    std                  | 1.1         |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 49\n",
      "day: 1940, episode: 49\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7432653.95\n",
      "total_reward: -2567346.05\n",
      "total_cost: 131882.05\n",
      "total_trades: 73681\n",
      "Sharpe: 0.029\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 378        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0223476  |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.7      |\n",
      "|    explained_variance   | 0.00632    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.31e+03   |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0299    |\n",
      "|    reward               | -7.7957006 |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 2.58e+03   |\n",
      "----------------------------------------\n",
      "Episode: 50\n",
      "day: 1940, episode: 50\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12493333.98\n",
      "total_reward: 2493333.98\n",
      "total_cost: 144900.02\n",
      "total_trades: 73659\n",
      "Sharpe: 0.248\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 386        |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04409989 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -57.8      |\n",
      "|    explained_variance   | 0.00925    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.12e+03   |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    reward               | -5.366226  |\n",
      "|    std                  | 1.11       |\n",
      "|    value_loss           | 2.04e+03   |\n",
      "----------------------------------------\n",
      "Episode: 51\n",
      "day: 1940, episode: 51\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8396786.20\n",
      "total_reward: -1603213.80\n",
      "total_cost: 145925.80\n",
      "total_trades: 73679\n",
      "Sharpe: 0.083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052860674 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -57.9       |\n",
      "|    explained_variance   | 0.00978     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 605         |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | 0.9165058   |\n",
      "|    std                  | 1.11        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 52\n",
      "day: 1940, episode: 52\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9388598.84\n",
      "total_reward: -611401.16\n",
      "total_cost: 143187.16\n",
      "total_trades: 73664\n",
      "Sharpe: 0.112\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049985424 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58         |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 638         |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -20.353134  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 53\n",
      "day: 1940, episode: 53\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11469701.29\n",
      "total_reward: 1469701.29\n",
      "total_cost: 136585.71\n",
      "total_trades: 73670\n",
      "Sharpe: 0.208\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051076315 |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.1       |\n",
      "|    explained_variance   | 0.0144      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 782         |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | 17.844595   |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 54\n",
      "day: 1940, episode: 54\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8590065.89\n",
      "total_reward: -1409934.11\n",
      "total_cost: 122165.11\n",
      "total_trades: 73670\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026061803 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 944         |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    reward               | -6.2099814  |\n",
      "|    std                  | 1.12        |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 55\n",
      "day: 1940, episode: 55\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8132115.20\n",
      "total_reward: -1867884.80\n",
      "total_cost: 127539.80\n",
      "total_trades: 73678\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 428        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04317993 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.3      |\n",
      "|    explained_variance   | 0.0165     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 784        |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | -4.9456944 |\n",
      "|    std                  | 1.12       |\n",
      "|    value_loss           | 1.45e+03   |\n",
      "----------------------------------------\n",
      "Episode: 56\n",
      "day: 1940, episode: 56\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6416007.04\n",
      "total_reward: -3583992.96\n",
      "total_cost: 131580.96\n",
      "total_trades: 73669\n",
      "Sharpe: -0.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037076376 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | 0.00314     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 484         |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    reward               | -13.126898  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n",
      "Episode: 57\n",
      "day: 1940, episode: 57\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9731066.45\n",
      "total_reward: -268933.55\n",
      "total_cost: 133765.55\n",
      "total_trades: 73656\n",
      "Sharpe: 0.125\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037639536 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.4       |\n",
      "|    explained_variance   | -0.00619    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 861         |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -16.307968  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 58\n",
      "day: 1940, episode: 58\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11908287.29\n",
      "total_reward: 1908287.29\n",
      "total_cost: 144223.71\n",
      "total_trades: 73649\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "Episode: 59\n",
      "day: 1940, episode: 59\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9456548.26\n",
      "total_reward: -543451.74\n",
      "total_cost: 143790.74\n",
      "total_trades: 73656\n",
      "Sharpe: 0.125\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 453        |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04113477 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.5      |\n",
      "|    explained_variance   | 0.00557    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.06e+03   |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    reward               | -6.13939   |\n",
      "|    std                  | 1.13       |\n",
      "|    value_loss           | 4.13e+03   |\n",
      "----------------------------------------\n",
      "Episode: 60\n",
      "day: 1940, episode: 60\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10880162.13\n",
      "total_reward: 880162.13\n",
      "total_cost: 147462.87\n",
      "total_trades: 73678\n",
      "Sharpe: 0.194\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043677703 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.6       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 985         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    reward               | -1.1195065  |\n",
      "|    std                  | 1.13        |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 61\n",
      "day: 1940, episode: 61\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13955263.36\n",
      "total_reward: 3955263.36\n",
      "total_cost: 135463.64\n",
      "total_trades: 73668\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 469         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030467357 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -58.8       |\n",
      "|    explained_variance   | 0.0308      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 768         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    reward               | 22.612103   |\n",
      "|    std                  | 1.14        |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 62\n",
      "day: 1940, episode: 62\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14931243.68\n",
      "total_reward: 4931243.68\n",
      "total_cost: 147244.32\n",
      "total_trades: 73663\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 477        |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03360296 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -58.9      |\n",
      "|    explained_variance   | 0.0175     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.71e+03   |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    reward               | -5.8625197 |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 4.09e+03   |\n",
      "----------------------------------------\n",
      "Episode: 63\n",
      "day: 1940, episode: 63\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10635049.80\n",
      "total_reward: 635049.80\n",
      "total_cost: 140406.20\n",
      "total_trades: 73673\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 485        |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04572723 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59        |\n",
      "|    explained_variance   | 0.0108     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.17e+03   |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    reward               | 0.76118016 |\n",
      "|    std                  | 1.14       |\n",
      "|    value_loss           | 4.11e+03   |\n",
      "----------------------------------------\n",
      "Episode: 64\n",
      "day: 1940, episode: 64\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9363484.68\n",
      "total_reward: -636515.32\n",
      "total_cost: 141558.32\n",
      "total_trades: 73678\n",
      "Sharpe: 0.134\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 493         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042629983 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.1       |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    reward               | -0.41921234 |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 65\n",
      "day: 1940, episode: 65\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7685485.78\n",
      "total_reward: -2314514.22\n",
      "total_cost: 129541.22\n",
      "total_trades: 73684\n",
      "Sharpe: 0.037\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031019341 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 842         |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    reward               | 17.190903   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 66\n",
      "day: 1940, episode: 66\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14534102.61\n",
      "total_reward: 4534102.61\n",
      "total_cost: 138170.39\n",
      "total_trades: 73660\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038397677 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.2       |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 375         |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    reward               | 25.204304   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 67\n",
      "day: 1940, episode: 67\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15672640.69\n",
      "total_reward: 5672640.69\n",
      "total_cost: 148926.31\n",
      "total_trades: 73677\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028561564 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.3       |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.41e+03    |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | -4.359757   |\n",
      "|    std                  | 1.15        |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 68\n",
      "day: 1940, episode: 68\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11248861.13\n",
      "total_reward: 1248861.13\n",
      "total_cost: 144337.87\n",
      "total_trades: 73662\n",
      "Sharpe: 0.196\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 525        |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04383874 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.4      |\n",
      "|    explained_variance   | -0.0257    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.66e+03   |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.00217   |\n",
      "|    reward               | 1.7407322  |\n",
      "|    std                  | 1.15       |\n",
      "|    value_loss           | 4.04e+03   |\n",
      "----------------------------------------\n",
      "Episode: 69\n",
      "day: 1940, episode: 69\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9340266.07\n",
      "total_reward: -659733.93\n",
      "total_cost: 140325.93\n",
      "total_trades: 73673\n",
      "Sharpe: 0.113\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032668825 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.4       |\n",
      "|    explained_variance   | 0.00765     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | -0.9028954  |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 2.1e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 70\n",
      "day: 1940, episode: 70\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10576666.64\n",
      "total_reward: 576666.64\n",
      "total_cost: 149762.36\n",
      "total_trades: 73668\n",
      "Sharpe: 0.167\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027415965 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.5       |\n",
      "|    explained_variance   | 0.00682     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | 14.230227   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 3.77e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 71\n",
      "day: 1940, episode: 71\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11275465.95\n",
      "total_reward: 1275465.95\n",
      "total_cost: 147642.05\n",
      "total_trades: 73679\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 550         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042700738 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.6       |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.46e+03    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | 3.1868367   |\n",
      "|    std                  | 1.16        |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 72\n",
      "day: 1940, episode: 72\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13302602.88\n",
      "total_reward: 3302602.88\n",
      "total_cost: 147710.12\n",
      "total_trades: 73683\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022509156 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.7       |\n",
      "|    explained_variance   | 0.00453     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 869         |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    reward               | 7.599135    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 73\n",
      "day: 1940, episode: 73\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9685101.87\n",
      "total_reward: -314898.13\n",
      "total_cost: 137921.13\n",
      "total_trades: 73665\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029917933 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -59.8       |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88e+03    |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | 15.14655    |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 74\n",
      "day: 1940, episode: 74\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11101141.44\n",
      "total_reward: 1101141.44\n",
      "total_cost: 147380.56\n",
      "total_trades: 73674\n",
      "Sharpe: 0.191\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 574        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03536192 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -59.9      |\n",
      "|    explained_variance   | 0.0333     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.74e+03   |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    reward               | 11.93612   |\n",
      "|    std                  | 1.17       |\n",
      "|    value_loss           | 2.91e+03   |\n",
      "----------------------------------------\n",
      "Episode: 75\n",
      "day: 1940, episode: 75\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12628532.54\n",
      "total_reward: 2628532.54\n",
      "total_cost: 135981.46\n",
      "total_trades: 73672\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 582         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028749313 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60         |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.49e+03    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    reward               | 3.5325243   |\n",
      "|    std                  | 1.17        |\n",
      "|    value_loss           | 2.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 76\n",
      "day: 1940, episode: 76\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12918195.46\n",
      "total_reward: 2918195.46\n",
      "total_cost: 143291.54\n",
      "total_trades: 73667\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030374793 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.017       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 764         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -0.7195981  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 77\n",
      "day: 1940, episode: 77\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10722491.30\n",
      "total_reward: 722491.30\n",
      "total_cost: 137694.70\n",
      "total_trades: 73670\n",
      "Sharpe: 0.191\n",
      "=================================\n",
      "Episode: 78\n",
      "day: 1940, episode: 78\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11290141.52\n",
      "total_reward: 1290141.52\n",
      "total_cost: 131478.48\n",
      "total_trades: 73651\n",
      "Sharpe: 0.195\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052760705 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.1       |\n",
      "|    explained_variance   | 0.0227      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 985         |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00826    |\n",
      "|    reward               | -2.7114608  |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 79\n",
      "day: 1940, episode: 79\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8542455.79\n",
      "total_reward: -1457544.21\n",
      "total_cost: 120299.21\n",
      "total_trades: 73676\n",
      "Sharpe: 0.090\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03703411  |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.2       |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    reward               | -0.70040095 |\n",
      "|    std                  | 1.18        |\n",
      "|    value_loss           | 3.7e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 80\n",
      "day: 1940, episode: 80\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9454715.72\n",
      "total_reward: -545284.28\n",
      "total_cost: 133406.28\n",
      "total_trades: 73680\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038395192 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.3       |\n",
      "|    explained_variance   | 0.0556      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 769         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    reward               | 4.864706    |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 2.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 81\n",
      "day: 1940, episode: 81\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9679238.52\n",
      "total_reward: -320761.48\n",
      "total_cost: 134802.48\n",
      "total_trades: 73675\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 624        |\n",
      "|    total_timesteps      | 155648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03706544 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.5      |\n",
      "|    explained_variance   | 0.0583     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.32e+03   |\n",
      "|    n_updates            | 750        |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    reward               | 8.641901   |\n",
      "|    std                  | 1.19       |\n",
      "|    value_loss           | 1.93e+03   |\n",
      "----------------------------------------\n",
      "Episode: 82\n",
      "day: 1940, episode: 82\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9220772.76\n",
      "total_reward: -779227.24\n",
      "total_cost: 132469.24\n",
      "total_trades: 73667\n",
      "Sharpe: 0.116\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049011327 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.6       |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 776         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    reward               | 1.536888    |\n",
      "|    std                  | 1.19        |\n",
      "|    value_loss           | 2.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 83\n",
      "day: 1940, episode: 83\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12440547.96\n",
      "total_reward: 2440547.96\n",
      "total_cost: 130129.04\n",
      "total_trades: 73685\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035586774 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -60.7       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 802         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.82214934  |\n",
      "|    std                  | 1.2         |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 84\n",
      "day: 1940, episode: 84\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7099524.88\n",
      "total_reward: -2900475.12\n",
      "total_cost: 129571.12\n",
      "total_trades: 73667\n",
      "Sharpe: 0.016\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 649        |\n",
      "|    total_timesteps      | 161792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03398071 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -60.9      |\n",
      "|    explained_variance   | 0.0393     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.3e+03    |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.0199    |\n",
      "|    reward               | -6.214831  |\n",
      "|    std                  | 1.2        |\n",
      "|    value_loss           | 4.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 85\n",
      "day: 1940, episode: 85\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10515886.02\n",
      "total_reward: 515886.02\n",
      "total_cost: 129872.98\n",
      "total_trades: 73658\n",
      "Sharpe: 0.180\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039507627 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61         |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | 39.9459     |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 86\n",
      "day: 1940, episode: 86\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12535304.87\n",
      "total_reward: 2535304.87\n",
      "total_cost: 147422.13\n",
      "total_trades: 73677\n",
      "Sharpe: 0.247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021972094 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.28e+03    |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    reward               | -16.382366  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 4.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 87\n",
      "day: 1940, episode: 87\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9525960.69\n",
      "total_reward: -474039.31\n",
      "total_cost: 126817.31\n",
      "total_trades: 73676\n",
      "Sharpe: 0.106\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029090544 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.1       |\n",
      "|    explained_variance   | -0.016      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -1.5200963  |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 4.83e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 88\n",
      "day: 1940, episode: 88\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13990821.45\n",
      "total_reward: 3990821.45\n",
      "total_cost: 136525.55\n",
      "total_trades: 73669\n",
      "Sharpe: 0.301\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 682         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025248919 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.2       |\n",
      "|    explained_variance   | 0.0597      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    reward               | 23.07471    |\n",
      "|    std                  | 1.21        |\n",
      "|    value_loss           | 5.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 89\n",
      "day: 1940, episode: 89\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8410686.75\n",
      "total_reward: -1589313.25\n",
      "total_cost: 121902.25\n",
      "total_trades: 73673\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 690         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047801994 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.0573      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 5.099759    |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 90\n",
      "day: 1940, episode: 90\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11092634.06\n",
      "total_reward: 1092634.06\n",
      "total_cost: 140124.94\n",
      "total_trades: 73666\n",
      "Sharpe: 0.183\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034710396 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.3       |\n",
      "|    explained_variance   | 0.0939      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    reward               | 4.6584644   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 3.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 91\n",
      "day: 1940, episode: 91\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9269096.79\n",
      "total_reward: -730903.21\n",
      "total_cost: 130399.21\n",
      "total_trades: 73678\n",
      "Sharpe: 0.118\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028384916 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.4       |\n",
      "|    explained_variance   | 0.0832      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 814         |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    reward               | 4.0133533   |\n",
      "|    std                  | 1.22        |\n",
      "|    value_loss           | 2.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 92\n",
      "day: 1940, episode: 92\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10804624.06\n",
      "total_reward: 804624.06\n",
      "total_cost: 134313.94\n",
      "total_trades: 73676\n",
      "Sharpe: 0.169\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 715        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03184353 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.5      |\n",
      "|    explained_variance   | 0.059      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.97e+03   |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    reward               | 0.97537935 |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 3.82e+03   |\n",
      "----------------------------------------\n",
      "Episode: 93\n",
      "day: 1940, episode: 93\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12309334.23\n",
      "total_reward: 2309334.23\n",
      "total_cost: 139837.77\n",
      "total_trades: 73673\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 723        |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03400576 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.5      |\n",
      "|    explained_variance   | 0.0837     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.29e+03   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    reward               | -19.170685 |\n",
      "|    std                  | 1.22       |\n",
      "|    value_loss           | 3.95e+03   |\n",
      "----------------------------------------\n",
      "Episode: 94\n",
      "day: 1940, episode: 94\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6489388.38\n",
      "total_reward: -3510611.62\n",
      "total_cost: 122601.62\n",
      "total_trades: 73685\n",
      "Sharpe: -0.031\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 89         |\n",
      "|    time_elapsed         | 731        |\n",
      "|    total_timesteps      | 182272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05652485 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -61.7      |\n",
      "|    explained_variance   | 0.0665     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.2e+03    |\n",
      "|    n_updates            | 880        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | -11.215871 |\n",
      "|    std                  | 1.23       |\n",
      "|    value_loss           | 2.1e+03    |\n",
      "----------------------------------------\n",
      "Episode: 95\n",
      "day: 1940, episode: 95\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11786273.88\n",
      "total_reward: 1786273.88\n",
      "total_cost: 135291.12\n",
      "total_trades: 73681\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 739         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026998006 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.8       |\n",
      "|    explained_variance   | 0.032       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.55e+03    |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -6.246095   |\n",
      "|    std                  | 1.23        |\n",
      "|    value_loss           | 6.74e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 96\n",
      "day: 1940, episode: 96\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12287954.92\n",
      "total_reward: 2287954.92\n",
      "total_cost: 141073.08\n",
      "total_trades: 73671\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "Episode: 97\n",
      "day: 1940, episode: 97\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10042084.90\n",
      "total_reward: 42084.90\n",
      "total_cost: 120742.10\n",
      "total_trades: 73676\n",
      "Sharpe: 0.143\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016166113 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -61.9       |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.39e+03    |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    reward               | -2.6192546  |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 5.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 98\n",
      "day: 1940, episode: 98\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14193403.16\n",
      "total_reward: 4193403.16\n",
      "total_cost: 129547.84\n",
      "total_trades: 73676\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 92         |\n",
      "|    time_elapsed         | 756        |\n",
      "|    total_timesteps      | 188416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0361304  |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62        |\n",
      "|    explained_variance   | 0.0891     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.17e+03   |\n",
      "|    n_updates            | 910        |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    reward               | -0.3015072 |\n",
      "|    std                  | 1.24       |\n",
      "|    value_loss           | 3.02e+03   |\n",
      "----------------------------------------\n",
      "Episode: 99\n",
      "day: 1940, episode: 99\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12511737.86\n",
      "total_reward: 2511737.86\n",
      "total_cost: 143006.14\n",
      "total_trades: 73675\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029044071 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.1       |\n",
      "|    explained_variance   | 0.084       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.48e+03    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | 3.999612    |\n",
      "|    std                  | 1.24        |\n",
      "|    value_loss           | 4.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 100\n",
      "day: 1940, episode: 100\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11590914.65\n",
      "total_reward: 1590914.65\n",
      "total_cost: 132324.35\n",
      "total_trades: 73673\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 772         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032636154 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.2       |\n",
      "|    explained_variance   | 0.0606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.57e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | 10.141235   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 5.81e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 101\n",
      "day: 1940, episode: 101\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10250276.28\n",
      "total_reward: 250276.28\n",
      "total_cost: 122959.72\n",
      "total_trades: 73679\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 780        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03416211 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.3      |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.29e+03   |\n",
      "|    n_updates            | 940        |\n",
      "|    policy_gradient_loss | -0.0207    |\n",
      "|    reward               | 7.972521   |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 3.47e+03   |\n",
      "----------------------------------------\n",
      "Episode: 102\n",
      "day: 1940, episode: 102\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19227244.69\n",
      "total_reward: 9227244.69\n",
      "total_cost: 152022.31\n",
      "total_trades: 73677\n",
      "Sharpe: 0.462\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 788         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027493056 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.4       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    reward               | -4.978531   |\n",
      "|    std                  | 1.25        |\n",
      "|    value_loss           | 3.64e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 103\n",
      "day: 1940, episode: 103\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9145008.95\n",
      "total_reward: -854991.05\n",
      "total_cost: 116866.05\n",
      "total_trades: 73673\n",
      "Sharpe: 0.102\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 796        |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03522049 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -62.5      |\n",
      "|    explained_variance   | 0.0284     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 5.13e+03   |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    reward               | 5.0440097  |\n",
      "|    std                  | 1.25       |\n",
      "|    value_loss           | 8.14e+03   |\n",
      "----------------------------------------\n",
      "Episode: 104\n",
      "day: 1940, episode: 104\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13138237.79\n",
      "total_reward: 3138237.79\n",
      "total_cost: 143633.21\n",
      "total_trades: 73674\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023558836 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.5       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    reward               | 6.139973    |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 2.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 105\n",
      "day: 1940, episode: 105\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9674733.88\n",
      "total_reward: -325266.12\n",
      "total_cost: 125217.12\n",
      "total_trades: 73677\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 813         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022903502 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.6       |\n",
      "|    explained_variance   | 0.0589      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.87e+03    |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    reward               | 22.518173   |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 5.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 106\n",
      "day: 1940, episode: 106\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12566394.00\n",
      "total_reward: 2566394.00\n",
      "total_cost: 128153.00\n",
      "total_trades: 73672\n",
      "Sharpe: 0.251\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 821         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031420693 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.7       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.71e+03    |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    reward               | -0.88240224 |\n",
      "|    std                  | 1.26        |\n",
      "|    value_loss           | 5.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 107\n",
      "day: 1940, episode: 107\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8158391.97\n",
      "total_reward: -1841608.03\n",
      "total_cost: 112948.03\n",
      "total_trades: 73663\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 829         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033173166 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.8       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 978         |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | -2.3531897  |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 3.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 108\n",
      "day: 1940, episode: 108\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17758364.56\n",
      "total_reward: 7758364.56\n",
      "total_cost: 146043.44\n",
      "total_trades: 73681\n",
      "Sharpe: 0.411\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 837         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020049894 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -62.9       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | -0.5609337  |\n",
      "|    std                  | 1.27        |\n",
      "|    value_loss           | 6.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 109\n",
      "day: 1940, episode: 109\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15998699.89\n",
      "total_reward: 5998699.89\n",
      "total_cost: 153905.11\n",
      "total_trades: 73674\n",
      "Sharpe: 0.370\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 846        |\n",
      "|    total_timesteps      | 210944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03892194 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63        |\n",
      "|    explained_variance   | 0.0301     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.9e+03    |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    reward               | -14.516224 |\n",
      "|    std                  | 1.27       |\n",
      "|    value_loss           | 6.61e+03   |\n",
      "----------------------------------------\n",
      "Episode: 110\n",
      "day: 1940, episode: 110\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11194340.17\n",
      "total_reward: 1194340.17\n",
      "total_cost: 133070.83\n",
      "total_trades: 73673\n",
      "Sharpe: 0.196\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 855        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02145211 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -63.1      |\n",
      "|    explained_variance   | 0.0522     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.45e+03   |\n",
      "|    n_updates            | 1030       |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    reward               | -16.360964 |\n",
      "|    std                  | 1.28       |\n",
      "|    value_loss           | 4.56e+03   |\n",
      "----------------------------------------\n",
      "Episode: 111\n",
      "day: 1940, episode: 111\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10246953.98\n",
      "total_reward: 246953.98\n",
      "total_cost: 127250.02\n",
      "total_trades: 73668\n",
      "Sharpe: 0.167\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 863         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038579956 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.2       |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 0.48660016  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 112\n",
      "day: 1940, episode: 112\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16598916.68\n",
      "total_reward: 6598916.68\n",
      "total_cost: 142253.32\n",
      "total_trades: 73681\n",
      "Sharpe: 0.390\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 872         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030460054 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.3       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | -51.165665  |\n",
      "|    std                  | 1.28        |\n",
      "|    value_loss           | 4.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 113\n",
      "day: 1940, episode: 113\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13899118.78\n",
      "total_reward: 3899118.78\n",
      "total_cost: 140243.22\n",
      "total_trades: 73678\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 880         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037543338 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.4       |\n",
      "|    explained_variance   | 0.0921      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.18e+03    |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 26.613792   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 5.71e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 114\n",
      "day: 1940, episode: 114\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18880403.67\n",
      "total_reward: 8880403.67\n",
      "total_cost: 141947.33\n",
      "total_trades: 73687\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 888         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021422567 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.5       |\n",
      "|    explained_variance   | 0.0395      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.45e+03    |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    reward               | 19.247807   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 8.71e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 115\n",
      "day: 1940, episode: 115\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16156425.71\n",
      "total_reward: 6156425.71\n",
      "total_cost: 134768.29\n",
      "total_trades: 73675\n",
      "Sharpe: 0.374\n",
      "=================================\n",
      "Episode: 116\n",
      "day: 1940, episode: 116\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13866911.05\n",
      "total_reward: 3866911.05\n",
      "total_cost: 125489.95\n",
      "total_trades: 73669\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 897         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019032247 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.2e+03     |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    reward               | 4.3678203   |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 5.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 117\n",
      "day: 1940, episode: 117\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15346306.31\n",
      "total_reward: 5346306.31\n",
      "total_cost: 132371.69\n",
      "total_trades: 73679\n",
      "Sharpe: 0.349\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 905         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03188049  |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.6       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.27e+03    |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    reward               | -0.14972761 |\n",
      "|    std                  | 1.29        |\n",
      "|    value_loss           | 4.54e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 118\n",
      "day: 1940, episode: 118\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14372992.80\n",
      "total_reward: 4372992.80\n",
      "total_cost: 139473.20\n",
      "total_trades: 73667\n",
      "Sharpe: 0.316\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 913         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018092953 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.7       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    reward               | -0.18563552 |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 5.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 119\n",
      "day: 1940, episode: 119\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16514900.58\n",
      "total_reward: 6514900.58\n",
      "total_cost: 135072.42\n",
      "total_trades: 73670\n",
      "Sharpe: 0.386\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 922         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040398717 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.8       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.5e+03     |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    reward               | -13.36007   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 4.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 120\n",
      "day: 1940, episode: 120\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17025500.17\n",
      "total_reward: 7025500.17\n",
      "total_cost: 130847.83\n",
      "total_trades: 73670\n",
      "Sharpe: 0.403\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 930         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028081944 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -63.9       |\n",
      "|    explained_variance   | 0.0957      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.02e+03    |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    reward               | 21.846987   |\n",
      "|    std                  | 1.3         |\n",
      "|    value_loss           | 4.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 121\n",
      "day: 1940, episode: 121\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14535452.93\n",
      "total_reward: 4535452.93\n",
      "total_cost: 137799.07\n",
      "total_trades: 73683\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 938        |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04182787 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.1      |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.43e+03   |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    reward               | -18.884474 |\n",
      "|    std                  | 1.31       |\n",
      "|    value_loss           | 5.08e+03   |\n",
      "----------------------------------------\n",
      "Episode: 122\n",
      "day: 1940, episode: 122\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 19448796.08\n",
      "total_reward: 9448796.08\n",
      "total_cost: 157427.92\n",
      "total_trades: 73685\n",
      "Sharpe: 0.468\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 946         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032499403 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.1       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.95e+03    |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | -4.284524   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 4.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 123\n",
      "day: 1940, episode: 123\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18969677.33\n",
      "total_reward: 8969677.33\n",
      "total_cost: 143616.67\n",
      "total_trades: 73673\n",
      "Sharpe: 0.451\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 955         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027275283 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.2       |\n",
      "|    explained_variance   | 0.0682      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.6e+03     |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 3.6933756   |\n",
      "|    std                  | 1.31        |\n",
      "|    value_loss           | 5.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 124\n",
      "day: 1940, episode: 124\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12594559.04\n",
      "total_reward: 2594559.04\n",
      "total_cost: 132665.96\n",
      "total_trades: 73682\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018243082 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.3       |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.63e+03    |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    reward               | 12.794447   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 6.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 125\n",
      "day: 1940, episode: 125\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 21429888.84\n",
      "total_reward: 11429888.84\n",
      "total_cost: 134135.16\n",
      "total_trades: 73677\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 971         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034331083 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.4       |\n",
      "|    explained_variance   | 0.094       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.11e+03    |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    reward               | 17.540798   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 7.58e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 126\n",
      "day: 1940, episode: 126\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 17486040.82\n",
      "total_reward: 7486040.82\n",
      "total_cost: 139162.18\n",
      "total_trades: 73682\n",
      "Sharpe: 0.410\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 979         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038944393 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.5       |\n",
      "|    explained_variance   | 0.0394      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.49e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    reward               | 18.695646   |\n",
      "|    std                  | 1.32        |\n",
      "|    value_loss           | 5.8e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 127\n",
      "day: 1940, episode: 127\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11536934.73\n",
      "total_reward: 1536934.73\n",
      "total_cost: 121739.27\n",
      "total_trades: 73684\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023509897 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.6       |\n",
      "|    explained_variance   | 0.0687      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | 3.8476863   |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 128\n",
      "day: 1940, episode: 128\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12749125.21\n",
      "total_reward: 2749125.21\n",
      "total_cost: 127479.79\n",
      "total_trades: 73678\n",
      "Sharpe: 0.274\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 995        |\n",
      "|    total_timesteps      | 247808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03754369 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -64.6      |\n",
      "|    explained_variance   | 0.111      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.32e+03   |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    reward               | -4.4660015 |\n",
      "|    std                  | 1.33       |\n",
      "|    value_loss           | 3.13e+03   |\n",
      "----------------------------------------\n",
      "Episode: 129\n",
      "day: 1940, episode: 129\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12500049.25\n",
      "total_reward: 2500049.25\n",
      "total_cost: 119411.75\n",
      "total_trades: 73690\n",
      "Sharpe: 0.263\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031757906 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.7       |\n",
      "|    explained_variance   | 0.069       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -0.9574395  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 3.58e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 130\n",
      "day: 1940, episode: 130\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9180346.64\n",
      "total_reward: -819653.36\n",
      "total_cost: 108430.36\n",
      "total_trades: 73677\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 1011        |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039958782 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.0866      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    reward               | 13.1133375  |\n",
      "|    std                  | 1.33        |\n",
      "|    value_loss           | 2.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 131\n",
      "day: 1940, episode: 131\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12656419.48\n",
      "total_reward: 2656419.48\n",
      "total_cost: 135424.52\n",
      "total_trades: 73675\n",
      "Sharpe: 0.263\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 1019        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034528807 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.8       |\n",
      "|    explained_variance   | 0.0791      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.22e+03    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.15904553  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 3.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 132\n",
      "day: 1940, episode: 132\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12852254.54\n",
      "total_reward: 2852254.54\n",
      "total_cost: 138261.46\n",
      "total_trades: 73667\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 1028        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041891307 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -64.9       |\n",
      "|    explained_variance   | 0.0288      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.04e+03    |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | 31.222843   |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 4.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 133\n",
      "day: 1940, episode: 133\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13628811.64\n",
      "total_reward: 3628811.64\n",
      "total_cost: 150784.36\n",
      "total_trades: 73681\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 1036        |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034821045 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.0181      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -10.819521  |\n",
      "|    std                  | 1.34        |\n",
      "|    value_loss           | 5.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 134\n",
      "day: 1940, episode: 134\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13308177.54\n",
      "total_reward: 3308177.54\n",
      "total_cost: 140157.46\n",
      "total_trades: 73683\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "Episode: 135\n",
      "day: 1940, episode: 135\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14146840.52\n",
      "total_reward: 4146840.52\n",
      "total_cost: 133672.48\n",
      "total_trades: 73682\n",
      "Sharpe: 0.306\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 1044        |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024618834 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.1       |\n",
      "|    explained_variance   | 0.025       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -1.1420858  |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 3.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 136\n",
      "day: 1940, episode: 136\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11584893.30\n",
      "total_reward: 1584893.30\n",
      "total_cost: 138014.70\n",
      "total_trades: 73669\n",
      "Sharpe: 0.214\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 1053        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03338951  |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.2       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.52e+03    |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -0.19939674 |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 4.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 137\n",
      "day: 1940, episode: 137\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13436439.68\n",
      "total_reward: 3436439.68\n",
      "total_cost: 148231.32\n",
      "total_trades: 73670\n",
      "Sharpe: 0.288\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 1061        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036580183 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.3       |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.53e+03    |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | 0.545766    |\n",
      "|    std                  | 1.35        |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 138\n",
      "day: 1940, episode: 138\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14289496.95\n",
      "total_reward: 4289496.95\n",
      "total_cost: 144471.05\n",
      "total_trades: 73676\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 248       |\n",
      "|    iterations           | 130       |\n",
      "|    time_elapsed         | 1069      |\n",
      "|    total_timesteps      | 266240    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0431107 |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -65.5     |\n",
      "|    explained_variance   | 0.0081    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 651       |\n",
      "|    n_updates            | 1290      |\n",
      "|    policy_gradient_loss | -0.0157   |\n",
      "|    reward               | 2.9362059 |\n",
      "|    std                  | 1.36      |\n",
      "|    value_loss           | 2.76e+03  |\n",
      "---------------------------------------\n",
      "Episode: 139\n",
      "day: 1940, episode: 139\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14060919.90\n",
      "total_reward: 4060919.90\n",
      "total_cost: 154772.10\n",
      "total_trades: 73667\n",
      "Sharpe: 0.304\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 1077        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040330797 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.6       |\n",
      "|    explained_variance   | -6.29e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.36e+03    |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 2.3144183   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 140\n",
      "day: 1940, episode: 140\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10139035.08\n",
      "total_reward: 139035.08\n",
      "total_cost: 142443.92\n",
      "total_trades: 73684\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 132        |\n",
      "|    time_elapsed         | 1086       |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01921241 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.7      |\n",
      "|    explained_variance   | -0.000191  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.66e+03   |\n",
      "|    n_updates            | 1310       |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    reward               | -6.1012125 |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 3.93e+03   |\n",
      "----------------------------------------\n",
      "Episode: 141\n",
      "day: 1940, episode: 141\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12234028.32\n",
      "total_reward: 2234028.32\n",
      "total_cost: 140548.68\n",
      "total_trades: 73680\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 1094       |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02774699 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -65.8      |\n",
      "|    explained_variance   | 0.0182     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.37e+03   |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | -0.0255    |\n",
      "|    reward               | 2.5955298  |\n",
      "|    std                  | 1.37       |\n",
      "|    value_loss           | 2.72e+03   |\n",
      "----------------------------------------\n",
      "Episode: 142\n",
      "day: 1940, episode: 142\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13077697.02\n",
      "total_reward: 3077697.02\n",
      "total_cost: 160353.98\n",
      "total_trades: 73676\n",
      "Sharpe: 0.269\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 1102        |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027196636 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.8       |\n",
      "|    explained_variance   | 0.0236      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    reward               | 2.7247105   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 4.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 143\n",
      "day: 1940, episode: 143\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14844515.60\n",
      "total_reward: 4844515.60\n",
      "total_cost: 158891.40\n",
      "total_trades: 73678\n",
      "Sharpe: 0.332\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 1110        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027132608 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | -0.0147     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.97e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    reward               | -27.90297   |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 5.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 144\n",
      "day: 1940, episode: 144\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14728638.61\n",
      "total_reward: 4728638.61\n",
      "total_cost: 157574.39\n",
      "total_trades: 73678\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 1118        |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019763635 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -65.9       |\n",
      "|    explained_variance   | 0.00279     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.35e+03    |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -20.401876  |\n",
      "|    std                  | 1.37        |\n",
      "|    value_loss           | 6.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 145\n",
      "day: 1940, episode: 145\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12720759.19\n",
      "total_reward: 2720759.19\n",
      "total_cost: 153415.81\n",
      "total_trades: 73682\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 1126        |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017711846 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66         |\n",
      "|    explained_variance   | 0.00948     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    reward               | -27.278423  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 4.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 146\n",
      "day: 1940, episode: 146\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9796144.75\n",
      "total_reward: -203855.25\n",
      "total_cost: 143670.25\n",
      "total_trades: 73687\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 1135        |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053103924 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.1       |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 880         |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -12.008169  |\n",
      "|    std                  | 1.38        |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 147\n",
      "day: 1940, episode: 147\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10910408.81\n",
      "total_reward: 910408.81\n",
      "total_cost: 153156.19\n",
      "total_trades: 73683\n",
      "Sharpe: 0.193\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 1143       |\n",
      "|    total_timesteps      | 284672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03127938 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.2      |\n",
      "|    explained_variance   | 0.015      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.91e+03   |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    reward               | -3.802943  |\n",
      "|    std                  | 1.39       |\n",
      "|    value_loss           | 2.37e+03   |\n",
      "----------------------------------------\n",
      "Episode: 148\n",
      "day: 1940, episode: 148\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14436587.67\n",
      "total_reward: 4436587.67\n",
      "total_cost: 152456.33\n",
      "total_trades: 73683\n",
      "Sharpe: 0.319\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 1151        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029404169 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.3       |\n",
      "|    explained_variance   | -0.00699    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    reward               | -5.344962   |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 3.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 149\n",
      "day: 1940, episode: 149\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9227383.64\n",
      "total_reward: -772616.36\n",
      "total_cost: 139768.36\n",
      "total_trades: 73675\n",
      "Sharpe: 0.122\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 1159        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047187887 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.4       |\n",
      "|    explained_variance   | -3.42e-05   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | -7.2152762  |\n",
      "|    std                  | 1.39        |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 150\n",
      "day: 1940, episode: 150\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16477587.45\n",
      "total_reward: 6477587.45\n",
      "total_cost: 140120.55\n",
      "total_trades: 73683\n",
      "Sharpe: 0.384\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 1168        |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034243163 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.5       |\n",
      "|    explained_variance   | 0.00356     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.029      |\n",
      "|    reward               | -36.184624  |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 151\n",
      "day: 1940, episode: 151\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18256716.50\n",
      "total_reward: 8256716.50\n",
      "total_cost: 151523.50\n",
      "total_trades: 73668\n",
      "Sharpe: 0.443\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1176        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026039869 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.6       |\n",
      "|    explained_variance   | 0.00241     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    reward               | -0.16706781 |\n",
      "|    std                  | 1.4         |\n",
      "|    value_loss           | 5.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 152\n",
      "day: 1940, episode: 152\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14056160.79\n",
      "total_reward: 4056160.79\n",
      "total_cost: 143632.21\n",
      "total_trades: 73676\n",
      "Sharpe: 0.313\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 1184        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026734425 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -66.8       |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | -11.62118   |\n",
      "|    std                  | 1.41        |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 153\n",
      "day: 1940, episode: 153\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16992007.08\n",
      "total_reward: 6992007.08\n",
      "total_cost: 153674.92\n",
      "total_trades: 73677\n",
      "Sharpe: 0.401\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 1192       |\n",
      "|    total_timesteps      | 296960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05151418 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.8      |\n",
      "|    explained_variance   | 0.0148     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 3.55e+03   |\n",
      "|    n_updates            | 1440       |\n",
      "|    policy_gradient_loss | -0.00772   |\n",
      "|    reward               | 27.949514  |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 5.93e+03   |\n",
      "----------------------------------------\n",
      "Episode: 154\n",
      "day: 1940, episode: 154\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14150495.76\n",
      "total_reward: 4150495.76\n",
      "total_cost: 136276.24\n",
      "total_trades: 73673\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "Episode: 155\n",
      "day: 1940, episode: 155\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 18136526.17\n",
      "total_reward: 8136526.17\n",
      "total_cost: 148844.83\n",
      "total_trades: 73689\n",
      "Sharpe: 0.438\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 1201       |\n",
      "|    total_timesteps      | 299008     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04263256 |\n",
      "|    clip_fraction        | 0.393      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -66.9      |\n",
      "|    explained_variance   | 0.0184     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.47e+03   |\n",
      "|    n_updates            | 1450       |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    reward               | -8.448115  |\n",
      "|    std                  | 1.41       |\n",
      "|    value_loss           | 2.81e+03   |\n",
      "----------------------------------------\n",
      "Episode: 156\n",
      "day: 1940, episode: 156\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13589063.69\n",
      "total_reward: 3589063.69\n",
      "total_cost: 153171.31\n",
      "total_trades: 73692\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 147        |\n",
      "|    time_elapsed         | 1209       |\n",
      "|    total_timesteps      | 301056     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06285358 |\n",
      "|    clip_fraction        | 0.411      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67        |\n",
      "|    explained_variance   | 0.00282    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.08e+03   |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | 0.000623   |\n",
      "|    reward               | -11.682394 |\n",
      "|    std                  | 1.42       |\n",
      "|    value_loss           | 4.18e+03   |\n",
      "----------------------------------------\n",
      "Episode: 157\n",
      "day: 1940, episode: 157\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10667268.68\n",
      "total_reward: 667268.68\n",
      "total_cost: 139992.32\n",
      "total_trades: 73688\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 1217        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024933122 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.2       |\n",
      "|    explained_variance   | 0.00163     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88e+03    |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | 2.6821458   |\n",
      "|    std                  | 1.42        |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 158\n",
      "day: 1940, episode: 158\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11225011.77\n",
      "total_reward: 1225011.77\n",
      "total_cost: 144344.23\n",
      "total_trades: 73681\n",
      "Sharpe: 0.212\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 1226        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043727443 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.3       |\n",
      "|    explained_variance   | -0.000465   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 987         |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 6.7255077   |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 159\n",
      "day: 1940, episode: 159\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12756801.35\n",
      "total_reward: 2756801.35\n",
      "total_cost: 147242.65\n",
      "total_trades: 73677\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1234        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045438923 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.4       |\n",
      "|    explained_variance   | 0.00563     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 8.266603    |\n",
      "|    std                  | 1.43        |\n",
      "|    value_loss           | 2.14e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 160\n",
      "day: 1940, episode: 160\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11858738.42\n",
      "total_reward: 1858738.42\n",
      "total_cost: 139111.58\n",
      "total_trades: 73683\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 151        |\n",
      "|    time_elapsed         | 1242       |\n",
      "|    total_timesteps      | 309248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02961365 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -67.5      |\n",
      "|    explained_variance   | 0.00292    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.29e+03   |\n",
      "|    n_updates            | 1500       |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    reward               | 11.788609  |\n",
      "|    std                  | 1.43       |\n",
      "|    value_loss           | 3.11e+03   |\n",
      "----------------------------------------\n",
      "Episode: 161\n",
      "day: 1940, episode: 161\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16661145.49\n",
      "total_reward: 6661145.49\n",
      "total_cost: 145905.51\n",
      "total_trades: 73674\n",
      "Sharpe: 0.393\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 1250        |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028085027 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.6       |\n",
      "|    explained_variance   | 0.00111     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 845         |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    reward               | 4.621562    |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 162\n",
      "day: 1940, episode: 162\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10450695.09\n",
      "total_reward: 450695.09\n",
      "total_cost: 141643.91\n",
      "total_trades: 73689\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 1258        |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028433856 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.8       |\n",
      "|    explained_variance   | 0.00348     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | -68.71168   |\n",
      "|    std                  | 1.44        |\n",
      "|    value_loss           | 3.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 163\n",
      "day: 1940, episode: 163\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12051684.32\n",
      "total_reward: 2051684.32\n",
      "total_cost: 146814.68\n",
      "total_trades: 73683\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 1267        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028846458 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.00341     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    reward               | -5.0446434  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 164\n",
      "day: 1940, episode: 164\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15192107.46\n",
      "total_reward: 5192107.46\n",
      "total_cost: 144361.54\n",
      "total_trades: 73686\n",
      "Sharpe: 0.346\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 1275        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029522281 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -67.9       |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    reward               | -80.11584   |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 2.83e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 165\n",
      "day: 1940, episode: 165\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13936307.88\n",
      "total_reward: 3936307.88\n",
      "total_cost: 142374.12\n",
      "total_trades: 73680\n",
      "Sharpe: 0.300\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 1283        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032793473 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68         |\n",
      "|    explained_variance   | -0.00218    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    reward               | -1.5946504  |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 166\n",
      "day: 1940, episode: 166\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 15216018.25\n",
      "total_reward: 5216018.25\n",
      "total_cost: 141506.75\n",
      "total_trades: 73678\n",
      "Sharpe: 0.345\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 1292        |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025327861 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.1       |\n",
      "|    explained_variance   | -0.00629    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | -0.91805696 |\n",
      "|    std                  | 1.45        |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 167\n",
      "day: 1940, episode: 167\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8746736.32\n",
      "total_reward: -1253263.68\n",
      "total_cost: 142976.68\n",
      "total_trades: 73684\n",
      "Sharpe: 0.083\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 1300       |\n",
      "|    total_timesteps      | 323584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03003558 |\n",
      "|    clip_fraction        | 0.257      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.1      |\n",
      "|    explained_variance   | -0.00556   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.04e+03   |\n",
      "|    n_updates            | 1570       |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    reward               | 1.086252   |\n",
      "|    std                  | 1.46       |\n",
      "|    value_loss           | 2.76e+03   |\n",
      "----------------------------------------\n",
      "Episode: 168\n",
      "day: 1940, episode: 168\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8697519.16\n",
      "total_reward: -1302480.84\n",
      "total_cost: 136559.84\n",
      "total_trades: 73685\n",
      "Sharpe: 0.072\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 1308        |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031428047 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.3       |\n",
      "|    explained_variance   | -0.0026     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | 9.394139    |\n",
      "|    std                  | 1.46        |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 169\n",
      "day: 1940, episode: 169\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10531114.42\n",
      "total_reward: 531114.42\n",
      "total_cost: 151204.58\n",
      "total_trades: 73693\n",
      "Sharpe: 0.153\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 1316        |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046446178 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.4       |\n",
      "|    explained_variance   | 0.0191      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 941         |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | -7.224017   |\n",
      "|    std                  | 1.47        |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 170\n",
      "day: 1940, episode: 170\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9108865.39\n",
      "total_reward: -891134.61\n",
      "total_cost: 144488.61\n",
      "total_trades: 73674\n",
      "Sharpe: 0.102\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 1325       |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03902527 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.5      |\n",
      "|    explained_variance   | 0.0148     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 688        |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    reward               | 18.689072  |\n",
      "|    std                  | 1.47       |\n",
      "|    value_loss           | 1.51e+03   |\n",
      "----------------------------------------\n",
      "Episode: 171\n",
      "day: 1940, episode: 171\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12068990.63\n",
      "total_reward: 2068990.63\n",
      "total_cost: 155286.37\n",
      "total_trades: 73681\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 162        |\n",
      "|    time_elapsed         | 1333       |\n",
      "|    total_timesteps      | 331776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04513062 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -68.6      |\n",
      "|    explained_variance   | -0.00502   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.08e+03   |\n",
      "|    n_updates            | 1610       |\n",
      "|    policy_gradient_loss | -0.00499   |\n",
      "|    reward               | -0.5019178 |\n",
      "|    std                  | 1.47       |\n",
      "|    value_loss           | 2.19e+03   |\n",
      "----------------------------------------\n",
      "Episode: 172\n",
      "day: 1940, episode: 172\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9871990.13\n",
      "total_reward: -128009.87\n",
      "total_cost: 138744.87\n",
      "total_trades: 73668\n",
      "Sharpe: 0.119\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 1341        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023666311 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.6       |\n",
      "|    explained_variance   | 0.00413     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0353     |\n",
      "|    reward               | -19.713085  |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 1.94e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 173\n",
      "day: 1940, episode: 173\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11527581.25\n",
      "total_reward: 1527581.25\n",
      "total_cost: 146613.75\n",
      "total_trades: 73683\n",
      "Sharpe: 0.199\n",
      "=================================\n",
      "Episode: 174\n",
      "day: 1940, episode: 174\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8894457.72\n",
      "total_reward: -1105542.28\n",
      "total_cost: 136301.28\n",
      "total_trades: 73676\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 1350        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038888395 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.8       |\n",
      "|    explained_variance   | 0.00827     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -4.369304   |\n",
      "|    std                  | 1.48        |\n",
      "|    value_loss           | 2.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 175\n",
      "day: 1940, episode: 175\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7283716.38\n",
      "total_reward: -2716283.62\n",
      "total_cost: 137075.62\n",
      "total_trades: 73684\n",
      "Sharpe: -0.000\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 1358        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042169064 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -68.9       |\n",
      "|    explained_variance   | 0.00886     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 651         |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | 6.717555    |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 1.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 176\n",
      "day: 1940, episode: 176\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14178748.71\n",
      "total_reward: 4178748.71\n",
      "total_cost: 139553.29\n",
      "total_trades: 73675\n",
      "Sharpe: 0.312\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 1366        |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028200775 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69         |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 532         |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    reward               | -11.522545  |\n",
      "|    std                  | 1.49        |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 177\n",
      "day: 1940, episode: 177\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10470689.54\n",
      "total_reward: 470689.54\n",
      "total_cost: 137439.46\n",
      "total_trades: 73685\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 1374        |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039149504 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.1       |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.29e+03    |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    reward               | -3.611783   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 3.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 178\n",
      "day: 1940, episode: 178\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8449548.21\n",
      "total_reward: -1550451.79\n",
      "total_cost: 138626.79\n",
      "total_trades: 73683\n",
      "Sharpe: 0.035\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1382        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046606254 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.2       |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | 0.4919643   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 2.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 179\n",
      "day: 1940, episode: 179\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7976438.34\n",
      "total_reward: -2023561.66\n",
      "total_cost: 133682.66\n",
      "total_trades: 73670\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 1390        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055640988 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.3       |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 844         |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 6.2978272   |\n",
      "|    std                  | 1.5         |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 180\n",
      "day: 1940, episode: 180\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13390754.06\n",
      "total_reward: 3390754.06\n",
      "total_cost: 129433.94\n",
      "total_trades: 73688\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 170        |\n",
      "|    time_elapsed         | 1398       |\n",
      "|    total_timesteps      | 348160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03376471 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -69.4      |\n",
      "|    explained_variance   | 0.0184     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 547        |\n",
      "|    n_updates            | 1690       |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    reward               | 11.954191  |\n",
      "|    std                  | 1.51       |\n",
      "|    value_loss           | 1.46e+03   |\n",
      "----------------------------------------\n",
      "Episode: 181\n",
      "day: 1940, episode: 181\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14989645.70\n",
      "total_reward: 4989645.70\n",
      "total_cost: 126023.30\n",
      "total_trades: 73677\n",
      "Sharpe: 0.335\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 1407        |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051532596 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.00209     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 966         |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    reward               | -9.528108   |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 2.1e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 182\n",
      "day: 1940, episode: 182\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10246121.02\n",
      "total_reward: 246121.02\n",
      "total_cost: 128327.98\n",
      "total_trades: 73672\n",
      "Sharpe: 0.140\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 1415        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028634243 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.5       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 9.438803    |\n",
      "|    std                  | 1.51        |\n",
      "|    value_loss           | 3.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 183\n",
      "day: 1940, episode: 183\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14647820.86\n",
      "total_reward: 4647820.86\n",
      "total_cost: 128922.14\n",
      "total_trades: 73683\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 1424        |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033155132 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.6       |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 949         |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | -4.5342107  |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 3.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 184\n",
      "day: 1940, episode: 184\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14484291.55\n",
      "total_reward: 4484291.55\n",
      "total_cost: 140451.45\n",
      "total_trades: 73678\n",
      "Sharpe: 0.322\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 1432        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0558636   |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.7       |\n",
      "|    explained_variance   | 0.000996    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    reward               | -0.64657307 |\n",
      "|    std                  | 1.52        |\n",
      "|    value_loss           | 3.16e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 185\n",
      "day: 1940, episode: 185\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8738213.90\n",
      "total_reward: -1261786.10\n",
      "total_cost: 118790.10\n",
      "total_trades: 73692\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 1440        |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037053782 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -69.9       |\n",
      "|    explained_variance   | -0.00164    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 882         |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 1.2903464   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 186\n",
      "day: 1940, episode: 186\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13544793.54\n",
      "total_reward: 3544793.54\n",
      "total_cost: 124524.46\n",
      "total_trades: 73680\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 1449        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039913956 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | 0.00259     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | 5.2326493   |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 187\n",
      "day: 1940, episode: 187\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7332236.46\n",
      "total_reward: -2667763.54\n",
      "total_cost: 110268.54\n",
      "total_trades: 73675\n",
      "Sharpe: 0.024\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1457        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044903345 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70         |\n",
      "|    explained_variance   | -0.0247     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | -1.4384129  |\n",
      "|    std                  | 1.53        |\n",
      "|    value_loss           | 1.34e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 188\n",
      "day: 1940, episode: 188\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12546444.50\n",
      "total_reward: 2546444.50\n",
      "total_cost: 118400.50\n",
      "total_trades: 73677\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 1466        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048103217 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.1       |\n",
      "|    explained_variance   | 0.00285     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 456         |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    reward               | -5.6403956  |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 1.16e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 189\n",
      "day: 1940, episode: 189\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12819227.13\n",
      "total_reward: 2819227.13\n",
      "total_cost: 120125.87\n",
      "total_trades: 73677\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 1474         |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.02657298   |\n",
      "|    clip_fraction        | 0.255        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -70.2        |\n",
      "|    explained_variance   | 0.0118       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    reward               | -0.052528974 |\n",
      "|    std                  | 1.54         |\n",
      "|    value_loss           | 3.34e+03     |\n",
      "------------------------------------------\n",
      "Episode: 190\n",
      "day: 1940, episode: 190\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12667906.45\n",
      "total_reward: 2667906.45\n",
      "total_cost: 127000.55\n",
      "total_trades: 73695\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 1482        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055602394 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.3       |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 571         |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    reward               | 11.361531   |\n",
      "|    std                  | 1.54        |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 191\n",
      "day: 1940, episode: 191\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13280679.29\n",
      "total_reward: 3280679.29\n",
      "total_cost: 121491.71\n",
      "total_trades: 73682\n",
      "Sharpe: 0.278\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 1491        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049304854 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.4       |\n",
      "|    explained_variance   | 0.00591     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 28.006966   |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 2.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 192\n",
      "day: 1940, episode: 192\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12187882.98\n",
      "total_reward: 2187882.98\n",
      "total_cost: 129523.02\n",
      "total_trades: 73691\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "Episode: 193\n",
      "day: 1940, episode: 193\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10566621.95\n",
      "total_reward: 566621.95\n",
      "total_cost: 115366.05\n",
      "total_trades: 73687\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 1499        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046502657 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.5       |\n",
      "|    explained_variance   | -0.0273     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 802         |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | -2.6737669  |\n",
      "|    std                  | 1.55        |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 194\n",
      "day: 1940, episode: 194\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10238490.72\n",
      "total_reward: 238490.72\n",
      "total_cost: 125809.28\n",
      "total_trades: 73684\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 1508       |\n",
      "|    total_timesteps      | 374784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03913904 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.6      |\n",
      "|    explained_variance   | 0.0183     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 795        |\n",
      "|    n_updates            | 1820       |\n",
      "|    policy_gradient_loss | -0.00879   |\n",
      "|    reward               | -8.930912  |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 1.66e+03   |\n",
      "----------------------------------------\n",
      "Episode: 195\n",
      "day: 1940, episode: 195\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10185596.15\n",
      "total_reward: 185596.15\n",
      "total_cost: 123924.85\n",
      "total_trades: 73693\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1516        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.077424176 |\n",
      "|    clip_fraction        | 0.445       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.7       |\n",
      "|    explained_variance   | -0.00955    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27e+03    |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | -4.6800504  |\n",
      "|    std                  | 1.56        |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 196\n",
      "day: 1940, episode: 196\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12703941.21\n",
      "total_reward: 2703941.21\n",
      "total_cost: 130936.79\n",
      "total_trades: 73691\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 1524       |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04712134 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.8      |\n",
      "|    explained_variance   | 0.00629    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 263        |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    reward               | -17.959276 |\n",
      "|    std                  | 1.56       |\n",
      "|    value_loss           | 1.11e+03   |\n",
      "----------------------------------------\n",
      "Episode: 197\n",
      "day: 1940, episode: 197\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11301369.26\n",
      "total_reward: 1301369.26\n",
      "total_cost: 132619.74\n",
      "total_trades: 73689\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 1532        |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033680554 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -70.9       |\n",
      "|    explained_variance   | 0.00959     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 885         |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -5.1262517  |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 198\n",
      "day: 1940, episode: 198\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9952364.18\n",
      "total_reward: -47635.82\n",
      "total_cost: 128589.82\n",
      "total_trades: 73684\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1540        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02271805  |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | -0.0147     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 803         |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    reward               | -0.64272976 |\n",
      "|    std                  | 1.57        |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 199\n",
      "day: 1940, episode: 199\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11538001.32\n",
      "total_reward: 1538001.32\n",
      "total_cost: 129019.68\n",
      "total_trades: 73693\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 188        |\n",
      "|    time_elapsed         | 1549       |\n",
      "|    total_timesteps      | 385024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05000961 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.1      |\n",
      "|    explained_variance   | 0.00992    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 575        |\n",
      "|    n_updates            | 1870       |\n",
      "|    policy_gradient_loss | -0.00854   |\n",
      "|    reward               | 27.10336   |\n",
      "|    std                  | 1.58       |\n",
      "|    value_loss           | 1.28e+03   |\n",
      "----------------------------------------\n",
      "Episode: 200\n",
      "day: 1940, episode: 200\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14149348.16\n",
      "total_reward: 4149348.16\n",
      "total_cost: 130685.84\n",
      "total_trades: 73689\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 1557        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046980824 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | -0.0263     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 867         |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | 38.238293   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 201\n",
      "day: 1940, episode: 201\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10972451.02\n",
      "total_reward: 972451.02\n",
      "total_cost: 129101.98\n",
      "total_trades: 73688\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 1565        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029981207 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.2       |\n",
      "|    explained_variance   | 0.00528     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 893         |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | 3.9229662   |\n",
      "|    std                  | 1.58        |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 202\n",
      "day: 1940, episode: 202\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13907938.74\n",
      "total_reward: 3907938.74\n",
      "total_cost: 130921.26\n",
      "total_trades: 73686\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 191        |\n",
      "|    time_elapsed         | 1573       |\n",
      "|    total_timesteps      | 391168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02977599 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.3      |\n",
      "|    explained_variance   | -0.0232    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 751        |\n",
      "|    n_updates            | 1900       |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | -3.3917809 |\n",
      "|    std                  | 1.59       |\n",
      "|    value_loss           | 2.26e+03   |\n",
      "----------------------------------------\n",
      "Episode: 203\n",
      "day: 1940, episode: 203\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9870596.88\n",
      "total_reward: -129403.12\n",
      "total_cost: 123784.12\n",
      "total_trades: 73683\n",
      "Sharpe: 0.113\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051328324 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.4       |\n",
      "|    explained_variance   | -0.00633    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 691         |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.0051     |\n",
      "|    reward               | -2.296811   |\n",
      "|    std                  | 1.59        |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 204\n",
      "day: 1940, episode: 204\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11062765.73\n",
      "total_reward: 1062765.73\n",
      "total_cost: 128548.27\n",
      "total_trades: 73693\n",
      "Sharpe: 0.183\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 193        |\n",
      "|    time_elapsed         | 1589       |\n",
      "|    total_timesteps      | 395264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05971125 |\n",
      "|    clip_fraction        | 0.421      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -71.6      |\n",
      "|    explained_variance   | 0.0118     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 705        |\n",
      "|    n_updates            | 1920       |\n",
      "|    policy_gradient_loss | -0.00876   |\n",
      "|    reward               | 2.910493   |\n",
      "|    std                  | 1.6        |\n",
      "|    value_loss           | 1.4e+03    |\n",
      "----------------------------------------\n",
      "Episode: 205\n",
      "day: 1940, episode: 205\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7696484.89\n",
      "total_reward: -2303515.11\n",
      "total_cost: 131471.11\n",
      "total_trades: 73692\n",
      "Sharpe: 0.016\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 1597        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047478966 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.7       |\n",
      "|    explained_variance   | 0.00929     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 682         |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    reward               | 17.94506    |\n",
      "|    std                  | 1.6         |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 206\n",
      "day: 1940, episode: 206\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11789741.37\n",
      "total_reward: 1789741.37\n",
      "total_cost: 130565.63\n",
      "total_trades: 73687\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 1606        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040920615 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.8       |\n",
      "|    explained_variance   | -0.00824    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 482         |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 0.82351553  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 1.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 207\n",
      "day: 1940, episode: 207\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10903549.21\n",
      "total_reward: 903549.21\n",
      "total_cost: 132168.79\n",
      "total_trades: 73688\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 1614        |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024518877 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.9       |\n",
      "|    explained_variance   | 0.000437    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -11.773569  |\n",
      "|    std                  | 1.61        |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 208\n",
      "day: 1940, episode: 208\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12552459.20\n",
      "total_reward: 2552459.20\n",
      "total_cost: 122383.80\n",
      "total_trades: 73695\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 197        |\n",
      "|    time_elapsed         | 1622       |\n",
      "|    total_timesteps      | 403456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02414749 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72        |\n",
      "|    explained_variance   | -0.00441   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 751        |\n",
      "|    n_updates            | 1960       |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    reward               | 0.7686039  |\n",
      "|    std                  | 1.62       |\n",
      "|    value_loss           | 1.54e+03   |\n",
      "----------------------------------------\n",
      "Episode: 209\n",
      "day: 1940, episode: 209\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14301200.29\n",
      "total_reward: 4301200.29\n",
      "total_cost: 122842.71\n",
      "total_trades: 73682\n",
      "Sharpe: 0.321\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 1630        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023524096 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.1       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -77.809235  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 2.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 210\n",
      "day: 1940, episode: 210\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12229400.25\n",
      "total_reward: 2229400.25\n",
      "total_cost: 118636.75\n",
      "total_trades: 73671\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 1638        |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022626374 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | -0.0103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 995         |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    reward               | 18.899742   |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 211\n",
      "day: 1940, episode: 211\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14315591.98\n",
      "total_reward: 4315591.98\n",
      "total_cost: 122030.02\n",
      "total_trades: 73683\n",
      "Sharpe: 0.314\n",
      "=================================\n",
      "Episode: 212\n",
      "day: 1940, episode: 212\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8888091.79\n",
      "total_reward: -1111908.21\n",
      "total_cost: 122429.21\n",
      "total_trades: 73684\n",
      "Sharpe: 0.101\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 1646        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028853007 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.2       |\n",
      "|    explained_variance   | 0.012       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 887         |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    reward               | -3.1081684  |\n",
      "|    std                  | 1.62        |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 213\n",
      "day: 1940, episode: 213\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14519645.28\n",
      "total_reward: 4519645.28\n",
      "total_cost: 128662.72\n",
      "total_trades: 73693\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 1655        |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040298246 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.3       |\n",
      "|    explained_variance   | -0.0226     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 529         |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -1.1357238  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 214\n",
      "day: 1940, episode: 214\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16030885.64\n",
      "total_reward: 6030885.64\n",
      "total_cost: 128912.36\n",
      "total_trades: 73694\n",
      "Sharpe: 0.380\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 1663        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014962286 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    reward               | -0.2087334  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 215\n",
      "day: 1940, episode: 215\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10878316.90\n",
      "total_reward: 878316.90\n",
      "total_cost: 123701.10\n",
      "total_trades: 73689\n",
      "Sharpe: 0.196\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 1671        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021025876 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.4       |\n",
      "|    explained_variance   | 0.00465     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 916         |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    reward               | 0.40885603  |\n",
      "|    std                  | 1.63        |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 216\n",
      "day: 1940, episode: 216\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9912875.61\n",
      "total_reward: -87124.39\n",
      "total_cost: 125859.39\n",
      "total_trades: 73689\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 1680        |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025727017 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.5       |\n",
      "|    explained_variance   | -0.0178     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    reward               | 0.73571473  |\n",
      "|    std                  | 1.64        |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 217\n",
      "day: 1940, episode: 217\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13238902.53\n",
      "total_reward: 3238902.53\n",
      "total_cost: 123628.47\n",
      "total_trades: 73685\n",
      "Sharpe: 0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 1688        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024514139 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -72.7       |\n",
      "|    explained_variance   | 0.00773     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 753         |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | 2.9254858   |\n",
      "|    std                  | 1.65        |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 218\n",
      "day: 1940, episode: 218\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7694943.15\n",
      "total_reward: -2305056.85\n",
      "total_cost: 124437.85\n",
      "total_trades: 73688\n",
      "Sharpe: 0.030\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 206        |\n",
      "|    time_elapsed         | 1696       |\n",
      "|    total_timesteps      | 421888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03318065 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.7      |\n",
      "|    explained_variance   | -0.00891   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 963        |\n",
      "|    n_updates            | 2050       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | -4.3636575 |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 1.86e+03   |\n",
      "----------------------------------------\n",
      "Episode: 219\n",
      "day: 1940, episode: 219\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9320634.00\n",
      "total_reward: -679366.00\n",
      "total_cost: 126570.00\n",
      "total_trades: 73688\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 207        |\n",
      "|    time_elapsed         | 1705       |\n",
      "|    total_timesteps      | 423936     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02343443 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -72.9      |\n",
      "|    explained_variance   | 0.00853    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 745        |\n",
      "|    n_updates            | 2060       |\n",
      "|    policy_gradient_loss | -0.0241    |\n",
      "|    reward               | -24.170689 |\n",
      "|    std                  | 1.65       |\n",
      "|    value_loss           | 1.33e+03   |\n",
      "----------------------------------------\n",
      "Episode: 220\n",
      "day: 1940, episode: 220\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9569009.86\n",
      "total_reward: -430990.14\n",
      "total_cost: 129868.14\n",
      "total_trades: 73680\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 1713        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031224506 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | -0.000323   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 16.660334   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 2.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 221\n",
      "day: 1940, episode: 221\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7902519.29\n",
      "total_reward: -2097480.71\n",
      "total_cost: 125453.71\n",
      "total_trades: 73682\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 1722        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036543526 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73         |\n",
      "|    explained_variance   | -0.0073     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 654         |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    reward               | 1.9868097   |\n",
      "|    std                  | 1.66        |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 222\n",
      "day: 1940, episode: 222\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6871187.27\n",
      "total_reward: -3128812.73\n",
      "total_cost: 122133.73\n",
      "total_trades: 73686\n",
      "Sharpe: -0.021\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 1730        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02977337  |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.1       |\n",
      "|    explained_variance   | 0.0179      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 527         |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -0.96977913 |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 1.29e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 223\n",
      "day: 1940, episode: 223\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8565096.92\n",
      "total_reward: -1434903.08\n",
      "total_cost: 131819.08\n",
      "total_trades: 73683\n",
      "Sharpe: 0.045\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 1739        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025471877 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.3       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    reward               | 0.88645744  |\n",
      "|    std                  | 1.67        |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 224\n",
      "day: 1940, episode: 224\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7422643.21\n",
      "total_reward: -2577356.79\n",
      "total_cost: 125998.79\n",
      "total_trades: 73687\n",
      "Sharpe: -0.014\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 1747        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034887683 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.4       |\n",
      "|    explained_variance   | -0.0157     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 732         |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | 0.43717498  |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 225\n",
      "day: 1940, episode: 225\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8646122.73\n",
      "total_reward: -1353877.27\n",
      "total_cost: 126729.27\n",
      "total_trades: 73678\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 1755        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046474703 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.5       |\n",
      "|    explained_variance   | 0.00696     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 804         |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -9.440295   |\n",
      "|    std                  | 1.68        |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 226\n",
      "day: 1940, episode: 226\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7169751.48\n",
      "total_reward: -2830248.52\n",
      "total_cost: 116312.52\n",
      "total_trades: 73689\n",
      "Sharpe: -0.002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 1763        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030100955 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.6       |\n",
      "|    explained_variance   | -0.00107    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    reward               | -7.521981   |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 227\n",
      "day: 1940, episode: 227\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10012497.86\n",
      "total_reward: 12497.86\n",
      "total_cost: 126449.14\n",
      "total_trades: 73689\n",
      "Sharpe: 0.122\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 1771        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029557273 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.7       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    reward               | 9.864139    |\n",
      "|    std                  | 1.69        |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 228\n",
      "day: 1940, episode: 228\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8606308.48\n",
      "total_reward: -1393691.52\n",
      "total_cost: 124426.52\n",
      "total_trades: 73684\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 1780       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03221914 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -73.8      |\n",
      "|    explained_variance   | -0.000474  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 959        |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    reward               | -3.125719  |\n",
      "|    std                  | 1.7        |\n",
      "|    value_loss           | 1.62e+03   |\n",
      "----------------------------------------\n",
      "Episode: 229\n",
      "day: 1940, episode: 229\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9539154.34\n",
      "total_reward: -460845.66\n",
      "total_cost: 126617.66\n",
      "total_trades: 73693\n",
      "Sharpe: 0.095\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 1788        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024313623 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -73.9       |\n",
      "|    explained_variance   | -0.00124    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 944         |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    reward               | 18.627796   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 2.02e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 230\n",
      "day: 1940, episode: 230\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9649044.77\n",
      "total_reward: -350955.23\n",
      "total_cost: 126060.23\n",
      "total_trades: 73698\n",
      "Sharpe: 0.121\n",
      "=================================\n",
      "Episode: 231\n",
      "day: 1940, episode: 231\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10584465.47\n",
      "total_reward: 584465.47\n",
      "total_cost: 125261.53\n",
      "total_trades: 73688\n",
      "Sharpe: 0.154\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 1796        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019932456 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74         |\n",
      "|    explained_variance   | 0.00302     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.49e+03    |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | 2.0564759   |\n",
      "|    std                  | 1.7         |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 232\n",
      "day: 1940, episode: 232\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10165137.60\n",
      "total_reward: 165137.60\n",
      "total_cost: 123853.40\n",
      "total_trades: 73678\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 1805        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021590583 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.1       |\n",
      "|    explained_variance   | 0.0023      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | 11.664335   |\n",
      "|    std                  | 1.71        |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 233\n",
      "day: 1940, episode: 233\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8476114.96\n",
      "total_reward: -1523885.04\n",
      "total_cost: 123771.04\n",
      "total_trades: 73690\n",
      "Sharpe: 0.076\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 1813        |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025292214 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.2       |\n",
      "|    explained_variance   | 0.00602     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 906         |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    reward               | -0.5894127  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 2.16e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 234\n",
      "day: 1940, episode: 234\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7637903.47\n",
      "total_reward: -2362096.53\n",
      "total_cost: 119680.53\n",
      "total_trades: 73674\n",
      "Sharpe: 0.030\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 1821        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030527962 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.4       |\n",
      "|    explained_variance   | -0.00723    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -0.9301538  |\n",
      "|    std                  | 1.72        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 235\n",
      "day: 1940, episode: 235\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8894938.99\n",
      "total_reward: -1105061.01\n",
      "total_cost: 122181.01\n",
      "total_trades: 73686\n",
      "Sharpe: 0.086\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 1830        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028026082 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.5       |\n",
      "|    explained_variance   | 0.000121    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 753         |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    reward               | -7.60372    |\n",
      "|    std                  | 1.73        |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 236\n",
      "day: 1940, episode: 236\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8259876.70\n",
      "total_reward: -1740123.30\n",
      "total_cost: 119026.30\n",
      "total_trades: 73696\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 223        |\n",
      "|    time_elapsed         | 1838       |\n",
      "|    total_timesteps      | 456704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02865959 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.6      |\n",
      "|    explained_variance   | 0.0157     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.55e+03   |\n",
      "|    n_updates            | 2220       |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    reward               | 0.10284784 |\n",
      "|    std                  | 1.73       |\n",
      "|    value_loss           | 2e+03      |\n",
      "----------------------------------------\n",
      "Episode: 237\n",
      "day: 1940, episode: 237\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6966993.40\n",
      "total_reward: -3033006.60\n",
      "total_cost: 120275.60\n",
      "total_trades: 73695\n",
      "Sharpe: 0.002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 1846        |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023244375 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.7       |\n",
      "|    explained_variance   | 0.00892     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 826         |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    reward               | 8.657163    |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 238\n",
      "day: 1940, episode: 238\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9328704.27\n",
      "total_reward: -671295.73\n",
      "total_cost: 124216.73\n",
      "total_trades: 73693\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 1854       |\n",
      "|    total_timesteps      | 460800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03692108 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.8      |\n",
      "|    explained_variance   | 0.0125     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 628        |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    reward               | 10.74353   |\n",
      "|    std                  | 1.74       |\n",
      "|    value_loss           | 1.52e+03   |\n",
      "----------------------------------------\n",
      "Episode: 239\n",
      "day: 1940, episode: 239\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9618613.03\n",
      "total_reward: -381386.97\n",
      "total_cost: 130478.97\n",
      "total_trades: 73698\n",
      "Sharpe: 0.111\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 1862        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016534438 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.8       |\n",
      "|    explained_variance   | 0.0343      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -3.9824305  |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 240\n",
      "day: 1940, episode: 240\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12556897.61\n",
      "total_reward: 2556897.61\n",
      "total_cost: 133185.39\n",
      "total_trades: 73688\n",
      "Sharpe: 0.247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 1870        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014999608 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -74.9       |\n",
      "|    explained_variance   | 0.0347      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    reward               | -9.498799   |\n",
      "|    std                  | 1.74        |\n",
      "|    value_loss           | 3.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 241\n",
      "day: 1940, episode: 241\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8325507.60\n",
      "total_reward: -1674492.40\n",
      "total_cost: 125158.40\n",
      "total_trades: 73680\n",
      "Sharpe: 0.079\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 228        |\n",
      "|    time_elapsed         | 1879       |\n",
      "|    total_timesteps      | 466944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02387185 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -74.9      |\n",
      "|    explained_variance   | 0.0116     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.19e+03   |\n",
      "|    n_updates            | 2270       |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    reward               | -7.0191865 |\n",
      "|    std                  | 1.75       |\n",
      "|    value_loss           | 2.91e+03   |\n",
      "----------------------------------------\n",
      "Episode: 242\n",
      "day: 1940, episode: 242\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11259833.81\n",
      "total_reward: 1259833.81\n",
      "total_cost: 127228.19\n",
      "total_trades: 73687\n",
      "Sharpe: 0.189\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 1887        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014125451 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75         |\n",
      "|    explained_variance   | 0.0168      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    reward               | 5.6974983   |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 2.98e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 243\n",
      "day: 1940, episode: 243\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9298869.62\n",
      "total_reward: -701130.38\n",
      "total_cost: 123304.38\n",
      "total_trades: 73694\n",
      "Sharpe: 0.121\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 1896        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016785173 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.1       |\n",
      "|    explained_variance   | 0.0333      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    reward               | -4.3139677  |\n",
      "|    std                  | 1.75        |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 244\n",
      "day: 1940, episode: 244\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7438162.65\n",
      "total_reward: -2561837.35\n",
      "total_cost: 116973.35\n",
      "total_trades: 73694\n",
      "Sharpe: 0.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 1904        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046764128 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 19.346718   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 245\n",
      "day: 1940, episode: 245\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10283645.28\n",
      "total_reward: 283645.28\n",
      "total_cost: 128048.72\n",
      "total_trades: 73676\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 1912        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028618498 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.2       |\n",
      "|    explained_variance   | 0.0413      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    reward               | 7.2804856   |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 246\n",
      "day: 1940, episode: 246\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8158012.05\n",
      "total_reward: -1841987.95\n",
      "total_cost: 115049.95\n",
      "total_trades: 73696\n",
      "Sharpe: 0.048\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 1920        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023196865 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.3       |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | 0.09073824  |\n",
      "|    std                  | 1.76        |\n",
      "|    value_loss           | 2.34e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 247\n",
      "day: 1940, episode: 247\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7324192.11\n",
      "total_reward: -2675807.89\n",
      "total_cost: 116191.89\n",
      "total_trades: 73689\n",
      "Sharpe: 0.005\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 1929        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023187928 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.4       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 655         |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    reward               | -8.57661    |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 2.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 248\n",
      "day: 1940, episode: 248\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7344899.48\n",
      "total_reward: -2655100.52\n",
      "total_cost: 115547.52\n",
      "total_trades: 73684\n",
      "Sharpe: 0.004\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 1937        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030742876 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.5       |\n",
      "|    explained_variance   | 0.0206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -5.379694   |\n",
      "|    std                  | 1.77        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 249\n",
      "day: 1940, episode: 249\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11014790.83\n",
      "total_reward: 1014790.83\n",
      "total_cost: 127171.17\n",
      "total_trades: 73690\n",
      "Sharpe: 0.178\n",
      "=================================\n",
      "Episode: 250\n",
      "day: 1940, episode: 250\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8511268.06\n",
      "total_reward: -1488731.94\n",
      "total_cost: 119865.94\n",
      "total_trades: 73680\n",
      "Sharpe: 0.084\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 1945        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026670145 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.86e+03    |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | -0.4671175  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 251\n",
      "day: 1940, episode: 251\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7348142.87\n",
      "total_reward: -2651857.13\n",
      "total_cost: 109243.13\n",
      "total_trades: 73690\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 1954        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030899942 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 4.1601825   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 2.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 252\n",
      "day: 1940, episode: 252\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7911165.60\n",
      "total_reward: -2088834.40\n",
      "total_cost: 110515.40\n",
      "total_trades: 73693\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 1962        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030413708 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.6       |\n",
      "|    explained_variance   | 0.0183      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | 2.8510585   |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 253\n",
      "day: 1940, episode: 253\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8293467.29\n",
      "total_reward: -1706532.71\n",
      "total_cost: 109066.71\n",
      "total_trades: 73691\n",
      "Sharpe: 0.072\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1971        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023961892 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.7       |\n",
      "|    explained_variance   | 0.0464      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 738         |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    reward               | -13.078139  |\n",
      "|    std                  | 1.78        |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 254\n",
      "day: 1940, episode: 254\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7711045.79\n",
      "total_reward: -2288954.21\n",
      "total_cost: 113825.21\n",
      "total_trades: 73689\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 1979        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016514687 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -75.9       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | 2.7066166   |\n",
      "|    std                  | 1.79        |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 255\n",
      "day: 1940, episode: 255\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8587874.05\n",
      "total_reward: -1412125.95\n",
      "total_cost: 107879.95\n",
      "total_trades: 73687\n",
      "Sharpe: 0.101\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 241        |\n",
      "|    time_elapsed         | 1987       |\n",
      "|    total_timesteps      | 493568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04272165 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76        |\n",
      "|    explained_variance   | 0.0581     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 797        |\n",
      "|    n_updates            | 2400       |\n",
      "|    policy_gradient_loss | -0.00504   |\n",
      "|    reward               | 4.036943   |\n",
      "|    std                  | 1.8        |\n",
      "|    value_loss           | 2.44e+03   |\n",
      "----------------------------------------\n",
      "Episode: 256\n",
      "day: 1940, episode: 256\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8831520.60\n",
      "total_reward: -1168479.40\n",
      "total_cost: 111978.40\n",
      "total_trades: 73692\n",
      "Sharpe: 0.088\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 1995        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024511045 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.1       |\n",
      "|    explained_variance   | 0.0775      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 772         |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 6.434635    |\n",
      "|    std                  | 1.8         |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 257\n",
      "day: 1940, episode: 257\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9246495.10\n",
      "total_reward: -753504.90\n",
      "total_cost: 113536.90\n",
      "total_trades: 73688\n",
      "Sharpe: 0.118\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 2004        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018874751 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.2       |\n",
      "|    explained_variance   | 0.0945      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    reward               | 26.232878   |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 258\n",
      "day: 1940, episode: 258\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8470498.12\n",
      "total_reward: -1529501.88\n",
      "total_cost: 118591.88\n",
      "total_trades: 73682\n",
      "Sharpe: 0.073\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 2012        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031212274 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.0955      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -47.141132  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 2.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 259\n",
      "day: 1940, episode: 259\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12037855.13\n",
      "total_reward: 2037855.13\n",
      "total_cost: 126869.87\n",
      "total_trades: 73691\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 2020        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019948304 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.3       |\n",
      "|    explained_variance   | 0.0659      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    reward               | -56.648056  |\n",
      "|    std                  | 1.81        |\n",
      "|    value_loss           | 3.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 260\n",
      "day: 1940, episode: 260\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7704599.23\n",
      "total_reward: -2295400.77\n",
      "total_cost: 110217.77\n",
      "total_trades: 73677\n",
      "Sharpe: 0.047\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 246        |\n",
      "|    time_elapsed         | 2028       |\n",
      "|    total_timesteps      | 503808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01916763 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.4      |\n",
      "|    explained_variance   | 0.0712     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.44e+03   |\n",
      "|    n_updates            | 2450       |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    reward               | -1.5827879 |\n",
      "|    std                  | 1.81       |\n",
      "|    value_loss           | 2.97e+03   |\n",
      "----------------------------------------\n",
      "Episode: 261\n",
      "day: 1940, episode: 261\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9502330.84\n",
      "total_reward: -497669.16\n",
      "total_cost: 114543.16\n",
      "total_trades: 73674\n",
      "Sharpe: 0.120\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 2036        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023679331 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.0727      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 902         |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    reward               | -2.5102262  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 262\n",
      "day: 1940, episode: 262\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9123661.87\n",
      "total_reward: -876338.13\n",
      "total_cost: 116642.13\n",
      "total_trades: 73690\n",
      "Sharpe: 0.105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 2045        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019962354 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.5       |\n",
      "|    explained_variance   | 0.0948      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    reward               | -2.4679692  |\n",
      "|    std                  | 1.82        |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 263\n",
      "day: 1940, episode: 263\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11452841.49\n",
      "total_reward: 1452841.49\n",
      "total_cost: 124704.51\n",
      "total_trades: 73686\n",
      "Sharpe: 0.198\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 2053        |\n",
      "|    total_timesteps      | 509952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019976988 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.6       |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 2480        |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    reward               | -15.050489  |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 3.64e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 264\n",
      "day: 1940, episode: 264\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8947794.60\n",
      "total_reward: -1052205.40\n",
      "total_cost: 117502.40\n",
      "total_trades: 73690\n",
      "Sharpe: 0.090\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 2061        |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016719012 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.7       |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.85e+03    |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | 16.289225   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 265\n",
      "day: 1940, episode: 265\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8137561.71\n",
      "total_reward: -1862438.29\n",
      "total_cost: 113588.29\n",
      "total_trades: 73687\n",
      "Sharpe: 0.077\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 2070        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025829814 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.0926      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 872         |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    reward               | 1.1082033   |\n",
      "|    std                  | 1.83        |\n",
      "|    value_loss           | 2.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 266\n",
      "day: 1940, episode: 266\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7642131.94\n",
      "total_reward: -2357868.06\n",
      "total_cost: 116744.06\n",
      "total_trades: 73684\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 2078        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028819192 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.8       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -8.481011   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 267\n",
      "day: 1940, episode: 267\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8897192.57\n",
      "total_reward: -1102807.43\n",
      "total_cost: 116280.43\n",
      "total_trades: 73691\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 2086        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021069467 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -76.9       |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    reward               | -8.881391   |\n",
      "|    std                  | 1.84        |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 268\n",
      "day: 1940, episode: 268\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8378014.64\n",
      "total_reward: -1621985.36\n",
      "total_cost: 113840.36\n",
      "total_trades: 73688\n",
      "Sharpe: 0.090\n",
      "=================================\n",
      "Episode: 269\n",
      "day: 1940, episode: 269\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10114685.23\n",
      "total_reward: 114685.23\n",
      "total_cost: 121775.77\n",
      "total_trades: 73690\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 254        |\n",
      "|    time_elapsed         | 2094       |\n",
      "|    total_timesteps      | 520192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03823065 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -76.9      |\n",
      "|    explained_variance   | 0.0597     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.18e+03   |\n",
      "|    n_updates            | 2530       |\n",
      "|    policy_gradient_loss | -0.0208    |\n",
      "|    reward               | -3.6227095 |\n",
      "|    std                  | 1.84       |\n",
      "|    value_loss           | 2.55e+03   |\n",
      "----------------------------------------\n",
      "Episode: 270\n",
      "day: 1940, episode: 270\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8748341.17\n",
      "total_reward: -1251658.83\n",
      "total_cost: 120500.83\n",
      "total_trades: 73698\n",
      "Sharpe: 0.080\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 2103        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017061904 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77         |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    reward               | -0.86327714 |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 271\n",
      "day: 1940, episode: 271\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10043502.58\n",
      "total_reward: 43502.58\n",
      "total_cost: 121390.42\n",
      "total_trades: 73691\n",
      "Sharpe: 0.148\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 2111        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032741684 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.1       |\n",
      "|    explained_variance   | 0.071       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | -11.684504  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 2.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 272\n",
      "day: 1940, episode: 272\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12302542.65\n",
      "total_reward: 2302542.65\n",
      "total_cost: 129993.35\n",
      "total_trades: 73696\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 2120        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022755649 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.2       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 893         |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -6.9972315  |\n",
      "|    std                  | 1.85        |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 273\n",
      "day: 1940, episode: 273\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9466363.70\n",
      "total_reward: -533636.30\n",
      "total_cost: 124931.30\n",
      "total_trades: 73689\n",
      "Sharpe: 0.120\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 258        |\n",
      "|    time_elapsed         | 2128       |\n",
      "|    total_timesteps      | 528384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03301262 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.2      |\n",
      "|    explained_variance   | 0.0353     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.36e+03   |\n",
      "|    n_updates            | 2570       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    reward               | 6.709715   |\n",
      "|    std                  | 1.86       |\n",
      "|    value_loss           | 3.52e+03   |\n",
      "----------------------------------------\n",
      "Episode: 274\n",
      "day: 1940, episode: 274\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10448188.40\n",
      "total_reward: 448188.40\n",
      "total_cost: 129506.60\n",
      "total_trades: 73696\n",
      "Sharpe: 0.155\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 2136        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027549129 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.3       |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    reward               | 23.452417   |\n",
      "|    std                  | 1.86        |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 275\n",
      "day: 1940, episode: 275\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11871398.57\n",
      "total_reward: 1871398.57\n",
      "total_cost: 130560.43\n",
      "total_trades: 73689\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 2144        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036541395 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.4       |\n",
      "|    explained_variance   | 0.0135      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | -9.682328   |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 276\n",
      "day: 1940, episode: 276\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10873194.40\n",
      "total_reward: 873194.40\n",
      "total_cost: 131848.60\n",
      "total_trades: 73685\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 2153        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017829943 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.5       |\n",
      "|    explained_variance   | 0.00783     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    reward               | 6.226357    |\n",
      "|    std                  | 1.87        |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 277\n",
      "day: 1940, episode: 277\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12460649.68\n",
      "total_reward: 2460649.68\n",
      "total_cost: 133659.32\n",
      "total_trades: 73696\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 2161       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750889 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.6      |\n",
      "|    explained_variance   | 0.000572   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.24e+03   |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | -0.0258    |\n",
      "|    reward               | -9.9060335 |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 3.32e+03   |\n",
      "----------------------------------------\n",
      "Episode: 278\n",
      "day: 1940, episode: 278\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9301633.28\n",
      "total_reward: -698366.72\n",
      "total_cost: 128823.72\n",
      "total_trades: 73691\n",
      "Sharpe: 0.107\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 263        |\n",
      "|    time_elapsed         | 2170       |\n",
      "|    total_timesteps      | 538624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0268874  |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.6      |\n",
      "|    explained_variance   | -0.00535   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.27e+03   |\n",
      "|    n_updates            | 2620       |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    reward               | -6.7618794 |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 4.24e+03   |\n",
      "----------------------------------------\n",
      "Episode: 279\n",
      "day: 1940, episode: 279\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9997371.23\n",
      "total_reward: -2628.77\n",
      "total_cost: 125101.77\n",
      "total_trades: 73690\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 264         |\n",
      "|    time_elapsed         | 2178        |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030414943 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.7       |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    reward               | 7.592755    |\n",
      "|    std                  | 1.88        |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 280\n",
      "day: 1940, episode: 280\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10449940.42\n",
      "total_reward: 449940.42\n",
      "total_cost: 130585.58\n",
      "total_trades: 73696\n",
      "Sharpe: 0.154\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 265        |\n",
      "|    time_elapsed         | 2186       |\n",
      "|    total_timesteps      | 542720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04259308 |\n",
      "|    clip_fraction        | 0.297      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.7      |\n",
      "|    explained_variance   | 0.023      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.75e+03   |\n",
      "|    n_updates            | 2640       |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | 8.049248   |\n",
      "|    std                  | 1.88       |\n",
      "|    value_loss           | 2.84e+03   |\n",
      "----------------------------------------\n",
      "Episode: 281\n",
      "day: 1940, episode: 281\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7479550.26\n",
      "total_reward: -2520449.74\n",
      "total_cost: 119513.74\n",
      "total_trades: 73690\n",
      "Sharpe: 0.029\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 2195        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03912607  |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -77.8       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 688         |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    reward               | -0.32476792 |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 2.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 282\n",
      "day: 1940, episode: 282\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5669403.15\n",
      "total_reward: -4330596.85\n",
      "total_cost: 106358.85\n",
      "total_trades: 73690\n",
      "Sharpe: -0.087\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 267        |\n",
      "|    time_elapsed         | 2203       |\n",
      "|    total_timesteps      | 546816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02796672 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -77.9      |\n",
      "|    explained_variance   | -0.000942  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 325        |\n",
      "|    n_updates            | 2660       |\n",
      "|    policy_gradient_loss | -0.024     |\n",
      "|    reward               | -3.986823  |\n",
      "|    std                  | 1.89       |\n",
      "|    value_loss           | 1.67e+03   |\n",
      "----------------------------------------\n",
      "Episode: 283\n",
      "day: 1940, episode: 283\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13802711.19\n",
      "total_reward: 3802711.19\n",
      "total_cost: 140078.81\n",
      "total_trades: 73692\n",
      "Sharpe: 0.297\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 2211        |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058922045 |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | -4.544213   |\n",
      "|    std                  | 1.89        |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 284\n",
      "day: 1940, episode: 284\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8674843.36\n",
      "total_reward: -1325156.64\n",
      "total_cost: 127488.64\n",
      "total_trades: 73686\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 2220        |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046677064 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78         |\n",
      "|    explained_variance   | 0.00337     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | 6.980972    |\n",
      "|    std                  | 1.9         |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 285\n",
      "day: 1940, episode: 285\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9008394.01\n",
      "total_reward: -991605.99\n",
      "total_cost: 125897.99\n",
      "total_trades: 73694\n",
      "Sharpe: 0.103\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 270        |\n",
      "|    time_elapsed         | 2228       |\n",
      "|    total_timesteps      | 552960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06618869 |\n",
      "|    clip_fraction        | 0.412      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.1      |\n",
      "|    explained_variance   | 0.0472     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 559        |\n",
      "|    n_updates            | 2690       |\n",
      "|    policy_gradient_loss | -0.00932   |\n",
      "|    reward               | -3.648861  |\n",
      "|    std                  | 1.9        |\n",
      "|    value_loss           | 1.7e+03    |\n",
      "----------------------------------------\n",
      "Episode: 286\n",
      "day: 1940, episode: 286\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6643061.53\n",
      "total_reward: -3356938.47\n",
      "total_cost: 107227.47\n",
      "total_trades: 73681\n",
      "Sharpe: -0.028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 2236        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021800278 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.2       |\n",
      "|    explained_variance   | -0.0191     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    reward               | -4.404218   |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 2.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 287\n",
      "day: 1940, episode: 287\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6741697.10\n",
      "total_reward: -3258302.90\n",
      "total_cost: 106238.90\n",
      "total_trades: 73697\n",
      "Sharpe: -0.016\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 2245        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022128277 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.3       |\n",
      "|    explained_variance   | 0.0504      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 905         |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    reward               | 8.837248    |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 288\n",
      "day: 1940, episode: 288\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9317104.92\n",
      "total_reward: -682895.08\n",
      "total_cost: 124243.08\n",
      "total_trades: 73690\n",
      "Sharpe: 0.124\n",
      "=================================\n",
      "Episode: 289\n",
      "day: 1940, episode: 289\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8051508.46\n",
      "total_reward: -1948491.54\n",
      "total_cost: 117223.54\n",
      "total_trades: 73688\n",
      "Sharpe: 0.062\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 2253        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031488314 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -78.4       |\n",
      "|    explained_variance   | 0.0248      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 417         |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    reward               | -1.5159011  |\n",
      "|    std                  | 1.91        |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 290\n",
      "day: 1940, episode: 290\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7959579.17\n",
      "total_reward: -2040420.83\n",
      "total_cost: 119064.83\n",
      "total_trades: 73684\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 274        |\n",
      "|    time_elapsed         | 2262       |\n",
      "|    total_timesteps      | 561152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02986759 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.5      |\n",
      "|    explained_variance   | 0.0499     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.49e+03   |\n",
      "|    n_updates            | 2730       |\n",
      "|    policy_gradient_loss | -0.0216    |\n",
      "|    reward               | -5.018528  |\n",
      "|    std                  | 1.92       |\n",
      "|    value_loss           | 2.04e+03   |\n",
      "----------------------------------------\n",
      "Episode: 291\n",
      "day: 1940, episode: 291\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7635004.12\n",
      "total_reward: -2364995.88\n",
      "total_cost: 117604.88\n",
      "total_trades: 73690\n",
      "Sharpe: 0.034\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 275        |\n",
      "|    time_elapsed         | 2270       |\n",
      "|    total_timesteps      | 563200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02526243 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.6      |\n",
      "|    explained_variance   | 0.0402     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.26e+03   |\n",
      "|    n_updates            | 2740       |\n",
      "|    policy_gradient_loss | -0.0246    |\n",
      "|    reward               | 6.836879   |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 2.18e+03   |\n",
      "----------------------------------------\n",
      "Episode: 292\n",
      "day: 1940, episode: 292\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11285994.03\n",
      "total_reward: 1285994.03\n",
      "total_cost: 140399.97\n",
      "total_trades: 73689\n",
      "Sharpe: 0.189\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 276        |\n",
      "|    time_elapsed         | 2278       |\n",
      "|    total_timesteps      | 565248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02564935 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.7      |\n",
      "|    explained_variance   | 0.0948     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 2750       |\n",
      "|    policy_gradient_loss | -0.0254    |\n",
      "|    reward               | 5.2937927  |\n",
      "|    std                  | 1.93       |\n",
      "|    value_loss           | 1.82e+03   |\n",
      "----------------------------------------\n",
      "Episode: 293\n",
      "day: 1940, episode: 293\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8443946.35\n",
      "total_reward: -1556053.65\n",
      "total_cost: 117729.65\n",
      "total_trades: 73697\n",
      "Sharpe: 0.077\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 277        |\n",
      "|    time_elapsed         | 2287       |\n",
      "|    total_timesteps      | 567296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04868468 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.8      |\n",
      "|    explained_variance   | 0.0179     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 720        |\n",
      "|    n_updates            | 2760       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    reward               | 4.4947834  |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 2.46e+03   |\n",
      "----------------------------------------\n",
      "Episode: 294\n",
      "day: 1940, episode: 294\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9771318.93\n",
      "total_reward: -228681.07\n",
      "total_cost: 120092.07\n",
      "total_trades: 73697\n",
      "Sharpe: 0.128\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 278        |\n",
      "|    time_elapsed         | 2295       |\n",
      "|    total_timesteps      | 569344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02623254 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -78.9      |\n",
      "|    explained_variance   | 0.0443     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.2e+03    |\n",
      "|    n_updates            | 2770       |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    reward               | -2.5369685 |\n",
      "|    std                  | 1.94       |\n",
      "|    value_loss           | 2.42e+03   |\n",
      "----------------------------------------\n",
      "Episode: 295\n",
      "day: 1940, episode: 295\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8177696.64\n",
      "total_reward: -1822303.36\n",
      "total_cost: 111652.36\n",
      "total_trades: 73694\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 2303        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034518473 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.0949      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 944         |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -14.414044  |\n",
      "|    std                  | 1.94        |\n",
      "|    value_loss           | 2.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 296\n",
      "day: 1940, episode: 296\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7991590.52\n",
      "total_reward: -2008409.48\n",
      "total_cost: 107065.48\n",
      "total_trades: 73691\n",
      "Sharpe: 0.062\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 2312        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023096167 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79         |\n",
      "|    explained_variance   | 0.0871      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -29.977818  |\n",
      "|    std                  | 1.95        |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 297\n",
      "day: 1940, episode: 297\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8900760.84\n",
      "total_reward: -1099239.16\n",
      "total_cost: 110901.16\n",
      "total_trades: 73684\n",
      "Sharpe: 0.079\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 281        |\n",
      "|    time_elapsed         | 2320       |\n",
      "|    total_timesteps      | 575488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01900151 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.1      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.67e+03   |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | -0.0277    |\n",
      "|    reward               | 31.478243  |\n",
      "|    std                  | 1.95       |\n",
      "|    value_loss           | 3.34e+03   |\n",
      "----------------------------------------\n",
      "Episode: 298\n",
      "day: 1940, episode: 298\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9211281.18\n",
      "total_reward: -788718.82\n",
      "total_cost: 115886.82\n",
      "total_trades: 73691\n",
      "Sharpe: 0.107\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 2328        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030726992 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.2       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 908         |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | 3.4440923   |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 299\n",
      "day: 1940, episode: 299\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7942452.07\n",
      "total_reward: -2057547.93\n",
      "total_cost: 108017.93\n",
      "total_trades: 73703\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 2337        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025833836 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.3       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 852         |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    reward               | 3.8993073   |\n",
      "|    std                  | 1.96        |\n",
      "|    value_loss           | 2.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 300\n",
      "day: 1940, episode: 300\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8344271.27\n",
      "total_reward: -1655728.73\n",
      "total_cost: 112366.73\n",
      "total_trades: 73688\n",
      "Sharpe: 0.080\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 2345        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034730475 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.4       |\n",
      "|    explained_variance   | 0.0492      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    reward               | 8.130225    |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 301\n",
      "day: 1940, episode: 301\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8450404.42\n",
      "total_reward: -1549595.58\n",
      "total_cost: 109123.58\n",
      "total_trades: 73683\n",
      "Sharpe: 0.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 2353        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019684747 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.5       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | 7.99565     |\n",
      "|    std                  | 1.97        |\n",
      "|    value_loss           | 2.66e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 302\n",
      "day: 1940, episode: 302\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9863953.05\n",
      "total_reward: -136046.95\n",
      "total_cost: 119453.95\n",
      "total_trades: 73686\n",
      "Sharpe: 0.124\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 2361        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033901416 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.6       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 3.710276    |\n",
      "|    std                  | 1.98        |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 303\n",
      "day: 1940, episode: 303\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7399869.10\n",
      "total_reward: -2600130.90\n",
      "total_cost: 109146.90\n",
      "total_trades: 73686\n",
      "Sharpe: 0.026\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 2370        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024142168 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.7       |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | 0.9007918   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 304\n",
      "day: 1940, episode: 304\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7654049.10\n",
      "total_reward: -2345950.90\n",
      "total_cost: 106763.90\n",
      "total_trades: 73695\n",
      "Sharpe: 0.046\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 288        |\n",
      "|    time_elapsed         | 2378       |\n",
      "|    total_timesteps      | 589824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206451 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -79.9      |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 854        |\n",
      "|    n_updates            | 2870       |\n",
      "|    policy_gradient_loss | -0.0224    |\n",
      "|    reward               | 0.7759049  |\n",
      "|    std                  | 1.99       |\n",
      "|    value_loss           | 2.17e+03   |\n",
      "----------------------------------------\n",
      "Episode: 305\n",
      "day: 1940, episode: 305\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9441707.32\n",
      "total_reward: -558292.68\n",
      "total_cost: 121145.68\n",
      "total_trades: 73694\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 2386        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024899425 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -79.9       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    reward               | 23.874863   |\n",
      "|    std                  | 1.99        |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 306\n",
      "day: 1940, episode: 306\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7971585.64\n",
      "total_reward: -2028414.36\n",
      "total_cost: 110553.36\n",
      "total_trades: 73678\n",
      "Sharpe: 0.062\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 2395        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034033008 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -1.9413757  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 307\n",
      "day: 1940, episode: 307\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7712473.38\n",
      "total_reward: -2287526.62\n",
      "total_cost: 112291.62\n",
      "total_trades: 73685\n",
      "Sharpe: 0.039\n",
      "=================================\n",
      "Episode: 308\n",
      "day: 1940, episode: 308\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10183858.74\n",
      "total_reward: 183858.74\n",
      "total_cost: 124955.26\n",
      "total_trades: 73688\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 2403        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025262073 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80         |\n",
      "|    explained_variance   | 0.0536      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    reward               | -6.044504   |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 309\n",
      "day: 1940, episode: 309\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8623320.19\n",
      "total_reward: -1376679.81\n",
      "total_cost: 116844.81\n",
      "total_trades: 73686\n",
      "Sharpe: 0.079\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 2411        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038649604 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.1       |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 0.15201621  |\n",
      "|    std                  | 2           |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 310\n",
      "day: 1940, episode: 310\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10598959.95\n",
      "total_reward: 598959.95\n",
      "total_cost: 128735.05\n",
      "total_trades: 73692\n",
      "Sharpe: 0.158\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 2419        |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028726064 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.2       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | -10.217089  |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 2.23e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 311\n",
      "day: 1940, episode: 311\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10603232.14\n",
      "total_reward: 603232.14\n",
      "total_cost: 126588.86\n",
      "total_trades: 73704\n",
      "Sharpe: 0.164\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 2428        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026059395 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.3       |\n",
      "|    explained_variance   | 0.0728      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | 10.766944   |\n",
      "|    std                  | 2.01        |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 312\n",
      "day: 1940, episode: 312\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7656749.41\n",
      "total_reward: -2343250.59\n",
      "total_cost: 113589.59\n",
      "total_trades: 73685\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 2436        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022262763 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.4       |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -14.899718  |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 3.34e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 313\n",
      "day: 1940, episode: 313\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11868664.12\n",
      "total_reward: 1868664.12\n",
      "total_cost: 141225.88\n",
      "total_trades: 73694\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 2444        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022366617 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 741         |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    reward               | -0.71495444 |\n",
      "|    std                  | 2.02        |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 314\n",
      "day: 1940, episode: 314\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10870459.86\n",
      "total_reward: 870459.86\n",
      "total_cost: 132496.14\n",
      "total_trades: 73694\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 2452        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027886307 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.5       |\n",
      "|    explained_variance   | 0.0241      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 1.3859822   |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "Episode: 315\n",
      "day: 1940, episode: 315\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8937957.16\n",
      "total_reward: -1062042.84\n",
      "total_cost: 122445.84\n",
      "total_trades: 73697\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 2461        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025237855 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.6       |\n",
      "|    explained_variance   | 0.0303      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | -26.813221  |\n",
      "|    std                  | 2.03        |\n",
      "|    value_loss           | 3.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 316\n",
      "day: 1940, episode: 316\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9127222.22\n",
      "total_reward: -872777.78\n",
      "total_cost: 120176.78\n",
      "total_trades: 73696\n",
      "Sharpe: 0.103\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 2469        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016251862 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.8       |\n",
      "|    explained_variance   | 0.0586      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.02e+03    |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    reward               | -8.383422   |\n",
      "|    std                  | 2.04        |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 317\n",
      "day: 1940, episode: 317\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10091399.79\n",
      "total_reward: 91399.79\n",
      "total_cost: 123655.21\n",
      "total_trades: 73690\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 2478        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033500064 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.0914      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | -3.5328815  |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 3.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 318\n",
      "day: 1940, episode: 318\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7982814.02\n",
      "total_reward: -2017185.98\n",
      "total_cost: 119505.98\n",
      "total_trades: 73691\n",
      "Sharpe: 0.054\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 2486        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029060762 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -80.9       |\n",
      "|    explained_variance   | 0.067       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 2.5667152   |\n",
      "|    std                  | 2.05        |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 319\n",
      "day: 1940, episode: 319\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8650295.49\n",
      "total_reward: -1349704.51\n",
      "total_cost: 116640.51\n",
      "total_trades: 73692\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 2494        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027614968 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81         |\n",
      "|    explained_variance   | 0.0692      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | -11.206473  |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 320\n",
      "day: 1940, episode: 320\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9402838.98\n",
      "total_reward: -597161.02\n",
      "total_cost: 116452.02\n",
      "total_trades: 73696\n",
      "Sharpe: 0.113\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 2502        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041248135 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.2       |\n",
      "|    explained_variance   | 0.0544      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -6.6114383  |\n",
      "|    std                  | 2.06        |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 321\n",
      "day: 1940, episode: 321\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12328978.99\n",
      "total_reward: 2328978.99\n",
      "total_cost: 137850.01\n",
      "total_trades: 73687\n",
      "Sharpe: 0.237\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 2511        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017773282 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.3       |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.09e+03    |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    reward               | 10.451548   |\n",
      "|    std                  | 2.07        |\n",
      "|    value_loss           | 3.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 322\n",
      "day: 1940, episode: 322\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9220746.12\n",
      "total_reward: -779253.88\n",
      "total_cost: 123628.88\n",
      "total_trades: 73699\n",
      "Sharpe: 0.109\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 305        |\n",
      "|    time_elapsed         | 2519       |\n",
      "|    total_timesteps      | 624640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01937482 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -81.4      |\n",
      "|    explained_variance   | 0.0311     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.5e+03    |\n",
      "|    n_updates            | 3040       |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    reward               | -1.0291147 |\n",
      "|    std                  | 2.07       |\n",
      "|    value_loss           | 3.16e+03   |\n",
      "----------------------------------------\n",
      "Episode: 323\n",
      "day: 1940, episode: 323\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8865369.91\n",
      "total_reward: -1134630.09\n",
      "total_cost: 123365.09\n",
      "total_trades: 73700\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 2527        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014716366 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.0866      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | -14.443609  |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 324\n",
      "day: 1940, episode: 324\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10953692.49\n",
      "total_reward: 953692.49\n",
      "total_cost: 134037.51\n",
      "total_trades: 73695\n",
      "Sharpe: 0.175\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 2535        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016512562 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.5       |\n",
      "|    explained_variance   | 0.0756      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | -9.088636   |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 3.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 325\n",
      "day: 1940, episode: 325\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10672543.12\n",
      "total_reward: 672543.12\n",
      "total_cost: 128181.88\n",
      "total_trades: 73688\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 2544        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045703743 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0859      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    reward               | 5.786179    |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 3.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 326\n",
      "day: 1940, episode: 326\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8269996.09\n",
      "total_reward: -1730003.91\n",
      "total_cost: 121881.91\n",
      "total_trades: 73697\n",
      "Sharpe: 0.071\n",
      "=================================\n",
      "Episode: 327\n",
      "day: 1940, episode: 327\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8089589.11\n",
      "total_reward: -1910410.89\n",
      "total_cost: 125303.89\n",
      "total_trades: 73701\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 2552        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019593786 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.6       |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    reward               | -5.218374   |\n",
      "|    std                  | 2.08        |\n",
      "|    value_loss           | 2.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 328\n",
      "day: 1940, episode: 328\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8545917.47\n",
      "total_reward: -1454082.53\n",
      "total_cost: 127254.53\n",
      "total_trades: 73701\n",
      "Sharpe: 0.066\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 310       |\n",
      "|    time_elapsed         | 2560      |\n",
      "|    total_timesteps      | 634880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.03363   |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -81.7     |\n",
      "|    explained_variance   | 0.0677    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.4e+03   |\n",
      "|    n_updates            | 3090      |\n",
      "|    policy_gradient_loss | -0.0152   |\n",
      "|    reward               | 4.4679775 |\n",
      "|    std                  | 2.09      |\n",
      "|    value_loss           | 2.23e+03  |\n",
      "---------------------------------------\n",
      "Episode: 329\n",
      "day: 1940, episode: 329\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8777769.08\n",
      "total_reward: -1222230.92\n",
      "total_cost: 124211.92\n",
      "total_trades: 73697\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 2569        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041493542 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -81.8       |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -6.364216   |\n",
      "|    std                  | 2.1         |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 330\n",
      "day: 1940, episode: 330\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7856656.28\n",
      "total_reward: -2143343.72\n",
      "total_cost: 114334.72\n",
      "total_trades: 73690\n",
      "Sharpe: 0.038\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 312        |\n",
      "|    time_elapsed         | 2577       |\n",
      "|    total_timesteps      | 638976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04578465 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82        |\n",
      "|    explained_variance   | 0.0334     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 883        |\n",
      "|    n_updates            | 3110       |\n",
      "|    policy_gradient_loss | -0.00518   |\n",
      "|    reward               | 11.572338  |\n",
      "|    std                  | 2.11       |\n",
      "|    value_loss           | 2.59e+03   |\n",
      "----------------------------------------\n",
      "Episode: 331\n",
      "day: 1940, episode: 331\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8759492.41\n",
      "total_reward: -1240507.59\n",
      "total_cost: 126580.59\n",
      "total_trades: 73698\n",
      "Sharpe: 0.090\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 2585        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029667288 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.0712      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    reward               | -1.7345456  |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 2.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 332\n",
      "day: 1940, episode: 332\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6831900.11\n",
      "total_reward: -3168099.89\n",
      "total_cost: 97347.89\n",
      "total_trades: 73695\n",
      "Sharpe: -0.009\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 2593        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054394677 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.1       |\n",
      "|    explained_variance   | 0.0312      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 872         |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | 1.2945858   |\n",
      "|    std                  | 2.11        |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 333\n",
      "day: 1940, episode: 333\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6465756.65\n",
      "total_reward: -3534243.35\n",
      "total_cost: 104450.35\n",
      "total_trades: 73672\n",
      "Sharpe: -0.035\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 315        |\n",
      "|    time_elapsed         | 2602       |\n",
      "|    total_timesteps      | 645120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02299292 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.2      |\n",
      "|    explained_variance   | 0.0125     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 638        |\n",
      "|    n_updates            | 3140       |\n",
      "|    policy_gradient_loss | -0.0228    |\n",
      "|    reward               | 1.9604944  |\n",
      "|    std                  | 2.12       |\n",
      "|    value_loss           | 1.76e+03   |\n",
      "----------------------------------------\n",
      "Episode: 334\n",
      "day: 1940, episode: 334\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6109319.01\n",
      "total_reward: -3890680.99\n",
      "total_cost: 98238.99\n",
      "total_trades: 73689\n",
      "Sharpe: -0.048\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 2610        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037047803 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.3       |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 776         |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    reward               | 38.204918   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 335\n",
      "day: 1940, episode: 335\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9876415.02\n",
      "total_reward: -123584.98\n",
      "total_cost: 128137.98\n",
      "total_trades: 73697\n",
      "Sharpe: 0.121\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 2618        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030697782 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.4       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | -3.9544635  |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 336\n",
      "day: 1940, episode: 336\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7500285.72\n",
      "total_reward: -2499714.28\n",
      "total_cost: 99983.28\n",
      "total_trades: 73697\n",
      "Sharpe: 0.033\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 2626        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022071654 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | -0.033      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 923         |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    reward               | -5.065089   |\n",
      "|    std                  | 2.13        |\n",
      "|    value_loss           | 3.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 337\n",
      "day: 1940, episode: 337\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7993871.00\n",
      "total_reward: -2006129.00\n",
      "total_cost: 107688.00\n",
      "total_trades: 73689\n",
      "Sharpe: 0.028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 2635        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018170789 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.5       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    reward               | -2.158158   |\n",
      "|    std                  | 2.14        |\n",
      "|    value_loss           | 2.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 338\n",
      "day: 1940, episode: 338\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10408109.40\n",
      "total_reward: 408109.40\n",
      "total_cost: 125642.60\n",
      "total_trades: 73694\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 320        |\n",
      "|    time_elapsed         | 2643       |\n",
      "|    total_timesteps      | 655360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03183175 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.6      |\n",
      "|    explained_variance   | 0.114      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 854        |\n",
      "|    n_updates            | 3190       |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    reward               | 1.2111306  |\n",
      "|    std                  | 2.14       |\n",
      "|    value_loss           | 3.14e+03   |\n",
      "----------------------------------------\n",
      "Episode: 339\n",
      "day: 1940, episode: 339\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7914876.55\n",
      "total_reward: -2085123.45\n",
      "total_cost: 110140.45\n",
      "total_trades: 73691\n",
      "Sharpe: 0.056\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 321       |\n",
      "|    time_elapsed         | 2651      |\n",
      "|    total_timesteps      | 657408    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0314543 |\n",
      "|    clip_fraction        | 0.316     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -82.7     |\n",
      "|    explained_variance   | 0.0932    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 912       |\n",
      "|    n_updates            | 3200      |\n",
      "|    policy_gradient_loss | -0.00862  |\n",
      "|    reward               | 11.691597 |\n",
      "|    std                  | 2.15      |\n",
      "|    value_loss           | 2.51e+03  |\n",
      "---------------------------------------\n",
      "Episode: 340\n",
      "day: 1940, episode: 340\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10180737.83\n",
      "total_reward: 180737.83\n",
      "total_cost: 128570.17\n",
      "total_trades: 73690\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 322        |\n",
      "|    time_elapsed         | 2659       |\n",
      "|    total_timesteps      | 659456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03481084 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -82.8      |\n",
      "|    explained_variance   | 0.073      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.74e+03   |\n",
      "|    n_updates            | 3210       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    reward               | 12.711938  |\n",
      "|    std                  | 2.15       |\n",
      "|    value_loss           | 2.79e+03   |\n",
      "----------------------------------------\n",
      "Episode: 341\n",
      "day: 1940, episode: 341\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9334091.58\n",
      "total_reward: -665908.42\n",
      "total_cost: 126685.42\n",
      "total_trades: 73682\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 2667        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024104422 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -82.9       |\n",
      "|    explained_variance   | 0.0751      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    reward               | -1.4165473  |\n",
      "|    std                  | 2.16        |\n",
      "|    value_loss           | 2.73e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 342\n",
      "day: 1940, episode: 342\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9098986.52\n",
      "total_reward: -901013.48\n",
      "total_cost: 120285.48\n",
      "total_trades: 73698\n",
      "Sharpe: 0.088\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 2675        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049694274 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83         |\n",
      "|    explained_variance   | 0.0386      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -18.876133  |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 2.58e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 343\n",
      "day: 1940, episode: 343\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8237991.80\n",
      "total_reward: -1762008.20\n",
      "total_cost: 114895.20\n",
      "total_trades: 73697\n",
      "Sharpe: 0.051\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 2684        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046269096 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.1       |\n",
      "|    explained_variance   | 0.0869      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -3.030143   |\n",
      "|    std                  | 2.17        |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 344\n",
      "day: 1940, episode: 344\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6608673.59\n",
      "total_reward: -3391326.41\n",
      "total_cost: 101414.41\n",
      "total_trades: 73702\n",
      "Sharpe: -0.017\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 326        |\n",
      "|    time_elapsed         | 2692       |\n",
      "|    total_timesteps      | 667648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02990733 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.3      |\n",
      "|    explained_variance   | 0.0527     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 511        |\n",
      "|    n_updates            | 3250       |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    reward               | -9.789623  |\n",
      "|    std                  | 2.18       |\n",
      "|    value_loss           | 1.44e+03   |\n",
      "----------------------------------------\n",
      "Episode: 345\n",
      "day: 1940, episode: 345\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7189587.20\n",
      "total_reward: -2810412.80\n",
      "total_cost: 107266.80\n",
      "total_trades: 73700\n",
      "Sharpe: 0.005\n",
      "=================================\n",
      "Episode: 346\n",
      "day: 1940, episode: 346\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8849189.00\n",
      "total_reward: -1150811.00\n",
      "total_cost: 117810.00\n",
      "total_trades: 73688\n",
      "Sharpe: 0.062\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 327        |\n",
      "|    time_elapsed         | 2700       |\n",
      "|    total_timesteps      | 669696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03312251 |\n",
      "|    clip_fraction        | 0.299      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.5      |\n",
      "|    explained_variance   | 0.0812     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 831        |\n",
      "|    n_updates            | 3260       |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    reward               | -9.697605  |\n",
      "|    std                  | 2.19       |\n",
      "|    value_loss           | 1.64e+03   |\n",
      "----------------------------------------\n",
      "Episode: 347\n",
      "day: 1940, episode: 347\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9287998.57\n",
      "total_reward: -712001.43\n",
      "total_cost: 123965.43\n",
      "total_trades: 73705\n",
      "Sharpe: 0.086\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 2708        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017326836 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.6       |\n",
      "|    explained_variance   | 0.0811      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 912         |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    reward               | 12.03038    |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 348\n",
      "day: 1940, episode: 348\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8318248.96\n",
      "total_reward: -1681751.04\n",
      "total_cost: 116427.04\n",
      "total_trades: 73695\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 2716        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026872694 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.7       |\n",
      "|    explained_variance   | 0.0924      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 801         |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    reward               | -4.516003   |\n",
      "|    std                  | 2.2         |\n",
      "|    value_loss           | 2.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 349\n",
      "day: 1940, episode: 349\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9785761.47\n",
      "total_reward: -214238.53\n",
      "total_cost: 130908.53\n",
      "total_trades: 73690\n",
      "Sharpe: 0.119\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 2724       |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03561176 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -83.8      |\n",
      "|    explained_variance   | 0.106      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 836        |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    reward               | -9.286408  |\n",
      "|    std                  | 2.21       |\n",
      "|    value_loss           | 2.07e+03   |\n",
      "----------------------------------------\n",
      "Episode: 350\n",
      "day: 1940, episode: 350\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8182371.59\n",
      "total_reward: -1817628.41\n",
      "total_cost: 122847.41\n",
      "total_trades: 73701\n",
      "Sharpe: 0.030\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 2732        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018492272 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -83.9       |\n",
      "|    explained_variance   | 0.0605      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27e+03    |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    reward               | -10.590882  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 2.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 351\n",
      "day: 1940, episode: 351\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8807180.09\n",
      "total_reward: -1192819.91\n",
      "total_cost: 129503.91\n",
      "total_trades: 73695\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 2741        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016816802 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.0993      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 962         |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    reward               | -11.459631  |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 2.14e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 352\n",
      "day: 1940, episode: 352\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9029079.89\n",
      "total_reward: -970920.11\n",
      "total_cost: 133499.11\n",
      "total_trades: 73691\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 333         |\n",
      "|    time_elapsed         | 2749        |\n",
      "|    total_timesteps      | 681984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040007994 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84         |\n",
      "|    explained_variance   | 0.0728      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89e+03    |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    reward               | 10.508604   |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 2.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 353\n",
      "day: 1940, episode: 353\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8328534.73\n",
      "total_reward: -1671465.27\n",
      "total_cost: 125000.27\n",
      "total_trades: 73699\n",
      "Sharpe: 0.036\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 2757        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020908702 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.1       |\n",
      "|    explained_variance   | 0.0693      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 11.651859   |\n",
      "|    std                  | 2.22        |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 354\n",
      "day: 1940, episode: 354\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9734505.82\n",
      "total_reward: -265494.18\n",
      "total_cost: 128993.18\n",
      "total_trades: 73700\n",
      "Sharpe: 0.109\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 335        |\n",
      "|    time_elapsed         | 2766       |\n",
      "|    total_timesteps      | 686080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02134711 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.1      |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.49e+03   |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    reward               | 17.49325   |\n",
      "|    std                  | 2.23       |\n",
      "|    value_loss           | 2.85e+03   |\n",
      "----------------------------------------\n",
      "Episode: 355\n",
      "day: 1940, episode: 355\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7243774.11\n",
      "total_reward: -2756225.89\n",
      "total_cost: 118850.89\n",
      "total_trades: 73706\n",
      "Sharpe: 0.011\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 2774        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046848886 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.2       |\n",
      "|    explained_variance   | -0.0686     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    reward               | 2.5508485   |\n",
      "|    std                  | 2.23        |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 356\n",
      "day: 1940, episode: 356\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8841358.36\n",
      "total_reward: -1158641.64\n",
      "total_cost: 133037.64\n",
      "total_trades: 73695\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 337        |\n",
      "|    time_elapsed         | 2782       |\n",
      "|    total_timesteps      | 690176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01771247 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.3      |\n",
      "|    explained_variance   | 0.0209     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.19e+03   |\n",
      "|    n_updates            | 3360       |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    reward               | -1.2774017 |\n",
      "|    std                  | 2.24       |\n",
      "|    value_loss           | 2.4e+03    |\n",
      "----------------------------------------\n",
      "Episode: 357\n",
      "day: 1940, episode: 357\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7943708.33\n",
      "total_reward: -2056291.67\n",
      "total_cost: 125214.67\n",
      "total_trades: 73692\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 2791        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024850147 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.4       |\n",
      "|    explained_variance   | 0.00506     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 946         |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    reward               | -7.401981   |\n",
      "|    std                  | 2.24        |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 358\n",
      "day: 1940, episode: 358\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8947000.85\n",
      "total_reward: -1052999.15\n",
      "total_cost: 129688.15\n",
      "total_trades: 73689\n",
      "Sharpe: 0.111\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 339        |\n",
      "|    time_elapsed         | 2799       |\n",
      "|    total_timesteps      | 694272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02303908 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.5      |\n",
      "|    explained_variance   | 0.016      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 777        |\n",
      "|    n_updates            | 3380       |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    reward               | -4.1438293 |\n",
      "|    std                  | 2.25       |\n",
      "|    value_loss           | 2.1e+03    |\n",
      "----------------------------------------\n",
      "Episode: 359\n",
      "day: 1940, episode: 359\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10368836.93\n",
      "total_reward: 368836.93\n",
      "total_cost: 130144.07\n",
      "total_trades: 73694\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 2807       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02327424 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.5      |\n",
      "|    explained_variance   | 0.0269     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.09e+03   |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    reward               | -2.2776623 |\n",
      "|    std                  | 2.25       |\n",
      "|    value_loss           | 3.04e+03   |\n",
      "----------------------------------------\n",
      "Episode: 360\n",
      "day: 1940, episode: 360\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8629588.94\n",
      "total_reward: -1370411.06\n",
      "total_cost: 127112.06\n",
      "total_trades: 73695\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 341        |\n",
      "|    time_elapsed         | 2816       |\n",
      "|    total_timesteps      | 698368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01732482 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.6      |\n",
      "|    explained_variance   | 0.0365     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    reward               | -0.2551618 |\n",
      "|    std                  | 2.26       |\n",
      "|    value_loss           | 2.2e+03    |\n",
      "----------------------------------------\n",
      "Episode: 361\n",
      "day: 1940, episode: 361\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8761064.42\n",
      "total_reward: -1238935.58\n",
      "total_cost: 124914.58\n",
      "total_trades: 73702\n",
      "Sharpe: 0.096\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 342        |\n",
      "|    time_elapsed         | 2824       |\n",
      "|    total_timesteps      | 700416     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02097244 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.7      |\n",
      "|    explained_variance   | 0.04       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 826        |\n",
      "|    n_updates            | 3410       |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    reward               | 14.822997  |\n",
      "|    std                  | 2.27       |\n",
      "|    value_loss           | 2.02e+03   |\n",
      "----------------------------------------\n",
      "Episode: 362\n",
      "day: 1940, episode: 362\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7466411.88\n",
      "total_reward: -2533588.12\n",
      "total_cost: 120493.12\n",
      "total_trades: 73695\n",
      "Sharpe: 0.029\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 2833        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024398357 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -84.8       |\n",
      "|    explained_variance   | 0.0627      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 621         |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    reward               | -0.8204916  |\n",
      "|    std                  | 2.27        |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 363\n",
      "day: 1940, episode: 363\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8684808.26\n",
      "total_reward: -1315191.74\n",
      "total_cost: 120850.74\n",
      "total_trades: 73694\n",
      "Sharpe: 0.086\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 344        |\n",
      "|    time_elapsed         | 2841       |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0358558  |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -84.9      |\n",
      "|    explained_variance   | 0.098      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.02e+03   |\n",
      "|    n_updates            | 3430       |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    reward               | -13.123472 |\n",
      "|    std                  | 2.28       |\n",
      "|    value_loss           | 2.42e+03   |\n",
      "----------------------------------------\n",
      "Episode: 364\n",
      "day: 1940, episode: 364\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8779801.09\n",
      "total_reward: -1220198.91\n",
      "total_cost: 126464.91\n",
      "total_trades: 73696\n",
      "Sharpe: 0.105\n",
      "=================================\n",
      "Episode: 365\n",
      "day: 1940, episode: 365\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10779500.12\n",
      "total_reward: 779500.12\n",
      "total_cost: 134735.88\n",
      "total_trades: 73689\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 2850        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028747916 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85         |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | -6.6944804  |\n",
      "|    std                  | 2.28        |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 366\n",
      "day: 1940, episode: 366\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10317787.50\n",
      "total_reward: 317787.50\n",
      "total_cost: 128539.50\n",
      "total_trades: 73694\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 2858        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032015525 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.1       |\n",
      "|    explained_variance   | -0.000103   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    reward               | -6.263398   |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 367\n",
      "day: 1940, episode: 367\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7451272.85\n",
      "total_reward: -2548727.15\n",
      "total_cost: 122450.15\n",
      "total_trades: 73694\n",
      "Sharpe: 0.021\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 2866        |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030985076 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.2       |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -1.7987115  |\n",
      "|    std                  | 2.29        |\n",
      "|    value_loss           | 3.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 368\n",
      "day: 1940, episode: 368\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11713224.78\n",
      "total_reward: 1713224.78\n",
      "total_cost: 133108.22\n",
      "total_trades: 73697\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 348        |\n",
      "|    time_elapsed         | 2875       |\n",
      "|    total_timesteps      | 712704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01865245 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.3      |\n",
      "|    explained_variance   | 0.0346     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.37e+03   |\n",
      "|    n_updates            | 3470       |\n",
      "|    policy_gradient_loss | -0.0207    |\n",
      "|    reward               | -7.4710116 |\n",
      "|    std                  | 2.3        |\n",
      "|    value_loss           | 1.86e+03   |\n",
      "----------------------------------------\n",
      "Episode: 369\n",
      "day: 1940, episode: 369\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7352988.06\n",
      "total_reward: -2647011.94\n",
      "total_cost: 122223.94\n",
      "total_trades: 73699\n",
      "Sharpe: 0.027\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 2883        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015627963 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.3       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | -1.3645282  |\n",
      "|    std                  | 2.3         |\n",
      "|    value_loss           | 4.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 370\n",
      "day: 1940, episode: 370\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7227685.85\n",
      "total_reward: -2772314.15\n",
      "total_cost: 124149.15\n",
      "total_trades: 73712\n",
      "Sharpe: 0.004\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 2892        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035171874 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.4       |\n",
      "|    explained_variance   | 0.00219     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 496         |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | 1.9116592   |\n",
      "|    std                  | 2.31        |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 371\n",
      "day: 1940, episode: 371\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9540934.66\n",
      "total_reward: -459065.34\n",
      "total_cost: 124960.34\n",
      "total_trades: 73697\n",
      "Sharpe: 0.118\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 351        |\n",
      "|    time_elapsed         | 2900       |\n",
      "|    total_timesteps      | 718848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02128578 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.5      |\n",
      "|    explained_variance   | 0.0111     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 972        |\n",
      "|    n_updates            | 3500       |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | 5.6916347  |\n",
      "|    std                  | 2.31       |\n",
      "|    value_loss           | 2.16e+03   |\n",
      "----------------------------------------\n",
      "Episode: 372\n",
      "day: 1940, episode: 372\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10232712.30\n",
      "total_reward: 232712.30\n",
      "total_cost: 127891.70\n",
      "total_trades: 73697\n",
      "Sharpe: 0.148\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 352        |\n",
      "|    time_elapsed         | 2908       |\n",
      "|    total_timesteps      | 720896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02516403 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.6      |\n",
      "|    explained_variance   | 0.0159     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.26e+03   |\n",
      "|    n_updates            | 3510       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    reward               | 19.611315  |\n",
      "|    std                  | 2.32       |\n",
      "|    value_loss           | 3.19e+03   |\n",
      "----------------------------------------\n",
      "Episode: 373\n",
      "day: 1940, episode: 373\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8139177.68\n",
      "total_reward: -1860822.32\n",
      "total_cost: 127335.32\n",
      "total_trades: 73697\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 2916        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027071822 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.7       |\n",
      "|    explained_variance   | 0.00868     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    reward               | -20.19059   |\n",
      "|    std                  | 2.32        |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 374\n",
      "day: 1940, episode: 374\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8712393.54\n",
      "total_reward: -1287606.46\n",
      "total_cost: 133115.46\n",
      "total_trades: 73698\n",
      "Sharpe: 0.099\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 2925        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016046928 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -85.8       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    reward               | -38.30206   |\n",
      "|    std                  | 2.33        |\n",
      "|    value_loss           | 3.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 375\n",
      "day: 1940, episode: 375\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9190315.22\n",
      "total_reward: -809684.78\n",
      "total_cost: 129029.78\n",
      "total_trades: 73699\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 355        |\n",
      "|    time_elapsed         | 2933       |\n",
      "|    total_timesteps      | 727040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02388176 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.8      |\n",
      "|    explained_variance   | 0.0138     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.2e+03    |\n",
      "|    n_updates            | 3540       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    reward               | -6.959347  |\n",
      "|    std                  | 2.33       |\n",
      "|    value_loss           | 2.82e+03   |\n",
      "----------------------------------------\n",
      "Episode: 376\n",
      "day: 1940, episode: 376\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8636613.90\n",
      "total_reward: -1363386.10\n",
      "total_cost: 129198.10\n",
      "total_trades: 73702\n",
      "Sharpe: 0.073\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 356        |\n",
      "|    time_elapsed         | 2942       |\n",
      "|    total_timesteps      | 729088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02511832 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -85.9      |\n",
      "|    explained_variance   | 0.00819    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.09e+03   |\n",
      "|    n_updates            | 3550       |\n",
      "|    policy_gradient_loss | -0.0209    |\n",
      "|    reward               | -0.5386317 |\n",
      "|    std                  | 2.34       |\n",
      "|    value_loss           | 2.58e+03   |\n",
      "----------------------------------------\n",
      "Episode: 377\n",
      "day: 1940, episode: 377\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9295777.39\n",
      "total_reward: -704222.61\n",
      "total_cost: 128835.61\n",
      "total_trades: 73691\n",
      "Sharpe: 0.098\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 357        |\n",
      "|    time_elapsed         | 2950       |\n",
      "|    total_timesteps      | 731136     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03450773 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86        |\n",
      "|    explained_variance   | 0.0201     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.91e+03   |\n",
      "|    n_updates            | 3560       |\n",
      "|    policy_gradient_loss | -0.00864   |\n",
      "|    reward               | -0.560057  |\n",
      "|    std                  | 2.35       |\n",
      "|    value_loss           | 2.67e+03   |\n",
      "----------------------------------------\n",
      "Episode: 378\n",
      "day: 1940, episode: 378\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9956039.07\n",
      "total_reward: -43960.93\n",
      "total_cost: 130217.93\n",
      "total_trades: 73692\n",
      "Sharpe: 0.130\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 358        |\n",
      "|    time_elapsed         | 2958       |\n",
      "|    total_timesteps      | 733184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0394685  |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.2      |\n",
      "|    explained_variance   | -0.00367   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.49e+03   |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | -0.000426  |\n",
      "|    reward               | -29.156582 |\n",
      "|    std                  | 2.35       |\n",
      "|    value_loss           | 2.79e+03   |\n",
      "----------------------------------------\n",
      "Episode: 379\n",
      "day: 1940, episode: 379\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8061196.75\n",
      "total_reward: -1938803.25\n",
      "total_cost: 122771.25\n",
      "total_trades: 73695\n",
      "Sharpe: 0.069\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 2966       |\n",
      "|    total_timesteps      | 735232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03047046 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -86.3      |\n",
      "|    explained_variance   | -0.00284   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 736        |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    reward               | 21.528357  |\n",
      "|    std                  | 2.36       |\n",
      "|    value_loss           | 2.18e+03   |\n",
      "----------------------------------------\n",
      "Episode: 380\n",
      "day: 1940, episode: 380\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8299449.44\n",
      "total_reward: -1700550.56\n",
      "total_cost: 131384.56\n",
      "total_trades: 73698\n",
      "Sharpe: 0.045\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 2974        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038214304 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.5       |\n",
      "|    explained_variance   | 0.0133      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 914         |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 2.7854369   |\n",
      "|    std                  | 2.37        |\n",
      "|    value_loss           | 2.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 381\n",
      "day: 1940, episode: 381\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6628235.73\n",
      "total_reward: -3371764.27\n",
      "total_cost: 125831.27\n",
      "total_trades: 73692\n",
      "Sharpe: -0.024\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 2982        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032886032 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.6       |\n",
      "|    explained_variance   | -0.00957    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 798         |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | -1.5603114  |\n",
      "|    std                  | 2.38        |\n",
      "|    value_loss           | 1.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 382\n",
      "day: 1940, episode: 382\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6665779.99\n",
      "total_reward: -3334220.01\n",
      "total_cost: 125522.01\n",
      "total_trades: 73700\n",
      "Sharpe: -0.017\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 2991        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031201027 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.7       |\n",
      "|    explained_variance   | -0.0238     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 832         |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | -8.25846    |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 1.29e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 383\n",
      "day: 1940, episode: 383\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7431457.07\n",
      "total_reward: -2568542.93\n",
      "total_cost: 133778.93\n",
      "total_trades: 73698\n",
      "Sharpe: 0.004\n",
      "=================================\n",
      "Episode: 384\n",
      "day: 1940, episode: 384\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6018057.39\n",
      "total_reward: -3981942.61\n",
      "total_cost: 120242.61\n",
      "total_trades: 73699\n",
      "Sharpe: -0.062\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 3000        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023676153 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.8       |\n",
      "|    explained_variance   | -0.0171     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 882         |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -0.19464274 |\n",
      "|    std                  | 2.39        |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 385\n",
      "day: 1940, episode: 385\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6894701.70\n",
      "total_reward: -3105298.30\n",
      "total_cost: 126801.30\n",
      "total_trades: 73690\n",
      "Sharpe: -0.034\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 3008        |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030693704 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | -0.0022     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 527         |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | -7.4377103  |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 386\n",
      "day: 1940, episode: 386\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8355591.61\n",
      "total_reward: -1644408.39\n",
      "total_cost: 129650.39\n",
      "total_trades: 73693\n",
      "Sharpe: 0.036\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 3017        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037161224 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -86.9       |\n",
      "|    explained_variance   | 0.016       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 839         |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -0.27768484 |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 387\n",
      "day: 1940, episode: 387\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8023146.40\n",
      "total_reward: -1976853.60\n",
      "total_cost: 133591.60\n",
      "total_trades: 73684\n",
      "Sharpe: 0.009\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 3025        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027861811 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87         |\n",
      "|    explained_variance   | 0.00913     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -2.994211   |\n",
      "|    std                  | 2.4         |\n",
      "|    value_loss           | 2.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 388\n",
      "day: 1940, episode: 388\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5475006.73\n",
      "total_reward: -4524993.27\n",
      "total_cost: 123083.27\n",
      "total_trades: 73690\n",
      "Sharpe: -0.112\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 367        |\n",
      "|    time_elapsed         | 3033       |\n",
      "|    total_timesteps      | 751616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02513974 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.1      |\n",
      "|    explained_variance   | 0.00453    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 971        |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    reward               | 0.58219236 |\n",
      "|    std                  | 2.41       |\n",
      "|    value_loss           | 2.21e+03   |\n",
      "----------------------------------------\n",
      "Episode: 389\n",
      "day: 1940, episode: 389\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7549611.27\n",
      "total_reward: -2450388.73\n",
      "total_cost: 130667.73\n",
      "total_trades: 73693\n",
      "Sharpe: -0.018\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 368        |\n",
      "|    time_elapsed         | 3042       |\n",
      "|    total_timesteps      | 753664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03395231 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.2      |\n",
      "|    explained_variance   | 0.0367     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 370        |\n",
      "|    n_updates            | 3670       |\n",
      "|    policy_gradient_loss | -0.0287    |\n",
      "|    reward               | 0.80404747 |\n",
      "|    std                  | 2.42       |\n",
      "|    value_loss           | 1.11e+03   |\n",
      "----------------------------------------\n",
      "Episode: 390\n",
      "day: 1940, episode: 390\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7426521.01\n",
      "total_reward: -2573478.99\n",
      "total_cost: 126763.99\n",
      "total_trades: 73696\n",
      "Sharpe: -0.026\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 369        |\n",
      "|    time_elapsed         | 3050       |\n",
      "|    total_timesteps      | 755712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0323802  |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.3      |\n",
      "|    explained_variance   | 0.0065     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 882        |\n",
      "|    n_updates            | 3680       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | -4.9762096 |\n",
      "|    std                  | 2.43       |\n",
      "|    value_loss           | 1.47e+03   |\n",
      "----------------------------------------\n",
      "Episode: 391\n",
      "day: 1940, episode: 391\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7873017.49\n",
      "total_reward: -2126982.51\n",
      "total_cost: 126882.51\n",
      "total_trades: 73695\n",
      "Sharpe: 0.011\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 3059        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026762698 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.4       |\n",
      "|    explained_variance   | 0.0191      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | -0.15818906 |\n",
      "|    std                  | 2.43        |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 392\n",
      "day: 1940, episode: 392\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5731621.71\n",
      "total_reward: -4268378.29\n",
      "total_cost: 120111.29\n",
      "total_trades: 73693\n",
      "Sharpe: -0.100\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 3067        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019451857 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.5       |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    reward               | -21.110334  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 393\n",
      "day: 1940, episode: 393\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7061373.78\n",
      "total_reward: -2938626.22\n",
      "total_cost: 121416.22\n",
      "total_trades: 73696\n",
      "Sharpe: -0.028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 3076        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037924394 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.0236      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 577         |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -11.170097  |\n",
      "|    std                  | 2.44        |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 394\n",
      "day: 1940, episode: 394\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7021716.63\n",
      "total_reward: -2978283.37\n",
      "total_cost: 124946.37\n",
      "total_trades: 73704\n",
      "Sharpe: -0.019\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 3084        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043827605 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.6       |\n",
      "|    explained_variance   | 0.00932     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 753         |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    reward               | -1.9746739  |\n",
      "|    std                  | 2.45        |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 395\n",
      "day: 1940, episode: 395\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5823043.70\n",
      "total_reward: -4176956.30\n",
      "total_cost: 123721.30\n",
      "total_trades: 73699\n",
      "Sharpe: -0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 3092        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025234014 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -87.8       |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 845         |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    reward               | -3.2444553  |\n",
      "|    std                  | 2.46        |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 396\n",
      "day: 1940, episode: 396\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5707258.95\n",
      "total_reward: -4292741.05\n",
      "total_cost: 117578.05\n",
      "total_trades: 73696\n",
      "Sharpe: -0.103\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 375        |\n",
      "|    time_elapsed         | 3100       |\n",
      "|    total_timesteps      | 768000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02761481 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -87.9      |\n",
      "|    explained_variance   | 0.00814    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 452        |\n",
      "|    n_updates            | 3740       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    reward               | -3.1902738 |\n",
      "|    std                  | 2.46       |\n",
      "|    value_loss           | 1.07e+03   |\n",
      "----------------------------------------\n",
      "Episode: 397\n",
      "day: 1940, episode: 397\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6253971.63\n",
      "total_reward: -3746028.37\n",
      "total_cost: 120885.37\n",
      "total_trades: 73699\n",
      "Sharpe: -0.076\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 376        |\n",
      "|    time_elapsed         | 3108       |\n",
      "|    total_timesteps      | 770048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03332953 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88        |\n",
      "|    explained_variance   | 0.0109     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 517        |\n",
      "|    n_updates            | 3750       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    reward               | 0.24206589 |\n",
      "|    std                  | 2.47       |\n",
      "|    value_loss           | 1.03e+03   |\n",
      "----------------------------------------\n",
      "Episode: 398\n",
      "day: 1940, episode: 398\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5814787.10\n",
      "total_reward: -4185212.90\n",
      "total_cost: 121024.90\n",
      "total_trades: 73698\n",
      "Sharpe: -0.087\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 3116        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018337272 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.1       |\n",
      "|    explained_variance   | -0.00426    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 621         |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    reward               | -5.7475777  |\n",
      "|    std                  | 2.47        |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 399\n",
      "day: 1940, episode: 399\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5755927.75\n",
      "total_reward: -4244072.25\n",
      "total_cost: 122930.25\n",
      "total_trades: 73703\n",
      "Sharpe: -0.101\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 3125        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032211684 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | -0.0117     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 402         |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 12.975594   |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 1.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 400\n",
      "day: 1940, episode: 400\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7266694.72\n",
      "total_reward: -2733305.28\n",
      "total_cost: 127613.28\n",
      "total_trades: 73690\n",
      "Sharpe: -0.031\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 3133        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027418828 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.2       |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 838         |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    reward               | -6.3216863  |\n",
      "|    std                  | 2.48        |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 401\n",
      "day: 1940, episode: 401\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7626702.46\n",
      "total_reward: -2373297.54\n",
      "total_cost: 129601.54\n",
      "total_trades: 73696\n",
      "Sharpe: -0.005\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 3141        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027941383 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.3       |\n",
      "|    explained_variance   | 0.00799     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | -12.648082  |\n",
      "|    std                  | 2.49        |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 402\n",
      "day: 1940, episode: 402\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9961339.31\n",
      "total_reward: -38660.69\n",
      "total_cost: 132643.69\n",
      "total_trades: 73705\n",
      "Sharpe: 0.123\n",
      "=================================\n",
      "Episode: 403\n",
      "day: 1940, episode: 403\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7779878.24\n",
      "total_reward: -2220121.76\n",
      "total_cost: 130986.76\n",
      "total_trades: 73688\n",
      "Sharpe: 0.032\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 381        |\n",
      "|    time_elapsed         | 3149       |\n",
      "|    total_timesteps      | 780288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02474577 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -88.5      |\n",
      "|    explained_variance   | 0.0149     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.55e+03   |\n",
      "|    n_updates            | 3800       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    reward               | 8.609502   |\n",
      "|    std                  | 2.5        |\n",
      "|    value_loss           | 2.93e+03   |\n",
      "----------------------------------------\n",
      "Episode: 404\n",
      "day: 1940, episode: 404\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6184857.26\n",
      "total_reward: -3815142.74\n",
      "total_cost: 128617.74\n",
      "total_trades: 73686\n",
      "Sharpe: -0.089\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 3157        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041483767 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.6       |\n",
      "|    explained_variance   | 0.000211    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 692         |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 5.4062448   |\n",
      "|    std                  | 2.51        |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 405\n",
      "day: 1940, episode: 405\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8315021.71\n",
      "total_reward: -1684978.29\n",
      "total_cost: 130092.29\n",
      "total_trades: 73699\n",
      "Sharpe: 0.036\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 3165        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026156222 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.7       |\n",
      "|    explained_variance   | -0.004      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 374         |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 11.453232   |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 904         |\n",
      "-----------------------------------------\n",
      "Episode: 406\n",
      "day: 1940, episode: 406\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7804805.28\n",
      "total_reward: -2195194.72\n",
      "total_cost: 125122.72\n",
      "total_trades: 73690\n",
      "Sharpe: 0.038\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 3174        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024987694 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.8       |\n",
      "|    explained_variance   | 0.00416     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 885         |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    reward               | -1.2003162  |\n",
      "|    std                  | 2.52        |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 407\n",
      "day: 1940, episode: 407\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7647122.68\n",
      "total_reward: -2352877.32\n",
      "total_cost: 132043.32\n",
      "total_trades: 73696\n",
      "Sharpe: -0.025\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 3182        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030326754 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -88.9       |\n",
      "|    explained_variance   | 0.00597     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 652         |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 0.27111486  |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 408\n",
      "day: 1940, episode: 408\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8145016.30\n",
      "total_reward: -1854983.70\n",
      "total_cost: 131224.70\n",
      "total_trades: 73693\n",
      "Sharpe: 0.059\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 3190        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036572482 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89         |\n",
      "|    explained_variance   | 0.0025      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 714         |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 7.0025      |\n",
      "|    std                  | 2.53        |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 409\n",
      "day: 1940, episode: 409\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6230376.33\n",
      "total_reward: -3769623.67\n",
      "total_cost: 128092.67\n",
      "total_trades: 73696\n",
      "Sharpe: -0.070\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 3198        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019749582 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.00734     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 630         |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    reward               | 6.3935766   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 1.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 410\n",
      "day: 1940, episode: 410\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8232895.52\n",
      "total_reward: -1767104.48\n",
      "total_cost: 131469.48\n",
      "total_trades: 73709\n",
      "Sharpe: 0.021\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 3207        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017878707 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.1       |\n",
      "|    explained_variance   | 0.00485     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 524         |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    reward               | 16.631428   |\n",
      "|    std                  | 2.54        |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 411\n",
      "day: 1940, episode: 411\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6724983.37\n",
      "total_reward: -3275016.63\n",
      "total_cost: 133400.63\n",
      "total_trades: 73695\n",
      "Sharpe: -0.034\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 3216        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022544727 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.2       |\n",
      "|    explained_variance   | 0.00592     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    reward               | -21.88985   |\n",
      "|    std                  | 2.55        |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 412\n",
      "day: 1940, episode: 412\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7525999.25\n",
      "total_reward: -2474000.75\n",
      "total_cost: 135850.75\n",
      "total_trades: 73704\n",
      "Sharpe: 0.008\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 3224        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023208693 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.3       |\n",
      "|    explained_variance   | 0.015       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 935         |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -52.52149   |\n",
      "|    std                  | 2.56        |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 413\n",
      "day: 1940, episode: 413\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6953680.54\n",
      "total_reward: -3046319.46\n",
      "total_cost: 128346.46\n",
      "total_trades: 73694\n",
      "Sharpe: -0.024\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 391        |\n",
      "|    time_elapsed         | 3233       |\n",
      "|    total_timesteps      | 800768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02447116 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -89.4      |\n",
      "|    explained_variance   | 0.000474   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 627        |\n",
      "|    n_updates            | 3900       |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    reward               | 2.335135   |\n",
      "|    std                  | 2.56       |\n",
      "|    value_loss           | 1.43e+03   |\n",
      "----------------------------------------\n",
      "Episode: 414\n",
      "day: 1940, episode: 414\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8016510.20\n",
      "total_reward: -1983489.80\n",
      "total_cost: 133137.80\n",
      "total_trades: 73705\n",
      "Sharpe: 0.039\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 3241        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029184902 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.5       |\n",
      "|    explained_variance   | 0.00192     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 600         |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 0.7914274   |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 415\n",
      "day: 1940, episode: 415\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7149457.31\n",
      "total_reward: -2850542.69\n",
      "total_cost: 136470.69\n",
      "total_trades: 73697\n",
      "Sharpe: -0.028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 3250        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029588932 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.6       |\n",
      "|    explained_variance   | -0.00706    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 551         |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | -3.8337274  |\n",
      "|    std                  | 2.57        |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 416\n",
      "day: 1940, episode: 416\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7581838.94\n",
      "total_reward: -2418161.06\n",
      "total_cost: 132249.06\n",
      "total_trades: 73703\n",
      "Sharpe: -0.021\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 3258        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037210457 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.7       |\n",
      "|    explained_variance   | 0.0136      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 686         |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -2.8168685  |\n",
      "|    std                  | 2.58        |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 417\n",
      "day: 1940, episode: 417\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6620419.59\n",
      "total_reward: -3379580.41\n",
      "total_cost: 127208.41\n",
      "total_trades: 73704\n",
      "Sharpe: -0.041\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 3266        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018706335 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.8       |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 585         |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 1.4251907   |\n",
      "|    std                  | 2.59        |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 418\n",
      "day: 1940, episode: 418\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7102582.96\n",
      "total_reward: -2897417.04\n",
      "total_cost: 129769.04\n",
      "total_trades: 73697\n",
      "Sharpe: -0.023\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 3275        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014853882 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -89.9       |\n",
      "|    explained_variance   | 0.00321     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 581         |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | 3.1883543   |\n",
      "|    std                  | 2.6         |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 419\n",
      "day: 1940, episode: 419\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8731217.95\n",
      "total_reward: -1268782.05\n",
      "total_cost: 135432.05\n",
      "total_trades: 73703\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 3283        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014889498 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.1       |\n",
      "|    explained_variance   | 0.00624     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 554         |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | 3.97508     |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 420\n",
      "day: 1940, episode: 420\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8165736.50\n",
      "total_reward: -1834263.50\n",
      "total_cost: 130322.50\n",
      "total_trades: 73708\n",
      "Sharpe: 0.045\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 3291        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035369523 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.0142      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 973         |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    reward               | 4.3667064   |\n",
      "|    std                  | 2.61        |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 421\n",
      "day: 1940, episode: 421\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8841514.92\n",
      "total_reward: -1158485.08\n",
      "total_cost: 139049.08\n",
      "total_trades: 73695\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 3299        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016042098 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.2       |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    reward               | 5.7598386   |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 2.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 422\n",
      "day: 1940, episode: 422\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8038729.50\n",
      "total_reward: -1961270.50\n",
      "total_cost: 141707.50\n",
      "total_trades: 73704\n",
      "Sharpe: 0.025\n",
      "=================================\n",
      "Episode: 423\n",
      "day: 1940, episode: 423\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6822751.09\n",
      "total_reward: -3177248.91\n",
      "total_cost: 128955.91\n",
      "total_trades: 73705\n",
      "Sharpe: -0.037\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 3308        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037805386 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.3       |\n",
      "|    explained_variance   | 0.00814     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | 0.00086     |\n",
      "|    reward               | 0.41514823  |\n",
      "|    std                  | 2.62        |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 424\n",
      "day: 1940, episode: 424\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6969330.18\n",
      "total_reward: -3030669.82\n",
      "total_cost: 139998.82\n",
      "total_trades: 73700\n",
      "Sharpe: -0.034\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 401        |\n",
      "|    time_elapsed         | 3316       |\n",
      "|    total_timesteps      | 821248     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02990086 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.4      |\n",
      "|    explained_variance   | 0.0022     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 596        |\n",
      "|    n_updates            | 4000       |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    reward               | 8.830998   |\n",
      "|    std                  | 2.63       |\n",
      "|    value_loss           | 1.21e+03   |\n",
      "----------------------------------------\n",
      "Episode: 425\n",
      "day: 1940, episode: 425\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9095327.44\n",
      "total_reward: -904672.56\n",
      "total_cost: 140028.56\n",
      "total_trades: 73703\n",
      "Sharpe: 0.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 3324        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036527038 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.4       |\n",
      "|    explained_variance   | -0.000632   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 445         |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | -3.2653785  |\n",
      "|    std                  | 2.63        |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 426\n",
      "day: 1940, episode: 426\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8391534.32\n",
      "total_reward: -1608465.68\n",
      "total_cost: 134120.68\n",
      "total_trades: 73702\n",
      "Sharpe: 0.030\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 3332        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040694304 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.5       |\n",
      "|    explained_variance   | 0.0189      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 954         |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    reward               | 5.101614    |\n",
      "|    std                  | 2.64        |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 427\n",
      "day: 1940, episode: 427\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6427465.69\n",
      "total_reward: -3572534.31\n",
      "total_cost: 133763.31\n",
      "total_trades: 73701\n",
      "Sharpe: -0.058\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 404        |\n",
      "|    time_elapsed         | 3341       |\n",
      "|    total_timesteps      | 827392     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03494027 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.6      |\n",
      "|    explained_variance   | 0.0235     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 855        |\n",
      "|    n_updates            | 4030       |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    reward               | -5.257567  |\n",
      "|    std                  | 2.65       |\n",
      "|    value_loss           | 1.62e+03   |\n",
      "----------------------------------------\n",
      "Episode: 428\n",
      "day: 1940, episode: 428\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7663482.05\n",
      "total_reward: -2336517.95\n",
      "total_cost: 142546.95\n",
      "total_trades: 73694\n",
      "Sharpe: -0.012\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 3349        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028536357 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -90.8       |\n",
      "|    explained_variance   | 0.00796     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 501         |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -4.140721   |\n",
      "|    std                  | 2.66        |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 429\n",
      "day: 1940, episode: 429\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 5804712.87\n",
      "total_reward: -4195287.13\n",
      "total_cost: 140165.13\n",
      "total_trades: 73703\n",
      "Sharpe: -0.095\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 406        |\n",
      "|    time_elapsed         | 3358       |\n",
      "|    total_timesteps      | 831488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03697066 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -90.9      |\n",
      "|    explained_variance   | -0.00492   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 475        |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | 0.00027    |\n",
      "|    reward               | -15.837605 |\n",
      "|    std                  | 2.66       |\n",
      "|    value_loss           | 1.24e+03   |\n",
      "----------------------------------------\n",
      "Episode: 430\n",
      "day: 1940, episode: 430\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8072042.00\n",
      "total_reward: -1927958.00\n",
      "total_cost: 144294.00\n",
      "total_trades: 73697\n",
      "Sharpe: 0.003\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 3366        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025999349 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91         |\n",
      "|    explained_variance   | -0.000203   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 380         |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 46.489937   |\n",
      "|    std                  | 2.67        |\n",
      "|    value_loss           | 946         |\n",
      "-----------------------------------------\n",
      "Episode: 431\n",
      "day: 1940, episode: 431\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6117027.66\n",
      "total_reward: -3882972.34\n",
      "total_cost: 137952.34\n",
      "total_trades: 73699\n",
      "Sharpe: -0.096\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 3374        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045692075 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 484         |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | 2.0540931   |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 432\n",
      "day: 1940, episode: 432\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7146154.78\n",
      "total_reward: -2853845.22\n",
      "total_cost: 142611.22\n",
      "total_trades: 73699\n",
      "Sharpe: -0.002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 3382        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043906976 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.1       |\n",
      "|    explained_variance   | -0.00389    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 604         |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -1.8571428  |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 433\n",
      "day: 1940, episode: 433\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8949215.48\n",
      "total_reward: -1050784.52\n",
      "total_cost: 146533.52\n",
      "total_trades: 73708\n",
      "Sharpe: 0.082\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 3391        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041664205 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.2       |\n",
      "|    explained_variance   | -0.0141     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    reward               | 6.112756    |\n",
      "|    std                  | 2.68        |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 434\n",
      "day: 1940, episode: 434\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6521234.17\n",
      "total_reward: -3478765.83\n",
      "total_cost: 138813.83\n",
      "total_trades: 73696\n",
      "Sharpe: -0.051\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 411        |\n",
      "|    time_elapsed         | 3399       |\n",
      "|    total_timesteps      | 841728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01461489 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.3      |\n",
      "|    explained_variance   | -0.00377   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 687        |\n",
      "|    n_updates            | 4100       |\n",
      "|    policy_gradient_loss | -0.0225    |\n",
      "|    reward               | -6.3029194 |\n",
      "|    std                  | 2.69       |\n",
      "|    value_loss           | 1.3e+03    |\n",
      "----------------------------------------\n",
      "Episode: 435\n",
      "day: 1940, episode: 435\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8608754.41\n",
      "total_reward: -1391245.59\n",
      "total_cost: 139276.59\n",
      "total_trades: 73703\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 3407        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035669103 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.4       |\n",
      "|    explained_variance   | 0.00417     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 849         |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | -3.158388   |\n",
      "|    std                  | 2.7         |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 436\n",
      "day: 1940, episode: 436\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8234685.59\n",
      "total_reward: -1765314.41\n",
      "total_cost: 136451.41\n",
      "total_trades: 73707\n",
      "Sharpe: 0.055\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 3416        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017494101 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.5       |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 709         |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    reward               | -17.369726  |\n",
      "|    std                  | 2.71        |\n",
      "|    value_loss           | 1.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 437\n",
      "day: 1940, episode: 437\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8056552.36\n",
      "total_reward: -1943447.64\n",
      "total_cost: 152022.64\n",
      "total_trades: 73701\n",
      "Sharpe: 0.037\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 414        |\n",
      "|    time_elapsed         | 3424       |\n",
      "|    total_timesteps      | 847872     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02810904 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -91.6      |\n",
      "|    explained_variance   | 0.00732    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 793        |\n",
      "|    n_updates            | 4130       |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    reward               | -17.941355 |\n",
      "|    std                  | 2.72       |\n",
      "|    value_loss           | 1.43e+03   |\n",
      "----------------------------------------\n",
      "Episode: 438\n",
      "day: 1940, episode: 438\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9419781.23\n",
      "total_reward: -580218.77\n",
      "total_cost: 143373.77\n",
      "total_trades: 73705\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 415       |\n",
      "|    time_elapsed         | 3432      |\n",
      "|    total_timesteps      | 849920    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0245708 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -91.7     |\n",
      "|    explained_variance   | 0.0136    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 741       |\n",
      "|    n_updates            | 4140      |\n",
      "|    policy_gradient_loss | -0.0182   |\n",
      "|    reward               | 1.1384326 |\n",
      "|    std                  | 2.73      |\n",
      "|    value_loss           | 2.11e+03  |\n",
      "---------------------------------------\n",
      "Episode: 439\n",
      "day: 1940, episode: 439\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8600967.08\n",
      "total_reward: -1399032.92\n",
      "total_cost: 154519.92\n",
      "total_trades: 73693\n",
      "Sharpe: 0.062\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 3441        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014542202 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -91.9       |\n",
      "|    explained_variance   | 0.0055      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 645         |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    reward               | -2.7809477  |\n",
      "|    std                  | 2.74        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 440\n",
      "day: 1940, episode: 440\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10340646.23\n",
      "total_reward: 340646.23\n",
      "total_cost: 152601.77\n",
      "total_trades: 73692\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 417        |\n",
      "|    time_elapsed         | 3449       |\n",
      "|    total_timesteps      | 854016     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02924641 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92        |\n",
      "|    explained_variance   | 0.00523    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 944        |\n",
      "|    n_updates            | 4160       |\n",
      "|    policy_gradient_loss | -0.0083    |\n",
      "|    reward               | -4.930327  |\n",
      "|    std                  | 2.74       |\n",
      "|    value_loss           | 2.15e+03   |\n",
      "----------------------------------------\n",
      "Episode: 441\n",
      "day: 1940, episode: 441\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9166012.99\n",
      "total_reward: -833987.01\n",
      "total_cost: 143413.01\n",
      "total_trades: 73693\n",
      "Sharpe: 0.089\n",
      "=================================\n",
      "Episode: 442\n",
      "day: 1940, episode: 442\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8579571.45\n",
      "total_reward: -1420428.55\n",
      "total_cost: 146879.55\n",
      "total_trades: 73700\n",
      "Sharpe: 0.095\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 3457        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015980156 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92         |\n",
      "|    explained_variance   | 0.00467     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | -7.1560383  |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 443\n",
      "day: 1940, episode: 443\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7671200.91\n",
      "total_reward: -2328799.09\n",
      "total_cost: 139675.09\n",
      "total_trades: 73709\n",
      "Sharpe: 0.053\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 3465        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027145294 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.1       |\n",
      "|    explained_variance   | 0.00934     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    reward               | 1.3590161   |\n",
      "|    std                  | 2.75        |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 444\n",
      "day: 1940, episode: 444\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7855442.56\n",
      "total_reward: -2144557.44\n",
      "total_cost: 141333.44\n",
      "total_trades: 73694\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 3474        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033931077 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.2       |\n",
      "|    explained_variance   | -0.0198     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 409         |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | -1.2672848  |\n",
      "|    std                  | 2.76        |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 445\n",
      "day: 1940, episode: 445\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7476549.19\n",
      "total_reward: -2523450.81\n",
      "total_cost: 132145.81\n",
      "total_trades: 73703\n",
      "Sharpe: 0.028\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 421          |\n",
      "|    time_elapsed         | 3482         |\n",
      "|    total_timesteps      | 862208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.017269203  |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -92.3        |\n",
      "|    explained_variance   | -0.00785     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 905          |\n",
      "|    n_updates            | 4200         |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    reward               | 0.0015277575 |\n",
      "|    std                  | 2.76         |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "Episode: 446\n",
      "day: 1940, episode: 446\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8610951.65\n",
      "total_reward: -1389048.35\n",
      "total_cost: 141225.35\n",
      "total_trades: 73702\n",
      "Sharpe: 0.071\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 422        |\n",
      "|    time_elapsed         | 3490       |\n",
      "|    total_timesteps      | 864256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03136652 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.4      |\n",
      "|    explained_variance   | -7.09e-05  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 392        |\n",
      "|    n_updates            | 4210       |\n",
      "|    policy_gradient_loss | -0.00972   |\n",
      "|    reward               | 0.70191807 |\n",
      "|    std                  | 2.77       |\n",
      "|    value_loss           | 1.26e+03   |\n",
      "----------------------------------------\n",
      "Episode: 447\n",
      "day: 1940, episode: 447\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8557844.16\n",
      "total_reward: -1442155.84\n",
      "total_cost: 143358.84\n",
      "total_trades: 73702\n",
      "Sharpe: 0.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 3498        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028538186 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.5       |\n",
      "|    explained_variance   | -0.00239    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 820         |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    reward               | 6.579158    |\n",
      "|    std                  | 2.78        |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 448\n",
      "day: 1940, episode: 448\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9087747.86\n",
      "total_reward: -912252.14\n",
      "total_cost: 142181.14\n",
      "total_trades: 73700\n",
      "Sharpe: 0.115\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 3506        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021657951 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.7       |\n",
      "|    explained_variance   | -0.0017     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 699         |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -40.50846   |\n",
      "|    std                  | 2.79        |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 449\n",
      "day: 1940, episode: 449\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11692808.75\n",
      "total_reward: 1692808.75\n",
      "total_cost: 153211.25\n",
      "total_trades: 73691\n",
      "Sharpe: 0.208\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 3515        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017641652 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.8       |\n",
      "|    explained_variance   | 0.00502     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | 11.736504   |\n",
      "|    std                  | 2.8         |\n",
      "|    value_loss           | 2.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 450\n",
      "day: 1940, episode: 450\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10743494.56\n",
      "total_reward: 743494.56\n",
      "total_cost: 136941.44\n",
      "total_trades: 73696\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 3523        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027257185 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -92.9       |\n",
      "|    explained_variance   | -0.0149     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.09e+03    |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 10.002804   |\n",
      "|    std                  | 2.81        |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 451\n",
      "day: 1940, episode: 451\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10911687.10\n",
      "total_reward: 911687.10\n",
      "total_cost: 143004.90\n",
      "total_trades: 73698\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 427        |\n",
      "|    time_elapsed         | 3531       |\n",
      "|    total_timesteps      | 874496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03142762 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -92.9      |\n",
      "|    explained_variance   | -0.00147   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.54e+03   |\n",
      "|    n_updates            | 4260       |\n",
      "|    policy_gradient_loss | -0.00627   |\n",
      "|    reward               | -1.8209031 |\n",
      "|    std                  | 2.81       |\n",
      "|    value_loss           | 3.1e+03    |\n",
      "----------------------------------------\n",
      "Episode: 452\n",
      "day: 1940, episode: 452\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10080399.71\n",
      "total_reward: 80399.71\n",
      "total_cost: 141057.29\n",
      "total_trades: 73706\n",
      "Sharpe: 0.135\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 3539        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026326068 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93         |\n",
      "|    explained_variance   | 0.00256     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | -1.2026165  |\n",
      "|    std                  | 2.82        |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 453\n",
      "day: 1940, episode: 453\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8503763.76\n",
      "total_reward: -1496236.24\n",
      "total_cost: 131196.24\n",
      "total_trades: 73699\n",
      "Sharpe: 0.082\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 3547        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034374356 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.1       |\n",
      "|    explained_variance   | 0.00485     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 953         |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 2.9997892   |\n",
      "|    std                  | 2.83        |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 454\n",
      "day: 1940, episode: 454\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8711297.73\n",
      "total_reward: -1288702.27\n",
      "total_cost: 130874.27\n",
      "total_trades: 73698\n",
      "Sharpe: 0.091\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 3556        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053225785 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.2       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 961         |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    reward               | -8.1898575  |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 455\n",
      "day: 1940, episode: 455\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7627268.02\n",
      "total_reward: -2372731.98\n",
      "total_cost: 129797.98\n",
      "total_trades: 73697\n",
      "Sharpe: 0.028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 3564        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030403998 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.4       |\n",
      "|    explained_variance   | 0.00785     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 862         |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    reward               | -8.610514   |\n",
      "|    std                  | 2.84        |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 456\n",
      "day: 1940, episode: 456\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9466977.82\n",
      "total_reward: -533022.18\n",
      "total_cost: 139496.18\n",
      "total_trades: 73697\n",
      "Sharpe: 0.100\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 3572        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026267027 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.00469     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 10.236562   |\n",
      "|    std                  | 2.85        |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 457\n",
      "day: 1940, episode: 457\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9285406.65\n",
      "total_reward: -714593.35\n",
      "total_cost: 138573.35\n",
      "total_trades: 73698\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 3580        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033083797 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.5       |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -18.281363  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 458\n",
      "day: 1940, episode: 458\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10184666.23\n",
      "total_reward: 184666.23\n",
      "total_cost: 139119.77\n",
      "total_trades: 73705\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 3588        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019740105 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.6       |\n",
      "|    explained_variance   | 0.000594    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | -1.0141896  |\n",
      "|    std                  | 2.86        |\n",
      "|    value_loss           | 2.61e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 459\n",
      "day: 1940, episode: 459\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6274920.99\n",
      "total_reward: -3725079.01\n",
      "total_cost: 132994.01\n",
      "total_trades: 73697\n",
      "Sharpe: -0.058\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 3596        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029615069 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.7       |\n",
      "|    explained_variance   | -0.00479    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 312         |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 2.4546342   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 460\n",
      "day: 1940, episode: 460\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9866576.27\n",
      "total_reward: -133423.73\n",
      "total_cost: 139713.73\n",
      "total_trades: 73700\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "Episode: 461\n",
      "day: 1940, episode: 461\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7061717.40\n",
      "total_reward: -2938282.60\n",
      "total_cost: 136045.60\n",
      "total_trades: 73705\n",
      "Sharpe: -0.000\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 3605        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029998923 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.00478     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | 7.4161706   |\n",
      "|    std                  | 2.87        |\n",
      "|    value_loss           | 2.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 462\n",
      "day: 1940, episode: 462\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10875636.33\n",
      "total_reward: 875636.33\n",
      "total_cost: 137916.67\n",
      "total_trades: 73707\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 3613        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027541373 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | -0.00644    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 618         |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -5.266521   |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 463\n",
      "day: 1940, episode: 463\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8680088.87\n",
      "total_reward: -1319911.13\n",
      "total_cost: 137245.13\n",
      "total_trades: 73703\n",
      "Sharpe: 0.090\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 3622        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031532593 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -93.8       |\n",
      "|    explained_variance   | 0.00377     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    reward               | -11.431641  |\n",
      "|    std                  | 2.88        |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 464\n",
      "day: 1940, episode: 464\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6798856.18\n",
      "total_reward: -3201143.82\n",
      "total_cost: 139967.82\n",
      "total_trades: 73701\n",
      "Sharpe: -0.032\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 439        |\n",
      "|    time_elapsed         | 3630       |\n",
      "|    total_timesteps      | 899072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02867573 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -93.9      |\n",
      "|    explained_variance   | 0.00825    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 647        |\n",
      "|    n_updates            | 4380       |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    reward               | -0.1540624 |\n",
      "|    std                  | 2.89       |\n",
      "|    value_loss           | 1.7e+03    |\n",
      "----------------------------------------\n",
      "Episode: 465\n",
      "day: 1940, episode: 465\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7252240.29\n",
      "total_reward: -2747759.71\n",
      "total_cost: 130831.71\n",
      "total_trades: 73704\n",
      "Sharpe: -0.018\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 3638        |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03469255  |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94         |\n",
      "|    explained_variance   | 0.00273     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 401         |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    reward               | -0.19603634 |\n",
      "|    std                  | 2.89        |\n",
      "|    value_loss           | 1.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 466\n",
      "day: 1940, episode: 466\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11414279.75\n",
      "total_reward: 1414279.75\n",
      "total_cost: 138115.25\n",
      "total_trades: 73699\n",
      "Sharpe: 0.199\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 3646        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025568495 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.1       |\n",
      "|    explained_variance   | 0.00133     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 629         |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | 3.1948972   |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 467\n",
      "day: 1940, episode: 467\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10611613.53\n",
      "total_reward: 611613.53\n",
      "total_cost: 140240.47\n",
      "total_trades: 73694\n",
      "Sharpe: 0.166\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 3655        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014197022 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.2       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    reward               | 26.804474   |\n",
      "|    std                  | 2.91        |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 468\n",
      "day: 1940, episode: 468\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8476737.62\n",
      "total_reward: -1523262.38\n",
      "total_cost: 146245.38\n",
      "total_trades: 73697\n",
      "Sharpe: 0.045\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 3663        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015184873 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.3       |\n",
      "|    explained_variance   | 0.00154     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    reward               | 5.770508    |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 469\n",
      "day: 1940, episode: 469\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9786799.17\n",
      "total_reward: -213200.83\n",
      "total_cost: 137029.83\n",
      "total_trades: 73701\n",
      "Sharpe: 0.118\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 3672        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022570223 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | 0.00396     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 29.463703   |\n",
      "|    std                  | 2.92        |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 470\n",
      "day: 1940, episode: 470\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7885654.40\n",
      "total_reward: -2114345.60\n",
      "total_cost: 136299.60\n",
      "total_trades: 73703\n",
      "Sharpe: 0.025\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 3680        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021096136 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.4       |\n",
      "|    explained_variance   | -0.0162     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | -1.1301471  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 471\n",
      "day: 1940, episode: 471\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6848031.95\n",
      "total_reward: -3151968.05\n",
      "total_cost: 139098.05\n",
      "total_trades: 73697\n",
      "Sharpe: -0.009\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 3688        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031941097 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.5       |\n",
      "|    explained_variance   | -0.0145     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 772         |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    reward               | 0.03405092  |\n",
      "|    std                  | 2.93        |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 472\n",
      "day: 1940, episode: 472\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11235992.75\n",
      "total_reward: 1235992.75\n",
      "total_cost: 145434.25\n",
      "total_trades: 73699\n",
      "Sharpe: 0.190\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 447          |\n",
      "|    time_elapsed         | 3697         |\n",
      "|    total_timesteps      | 915456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.022571726  |\n",
      "|    clip_fraction        | 0.229        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -94.6        |\n",
      "|    explained_variance   | 0.00176      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 4460         |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    reward               | -0.106781706 |\n",
      "|    std                  | 2.94         |\n",
      "|    value_loss           | 2.27e+03     |\n",
      "------------------------------------------\n",
      "Episode: 473\n",
      "day: 1940, episode: 473\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6700326.83\n",
      "total_reward: -3299673.17\n",
      "total_cost: 136450.17\n",
      "total_trades: 73701\n",
      "Sharpe: -0.043\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 3705        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030280588 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.6       |\n",
      "|    explained_variance   | 0.0125      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 790         |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -4.6660657  |\n",
      "|    std                  | 2.94        |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 474\n",
      "day: 1940, episode: 474\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7937022.27\n",
      "total_reward: -2062977.73\n",
      "total_cost: 141768.73\n",
      "total_trades: 73698\n",
      "Sharpe: 0.022\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 3713        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018202007 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.7       |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 537         |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    reward               | 8.11365     |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 1.23e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 475\n",
      "day: 1940, episode: 475\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7010014.57\n",
      "total_reward: -2989985.43\n",
      "total_cost: 128690.43\n",
      "total_trades: 73699\n",
      "Sharpe: 0.010\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 450        |\n",
      "|    time_elapsed         | 3722       |\n",
      "|    total_timesteps      | 921600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04245188 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.7      |\n",
      "|    explained_variance   | 0.0189     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 312        |\n",
      "|    n_updates            | 4490       |\n",
      "|    policy_gradient_loss | -0.00574   |\n",
      "|    reward               | -2.1790843 |\n",
      "|    std                  | 2.95       |\n",
      "|    value_loss           | 942        |\n",
      "----------------------------------------\n",
      "Episode: 476\n",
      "day: 1940, episode: 476\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8714099.97\n",
      "total_reward: -1285900.03\n",
      "total_cost: 129072.03\n",
      "total_trades: 73697\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 3730        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025162965 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | -0.0018     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 654         |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -2.2089443  |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 477\n",
      "day: 1940, episode: 477\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6323468.92\n",
      "total_reward: -3676531.08\n",
      "total_cost: 136041.08\n",
      "total_trades: 73701\n",
      "Sharpe: -0.050\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 3738        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024395913 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -94.8       |\n",
      "|    explained_variance   | -0.00181    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 509         |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 15.860632   |\n",
      "|    std                  | 2.95        |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 478\n",
      "day: 1940, episode: 478\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 6699422.31\n",
      "total_reward: -3300577.69\n",
      "total_cost: 130639.69\n",
      "total_trades: 73707\n",
      "Sharpe: 0.001\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 453        |\n",
      "|    time_elapsed         | 3746       |\n",
      "|    total_timesteps      | 927744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03251309 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -94.9      |\n",
      "|    explained_variance   | -0.000945  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 284        |\n",
      "|    n_updates            | 4520       |\n",
      "|    policy_gradient_loss | -0.00636   |\n",
      "|    reward               | -1.4967663 |\n",
      "|    std                  | 2.97       |\n",
      "|    value_loss           | 869        |\n",
      "----------------------------------------\n",
      "Episode: 479\n",
      "day: 1940, episode: 479\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8160864.12\n",
      "total_reward: -1839135.88\n",
      "total_cost: 139781.88\n",
      "total_trades: 73694\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "Episode: 480\n",
      "day: 1940, episode: 480\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8216970.81\n",
      "total_reward: -1783029.19\n",
      "total_cost: 131503.19\n",
      "total_trades: 73696\n",
      "Sharpe: 0.082\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 3754        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026200503 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95         |\n",
      "|    explained_variance   | 0.00365     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 959         |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    reward               | -1.9134833  |\n",
      "|    std                  | 2.97        |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 481\n",
      "day: 1940, episode: 481\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7993139.89\n",
      "total_reward: -2006860.11\n",
      "total_cost: 128645.11\n",
      "total_trades: 73698\n",
      "Sharpe: 0.075\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 455         |\n",
      "|    time_elapsed         | 3762        |\n",
      "|    total_timesteps      | 931840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030862045 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.1       |\n",
      "|    explained_variance   | 0.00623     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 980         |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    reward               | 1.9250324   |\n",
      "|    std                  | 2.98        |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 482\n",
      "day: 1940, episode: 482\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11663350.81\n",
      "total_reward: 1663350.81\n",
      "total_cost: 131668.19\n",
      "total_trades: 73699\n",
      "Sharpe: 0.213\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 456       |\n",
      "|    time_elapsed         | 3770      |\n",
      "|    total_timesteps      | 933888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0421011 |\n",
      "|    clip_fraction        | 0.272     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -95.1     |\n",
      "|    explained_variance   | -0.0124   |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 852       |\n",
      "|    n_updates            | 4550      |\n",
      "|    policy_gradient_loss | -0.0056   |\n",
      "|    reward               | 10.613047 |\n",
      "|    std                  | 2.98      |\n",
      "|    value_loss           | 1.31e+03  |\n",
      "---------------------------------------\n",
      "Episode: 483\n",
      "day: 1940, episode: 483\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7547265.88\n",
      "total_reward: -2452734.12\n",
      "total_cost: 128579.12\n",
      "total_trades: 73695\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 3778        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014355233 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.2       |\n",
      "|    explained_variance   | 0.000152    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | -4.7424603  |\n",
      "|    std                  | 2.99        |\n",
      "|    value_loss           | 2.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 484\n",
      "day: 1940, episode: 484\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9742102.33\n",
      "total_reward: -257897.67\n",
      "total_cost: 140981.67\n",
      "total_trades: 73699\n",
      "Sharpe: 0.131\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 458        |\n",
      "|    time_elapsed         | 3786       |\n",
      "|    total_timesteps      | 937984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03386282 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.3      |\n",
      "|    explained_variance   | 0.0187     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 502        |\n",
      "|    n_updates            | 4570       |\n",
      "|    policy_gradient_loss | -0.0182    |\n",
      "|    reward               | 13.593135  |\n",
      "|    std                  | 3          |\n",
      "|    value_loss           | 1.08e+03   |\n",
      "----------------------------------------\n",
      "Episode: 485\n",
      "day: 1940, episode: 485\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10786081.86\n",
      "total_reward: 786081.86\n",
      "total_cost: 134372.14\n",
      "total_trades: 73707\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 3795        |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025421869 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 636         |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    reward               | -7.3233185  |\n",
      "|    std                  | 3           |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 486\n",
      "day: 1940, episode: 486\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7702968.31\n",
      "total_reward: -2297031.69\n",
      "total_cost: 127852.69\n",
      "total_trades: 73706\n",
      "Sharpe: 0.061\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 3803        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022531494 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.4       |\n",
      "|    explained_variance   | 0.0208      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 5.7562947   |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 2.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 487\n",
      "day: 1940, episode: 487\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8296573.38\n",
      "total_reward: -1703426.62\n",
      "total_cost: 130889.62\n",
      "total_trades: 73698\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 3811        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022043996 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.5       |\n",
      "|    explained_variance   | -0.0225     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 826         |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -15.347     |\n",
      "|    std                  | 3.01        |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 488\n",
      "day: 1940, episode: 488\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10440289.66\n",
      "total_reward: 440289.66\n",
      "total_cost: 138430.34\n",
      "total_trades: 73705\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 3819        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023973357 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.00698     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 715         |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    reward               | -4.3523884  |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 489\n",
      "day: 1940, episode: 489\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7637306.17\n",
      "total_reward: -2362693.83\n",
      "total_cost: 127509.83\n",
      "total_trades: 73705\n",
      "Sharpe: 0.037\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 3827        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025960624 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.6       |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    reward               | 9.345535    |\n",
      "|    std                  | 3.02        |\n",
      "|    value_loss           | 2.25e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 490\n",
      "day: 1940, episode: 490\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7817328.76\n",
      "total_reward: -2182671.24\n",
      "total_cost: 123941.24\n",
      "total_trades: 73706\n",
      "Sharpe: 0.068\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 3835        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030981861 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -95.7       |\n",
      "|    explained_variance   | -0.0029     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    reward               | 0.7475282   |\n",
      "|    std                  | 3.03        |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 491\n",
      "day: 1940, episode: 491\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11101932.71\n",
      "total_reward: 1101932.71\n",
      "total_cost: 141120.29\n",
      "total_trades: 73707\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 465        |\n",
      "|    time_elapsed         | 3844       |\n",
      "|    total_timesteps      | 952320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02791275 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -95.9      |\n",
      "|    explained_variance   | 0.0224     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 797        |\n",
      "|    n_updates            | 4640       |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    reward               | -3.4817698 |\n",
      "|    std                  | 3.05       |\n",
      "|    value_loss           | 1.46e+03   |\n",
      "----------------------------------------\n",
      "Episode: 492\n",
      "day: 1940, episode: 492\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9643056.18\n",
      "total_reward: -356943.82\n",
      "total_cost: 131352.82\n",
      "total_trades: 73700\n",
      "Sharpe: 0.133\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 3852        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016201701 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96         |\n",
      "|    explained_variance   | -0.000937   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    reward               | -1.0559397  |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 493\n",
      "day: 1940, episode: 493\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12404846.43\n",
      "total_reward: 2404846.43\n",
      "total_cost: 138068.57\n",
      "total_trades: 73706\n",
      "Sharpe: 0.248\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 3860        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028194968 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.1       |\n",
      "|    explained_variance   | 0.00908     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 4.9154563   |\n",
      "|    std                  | 3.06        |\n",
      "|    value_loss           | 2.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 494\n",
      "day: 1940, episode: 494\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10403597.74\n",
      "total_reward: 403597.74\n",
      "total_cost: 141232.26\n",
      "total_trades: 73707\n",
      "Sharpe: 0.163\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 3868        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026625898 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.2       |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 838         |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    reward               | 9.209812    |\n",
      "|    std                  | 3.07        |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 495\n",
      "day: 1940, episode: 495\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10698678.92\n",
      "total_reward: 698678.92\n",
      "total_cost: 130873.08\n",
      "total_trades: 73698\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 3877        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021165553 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.3       |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 808         |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    reward               | -3.6332302  |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 496\n",
      "day: 1940, episode: 496\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9185198.59\n",
      "total_reward: -814801.41\n",
      "total_cost: 131787.41\n",
      "total_trades: 73702\n",
      "Sharpe: 0.144\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 3885        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023137635 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.4       |\n",
      "|    explained_variance   | -0.00144    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 714         |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 16.751883   |\n",
      "|    std                  | 3.08        |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 497\n",
      "day: 1940, episode: 497\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9760505.27\n",
      "total_reward: -239494.73\n",
      "total_cost: 131772.73\n",
      "total_trades: 73699\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 3893        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043186408 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.5       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 875         |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    reward               | -5.6638346  |\n",
      "|    std                  | 3.09        |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 498\n",
      "day: 1940, episode: 498\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7211846.48\n",
      "total_reward: -2788153.52\n",
      "total_cost: 129288.52\n",
      "total_trades: 73700\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "Episode: 499\n",
      "day: 1940, episode: 499\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10155650.65\n",
      "total_reward: 155650.65\n",
      "total_cost: 129390.35\n",
      "total_trades: 73703\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 3901        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033598267 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.6       |\n",
      "|    explained_variance   | -0.0153     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    reward               | 3.7952127   |\n",
      "|    std                  | 3.1         |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 500\n",
      "day: 1940, episode: 500\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8278966.66\n",
      "total_reward: -1721033.34\n",
      "total_cost: 138262.34\n",
      "total_trades: 73703\n",
      "Sharpe: 0.073\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 3909        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036797464 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.7       |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 978         |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | -6.614819   |\n",
      "|    std                  | 3.11        |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 501\n",
      "day: 1940, episode: 501\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7893153.44\n",
      "total_reward: -2106846.56\n",
      "total_cost: 140820.56\n",
      "total_trades: 73712\n",
      "Sharpe: 0.086\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 474        |\n",
      "|    time_elapsed         | 3917       |\n",
      "|    total_timesteps      | 970752     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03366532 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -96.8      |\n",
      "|    explained_variance   | -0.00201   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 649        |\n",
      "|    n_updates            | 4730       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    reward               | 1.9027491  |\n",
      "|    std                  | 3.11       |\n",
      "|    value_loss           | 1.53e+03   |\n",
      "----------------------------------------\n",
      "Episode: 502\n",
      "day: 1940, episode: 502\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9491979.51\n",
      "total_reward: -508020.49\n",
      "total_cost: 138111.49\n",
      "total_trades: 73698\n",
      "Sharpe: 0.122\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 3925        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032312408 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -96.9       |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    reward               | 10.886817   |\n",
      "|    std                  | 3.13        |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 503\n",
      "day: 1940, episode: 503\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7191169.27\n",
      "total_reward: -2808830.73\n",
      "total_cost: 134739.73\n",
      "total_trades: 73701\n",
      "Sharpe: 0.039\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 476        |\n",
      "|    time_elapsed         | 3933       |\n",
      "|    total_timesteps      | 974848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03471756 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97        |\n",
      "|    explained_variance   | -0.00605   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.27e+03   |\n",
      "|    n_updates            | 4750       |\n",
      "|    policy_gradient_loss | -0.00944   |\n",
      "|    reward               | -5.02176   |\n",
      "|    std                  | 3.13       |\n",
      "|    value_loss           | 1.64e+03   |\n",
      "----------------------------------------\n",
      "Episode: 504\n",
      "day: 1940, episode: 504\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8439042.73\n",
      "total_reward: -1560957.27\n",
      "total_cost: 133383.27\n",
      "total_trades: 73705\n",
      "Sharpe: 0.069\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 477        |\n",
      "|    time_elapsed         | 3942       |\n",
      "|    total_timesteps      | 976896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03427262 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.1      |\n",
      "|    explained_variance   | 0.0378     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 512        |\n",
      "|    n_updates            | 4760       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    reward               | 1.3280871  |\n",
      "|    std                  | 3.14       |\n",
      "|    value_loss           | 1.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 505\n",
      "day: 1940, episode: 505\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8200696.17\n",
      "total_reward: -1799303.83\n",
      "total_cost: 133676.83\n",
      "total_trades: 73703\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 3950        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025814617 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.2       |\n",
      "|    explained_variance   | 0.0333      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 746         |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | -9.620734   |\n",
      "|    std                  | 3.15        |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 506\n",
      "day: 1940, episode: 506\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8694227.42\n",
      "total_reward: -1305772.58\n",
      "total_cost: 140216.58\n",
      "total_trades: 73704\n",
      "Sharpe: 0.100\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 3958        |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019941475 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.3       |\n",
      "|    explained_variance   | 0.0434      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 563         |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 0.68899447  |\n",
      "|    std                  | 3.16        |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 507\n",
      "day: 1940, episode: 507\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8421503.37\n",
      "total_reward: -1578496.63\n",
      "total_cost: 138550.63\n",
      "total_trades: 73695\n",
      "Sharpe: 0.076\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 3966        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024613248 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.00845     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 733         |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 31.927765   |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 508\n",
      "day: 1940, episode: 508\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8701349.80\n",
      "total_reward: -1298650.20\n",
      "total_cost: 136796.20\n",
      "total_trades: 73699\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 3974        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030615855 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.4       |\n",
      "|    explained_variance   | 0.0511      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | -8.332403   |\n",
      "|    std                  | 3.17        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 509\n",
      "day: 1940, episode: 509\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10010719.20\n",
      "total_reward: 10719.20\n",
      "total_cost: 144533.80\n",
      "total_trades: 73703\n",
      "Sharpe: 0.147\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 3982        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019907705 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.5       |\n",
      "|    explained_variance   | 0.0307      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -1.0869964  |\n",
      "|    std                  | 3.18        |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 510\n",
      "day: 1940, episode: 510\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7983961.26\n",
      "total_reward: -2016038.74\n",
      "total_cost: 136366.74\n",
      "total_trades: 73700\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 483        |\n",
      "|    time_elapsed         | 3991       |\n",
      "|    total_timesteps      | 989184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01895049 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -97.7      |\n",
      "|    explained_variance   | 0.0665     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 539        |\n",
      "|    n_updates            | 4820       |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    reward               | 1.855867   |\n",
      "|    std                  | 3.19       |\n",
      "|    value_loss           | 1.44e+03   |\n",
      "----------------------------------------\n",
      "Episode: 511\n",
      "day: 1940, episode: 511\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8361962.58\n",
      "total_reward: -1638037.42\n",
      "total_cost: 137241.42\n",
      "total_trades: 73707\n",
      "Sharpe: 0.078\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 3999        |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020412508 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.8       |\n",
      "|    explained_variance   | 0.0781      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 314         |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    reward               | -1.8818946  |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 512\n",
      "day: 1940, episode: 512\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10639599.43\n",
      "total_reward: 639599.43\n",
      "total_cost: 130522.57\n",
      "total_trades: 73704\n",
      "Sharpe: 0.176\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 4007        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015920205 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -97.9       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 887         |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | -9.050791   |\n",
      "|    std                  | 3.21        |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 513\n",
      "day: 1940, episode: 513\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10966579.79\n",
      "total_reward: 966579.79\n",
      "total_cost: 145740.21\n",
      "total_trades: 73695\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 4015        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023442127 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 796         |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | -2.0062525  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 2.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 514\n",
      "day: 1940, episode: 514\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10802167.46\n",
      "total_reward: 802167.46\n",
      "total_cost: 139232.54\n",
      "total_trades: 73703\n",
      "Sharpe: 0.180\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 4023        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014102617 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98         |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    reward               | -14.792174  |\n",
      "|    std                  | 3.22        |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 515\n",
      "day: 1940, episode: 515\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11018757.25\n",
      "total_reward: 1018757.25\n",
      "total_cost: 137053.75\n",
      "total_trades: 73702\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 488        |\n",
      "|    time_elapsed         | 4031       |\n",
      "|    total_timesteps      | 999424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02474475 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -98.1      |\n",
      "|    explained_variance   | 0.055      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.16e+03   |\n",
      "|    n_updates            | 4870       |\n",
      "|    policy_gradient_loss | -0.00844   |\n",
      "|    reward               | -30.096823 |\n",
      "|    std                  | 3.22       |\n",
      "|    value_loss           | 2.29e+03   |\n",
      "----------------------------------------\n",
      "Episode: 516\n",
      "day: 1940, episode: 516\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11832775.52\n",
      "total_reward: 1832775.52\n",
      "total_cost: 135225.48\n",
      "total_trades: 73708\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 489       |\n",
      "|    time_elapsed         | 4040      |\n",
      "|    total_timesteps      | 1001472   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0246808 |\n",
      "|    clip_fraction        | 0.219     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -98.1     |\n",
      "|    explained_variance   | 0.0851    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.14e+03  |\n",
      "|    n_updates            | 4880      |\n",
      "|    policy_gradient_loss | -0.00402  |\n",
      "|    reward               | 9.584685  |\n",
      "|    std                  | 3.23      |\n",
      "|    value_loss           | 2.13e+03  |\n",
      "---------------------------------------\n",
      "Episode: 517\n",
      "day: 1940, episode: 517\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7450949.16\n",
      "total_reward: -2549050.84\n",
      "total_cost: 131326.84\n",
      "total_trades: 73701\n",
      "Sharpe: 0.049\n",
      "=================================\n",
      "Episode: 518\n",
      "day: 1940, episode: 518\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8359635.06\n",
      "total_reward: -1640364.94\n",
      "total_cost: 130287.94\n",
      "total_trades: 73709\n",
      "Sharpe: 0.091\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 4048        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030572454 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.0321      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    reward               | -4.9606333  |\n",
      "|    std                  | 3.23        |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 519\n",
      "day: 1940, episode: 519\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10131101.91\n",
      "total_reward: 131101.91\n",
      "total_cost: 133877.09\n",
      "total_trades: 73702\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 4057        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025843218 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.2       |\n",
      "|    explained_variance   | 0.0516      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 591         |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | -4.687127   |\n",
      "|    std                  | 3.24        |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 520\n",
      "day: 1940, episode: 520\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13048480.65\n",
      "total_reward: 3048480.65\n",
      "total_cost: 141724.35\n",
      "total_trades: 73704\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 4065        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022610148 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.3       |\n",
      "|    explained_variance   | -0.0168     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 10.442131   |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 521\n",
      "day: 1940, episode: 521\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9661394.85\n",
      "total_reward: -338605.15\n",
      "total_cost: 133093.15\n",
      "total_trades: 73706\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 4073        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019240096 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.0155      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    reward               | 2.254347    |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 522\n",
      "day: 1940, episode: 522\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11681350.78\n",
      "total_reward: 1681350.78\n",
      "total_cost: 138743.22\n",
      "total_trades: 73713\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 4082        |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029545018 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.4       |\n",
      "|    explained_variance   | 0.000834    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 914         |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.000964   |\n",
      "|    reward               | 0.8192267   |\n",
      "|    std                  | 3.25        |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 523\n",
      "day: 1940, episode: 523\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13297312.97\n",
      "total_reward: 3297312.97\n",
      "total_cost: 131013.03\n",
      "total_trades: 73700\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 4090        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014774121 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | -16.16394   |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 524\n",
      "day: 1940, episode: 524\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11977555.81\n",
      "total_reward: 1977555.81\n",
      "total_cost: 136793.19\n",
      "total_trades: 73708\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 4099        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019129265 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.5       |\n",
      "|    explained_variance   | -0.0153     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -3.6648989  |\n",
      "|    std                  | 3.26        |\n",
      "|    value_loss           | 3.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 525\n",
      "day: 1940, episode: 525\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9904321.94\n",
      "total_reward: -95678.06\n",
      "total_cost: 127373.06\n",
      "total_trades: 73698\n",
      "Sharpe: 0.169\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 4107        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018129624 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.6       |\n",
      "|    explained_variance   | -0.00109    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | 11.880592   |\n",
      "|    std                  | 3.27        |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 526\n",
      "day: 1940, episode: 526\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9752075.68\n",
      "total_reward: -247924.32\n",
      "total_cost: 130183.32\n",
      "total_trades: 73703\n",
      "Sharpe: 0.153\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 4116        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023048218 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.7       |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    reward               | -63.235775  |\n",
      "|    std                  | 3.28        |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 527\n",
      "day: 1940, episode: 527\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8295159.13\n",
      "total_reward: -1704840.87\n",
      "total_cost: 137328.87\n",
      "total_trades: 73697\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 4125        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026161645 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.8       |\n",
      "|    explained_variance   | 0.00973     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    reward               | -12.922471  |\n",
      "|    std                  | 3.29        |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 528\n",
      "day: 1940, episode: 528\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7807874.41\n",
      "total_reward: -2192125.59\n",
      "total_cost: 123366.59\n",
      "total_trades: 73700\n",
      "Sharpe: 0.066\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 4133        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013287909 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -98.9       |\n",
      "|    explained_variance   | -0.011      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 603         |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | 17.261604   |\n",
      "|    std                  | 3.3         |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 529\n",
      "day: 1940, episode: 529\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8584840.18\n",
      "total_reward: -1415159.82\n",
      "total_cost: 124027.82\n",
      "total_trades: 73698\n",
      "Sharpe: 0.091\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 4141        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015510832 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99         |\n",
      "|    explained_variance   | 0.00118     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 851         |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | -1.4889134  |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 530\n",
      "day: 1940, episode: 530\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8920691.24\n",
      "total_reward: -1079308.76\n",
      "total_cost: 122766.76\n",
      "total_trades: 73700\n",
      "Sharpe: 0.117\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 502        |\n",
      "|    time_elapsed         | 4150       |\n",
      "|    total_timesteps      | 1028096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01625475 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -99.1      |\n",
      "|    explained_variance   | 0.00387    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 928        |\n",
      "|    n_updates            | 5010       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    reward               | -3.611972  |\n",
      "|    std                  | 3.31       |\n",
      "|    value_loss           | 1.85e+03   |\n",
      "----------------------------------------\n",
      "Episode: 531\n",
      "day: 1940, episode: 531\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12085786.79\n",
      "total_reward: 2085786.79\n",
      "total_cost: 135230.21\n",
      "total_trades: 73693\n",
      "Sharpe: 0.229\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 503         |\n",
      "|    time_elapsed         | 4158        |\n",
      "|    total_timesteps      | 1030144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017987095 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.1       |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 837         |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 32.94501    |\n",
      "|    std                  | 3.31        |\n",
      "|    value_loss           | 3.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 532\n",
      "day: 1940, episode: 532\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8445166.89\n",
      "total_reward: -1554833.11\n",
      "total_cost: 126807.11\n",
      "total_trades: 73707\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 4166        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022765046 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.2       |\n",
      "|    explained_variance   | -0.0103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 868         |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -13.163797  |\n",
      "|    std                  | 3.33        |\n",
      "|    value_loss           | 2.45e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 533\n",
      "day: 1940, episode: 533\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9042077.57\n",
      "total_reward: -957922.43\n",
      "total_cost: 132310.43\n",
      "total_trades: 73699\n",
      "Sharpe: 0.124\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 4174        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019579777 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.3       |\n",
      "|    explained_variance   | -0.00423    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 893         |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -10.388494  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 2.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 534\n",
      "day: 1940, episode: 534\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8059030.83\n",
      "total_reward: -1940969.17\n",
      "total_cost: 131990.17\n",
      "total_trades: 73703\n",
      "Sharpe: 0.077\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 4182        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018161893 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.4       |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 977         |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | 0.30248773  |\n",
      "|    std                  | 3.34        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 535\n",
      "day: 1940, episode: 535\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9708140.63\n",
      "total_reward: -291859.37\n",
      "total_cost: 129650.37\n",
      "total_trades: 73700\n",
      "Sharpe: 0.124\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 4190        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024911718 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.5       |\n",
      "|    explained_variance   | -0.000531   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -7.056037   |\n",
      "|    std                  | 3.35        |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 536\n",
      "day: 1940, episode: 536\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11861457.24\n",
      "total_reward: 1861457.24\n",
      "total_cost: 138136.76\n",
      "total_trades: 73701\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "Episode: 537\n",
      "day: 1940, episode: 537\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8182343.70\n",
      "total_reward: -1817656.30\n",
      "total_cost: 128313.30\n",
      "total_trades: 73701\n",
      "Sharpe: 0.082\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 4198        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014962429 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.6       |\n",
      "|    explained_variance   | 0.0248      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.75e+03    |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | 3.7700224   |\n",
      "|    std                  | 3.36        |\n",
      "|    value_loss           | 3.67e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 538\n",
      "day: 1940, episode: 538\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11285559.20\n",
      "total_reward: 1285559.20\n",
      "total_cost: 140027.80\n",
      "total_trades: 73704\n",
      "Sharpe: 0.195\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 4207        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018988457 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.7       |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 561         |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | -0.76579744 |\n",
      "|    std                  | 3.37        |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 539\n",
      "day: 1940, episode: 539\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8760358.32\n",
      "total_reward: -1239641.68\n",
      "total_cost: 133630.68\n",
      "total_trades: 73695\n",
      "Sharpe: 0.105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 4215        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014420692 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -99.8       |\n",
      "|    explained_variance   | 0.0218      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | 9.210999    |\n",
      "|    std                  | 3.38        |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 540\n",
      "day: 1940, episode: 540\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8485797.23\n",
      "total_reward: -1514202.77\n",
      "total_cost: 136562.77\n",
      "total_trades: 73702\n",
      "Sharpe: 0.089\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 4223        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021237876 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 946         |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | 3.9811065   |\n",
      "|    std                  | 3.39        |\n",
      "|    value_loss           | 2.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 541\n",
      "day: 1940, episode: 541\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7882560.08\n",
      "total_reward: -2117439.92\n",
      "total_cost: 127786.92\n",
      "total_trades: 73699\n",
      "Sharpe: 0.063\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 4231        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013765588 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | 1.5928768   |\n",
      "|    std                  | 3.4         |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 542\n",
      "day: 1940, episode: 542\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11139238.89\n",
      "total_reward: 1139238.89\n",
      "total_cost: 138624.11\n",
      "total_trades: 73705\n",
      "Sharpe: 0.187\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 4239        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019001042 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0391      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 585         |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 1.1508077   |\n",
      "|    std                  | 3.41        |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 543\n",
      "day: 1940, episode: 543\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11921798.00\n",
      "total_reward: 1921798.00\n",
      "total_cost: 151639.00\n",
      "total_trades: 73702\n",
      "Sharpe: 0.220\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 514        |\n",
      "|    time_elapsed         | 4248       |\n",
      "|    total_timesteps      | 1052672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01863718 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -100       |\n",
      "|    explained_variance   | 0.0329     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.06e+03   |\n",
      "|    n_updates            | 5130       |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | -12.346248 |\n",
      "|    std                  | 3.42       |\n",
      "|    value_loss           | 2.95e+03   |\n",
      "----------------------------------------\n",
      "Episode: 544\n",
      "day: 1940, episode: 544\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9056953.98\n",
      "total_reward: -943046.02\n",
      "total_cost: 134310.02\n",
      "total_trades: 73705\n",
      "Sharpe: 0.115\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 4256        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01782259  |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.55e+03    |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -0.18452442 |\n",
      "|    std                  | 3.42        |\n",
      "|    value_loss           | 3.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 545\n",
      "day: 1940, episode: 545\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10707001.65\n",
      "total_reward: 707001.65\n",
      "total_cost: 135626.35\n",
      "total_trades: 73707\n",
      "Sharpe: 0.180\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 4264        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011739005 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.0589      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -33.451958  |\n",
      "|    std                  | 3.43        |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 546\n",
      "day: 1940, episode: 546\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9874744.00\n",
      "total_reward: -125256.00\n",
      "total_cost: 136943.00\n",
      "total_trades: 73711\n",
      "Sharpe: 0.164\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 4273        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015209436 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -100        |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    reward               | -29.470524  |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 4.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 547\n",
      "day: 1940, episode: 547\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11408278.50\n",
      "total_reward: 1408278.50\n",
      "total_cost: 139369.50\n",
      "total_trades: 73707\n",
      "Sharpe: 0.205\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 4281        |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015741797 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89e+03    |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | -4.274005   |\n",
      "|    std                  | 3.44        |\n",
      "|    value_loss           | 3.73e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 548\n",
      "day: 1940, episode: 548\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8698909.97\n",
      "total_reward: -1301090.03\n",
      "total_cost: 133137.03\n",
      "total_trades: 73709\n",
      "Sharpe: 0.113\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 4289        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016789015 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0475      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27e+03    |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    reward               | 7.869518    |\n",
      "|    std                  | 3.45        |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 549\n",
      "day: 1940, episode: 549\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10082008.05\n",
      "total_reward: 82008.05\n",
      "total_cost: 130839.95\n",
      "total_trades: 73700\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 4297        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012516152 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | -6.8978233  |\n",
      "|    std                  | 3.46        |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 550\n",
      "day: 1940, episode: 550\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12098069.04\n",
      "total_reward: 2098069.04\n",
      "total_cost: 131181.96\n",
      "total_trades: 73711\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 4306        |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016848419 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0607      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.2e+03     |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -10.661265  |\n",
      "|    std                  | 3.47        |\n",
      "|    value_loss           | 3.83e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 551\n",
      "day: 1940, episode: 551\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10302547.03\n",
      "total_reward: 302547.03\n",
      "total_cost: 135378.97\n",
      "total_trades: 73706\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 522        |\n",
      "|    time_elapsed         | 4314       |\n",
      "|    total_timesteps      | 1069056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02096193 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.0791     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.52e+03   |\n",
      "|    n_updates            | 5210       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    reward               | -5.236381  |\n",
      "|    std                  | 3.48       |\n",
      "|    value_loss           | 3.04e+03   |\n",
      "----------------------------------------\n",
      "Episode: 552\n",
      "day: 1940, episode: 552\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11263999.47\n",
      "total_reward: 1263999.47\n",
      "total_cost: 139204.53\n",
      "total_trades: 73698\n",
      "Sharpe: 0.196\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 4322        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015133257 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0661      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | 17.828106   |\n",
      "|    std                  | 3.48        |\n",
      "|    value_loss           | 3.73e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 553\n",
      "day: 1940, episode: 553\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9342312.32\n",
      "total_reward: -657687.68\n",
      "total_cost: 133901.68\n",
      "total_trades: 73704\n",
      "Sharpe: 0.135\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 524        |\n",
      "|    time_elapsed         | 4330       |\n",
      "|    total_timesteps      | 1073152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01704458 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.0276     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.95e+03   |\n",
      "|    n_updates            | 5230       |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    reward               | 13.944235  |\n",
      "|    std                  | 3.49       |\n",
      "|    value_loss           | 2.65e+03   |\n",
      "----------------------------------------\n",
      "Episode: 554\n",
      "day: 1940, episode: 554\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9894831.62\n",
      "total_reward: -105168.38\n",
      "total_cost: 137767.38\n",
      "total_trades: 73701\n",
      "Sharpe: 0.150\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 4338        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023910016 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0379      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | -9.185631   |\n",
      "|    std                  | 3.5         |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 555\n",
      "day: 1940, episode: 555\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11226633.19\n",
      "total_reward: 1226633.19\n",
      "total_cost: 141464.81\n",
      "total_trades: 73708\n",
      "Sharpe: 0.192\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 526        |\n",
      "|    time_elapsed         | 4347       |\n",
      "|    total_timesteps      | 1077248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01711222 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -101       |\n",
      "|    explained_variance   | 0.04       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.36e+03   |\n",
      "|    n_updates            | 5250       |\n",
      "|    policy_gradient_loss | -0.0219    |\n",
      "|    reward               | -13.675579 |\n",
      "|    std                  | 3.5        |\n",
      "|    value_loss           | 2.96e+03   |\n",
      "----------------------------------------\n",
      "Episode: 556\n",
      "day: 1940, episode: 556\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11356890.42\n",
      "total_reward: 1356890.42\n",
      "total_cost: 142059.58\n",
      "total_trades: 73701\n",
      "Sharpe: 0.203\n",
      "=================================\n",
      "Episode: 557\n",
      "day: 1940, episode: 557\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11901374.91\n",
      "total_reward: 1901374.91\n",
      "total_cost: 147895.09\n",
      "total_trades: 73710\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 4355        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027895454 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -3.3985507  |\n",
      "|    std                  | 3.51        |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 558\n",
      "day: 1940, episode: 558\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9899394.99\n",
      "total_reward: -100605.01\n",
      "total_cost: 141287.01\n",
      "total_trades: 73706\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 4363        |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015743261 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.0111      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -1.4449788  |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 559\n",
      "day: 1940, episode: 559\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11145398.92\n",
      "total_reward: 1145398.92\n",
      "total_cost: 143734.08\n",
      "total_trades: 73699\n",
      "Sharpe: 0.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 4371        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014532985 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.00393     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 13.825218   |\n",
      "|    std                  | 3.52        |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 560\n",
      "day: 1940, episode: 560\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10685225.26\n",
      "total_reward: 685225.26\n",
      "total_cost: 150055.74\n",
      "total_trades: 73702\n",
      "Sharpe: 0.174\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 4380        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014591197 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -101        |\n",
      "|    explained_variance   | 0.00876     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 951         |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    reward               | -3.668196   |\n",
      "|    std                  | 3.53        |\n",
      "|    value_loss           | 3.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 561\n",
      "day: 1940, episode: 561\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9229770.66\n",
      "total_reward: -770229.34\n",
      "total_cost: 139386.34\n",
      "total_trades: 73704\n",
      "Sharpe: 0.122\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 4388        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015135387 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.00798     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 20.743122   |\n",
      "|    std                  | 3.54        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 562\n",
      "day: 1940, episode: 562\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12897009.35\n",
      "total_reward: 2897009.35\n",
      "total_cost: 147695.65\n",
      "total_trades: 73708\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 4396        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021245869 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.0051     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 787         |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | -7.180682   |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 563\n",
      "day: 1940, episode: 563\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13785711.27\n",
      "total_reward: 3785711.27\n",
      "total_cost: 148535.73\n",
      "total_trades: 73706\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 4405        |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013119368 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.00662     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | -27.151306  |\n",
      "|    std                  | 3.56        |\n",
      "|    value_loss           | 3.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 564\n",
      "day: 1940, episode: 564\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12923978.22\n",
      "total_reward: 2923978.22\n",
      "total_cost: 148817.78\n",
      "total_trades: 73708\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 4413        |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013595112 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 31.335903   |\n",
      "|    std                  | 3.57        |\n",
      "|    value_loss           | 4.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 565\n",
      "day: 1940, episode: 565\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13405884.50\n",
      "total_reward: 3405884.50\n",
      "total_cost: 144413.50\n",
      "total_trades: 73703\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 4421        |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020040132 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.000332   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.26e+03    |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -1.7532434  |\n",
      "|    std                  | 3.58        |\n",
      "|    value_loss           | 5.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 566\n",
      "day: 1940, episode: 566\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11722530.41\n",
      "total_reward: 1722530.41\n",
      "total_cost: 152678.59\n",
      "total_trades: 73709\n",
      "Sharpe: 0.221\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 536        |\n",
      "|    time_elapsed         | 4429       |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01489008 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -102       |\n",
      "|    explained_variance   | -0.00309   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.47e+03   |\n",
      "|    n_updates            | 5350       |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    reward               | -2.4552286 |\n",
      "|    std                  | 3.59       |\n",
      "|    value_loss           | 3.33e+03   |\n",
      "----------------------------------------\n",
      "Episode: 567\n",
      "day: 1940, episode: 567\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11275888.25\n",
      "total_reward: 1275888.25\n",
      "total_cost: 152375.75\n",
      "total_trades: 73707\n",
      "Sharpe: 0.195\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 4437        |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013859813 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.00702    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    reward               | 0.35168666  |\n",
      "|    std                  | 3.6         |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 568\n",
      "day: 1940, episode: 568\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9559148.55\n",
      "total_reward: -440851.45\n",
      "total_cost: 144728.45\n",
      "total_trades: 73702\n",
      "Sharpe: 0.139\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 538         |\n",
      "|    time_elapsed         | 4446        |\n",
      "|    total_timesteps      | 1101824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019179378 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | -2.8033295  |\n",
      "|    std                  | 3.61        |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 569\n",
      "day: 1940, episode: 569\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11942033.29\n",
      "total_reward: 1942033.29\n",
      "total_cost: 148738.71\n",
      "total_trades: 73702\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 4454        |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019267928 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -102        |\n",
      "|    explained_variance   | 0.00578     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 715         |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 16.869312   |\n",
      "|    std                  | 3.62        |\n",
      "|    value_loss           | 2.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 570\n",
      "day: 1940, episode: 570\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10861715.05\n",
      "total_reward: 861715.05\n",
      "total_cost: 152044.95\n",
      "total_trades: 73702\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 540          |\n",
      "|    time_elapsed         | 4462         |\n",
      "|    total_timesteps      | 1105920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135540515 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -102         |\n",
      "|    explained_variance   | -0.00746     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 5390         |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    reward               | 15.61091     |\n",
      "|    std                  | 3.62         |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "Episode: 571\n",
      "day: 1940, episode: 571\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13236814.15\n",
      "total_reward: 3236814.15\n",
      "total_cost: 151121.85\n",
      "total_trades: 73705\n",
      "Sharpe: 0.273\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 4470        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016044434 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.00872     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | -8.949388   |\n",
      "|    std                  | 3.63        |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 572\n",
      "day: 1940, episode: 572\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10140033.89\n",
      "total_reward: 140033.89\n",
      "total_cost: 145472.11\n",
      "total_trades: 73700\n",
      "Sharpe: 0.153\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 542         |\n",
      "|    time_elapsed         | 4478        |\n",
      "|    total_timesteps      | 1110016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020147009 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.0146      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | -4.9653964  |\n",
      "|    std                  | 3.65        |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 573\n",
      "day: 1940, episode: 573\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9261607.43\n",
      "total_reward: -738392.57\n",
      "total_cost: 142943.57\n",
      "total_trades: 73705\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 4487        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018800583 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | -0.00589    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | -4.7772245  |\n",
      "|    std                  | 3.66        |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 574\n",
      "day: 1940, episode: 574\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8901427.72\n",
      "total_reward: -1098572.28\n",
      "total_cost: 151823.28\n",
      "total_trades: 73708\n",
      "Sharpe: 0.105\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 4495        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016716689 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.00484     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 1.6338747   |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 575\n",
      "day: 1940, episode: 575\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10692891.62\n",
      "total_reward: 692891.62\n",
      "total_cost: 148061.38\n",
      "total_trades: 73704\n",
      "Sharpe: 0.177\n",
      "=================================\n",
      "Episode: 576\n",
      "day: 1940, episode: 576\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10014278.59\n",
      "total_reward: 14278.59\n",
      "total_cost: 148755.41\n",
      "total_trades: 73707\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 545         |\n",
      "|    time_elapsed         | 4503        |\n",
      "|    total_timesteps      | 1116160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013165599 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | -0.0071     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | 9.966227    |\n",
      "|    std                  | 3.67        |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 577\n",
      "day: 1940, episode: 577\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11567959.40\n",
      "total_reward: 1567959.40\n",
      "total_cost: 154913.60\n",
      "total_trades: 73706\n",
      "Sharpe: 0.208\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 4511        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022088941 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | -0.000411   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -14.277848  |\n",
      "|    std                  | 3.68        |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 578\n",
      "day: 1940, episode: 578\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8726298.05\n",
      "total_reward: -1273701.95\n",
      "total_cost: 150167.95\n",
      "total_trades: 73707\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 547        |\n",
      "|    time_elapsed         | 4520       |\n",
      "|    total_timesteps      | 1120256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01602212 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.00574    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.09e+03   |\n",
      "|    n_updates            | 5460       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    reward               | 1.6977181  |\n",
      "|    std                  | 3.69       |\n",
      "|    value_loss           | 3.1e+03    |\n",
      "----------------------------------------\n",
      "Episode: 579\n",
      "day: 1940, episode: 579\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12607471.39\n",
      "total_reward: 2607471.39\n",
      "total_cost: 154714.61\n",
      "total_trades: 73706\n",
      "Sharpe: 0.249\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 548        |\n",
      "|    time_elapsed         | 4528       |\n",
      "|    total_timesteps      | 1122304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02126407 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.00155    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 904        |\n",
      "|    n_updates            | 5470       |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    reward               | -2.6751204 |\n",
      "|    std                  | 3.7        |\n",
      "|    value_loss           | 1.81e+03   |\n",
      "----------------------------------------\n",
      "Episode: 580\n",
      "day: 1940, episode: 580\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12257264.92\n",
      "total_reward: 2257264.92\n",
      "total_cost: 151237.08\n",
      "total_trades: 73706\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 549        |\n",
      "|    time_elapsed         | 4536       |\n",
      "|    total_timesteps      | 1124352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01829841 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | 0.00154    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.67e+03   |\n",
      "|    n_updates            | 5480       |\n",
      "|    policy_gradient_loss | -0.00725   |\n",
      "|    reward               | 10.415767  |\n",
      "|    std                  | 3.7        |\n",
      "|    value_loss           | 4.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 581\n",
      "day: 1940, episode: 581\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9164243.32\n",
      "total_reward: -835756.68\n",
      "total_cost: 150144.68\n",
      "total_trades: 73704\n",
      "Sharpe: 0.120\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 550        |\n",
      "|    time_elapsed         | 4545       |\n",
      "|    total_timesteps      | 1126400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01443003 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -103       |\n",
      "|    explained_variance   | -0.0101    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1e+03      |\n",
      "|    n_updates            | 5490       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    reward               | 16.84614   |\n",
      "|    std                  | 3.71       |\n",
      "|    value_loss           | 3.39e+03   |\n",
      "----------------------------------------\n",
      "Episode: 582\n",
      "day: 1940, episode: 582\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13588513.43\n",
      "total_reward: 3588513.43\n",
      "total_cost: 159247.57\n",
      "total_trades: 73705\n",
      "Sharpe: 0.288\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 4553        |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014192951 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -103        |\n",
      "|    explained_variance   | 0.0154      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    reward               | -21.493551  |\n",
      "|    std                  | 3.71        |\n",
      "|    value_loss           | 2.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 583\n",
      "day: 1940, episode: 583\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9884411.96\n",
      "total_reward: -115588.04\n",
      "total_cost: 151842.04\n",
      "total_trades: 73701\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 552       |\n",
      "|    time_elapsed         | 4561      |\n",
      "|    total_timesteps      | 1130496   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0181017 |\n",
      "|    clip_fraction        | 0.174     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -103      |\n",
      "|    explained_variance   | -0.00296  |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 2.5e+03   |\n",
      "|    n_updates            | 5510      |\n",
      "|    policy_gradient_loss | -0.0178   |\n",
      "|    reward               | -82.03946 |\n",
      "|    std                  | 3.72      |\n",
      "|    value_loss           | 3.47e+03  |\n",
      "---------------------------------------\n",
      "Episode: 584\n",
      "day: 1940, episode: 584\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9291090.71\n",
      "total_reward: -708909.29\n",
      "total_cost: 143333.29\n",
      "total_trades: 73707\n",
      "Sharpe: 0.130\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 553        |\n",
      "|    time_elapsed         | 4569       |\n",
      "|    total_timesteps      | 1132544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01000287 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | -0.00211   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.19e+03   |\n",
      "|    n_updates            | 5520       |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    reward               | -53.01484  |\n",
      "|    std                  | 3.73       |\n",
      "|    value_loss           | 2.56e+03   |\n",
      "----------------------------------------\n",
      "Episode: 585\n",
      "day: 1940, episode: 585\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10036285.66\n",
      "total_reward: 36285.66\n",
      "total_cost: 147434.34\n",
      "total_trades: 73706\n",
      "Sharpe: 0.153\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 4577        |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018131759 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0212      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | -39.831047  |\n",
      "|    std                  | 3.73        |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 586\n",
      "day: 1940, episode: 586\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10451832.28\n",
      "total_reward: 451832.28\n",
      "total_cost: 140112.72\n",
      "total_trades: 73706\n",
      "Sharpe: 0.158\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 4585        |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010699396 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0121      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -6.569077   |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 587\n",
      "day: 1940, episode: 587\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11179614.54\n",
      "total_reward: 1179614.54\n",
      "total_cost: 147371.46\n",
      "total_trades: 73704\n",
      "Sharpe: 0.187\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 4593        |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010652581 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.00588     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 8.239292    |\n",
      "|    std                  | 3.74        |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 588\n",
      "day: 1940, episode: 588\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9570972.83\n",
      "total_reward: -429027.17\n",
      "total_cost: 146859.17\n",
      "total_trades: 73708\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 4601        |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023042373 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.00829     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    reward               | 10.631959   |\n",
      "|    std                  | 3.75        |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 589\n",
      "day: 1940, episode: 589\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11690681.71\n",
      "total_reward: 1690681.71\n",
      "total_cost: 158135.29\n",
      "total_trades: 73698\n",
      "Sharpe: 0.210\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 4610        |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013578868 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | -0.00634    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    reward               | -24.50705   |\n",
      "|    std                  | 3.76        |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 590\n",
      "day: 1940, episode: 590\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9765820.66\n",
      "total_reward: -234179.34\n",
      "total_cost: 146396.34\n",
      "total_trades: 73705\n",
      "Sharpe: 0.148\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 559        |\n",
      "|    time_elapsed         | 4618       |\n",
      "|    total_timesteps      | 1144832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01439032 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -104       |\n",
      "|    explained_variance   | -0.000405  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.29e+03   |\n",
      "|    n_updates            | 5580       |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    reward               | 1.4434017  |\n",
      "|    std                  | 3.77       |\n",
      "|    value_loss           | 2.62e+03   |\n",
      "----------------------------------------\n",
      "Episode: 591\n",
      "day: 1940, episode: 591\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10237447.49\n",
      "total_reward: 237447.49\n",
      "total_cost: 145330.51\n",
      "total_trades: 73704\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 4626        |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013689151 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -3.2346206  |\n",
      "|    std                  | 3.77        |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 592\n",
      "day: 1940, episode: 592\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12236730.43\n",
      "total_reward: 2236730.43\n",
      "total_cost: 153874.57\n",
      "total_trades: 73705\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 4634        |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011797158 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | -12.894909  |\n",
      "|    std                  | 3.78        |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 593\n",
      "day: 1940, episode: 593\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16534530.25\n",
      "total_reward: 6534530.25\n",
      "total_cost: 147212.75\n",
      "total_trades: 73699\n",
      "Sharpe: 0.385\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 4642        |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013598977 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | -0.0113     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | -19.95269   |\n",
      "|    std                  | 3.8         |\n",
      "|    value_loss           | 4.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 594\n",
      "day: 1940, episode: 594\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9397915.56\n",
      "total_reward: -602084.44\n",
      "total_cost: 134690.44\n",
      "total_trades: 73702\n",
      "Sharpe: 0.130\n",
      "=================================\n",
      "Episode: 595\n",
      "day: 1940, episode: 595\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13744487.50\n",
      "total_reward: 3744487.50\n",
      "total_cost: 142157.50\n",
      "total_trades: 73707\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 4650        |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014834088 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 810         |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    reward               | 2.1678529   |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 596\n",
      "day: 1940, episode: 596\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14957873.49\n",
      "total_reward: 4957873.49\n",
      "total_cost: 151532.51\n",
      "total_trades: 73707\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 564         |\n",
      "|    time_elapsed         | 4658        |\n",
      "|    total_timesteps      | 1155072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025937172 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -104        |\n",
      "|    explained_variance   | 0.00974     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    reward               | 8.701382    |\n",
      "|    std                  | 3.81        |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 597\n",
      "day: 1940, episode: 597\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8414973.48\n",
      "total_reward: -1585026.52\n",
      "total_cost: 145213.52\n",
      "total_trades: 73708\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 4666        |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017477624 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.0139     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    reward               | 0.04546619  |\n",
      "|    std                  | 3.82        |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 598\n",
      "day: 1940, episode: 598\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14796828.80\n",
      "total_reward: 4796828.80\n",
      "total_cost: 163070.20\n",
      "total_trades: 73705\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 566        |\n",
      "|    time_elapsed         | 4674       |\n",
      "|    total_timesteps      | 1159168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01786808 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | 0.0189     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.05e+03   |\n",
      "|    n_updates            | 5650       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    reward               | -1.1051546 |\n",
      "|    std                  | 3.83       |\n",
      "|    value_loss           | 2.05e+03   |\n",
      "----------------------------------------\n",
      "Episode: 599\n",
      "day: 1940, episode: 599\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9151637.81\n",
      "total_reward: -848362.19\n",
      "total_cost: 147335.19\n",
      "total_trades: 73716\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 4683        |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012759141 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.000714   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    reward               | -1.9285598  |\n",
      "|    std                  | 3.84        |\n",
      "|    value_loss           | 3.31e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 600\n",
      "day: 1940, episode: 600\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9762262.77\n",
      "total_reward: -237737.23\n",
      "total_cost: 153097.23\n",
      "total_trades: 73706\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 4691        |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020200862 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.00752    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | 8.245102    |\n",
      "|    std                  | 3.85        |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 601\n",
      "day: 1940, episode: 601\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14699778.20\n",
      "total_reward: 4699778.20\n",
      "total_cost: 158940.80\n",
      "total_trades: 73701\n",
      "Sharpe: 0.329\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 4699        |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011553963 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.00775    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 913         |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | -2.778076   |\n",
      "|    std                  | 3.86        |\n",
      "|    value_loss           | 2.29e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 602\n",
      "day: 1940, episode: 602\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11703124.55\n",
      "total_reward: 1703124.55\n",
      "total_cost: 148480.45\n",
      "total_trades: 73704\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 570        |\n",
      "|    time_elapsed         | 4708       |\n",
      "|    total_timesteps      | 1167360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01887164 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | -0.00375   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.01e+03   |\n",
      "|    n_updates            | 5690       |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    reward               | -2.1031487 |\n",
      "|    std                  | 3.87       |\n",
      "|    value_loss           | 4.28e+03   |\n",
      "----------------------------------------\n",
      "Episode: 603\n",
      "day: 1940, episode: 603\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10723085.12\n",
      "total_reward: 723085.12\n",
      "total_cost: 150246.88\n",
      "total_trades: 73700\n",
      "Sharpe: 0.177\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 4717        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013665951 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.00298    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 780         |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    reward               | 40.49942    |\n",
      "|    std                  | 3.88        |\n",
      "|    value_loss           | 2.8e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 604\n",
      "day: 1940, episode: 604\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13145135.14\n",
      "total_reward: 3145135.14\n",
      "total_cost: 157499.86\n",
      "total_trades: 73701\n",
      "Sharpe: 0.273\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 572        |\n",
      "|    time_elapsed         | 4725       |\n",
      "|    total_timesteps      | 1171456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01787499 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | -0.0179    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.94e+03   |\n",
      "|    n_updates            | 5710       |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    reward               | -0.4661518 |\n",
      "|    std                  | 3.89       |\n",
      "|    value_loss           | 3.47e+03   |\n",
      "----------------------------------------\n",
      "Episode: 605\n",
      "day: 1940, episode: 605\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9715155.84\n",
      "total_reward: -284844.16\n",
      "total_cost: 145013.16\n",
      "total_trades: 73712\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 573        |\n",
      "|    time_elapsed         | 4733       |\n",
      "|    total_timesteps      | 1173504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02206035 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -105       |\n",
      "|    explained_variance   | -0.0152    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.14e+03   |\n",
      "|    n_updates            | 5720       |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    reward               | 6.4335666  |\n",
      "|    std                  | 3.9        |\n",
      "|    value_loss           | 2.29e+03   |\n",
      "----------------------------------------\n",
      "Episode: 606\n",
      "day: 1940, episode: 606\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14332058.96\n",
      "total_reward: 4332058.96\n",
      "total_cost: 155786.04\n",
      "total_trades: 73711\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 4742        |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015427776 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.00727    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    reward               | -2.8945558  |\n",
      "|    std                  | 3.91        |\n",
      "|    value_loss           | 3.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 607\n",
      "day: 1940, episode: 607\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9916210.79\n",
      "total_reward: -83789.21\n",
      "total_cost: 151009.21\n",
      "total_trades: 73706\n",
      "Sharpe: 0.159\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 4751        |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022883987 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -105        |\n",
      "|    explained_variance   | -0.00326    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 33.018192   |\n",
      "|    std                  | 3.92        |\n",
      "|    value_loss           | 2.41e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 608\n",
      "day: 1940, episode: 608\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13726320.02\n",
      "total_reward: 3726320.02\n",
      "total_cost: 153376.98\n",
      "total_trades: 73708\n",
      "Sharpe: 0.292\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 4759        |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014430398 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.00345     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    reward               | -13.219496  |\n",
      "|    std                  | 3.93        |\n",
      "|    value_loss           | 3.28e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 609\n",
      "day: 1940, episode: 609\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10640304.32\n",
      "total_reward: 640304.32\n",
      "total_cost: 149099.68\n",
      "total_trades: 73706\n",
      "Sharpe: 0.185\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 4768        |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017817762 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | -0.00819    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -4.289323   |\n",
      "|    std                  | 3.94        |\n",
      "|    value_loss           | 2.57e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 610\n",
      "day: 1940, episode: 610\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10403730.13\n",
      "total_reward: 403730.13\n",
      "total_cost: 143044.87\n",
      "total_trades: 73707\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 4777        |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019008592 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | -0.000565   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 788         |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | -9.132706   |\n",
      "|    std                  | 3.96        |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 611\n",
      "day: 1940, episode: 611\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 16192211.17\n",
      "total_reward: 6192211.17\n",
      "total_cost: 148566.83\n",
      "total_trades: 73705\n",
      "Sharpe: 0.373\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 4786        |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016843151 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.00135     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | 0.52563614  |\n",
      "|    std                  | 3.97        |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 612\n",
      "day: 1940, episode: 612\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10157296.96\n",
      "total_reward: 157296.96\n",
      "total_cost: 143890.04\n",
      "total_trades: 73706\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 4794        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016379923 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | -0.0169     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 949         |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -2.3533223  |\n",
      "|    std                  | 3.99        |\n",
      "|    value_loss           | 2.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 613\n",
      "day: 1940, episode: 613\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10515271.08\n",
      "total_reward: 515271.08\n",
      "total_cost: 147532.92\n",
      "total_trades: 73702\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "Episode: 614\n",
      "day: 1940, episode: 614\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9160191.54\n",
      "total_reward: -839808.46\n",
      "total_cost: 135644.46\n",
      "total_trades: 73706\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 4802        |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020654367 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | -0.0153     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | 20.70464    |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 2.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 615\n",
      "day: 1940, episode: 615\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12278704.21\n",
      "total_reward: 2278704.21\n",
      "total_cost: 148802.79\n",
      "total_trades: 73708\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 582         |\n",
      "|    time_elapsed         | 4810        |\n",
      "|    total_timesteps      | 1191936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016294593 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | 0.00228     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 921         |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    reward               | 22.184944   |\n",
      "|    std                  | 4           |\n",
      "|    value_loss           | 2.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 616\n",
      "day: 1940, episode: 616\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9617663.86\n",
      "total_reward: -382336.14\n",
      "total_cost: 141238.14\n",
      "total_trades: 73704\n",
      "Sharpe: 0.136\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 4818        |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014800884 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -106        |\n",
      "|    explained_variance   | -0.0061     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -3.707276   |\n",
      "|    std                  | 4.01        |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 617\n",
      "day: 1940, episode: 617\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12230660.45\n",
      "total_reward: 2230660.45\n",
      "total_cost: 136694.55\n",
      "total_trades: 73708\n",
      "Sharpe: 0.241\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 584          |\n",
      "|    time_elapsed         | 4826         |\n",
      "|    total_timesteps      | 1196032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150091285 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -106         |\n",
      "|    explained_variance   | 0.0102       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 874          |\n",
      "|    n_updates            | 5830         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    reward               | -1.9218252   |\n",
      "|    std                  | 4.03         |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Episode: 618\n",
      "day: 1940, episode: 618\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9750518.68\n",
      "total_reward: -249481.32\n",
      "total_cost: 138575.32\n",
      "total_trades: 73709\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 585        |\n",
      "|    time_elapsed         | 4834       |\n",
      "|    total_timesteps      | 1198080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01965609 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.0094     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.88e+03   |\n",
      "|    n_updates            | 5840       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    reward               | -11.014055 |\n",
      "|    std                  | 4.04       |\n",
      "|    value_loss           | 3.53e+03   |\n",
      "----------------------------------------\n",
      "Episode: 619\n",
      "day: 1940, episode: 619\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10323537.05\n",
      "total_reward: 323537.05\n",
      "total_cost: 141390.95\n",
      "total_trades: 73708\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 586         |\n",
      "|    time_elapsed         | 4843        |\n",
      "|    total_timesteps      | 1200128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021866404 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.01        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 580         |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    reward               | 4.4244947   |\n",
      "|    std                  | 4.05        |\n",
      "|    value_loss           | 2.21e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 620\n",
      "day: 1940, episode: 620\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11841651.05\n",
      "total_reward: 1841651.05\n",
      "total_cost: 146866.95\n",
      "total_trades: 73707\n",
      "Sharpe: 0.223\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 4851        |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016279696 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 9.573153    |\n",
      "|    std                  | 4.07        |\n",
      "|    value_loss           | 2.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 621\n",
      "day: 1940, episode: 621\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12771374.65\n",
      "total_reward: 2771374.65\n",
      "total_cost: 143669.35\n",
      "total_trades: 73708\n",
      "Sharpe: 0.256\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 588        |\n",
      "|    time_elapsed         | 4859       |\n",
      "|    total_timesteps      | 1204224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01707793 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.0129     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.47e+03   |\n",
      "|    n_updates            | 5870       |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    reward               | 5.39213    |\n",
      "|    std                  | 4.07       |\n",
      "|    value_loss           | 3.12e+03   |\n",
      "----------------------------------------\n",
      "Episode: 622\n",
      "day: 1940, episode: 622\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12194743.52\n",
      "total_reward: 2194743.52\n",
      "total_cost: 142945.48\n",
      "total_trades: 73699\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 4867        |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020825515 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0257      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.67e+03    |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | 2.6024542   |\n",
      "|    std                  | 4.08        |\n",
      "|    value_loss           | 4.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 623\n",
      "day: 1940, episode: 623\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12940009.84\n",
      "total_reward: 2940009.84\n",
      "total_cost: 145777.16\n",
      "total_trades: 73704\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 4876        |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011934975 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | -0.00498    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.12e+03    |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | -0.02698095 |\n",
      "|    std                  | 4.1         |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 624\n",
      "day: 1940, episode: 624\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9448191.01\n",
      "total_reward: -551808.99\n",
      "total_cost: 139418.99\n",
      "total_trades: 73704\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 591        |\n",
      "|    time_elapsed         | 4884       |\n",
      "|    total_timesteps      | 1210368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01708368 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -107       |\n",
      "|    explained_variance   | 0.0114     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 910        |\n",
      "|    n_updates            | 5900       |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    reward               | -2.5099747 |\n",
      "|    std                  | 4.1        |\n",
      "|    value_loss           | 2.92e+03   |\n",
      "----------------------------------------\n",
      "Episode: 625\n",
      "day: 1940, episode: 625\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11034377.78\n",
      "total_reward: 1034377.78\n",
      "total_cost: 136660.22\n",
      "total_trades: 73709\n",
      "Sharpe: 0.191\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 592          |\n",
      "|    time_elapsed         | 4892         |\n",
      "|    total_timesteps      | 1212416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105475485 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -107         |\n",
      "|    explained_variance   | -0.00773     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 820          |\n",
      "|    n_updates            | 5910         |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    reward               | 0.60214263   |\n",
      "|    std                  | 4.11         |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "Episode: 626\n",
      "day: 1940, episode: 626\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11205427.12\n",
      "total_reward: 1205427.12\n",
      "total_cost: 144534.88\n",
      "total_trades: 73703\n",
      "Sharpe: 0.189\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 4900        |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024000823 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    reward               | -2.0566711  |\n",
      "|    std                  | 4.12        |\n",
      "|    value_loss           | 3.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 627\n",
      "day: 1940, episode: 627\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9946576.31\n",
      "total_reward: -53423.69\n",
      "total_cost: 145141.69\n",
      "total_trades: 73709\n",
      "Sharpe: 0.155\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 4908        |\n",
      "|    total_timesteps      | 1216512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014786005 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -107        |\n",
      "|    explained_variance   | 0.0099      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 998         |\n",
      "|    n_updates            | 5930        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    reward               | 20.10636    |\n",
      "|    std                  | 4.14        |\n",
      "|    value_loss           | 2.56e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 628\n",
      "day: 1940, episode: 628\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12358852.89\n",
      "total_reward: 2358852.89\n",
      "total_cost: 149510.11\n",
      "total_trades: 73709\n",
      "Sharpe: 0.239\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 595        |\n",
      "|    time_elapsed         | 4917       |\n",
      "|    total_timesteps      | 1218560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01121333 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | -0.00915   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.03e+03   |\n",
      "|    n_updates            | 5940       |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    reward               | -33.268097 |\n",
      "|    std                  | 4.15       |\n",
      "|    value_loss           | 3.27e+03   |\n",
      "----------------------------------------\n",
      "Episode: 629\n",
      "day: 1940, episode: 629\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10523999.43\n",
      "total_reward: 523999.43\n",
      "total_cost: 145581.57\n",
      "total_trades: 73703\n",
      "Sharpe: 0.188\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 4925        |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012349412 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.00815     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    reward               | -3.011403   |\n",
      "|    std                  | 4.15        |\n",
      "|    value_loss           | 3.12e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 630\n",
      "day: 1940, episode: 630\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12746527.25\n",
      "total_reward: 2746527.25\n",
      "total_cost: 147209.75\n",
      "total_trades: 73711\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 4933        |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012319777 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.0129      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.39e+03    |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 6.713557    |\n",
      "|    std                  | 4.16        |\n",
      "|    value_loss           | 3.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 631\n",
      "day: 1940, episode: 631\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13688984.36\n",
      "total_reward: 3688984.36\n",
      "total_cost: 155661.64\n",
      "total_trades: 73702\n",
      "Sharpe: 0.291\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 4941        |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013832866 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.85e+03    |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -13.598623  |\n",
      "|    std                  | 4.17        |\n",
      "|    value_loss           | 3.94e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 632\n",
      "day: 1940, episode: 632\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9092523.86\n",
      "total_reward: -907476.14\n",
      "total_cost: 138896.14\n",
      "total_trades: 73710\n",
      "Sharpe: 0.126\n",
      "=================================\n",
      "Episode: 633\n",
      "day: 1940, episode: 633\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8860467.00\n",
      "total_reward: -1139533.00\n",
      "total_cost: 132893.00\n",
      "total_trades: 73708\n",
      "Sharpe: 0.109\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 4950        |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017013144 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.000461    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 817         |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | 1.2496401   |\n",
      "|    std                  | 4.18        |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 634\n",
      "day: 1940, episode: 634\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13663046.66\n",
      "total_reward: 3663046.66\n",
      "total_cost: 152036.34\n",
      "total_trades: 73706\n",
      "Sharpe: 0.290\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 4958        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018548219 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.00303     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 768         |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -8.20145    |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 635\n",
      "day: 1940, episode: 635\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9468565.54\n",
      "total_reward: -531434.46\n",
      "total_cost: 134405.46\n",
      "total_trades: 73706\n",
      "Sharpe: 0.128\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 601         |\n",
      "|    time_elapsed         | 4966        |\n",
      "|    total_timesteps      | 1230848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017399034 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.13e+03    |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 8.067325    |\n",
      "|    std                  | 4.2         |\n",
      "|    value_loss           | 3.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 636\n",
      "day: 1940, episode: 636\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13309485.43\n",
      "total_reward: 3309485.43\n",
      "total_cost: 152065.57\n",
      "total_trades: 73699\n",
      "Sharpe: 0.277\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 602        |\n",
      "|    time_elapsed         | 4974       |\n",
      "|    total_timesteps      | 1232896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01965129 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.0732     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 558        |\n",
      "|    n_updates            | 6010       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    reward               | -8.879406  |\n",
      "|    std                  | 4.22       |\n",
      "|    value_loss           | 2.26e+03   |\n",
      "----------------------------------------\n",
      "Episode: 637\n",
      "day: 1940, episode: 637\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13019734.73\n",
      "total_reward: 3019734.73\n",
      "total_cost: 152413.27\n",
      "total_trades: 73707\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 4983        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014722958 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    reward               | -11.162862  |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 3.81e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 638\n",
      "day: 1940, episode: 638\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9896547.38\n",
      "total_reward: -103452.62\n",
      "total_cost: 146834.62\n",
      "total_trades: 73709\n",
      "Sharpe: 0.164\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 4991        |\n",
      "|    total_timesteps      | 1236992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013906047 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -108        |\n",
      "|    explained_variance   | 0.021       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | -0.59246266 |\n",
      "|    std                  | 4.23        |\n",
      "|    value_loss           | 3.34e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 639\n",
      "day: 1940, episode: 639\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12367716.87\n",
      "total_reward: 2367716.87\n",
      "total_cost: 153062.13\n",
      "total_trades: 73711\n",
      "Sharpe: 0.258\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 605        |\n",
      "|    time_elapsed         | 5000       |\n",
      "|    total_timesteps      | 1239040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01528955 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -108       |\n",
      "|    explained_variance   | 0.042      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.06e+03   |\n",
      "|    n_updates            | 6040       |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    reward               | 3.1265354  |\n",
      "|    std                  | 4.24       |\n",
      "|    value_loss           | 2.48e+03   |\n",
      "----------------------------------------\n",
      "Episode: 640\n",
      "day: 1940, episode: 640\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10153437.34\n",
      "total_reward: 153437.34\n",
      "total_cost: 143005.66\n",
      "total_trades: 73708\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 5008        |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015455365 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | -0.0017     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 892         |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | 48.169537   |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 641\n",
      "day: 1940, episode: 641\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12033771.93\n",
      "total_reward: 2033771.93\n",
      "total_cost: 140673.07\n",
      "total_trades: 73702\n",
      "Sharpe: 0.227\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 5016        |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023896798 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | -0.17081167 |\n",
      "|    std                  | 4.26        |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 642\n",
      "day: 1940, episode: 642\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12832872.68\n",
      "total_reward: 2832872.68\n",
      "total_cost: 147759.32\n",
      "total_trades: 73711\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 5024        |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012384853 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0158      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.21e+03    |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 30.142796   |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 643\n",
      "day: 1940, episode: 643\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11649785.79\n",
      "total_reward: 1649785.79\n",
      "total_cost: 153044.21\n",
      "total_trades: 73709\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 5033        |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012735989 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | -4.344975   |\n",
      "|    std                  | 4.27        |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 644\n",
      "day: 1940, episode: 644\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14518718.97\n",
      "total_reward: 4518718.97\n",
      "total_cost: 150707.03\n",
      "total_trades: 73708\n",
      "Sharpe: 0.321\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 610        |\n",
      "|    time_elapsed         | 5041       |\n",
      "|    total_timesteps      | 1249280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01277985 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -109       |\n",
      "|    explained_variance   | 0.0121     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.95e+03   |\n",
      "|    n_updates            | 6090       |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    reward               | -1.5744995 |\n",
      "|    std                  | 4.29       |\n",
      "|    value_loss           | 3.65e+03   |\n",
      "----------------------------------------\n",
      "Episode: 645\n",
      "day: 1940, episode: 645\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8724293.85\n",
      "total_reward: -1275706.15\n",
      "total_cost: 137071.15\n",
      "total_trades: 73703\n",
      "Sharpe: 0.104\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 5049        |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023680666 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 936         |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    reward               | 20.187119   |\n",
      "|    std                  | 4.3         |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 646\n",
      "day: 1940, episode: 646\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14803150.45\n",
      "total_reward: 4803150.45\n",
      "total_cost: 156844.55\n",
      "total_trades: 73704\n",
      "Sharpe: 0.331\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 5057        |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016075648 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0759      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | -9.0212     |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 3.35e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 647\n",
      "day: 1940, episode: 647\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10791550.22\n",
      "total_reward: 791550.22\n",
      "total_cost: 151549.78\n",
      "total_trades: 73707\n",
      "Sharpe: 0.177\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 5065        |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012864914 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | -0.00629    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    reward               | -11.012006  |\n",
      "|    std                  | 4.31        |\n",
      "|    value_loss           | 3.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 648\n",
      "day: 1940, episode: 648\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12023461.02\n",
      "total_reward: 2023461.02\n",
      "total_cost: 147643.98\n",
      "total_trades: 73703\n",
      "Sharpe: 0.226\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 5073        |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019990692 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.83e+03    |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -28.120682  |\n",
      "|    std                  | 4.32        |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 649\n",
      "day: 1940, episode: 649\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14461386.54\n",
      "total_reward: 4461386.54\n",
      "total_cost: 157765.46\n",
      "total_trades: 73706\n",
      "Sharpe: 0.320\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 5081        |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015813604 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    reward               | -0.54944265 |\n",
      "|    std                  | 4.33        |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 650\n",
      "day: 1940, episode: 650\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10181102.60\n",
      "total_reward: 181102.60\n",
      "total_cost: 144261.40\n",
      "total_trades: 73709\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 5090        |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013917662 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0428      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    reward               | -0.88771904 |\n",
      "|    std                  | 4.34        |\n",
      "|    value_loss           | 2.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 651\n",
      "day: 1940, episode: 651\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14712592.56\n",
      "total_reward: 4712592.56\n",
      "total_cost: 153946.44\n",
      "total_trades: 73708\n",
      "Sharpe: 0.328\n",
      "=================================\n",
      "Episode: 652\n",
      "day: 1940, episode: 652\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9275344.95\n",
      "total_reward: -724655.05\n",
      "total_cost: 146829.05\n",
      "total_trades: 73708\n",
      "Sharpe: 0.134\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 5098        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015084685 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -109        |\n",
      "|    explained_variance   | 0.0412      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    reward               | -0.43151844 |\n",
      "|    std                  | 4.35        |\n",
      "|    value_loss           | 3.52e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 653\n",
      "day: 1940, episode: 653\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12707697.43\n",
      "total_reward: 2707697.43\n",
      "total_cost: 159844.57\n",
      "total_trades: 73705\n",
      "Sharpe: 0.252\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 618          |\n",
      "|    time_elapsed         | 5106         |\n",
      "|    total_timesteps      | 1265664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115075745 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -110         |\n",
      "|    explained_variance   | -0.00621     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 958          |\n",
      "|    n_updates            | 6170         |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    reward               | -9.242675    |\n",
      "|    std                  | 4.37         |\n",
      "|    value_loss           | 2.43e+03     |\n",
      "------------------------------------------\n",
      "Episode: 654\n",
      "day: 1940, episode: 654\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12337328.97\n",
      "total_reward: 2337328.97\n",
      "total_cost: 152875.03\n",
      "total_trades: 73709\n",
      "Sharpe: 0.243\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 619        |\n",
      "|    time_elapsed         | 5114       |\n",
      "|    total_timesteps      | 1267712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01171899 |\n",
      "|    clip_fraction        | 0.118      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.0335     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.64e+03   |\n",
      "|    n_updates            | 6180       |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    reward               | -9.359527  |\n",
      "|    std                  | 4.37       |\n",
      "|    value_loss           | 3.51e+03   |\n",
      "----------------------------------------\n",
      "Episode: 655\n",
      "day: 1940, episode: 655\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10142576.86\n",
      "total_reward: 142576.86\n",
      "total_cost: 149182.14\n",
      "total_trades: 73710\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 620        |\n",
      "|    time_elapsed         | 5123       |\n",
      "|    total_timesteps      | 1269760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01591831 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.00711    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.27e+03   |\n",
      "|    n_updates            | 6190       |\n",
      "|    policy_gradient_loss | -0.0149    |\n",
      "|    reward               | -2.698437  |\n",
      "|    std                  | 4.38       |\n",
      "|    value_loss           | 4.18e+03   |\n",
      "----------------------------------------\n",
      "Episode: 656\n",
      "day: 1940, episode: 656\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9407529.15\n",
      "total_reward: -592470.85\n",
      "total_cost: 150915.85\n",
      "total_trades: 73707\n",
      "Sharpe: 0.141\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 621        |\n",
      "|    time_elapsed         | 5131       |\n",
      "|    total_timesteps      | 1271808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01524745 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.0156     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.14e+03   |\n",
      "|    n_updates            | 6200       |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    reward               | 4.8143935  |\n",
      "|    std                  | 4.39       |\n",
      "|    value_loss           | 2.57e+03   |\n",
      "----------------------------------------\n",
      "Episode: 657\n",
      "day: 1940, episode: 657\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10751233.30\n",
      "total_reward: 751233.30\n",
      "total_cost: 156688.70\n",
      "total_trades: 73712\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 5140        |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023442026 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.0079      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | 1.0558621   |\n",
      "|    std                  | 4.4         |\n",
      "|    value_loss           | 2.46e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 658\n",
      "day: 1940, episode: 658\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11005964.02\n",
      "total_reward: 1005964.02\n",
      "total_cost: 149291.98\n",
      "total_trades: 73709\n",
      "Sharpe: 0.181\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 5148        |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014907871 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | -0.00128    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.22e+03    |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -9.131594   |\n",
      "|    std                  | 4.41        |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 659\n",
      "day: 1940, episode: 659\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8316728.47\n",
      "total_reward: -1683271.53\n",
      "total_cost: 149520.53\n",
      "total_trades: 73707\n",
      "Sharpe: 0.071\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 5156        |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017964222 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 957         |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -13.260565  |\n",
      "|    std                  | 4.43        |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 660\n",
      "day: 1940, episode: 660\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10277877.81\n",
      "total_reward: 277877.81\n",
      "total_cost: 148500.19\n",
      "total_trades: 73703\n",
      "Sharpe: 0.172\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 5165        |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015749536 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | 0.00521     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 850         |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    reward               | 7.9285665   |\n",
      "|    std                  | 4.44        |\n",
      "|    value_loss           | 2.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 661\n",
      "day: 1940, episode: 661\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10870104.99\n",
      "total_reward: 870104.99\n",
      "total_cost: 142518.01\n",
      "total_trades: 73706\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 626        |\n",
      "|    time_elapsed         | 5174       |\n",
      "|    total_timesteps      | 1282048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01749907 |\n",
      "|    clip_fraction        | 0.173      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -110       |\n",
      "|    explained_variance   | 0.00926    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.03e+03   |\n",
      "|    n_updates            | 6250       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    reward               | 8.673264   |\n",
      "|    std                  | 4.45       |\n",
      "|    value_loss           | 3.56e+03   |\n",
      "----------------------------------------\n",
      "Episode: 662\n",
      "day: 1940, episode: 662\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9339026.39\n",
      "total_reward: -660973.61\n",
      "total_cost: 145162.61\n",
      "total_trades: 73702\n",
      "Sharpe: 0.124\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 5182        |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015955772 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -110        |\n",
      "|    explained_variance   | -0.00812    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 877         |\n",
      "|    n_updates            | 6260        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -1.7915986  |\n",
      "|    std                  | 4.47        |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 663\n",
      "day: 1940, episode: 663\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12625310.00\n",
      "total_reward: 2625310.00\n",
      "total_cost: 150414.00\n",
      "total_trades: 73706\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 5190        |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012593749 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.00308     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.7e+03     |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    reward               | 9.412418    |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 664\n",
      "day: 1940, episode: 664\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9357543.13\n",
      "total_reward: -642456.87\n",
      "total_cost: 150541.87\n",
      "total_trades: 73710\n",
      "Sharpe: 0.133\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 5198        |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018466786 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | -20.38405   |\n",
      "|    std                  | 4.49        |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 665\n",
      "day: 1940, episode: 665\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13796967.80\n",
      "total_reward: 3796967.80\n",
      "total_cost: 158535.20\n",
      "total_trades: 73705\n",
      "Sharpe: 0.295\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 630          |\n",
      "|    time_elapsed         | 5207         |\n",
      "|    total_timesteps      | 1290240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151426215 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -111         |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 6290         |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    reward               | 7.80071      |\n",
      "|    std                  | 4.5          |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "Episode: 666\n",
      "day: 1940, episode: 666\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9465594.87\n",
      "total_reward: -534405.13\n",
      "total_cost: 152975.13\n",
      "total_trades: 73711\n",
      "Sharpe: 0.134\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 5215        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015864303 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.00143     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    reward               | 12.656482   |\n",
      "|    std                  | 4.52        |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 667\n",
      "day: 1940, episode: 667\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10135943.65\n",
      "total_reward: 135943.65\n",
      "total_cost: 147219.35\n",
      "total_trades: 73708\n",
      "Sharpe: 0.161\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 5223        |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014178423 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.00485     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | 11.223661   |\n",
      "|    std                  | 4.53        |\n",
      "|    value_loss           | 2.03e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 668\n",
      "day: 1940, episode: 668\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9753254.67\n",
      "total_reward: -246745.33\n",
      "total_cost: 154411.33\n",
      "total_trades: 73705\n",
      "Sharpe: 0.133\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 5231        |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019219074 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 692         |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | 6.2140455   |\n",
      "|    std                  | 4.54        |\n",
      "|    value_loss           | 2.53e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 669\n",
      "day: 1940, episode: 669\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8086372.09\n",
      "total_reward: -1913627.91\n",
      "total_cost: 145259.91\n",
      "total_trades: 73712\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 5239        |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016264226 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | -0.0103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    reward               | -4.6843066  |\n",
      "|    std                  | 4.55        |\n",
      "|    value_loss           | 2.12e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 670\n",
      "day: 1940, episode: 670\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10674398.62\n",
      "total_reward: 674398.62\n",
      "total_cost: 146411.38\n",
      "total_trades: 73709\n",
      "Sharpe: 0.165\n",
      "=================================\n",
      "Episode: 671\n",
      "day: 1940, episode: 671\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13624264.31\n",
      "total_reward: 3624264.31\n",
      "total_cost: 156880.69\n",
      "total_trades: 73709\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 635        |\n",
      "|    time_elapsed         | 5247       |\n",
      "|    total_timesteps      | 1300480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01681072 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.00843    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.56e+03   |\n",
      "|    n_updates            | 6340       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    reward               | -2.690431  |\n",
      "|    std                  | 4.56       |\n",
      "|    value_loss           | 3.4e+03    |\n",
      "----------------------------------------\n",
      "Episode: 672\n",
      "day: 1940, episode: 672\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12953647.62\n",
      "total_reward: 2953647.62\n",
      "total_cost: 160488.38\n",
      "total_trades: 73710\n",
      "Sharpe: 0.262\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 636         |\n",
      "|    time_elapsed         | 5256        |\n",
      "|    total_timesteps      | 1302528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017348565 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | -0.00326    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.39e+03    |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | 9.178948    |\n",
      "|    std                  | 4.57        |\n",
      "|    value_loss           | 4.87e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 673\n",
      "day: 1940, episode: 673\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9088074.73\n",
      "total_reward: -911925.27\n",
      "total_cost: 148504.27\n",
      "total_trades: 73711\n",
      "Sharpe: 0.119\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 5264        |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019934803 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -111        |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    reward               | -3.1583192  |\n",
      "|    std                  | 4.58        |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 674\n",
      "day: 1940, episode: 674\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11760043.85\n",
      "total_reward: 1760043.85\n",
      "total_cost: 153322.15\n",
      "total_trades: 73707\n",
      "Sharpe: 0.215\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 638        |\n",
      "|    time_elapsed         | 5272       |\n",
      "|    total_timesteps      | 1306624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01425902 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -111       |\n",
      "|    explained_variance   | 0.0128     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.49e+03   |\n",
      "|    n_updates            | 6370       |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    reward               | 10.147715  |\n",
      "|    std                  | 4.59       |\n",
      "|    value_loss           | 2.38e+03   |\n",
      "----------------------------------------\n",
      "Episode: 675\n",
      "day: 1940, episode: 675\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7795371.24\n",
      "total_reward: -2204628.76\n",
      "total_cost: 146345.76\n",
      "total_trades: 73702\n",
      "Sharpe: 0.048\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 5280        |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016443392 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0062      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    reward               | -8.523967   |\n",
      "|    std                  | 4.61        |\n",
      "|    value_loss           | 3.97e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 676\n",
      "day: 1940, episode: 676\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11100130.48\n",
      "total_reward: 1100130.48\n",
      "total_cost: 153832.52\n",
      "total_trades: 73713\n",
      "Sharpe: 0.186\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 5288        |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016154055 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 913         |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    reward               | -4.2608395  |\n",
      "|    std                  | 4.62        |\n",
      "|    value_loss           | 2.24e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 677\n",
      "day: 1940, episode: 677\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12916498.52\n",
      "total_reward: 2916498.52\n",
      "total_cost: 159691.48\n",
      "total_trades: 73713\n",
      "Sharpe: 0.261\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 5297        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020625692 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.00799     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.85e+03    |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | -1.9748142  |\n",
      "|    std                  | 4.63        |\n",
      "|    value_loss           | 4.1e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 678\n",
      "day: 1940, episode: 678\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8573244.49\n",
      "total_reward: -1426755.51\n",
      "total_cost: 148480.51\n",
      "total_trades: 73709\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 5305        |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021544859 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.00139     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -0.78652    |\n",
      "|    std                  | 4.64        |\n",
      "|    value_loss           | 4.1e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 679\n",
      "day: 1940, episode: 679\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8316234.04\n",
      "total_reward: -1683765.96\n",
      "total_cost: 144477.96\n",
      "total_trades: 73708\n",
      "Sharpe: 0.086\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 5313        |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013153262 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    reward               | -23.84265   |\n",
      "|    std                  | 4.65        |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 680\n",
      "day: 1940, episode: 680\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11701370.24\n",
      "total_reward: 1701370.24\n",
      "total_cost: 159832.76\n",
      "total_trades: 73709\n",
      "Sharpe: 0.211\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 5322        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015422562 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -18.220873  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 4.11e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 681\n",
      "day: 1940, episode: 681\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10683050.02\n",
      "total_reward: 683050.02\n",
      "total_cost: 152043.98\n",
      "total_trades: 73710\n",
      "Sharpe: 0.176\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 5330        |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011618799 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0197      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -4.2933345  |\n",
      "|    std                  | 4.66        |\n",
      "|    value_loss           | 3.99e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 682\n",
      "day: 1940, episode: 682\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9872957.43\n",
      "total_reward: -127042.57\n",
      "total_cost: 154934.57\n",
      "total_trades: 73710\n",
      "Sharpe: 0.149\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 5339        |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021085426 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0392      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 793         |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | -10.536995  |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 683\n",
      "day: 1940, episode: 683\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8119531.92\n",
      "total_reward: -1880468.08\n",
      "total_cost: 148545.08\n",
      "total_trades: 73712\n",
      "Sharpe: 0.070\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 5347        |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022553768 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.0245      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 745         |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | -1.027179   |\n",
      "|    std                  | 4.68        |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 684\n",
      "day: 1940, episode: 684\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8405437.71\n",
      "total_reward: -1594562.29\n",
      "total_cost: 151181.29\n",
      "total_trades: 73710\n",
      "Sharpe: 0.085\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 5356        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023580786 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.022       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    reward               | 3.3441005   |\n",
      "|    std                  | 4.69        |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 685\n",
      "day: 1940, episode: 685\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12285710.59\n",
      "total_reward: 2285710.59\n",
      "total_cost: 153122.41\n",
      "total_trades: 73696\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 247       |\n",
      "|    iterations           | 649       |\n",
      "|    time_elapsed         | 5364      |\n",
      "|    total_timesteps      | 1329152   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0136258 |\n",
      "|    clip_fraction        | 0.131     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -112      |\n",
      "|    explained_variance   | 0.0255    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | 1.95e+03  |\n",
      "|    n_updates            | 6480      |\n",
      "|    policy_gradient_loss | -0.0116   |\n",
      "|    reward               | -8.284329 |\n",
      "|    std                  | 4.71      |\n",
      "|    value_loss           | 3.44e+03  |\n",
      "---------------------------------------\n",
      "Episode: 686\n",
      "day: 1940, episode: 686\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7986558.30\n",
      "total_reward: -2013441.70\n",
      "total_cost: 136576.70\n",
      "total_trades: 73709\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 650         |\n",
      "|    time_elapsed         | 5372        |\n",
      "|    total_timesteps      | 1331200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013464704 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -112        |\n",
      "|    explained_variance   | 0.022       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    reward               | -4.990493   |\n",
      "|    std                  | 4.72        |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 687\n",
      "day: 1940, episode: 687\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12333438.86\n",
      "total_reward: 2333438.86\n",
      "total_cost: 157834.14\n",
      "total_trades: 73707\n",
      "Sharpe: 0.238\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 651        |\n",
      "|    time_elapsed         | 5380       |\n",
      "|    total_timesteps      | 1333248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01544947 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -113       |\n",
      "|    explained_variance   | 0.0195     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.55e+03   |\n",
      "|    n_updates            | 6500       |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    reward               | 10.031541  |\n",
      "|    std                  | 4.73       |\n",
      "|    value_loss           | 3.62e+03   |\n",
      "----------------------------------------\n",
      "Episode: 688\n",
      "day: 1940, episode: 688\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10057793.74\n",
      "total_reward: 57793.74\n",
      "total_cost: 149872.26\n",
      "total_trades: 73705\n",
      "Sharpe: 0.153\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 5389        |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011591438 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | -0.0181     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | 6.97905     |\n",
      "|    std                  | 4.73        |\n",
      "|    value_loss           | 3.15e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 689\n",
      "day: 1940, episode: 689\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9365703.90\n",
      "total_reward: -634296.10\n",
      "total_cost: 147507.10\n",
      "total_trades: 73704\n",
      "Sharpe: 0.137\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 5397        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021903507 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.00506     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    reward               | 10.168646   |\n",
      "|    std                  | 4.76        |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 690\n",
      "day: 1940, episode: 690\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13411891.30\n",
      "total_reward: 3411891.30\n",
      "total_cost: 163123.70\n",
      "total_trades: 73705\n",
      "Sharpe: 0.282\n",
      "=================================\n",
      "Episode: 691\n",
      "day: 1940, episode: 691\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11538381.31\n",
      "total_reward: 1538381.31\n",
      "total_cost: 151153.69\n",
      "total_trades: 73713\n",
      "Sharpe: 0.213\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 5405        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013357595 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.00546     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    reward               | -2.1022198  |\n",
      "|    std                  | 4.77        |\n",
      "|    value_loss           | 3.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 692\n",
      "day: 1940, episode: 692\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14491772.67\n",
      "total_reward: 4491772.67\n",
      "total_cost: 160145.33\n",
      "total_trades: 73705\n",
      "Sharpe: 0.318\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 5414        |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016160633 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.00414     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | -3.1038299  |\n",
      "|    std                  | 4.78        |\n",
      "|    value_loss           | 3.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 693\n",
      "day: 1940, episode: 693\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8430219.25\n",
      "total_reward: -1569780.75\n",
      "total_cost: 147853.75\n",
      "total_trades: 73709\n",
      "Sharpe: 0.089\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 5422        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017342169 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.00552     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 3.044627    |\n",
      "|    std                  | 4.79        |\n",
      "|    value_loss           | 4.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 694\n",
      "day: 1940, episode: 694\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11881415.59\n",
      "total_reward: 1881415.59\n",
      "total_cost: 156384.41\n",
      "total_trades: 73712\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 5430        |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016258618 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 909         |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    reward               | 2.724471    |\n",
      "|    std                  | 4.8         |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 695\n",
      "day: 1940, episode: 695\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8807185.42\n",
      "total_reward: -1192814.58\n",
      "total_cost: 151239.58\n",
      "total_trades: 73711\n",
      "Sharpe: 0.106\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 5439        |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016990427 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.0051      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.92e+03    |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -2.0954196  |\n",
      "|    std                  | 4.81        |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 696\n",
      "day: 1940, episode: 696\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14714913.59\n",
      "total_reward: 4714913.59\n",
      "total_cost: 158796.41\n",
      "total_trades: 73704\n",
      "Sharpe: 0.330\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 5448        |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016807895 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.00456     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    reward               | -0.36791012 |\n",
      "|    std                  | 4.82        |\n",
      "|    value_loss           | 2.1e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 697\n",
      "day: 1940, episode: 697\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10886535.57\n",
      "total_reward: 886535.57\n",
      "total_cost: 153875.43\n",
      "total_trades: 73712\n",
      "Sharpe: 0.182\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 660          |\n",
      "|    time_elapsed         | 5456         |\n",
      "|    total_timesteps      | 1351680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131701175 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -113         |\n",
      "|    explained_variance   | 0.00696      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.17e+03     |\n",
      "|    n_updates            | 6590         |\n",
      "|    policy_gradient_loss | -0.0205      |\n",
      "|    reward               | -10.009057   |\n",
      "|    std                  | 4.82         |\n",
      "|    value_loss           | 3.63e+03     |\n",
      "------------------------------------------\n",
      "Episode: 698\n",
      "day: 1940, episode: 698\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7391963.27\n",
      "total_reward: -2608036.73\n",
      "total_cost: 145937.73\n",
      "total_trades: 73704\n",
      "Sharpe: 0.024\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 5465        |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012968989 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | -0.0192     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -15.688572  |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 2.49e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 699\n",
      "day: 1940, episode: 699\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11926730.56\n",
      "total_reward: 1926730.56\n",
      "total_cost: 152571.44\n",
      "total_trades: 73706\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 5473        |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016507972 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -113        |\n",
      "|    explained_variance   | 0.00989     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    reward               | -0.14469326 |\n",
      "|    std                  | 4.84        |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 700\n",
      "day: 1940, episode: 700\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10403395.97\n",
      "total_reward: 403395.97\n",
      "total_cost: 151806.03\n",
      "total_trades: 73710\n",
      "Sharpe: 0.184\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 5481        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015019325 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | -0.00297    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 22.668047   |\n",
      "|    std                  | 4.85        |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 701\n",
      "day: 1940, episode: 701\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9489330.16\n",
      "total_reward: -510669.84\n",
      "total_cost: 149032.84\n",
      "total_trades: 73707\n",
      "Sharpe: 0.146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 664        |\n",
      "|    time_elapsed         | 5490       |\n",
      "|    total_timesteps      | 1359872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01724129 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -114       |\n",
      "|    explained_variance   | 0.00529    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.2e+03    |\n",
      "|    n_updates            | 6630       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    reward               | 3.0187335  |\n",
      "|    std                  | 4.86       |\n",
      "|    value_loss           | 2.84e+03   |\n",
      "----------------------------------------\n",
      "Episode: 702\n",
      "day: 1940, episode: 702\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8369247.03\n",
      "total_reward: -1630752.97\n",
      "total_cost: 145481.97\n",
      "total_trades: 73710\n",
      "Sharpe: 0.071\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 5498        |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022310331 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.0128      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    reward               | -4.091585   |\n",
      "|    std                  | 4.87        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 703\n",
      "day: 1940, episode: 703\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9189350.93\n",
      "total_reward: -810649.07\n",
      "total_cost: 147493.07\n",
      "total_trades: 73706\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 5506        |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018547902 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.00898     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | 6.453736    |\n",
      "|    std                  | 4.88        |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 704\n",
      "day: 1940, episode: 704\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12397284.35\n",
      "total_reward: 2397284.35\n",
      "total_cost: 159576.65\n",
      "total_trades: 73709\n",
      "Sharpe: 0.242\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 5515        |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013273347 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.00469     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    reward               | -2.7357178  |\n",
      "|    std                  | 4.89        |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 705\n",
      "day: 1940, episode: 705\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9441435.60\n",
      "total_reward: -558564.40\n",
      "total_cost: 153576.40\n",
      "total_trades: 73709\n",
      "Sharpe: 0.137\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 5523        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014930479 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.00888     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 6670        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    reward               | -0.8856099  |\n",
      "|    std                  | 4.9         |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 706\n",
      "day: 1940, episode: 706\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10040260.23\n",
      "total_reward: 40260.23\n",
      "total_cost: 151128.77\n",
      "total_trades: 73710\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 5531        |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011647053 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    reward               | -0.45302555 |\n",
      "|    std                  | 4.91        |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 707\n",
      "day: 1940, episode: 707\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9745167.06\n",
      "total_reward: -254832.94\n",
      "total_cost: 153191.94\n",
      "total_trades: 73712\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 5539        |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014585081 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.000443    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | -10.305839  |\n",
      "|    std                  | 4.92        |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 708\n",
      "day: 1940, episode: 708\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13137143.58\n",
      "total_reward: 3137143.58\n",
      "total_cost: 155216.42\n",
      "total_trades: 73706\n",
      "Sharpe: 0.271\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 5547        |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011372713 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.000866    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    reward               | -3.1124945  |\n",
      "|    std                  | 4.94        |\n",
      "|    value_loss           | 4.09e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 709\n",
      "day: 1940, episode: 709\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11740230.58\n",
      "total_reward: 1740230.58\n",
      "total_cost: 154854.42\n",
      "total_trades: 73711\n",
      "Sharpe: 0.216\n",
      "=================================\n",
      "Episode: 710\n",
      "day: 1940, episode: 710\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11225101.04\n",
      "total_reward: 1225101.04\n",
      "total_cost: 148950.96\n",
      "total_trades: 73707\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 5556        |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013443463 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | -0.00306    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 6710        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    reward               | -3.1913202  |\n",
      "|    std                  | 4.95        |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 711\n",
      "day: 1940, episode: 711\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10105431.88\n",
      "total_reward: 105431.88\n",
      "total_cost: 149036.12\n",
      "total_trades: 73711\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 673        |\n",
      "|    time_elapsed         | 5564       |\n",
      "|    total_timesteps      | 1378304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01123626 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -114       |\n",
      "|    explained_variance   | -0.00488   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.53e+03   |\n",
      "|    n_updates            | 6720       |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    reward               | 2.732923   |\n",
      "|    std                  | 4.96       |\n",
      "|    value_loss           | 3.22e+03   |\n",
      "----------------------------------------\n",
      "Episode: 712\n",
      "day: 1940, episode: 712\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9947765.23\n",
      "total_reward: -52234.77\n",
      "total_cost: 144840.77\n",
      "total_trades: 73708\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 5572        |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017172903 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 631         |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    reward               | -3.629674   |\n",
      "|    std                  | 4.97        |\n",
      "|    value_loss           | 2.98e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 713\n",
      "day: 1940, episode: 713\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12069272.92\n",
      "total_reward: 2069272.92\n",
      "total_cost: 147813.08\n",
      "total_trades: 73709\n",
      "Sharpe: 0.231\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 5580        |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014519159 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.0216      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | -7.100732   |\n",
      "|    std                  | 4.97        |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 714\n",
      "day: 1940, episode: 714\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14382944.61\n",
      "total_reward: 4382944.61\n",
      "total_cost: 152479.39\n",
      "total_trades: 73705\n",
      "Sharpe: 0.315\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 5589        |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018405413 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | 0.0102      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | -3.5251667  |\n",
      "|    std                  | 4.97        |\n",
      "|    value_loss           | 3.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 715\n",
      "day: 1940, episode: 715\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9723335.80\n",
      "total_reward: -276664.20\n",
      "total_cost: 142678.20\n",
      "total_trades: 73709\n",
      "Sharpe: 0.152\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 5597        |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022369362 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -114        |\n",
      "|    explained_variance   | -0.00163    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | -3.8473074  |\n",
      "|    std                  | 4.98        |\n",
      "|    value_loss           | 4.89e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 716\n",
      "day: 1940, episode: 716\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13452905.59\n",
      "total_reward: 3452905.59\n",
      "total_cost: 148468.41\n",
      "total_trades: 73709\n",
      "Sharpe: 0.283\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 678        |\n",
      "|    time_elapsed         | 5605       |\n",
      "|    total_timesteps      | 1388544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01096334 |\n",
      "|    clip_fraction        | 0.0927     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | -0.00793   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.52e+03   |\n",
      "|    n_updates            | 6770       |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    reward               | -3.6976664 |\n",
      "|    std                  | 5          |\n",
      "|    value_loss           | 2.58e+03   |\n",
      "----------------------------------------\n",
      "Episode: 717\n",
      "day: 1940, episode: 717\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10678369.42\n",
      "total_reward: 678369.42\n",
      "total_cost: 142355.58\n",
      "total_trades: 73714\n",
      "Sharpe: 0.178\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 679         |\n",
      "|    time_elapsed         | 5613        |\n",
      "|    total_timesteps      | 1390592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027151939 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.000373    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 6780        |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    reward               | 38.534466   |\n",
      "|    std                  | 5           |\n",
      "|    value_loss           | 4.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 718\n",
      "day: 1940, episode: 718\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12687321.64\n",
      "total_reward: 2687321.64\n",
      "total_cost: 145923.36\n",
      "total_trades: 73703\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 5621        |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010927144 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.0054      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.97e+03    |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    reward               | 6.050495    |\n",
      "|    std                  | 5.01        |\n",
      "|    value_loss           | 4.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 719\n",
      "day: 1940, episode: 719\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10845047.97\n",
      "total_reward: 845047.97\n",
      "total_cost: 142147.03\n",
      "total_trades: 73708\n",
      "Sharpe: 0.200\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 681        |\n",
      "|    time_elapsed         | 5630       |\n",
      "|    total_timesteps      | 1394688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01116006 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -115       |\n",
      "|    explained_variance   | 0.00926    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.2e+03    |\n",
      "|    n_updates            | 6800       |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    reward               | 3.5561647  |\n",
      "|    std                  | 5.02       |\n",
      "|    value_loss           | 3.87e+03   |\n",
      "----------------------------------------\n",
      "Episode: 720\n",
      "day: 1940, episode: 720\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14659211.17\n",
      "total_reward: 4659211.17\n",
      "total_cost: 147370.83\n",
      "total_trades: 73712\n",
      "Sharpe: 0.323\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 5638        |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015612923 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    reward               | -0.44033346 |\n",
      "|    std                  | 5.03        |\n",
      "|    value_loss           | 4.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 721\n",
      "day: 1940, episode: 721\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9764618.77\n",
      "total_reward: -235381.23\n",
      "total_cost: 136331.23\n",
      "total_trades: 73710\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 5646        |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012174843 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | -0.0213     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.28e+03    |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    reward               | -5.691164   |\n",
      "|    std                  | 5.04        |\n",
      "|    value_loss           | 3.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 722\n",
      "day: 1940, episode: 722\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12961135.52\n",
      "total_reward: 2961135.52\n",
      "total_cost: 145243.48\n",
      "total_trades: 73707\n",
      "Sharpe: 0.264\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 684         |\n",
      "|    time_elapsed         | 5654        |\n",
      "|    total_timesteps      | 1400832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011297398 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.00733     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.4e+03     |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 11.9723425  |\n",
      "|    std                  | 5.06        |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 723\n",
      "day: 1940, episode: 723\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13359261.97\n",
      "total_reward: 3359261.97\n",
      "total_cost: 148347.03\n",
      "total_trades: 73709\n",
      "Sharpe: 0.278\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 5662        |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013557561 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.000886    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.07e+03    |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -32.83083   |\n",
      "|    std                  | 5.08        |\n",
      "|    value_loss           | 4.51e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 724\n",
      "day: 1940, episode: 724\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9720595.75\n",
      "total_reward: -279404.25\n",
      "total_cost: 137080.25\n",
      "total_trades: 73712\n",
      "Sharpe: 0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 5670        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012556333 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.00984     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    reward               | -8.118169   |\n",
      "|    std                  | 5.1         |\n",
      "|    value_loss           | 3.55e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 725\n",
      "day: 1940, episode: 725\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12470476.58\n",
      "total_reward: 2470476.58\n",
      "total_cost: 150843.42\n",
      "total_trades: 73712\n",
      "Sharpe: 0.248\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 5679        |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015203366 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.4e+03     |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    reward               | 7.298107    |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 4.66e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 726\n",
      "day: 1940, episode: 726\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9961173.54\n",
      "total_reward: -38826.46\n",
      "total_cost: 134648.46\n",
      "total_trades: 73707\n",
      "Sharpe: 0.168\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 5687        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029443197 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -115        |\n",
      "|    explained_variance   | -0.00584    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 938         |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    reward               | -21.283571  |\n",
      "|    std                  | 5.11        |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 727\n",
      "day: 1940, episode: 727\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9374500.94\n",
      "total_reward: -625499.06\n",
      "total_cost: 129329.06\n",
      "total_trades: 73701\n",
      "Sharpe: 0.151\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 5695        |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011096522 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.0073      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    reward               | -10.761939  |\n",
      "|    std                  | 5.13        |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 728\n",
      "day: 1940, episode: 728\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8916977.47\n",
      "total_reward: -1083022.53\n",
      "total_cost: 129681.53\n",
      "total_trades: 73709\n",
      "Sharpe: 0.134\n",
      "=================================\n",
      "Episode: 729\n",
      "day: 1940, episode: 729\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9567145.23\n",
      "total_reward: -432854.77\n",
      "total_cost: 139380.77\n",
      "total_trades: 73710\n",
      "Sharpe: 0.157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 5703        |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013573518 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -0.40886572 |\n",
      "|    std                  | 5.14        |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 730\n",
      "day: 1940, episode: 730\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9605969.33\n",
      "total_reward: -394030.67\n",
      "total_cost: 133215.67\n",
      "total_trades: 73710\n",
      "Sharpe: 0.164\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 691          |\n",
      "|    time_elapsed         | 5711         |\n",
      "|    total_timesteps      | 1415168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126245795 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -116         |\n",
      "|    explained_variance   | -0.00403     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 934          |\n",
      "|    n_updates            | 6900         |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    reward               | 11.050539    |\n",
      "|    std                  | 5.14         |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "Episode: 731\n",
      "day: 1940, episode: 731\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9585043.39\n",
      "total_reward: -414956.61\n",
      "total_cost: 127222.61\n",
      "total_trades: 73712\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 5719        |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013261385 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | -0.00231    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.19e+03    |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    reward               | 4.7270737   |\n",
      "|    std                  | 5.16        |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 732\n",
      "day: 1940, episode: 732\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11237134.75\n",
      "total_reward: 1237134.75\n",
      "total_cost: 146570.25\n",
      "total_trades: 73711\n",
      "Sharpe: 0.219\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 5727        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012887809 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | 3.0945222   |\n",
      "|    std                  | 5.18        |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 733\n",
      "day: 1940, episode: 733\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12420897.23\n",
      "total_reward: 2420897.23\n",
      "total_cost: 144267.77\n",
      "total_trades: 73707\n",
      "Sharpe: 0.248\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 694         |\n",
      "|    time_elapsed         | 5735        |\n",
      "|    total_timesteps      | 1421312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012863916 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.000536    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    reward               | 1.1428958   |\n",
      "|    std                  | 5.19        |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 734\n",
      "day: 1940, episode: 734\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10474301.39\n",
      "total_reward: 474301.39\n",
      "total_cost: 142201.61\n",
      "total_trades: 73707\n",
      "Sharpe: 0.194\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 5743        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012810314 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.000679    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    reward               | -6.873102   |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 735\n",
      "day: 1940, episode: 735\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11692570.37\n",
      "total_reward: 1692570.37\n",
      "total_cost: 140327.63\n",
      "total_trades: 73700\n",
      "Sharpe: 0.236\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 5751        |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013812817 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.000902    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    reward               | -4.311434   |\n",
      "|    std                  | 5.2         |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 736\n",
      "day: 1940, episode: 736\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10034125.02\n",
      "total_reward: 34125.02\n",
      "total_cost: 131863.98\n",
      "total_trades: 73704\n",
      "Sharpe: 0.178\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 5759        |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011958778 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | -0.00955    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    reward               | 49.033936   |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 3.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 737\n",
      "day: 1940, episode: 737\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10954470.65\n",
      "total_reward: 954470.65\n",
      "total_cost: 145306.35\n",
      "total_trades: 73706\n",
      "Sharpe: 0.207\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 5767        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015969064 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.00322     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -2.4357445  |\n",
      "|    std                  | 5.22        |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 738\n",
      "day: 1940, episode: 738\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9107883.93\n",
      "total_reward: -892116.07\n",
      "total_cost: 138633.07\n",
      "total_trades: 73707\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 699         |\n",
      "|    time_elapsed         | 5775        |\n",
      "|    total_timesteps      | 1431552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017551005 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | -0.0108     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | -6.9801993  |\n",
      "|    std                  | 5.23        |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 739\n",
      "day: 1940, episode: 739\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9634419.55\n",
      "total_reward: -365580.45\n",
      "total_cost: 131152.45\n",
      "total_trades: 73708\n",
      "Sharpe: 0.160\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 5783        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012468902 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | -0.0166     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | -0.3568772  |\n",
      "|    std                  | 5.24        |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 740\n",
      "day: 1940, episode: 740\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12818528.45\n",
      "total_reward: 2818528.45\n",
      "total_cost: 150545.55\n",
      "total_trades: 73711\n",
      "Sharpe: 0.258\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 5791        |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011378344 |\n",
      "|    clip_fraction        | 0.0967      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -116        |\n",
      "|    explained_variance   | 0.00103     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | -1.4314895  |\n",
      "|    std                  | 5.25        |\n",
      "|    value_loss           | 3.96e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 741\n",
      "day: 1940, episode: 741\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9783578.84\n",
      "total_reward: -216421.16\n",
      "total_cost: 137116.16\n",
      "total_trades: 73712\n",
      "Sharpe: 0.170\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 5800        |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011888391 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.00451     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    reward               | -6.528515   |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 742\n",
      "day: 1940, episode: 742\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11858214.20\n",
      "total_reward: 1858214.20\n",
      "total_cost: 145859.80\n",
      "total_trades: 73710\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 5808        |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025253087 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | -14.329091  |\n",
      "|    std                  | 5.27        |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 743\n",
      "day: 1940, episode: 743\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10345606.68\n",
      "total_reward: 345606.68\n",
      "total_cost: 148842.32\n",
      "total_trades: 73715\n",
      "Sharpe: 0.173\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 5816        |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011191259 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | -0.0243     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    reward               | 3.7820997   |\n",
      "|    std                  | 5.28        |\n",
      "|    value_loss           | 3.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 744\n",
      "day: 1940, episode: 744\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11939946.14\n",
      "total_reward: 1939946.14\n",
      "total_cost: 147627.86\n",
      "total_trades: 73705\n",
      "Sharpe: 0.235\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 5824        |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029321808 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | -0.00263    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    reward               | 15.693777   |\n",
      "|    std                  | 5.29        |\n",
      "|    value_loss           | 3.44e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 745\n",
      "day: 1940, episode: 745\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9109022.72\n",
      "total_reward: -890977.28\n",
      "total_cost: 143692.28\n",
      "total_trades: 73707\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 706        |\n",
      "|    time_elapsed         | 5832       |\n",
      "|    total_timesteps      | 1445888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01524791 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -117       |\n",
      "|    explained_variance   | 0.00654    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 991        |\n",
      "|    n_updates            | 7050       |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    reward               | -5.301297  |\n",
      "|    std                  | 5.31       |\n",
      "|    value_loss           | 2.68e+03   |\n",
      "----------------------------------------\n",
      "Episode: 746\n",
      "day: 1940, episode: 746\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 14051926.56\n",
      "total_reward: 4051926.56\n",
      "total_cost: 146415.44\n",
      "total_trades: 73712\n",
      "Sharpe: 0.302\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 5840        |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009995792 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.00998     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    reward               | -2.9381664  |\n",
      "|    std                  | 5.32        |\n",
      "|    value_loss           | 4.82e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 747\n",
      "day: 1940, episode: 747\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12341752.97\n",
      "total_reward: 2341752.97\n",
      "total_cost: 151957.03\n",
      "total_trades: 73711\n",
      "Sharpe: 0.240\n",
      "=================================\n",
      "Episode: 748\n",
      "day: 1940, episode: 748\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9208052.15\n",
      "total_reward: -791947.85\n",
      "total_cost: 131764.85\n",
      "total_trades: 73709\n",
      "Sharpe: 0.144\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 5848        |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017530683 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | -0.0098     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88e+03    |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -3.1678255  |\n",
      "|    std                  | 5.33        |\n",
      "|    value_loss           | 4.37e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 749\n",
      "day: 1940, episode: 749\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11752479.62\n",
      "total_reward: 1752479.62\n",
      "total_cost: 143315.38\n",
      "total_trades: 73710\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 5856        |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018221512 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | -0.00779    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | -5.060615   |\n",
      "|    std                  | 5.34        |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 750\n",
      "day: 1940, episode: 750\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9197373.27\n",
      "total_reward: -802626.73\n",
      "total_cost: 133294.73\n",
      "total_trades: 73707\n",
      "Sharpe: 0.139\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 5864        |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014313697 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    reward               | -16.247486  |\n",
      "|    std                  | 5.36        |\n",
      "|    value_loss           | 4.72e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 751\n",
      "day: 1940, episode: 751\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12438974.75\n",
      "total_reward: 2438974.75\n",
      "total_cost: 139523.25\n",
      "total_trades: 73708\n",
      "Sharpe: 0.246\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 5872        |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021778174 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.00768     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 706         |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    reward               | 6.835703    |\n",
      "|    std                  | 5.38        |\n",
      "|    value_loss           | 3.12e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 752\n",
      "day: 1940, episode: 752\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8463499.03\n",
      "total_reward: -1536500.97\n",
      "total_cost: 126735.97\n",
      "total_trades: 73709\n",
      "Sharpe: 0.109\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 5880        |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016414456 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -117        |\n",
      "|    explained_variance   | 0.0271      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.03e+03    |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    reward               | 13.64385    |\n",
      "|    std                  | 5.39        |\n",
      "|    value_loss           | 5.04e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 753\n",
      "day: 1940, episode: 753\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12627794.79\n",
      "total_reward: 2627794.79\n",
      "total_cost: 142053.21\n",
      "total_trades: 73708\n",
      "Sharpe: 0.255\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 5889        |\n",
      "|    total_timesteps      | 1460224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018478727 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.00458     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 918         |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | -10.386057  |\n",
      "|    std                  | 5.41        |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 754\n",
      "day: 1940, episode: 754\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11300414.48\n",
      "total_reward: 1300414.48\n",
      "total_cost: 134138.52\n",
      "total_trades: 73709\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 247        |\n",
      "|    iterations           | 714        |\n",
      "|    time_elapsed         | 5897       |\n",
      "|    total_timesteps      | 1462272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01028046 |\n",
      "|    clip_fraction        | 0.0743     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.0213     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.64e+03   |\n",
      "|    n_updates            | 7130       |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    reward               | 4.8928313  |\n",
      "|    std                  | 5.42       |\n",
      "|    value_loss           | 5.79e+03   |\n",
      "----------------------------------------\n",
      "Episode: 755\n",
      "day: 1940, episode: 755\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9245559.20\n",
      "total_reward: -754440.80\n",
      "total_cost: 131025.80\n",
      "total_trades: 73705\n",
      "Sharpe: 0.142\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 5905        |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016229052 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 52.969933   |\n",
      "|    std                  | 5.43        |\n",
      "|    value_loss           | 4.4e+03     |\n",
      "-----------------------------------------\n",
      "Episode: 756\n",
      "day: 1940, episode: 756\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11661668.26\n",
      "total_reward: 1661668.26\n",
      "total_cost: 146053.74\n",
      "total_trades: 73709\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 5913        |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012110807 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.044       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 5.2629533   |\n",
      "|    std                  | 5.44        |\n",
      "|    value_loss           | 3.95e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 757\n",
      "day: 1940, episode: 757\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12474102.71\n",
      "total_reward: 2474102.71\n",
      "total_cost: 147352.29\n",
      "total_trades: 73705\n",
      "Sharpe: 0.245\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 5921        |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010541821 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.00648     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 2.6071908   |\n",
      "|    std                  | 5.45        |\n",
      "|    value_loss           | 6.38e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 758\n",
      "day: 1940, episode: 758\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 7898322.19\n",
      "total_reward: -2101677.81\n",
      "total_cost: 130503.81\n",
      "total_trades: 73710\n",
      "Sharpe: 0.080\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 718         |\n",
      "|    time_elapsed         | 5929        |\n",
      "|    total_timesteps      | 1470464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016054489 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    reward               | -5.9500813  |\n",
      "|    std                  | 5.47        |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 759\n",
      "day: 1940, episode: 759\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8979761.41\n",
      "total_reward: -1020238.59\n",
      "total_cost: 126071.59\n",
      "total_trades: 73704\n",
      "Sharpe: 0.141\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 5937        |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012327852 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    reward               | 9.209531    |\n",
      "|    std                  | 5.49        |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 760\n",
      "day: 1940, episode: 760\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13182085.11\n",
      "total_reward: 3182085.11\n",
      "total_cost: 153923.89\n",
      "total_trades: 73708\n",
      "Sharpe: 0.272\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 248          |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 5945         |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116060525 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -118         |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.5e+03      |\n",
      "|    n_updates            | 7190         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    reward               | 13.753138    |\n",
      "|    std                  | 5.5          |\n",
      "|    value_loss           | 4.77e+03     |\n",
      "------------------------------------------\n",
      "Episode: 761\n",
      "day: 1940, episode: 761\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12113034.22\n",
      "total_reward: 2113034.22\n",
      "total_cost: 153122.78\n",
      "total_trades: 73706\n",
      "Sharpe: 0.233\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 5953        |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016065584 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.0257      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.87e+03    |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    reward               | 53.02607    |\n",
      "|    std                  | 5.51        |\n",
      "|    value_loss           | 4.81e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 762\n",
      "day: 1940, episode: 762\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12408836.30\n",
      "total_reward: 2408836.30\n",
      "total_cost: 138509.70\n",
      "total_trades: 73711\n",
      "Sharpe: 0.247\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 5961        |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015940288 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -118        |\n",
      "|    explained_variance   | 0.0156      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.38e+03    |\n",
      "|    n_updates            | 7210        |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    reward               | -21.005804  |\n",
      "|    std                  | 5.53        |\n",
      "|    value_loss           | 5.88e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 763\n",
      "day: 1940, episode: 763\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8184305.27\n",
      "total_reward: -1815694.73\n",
      "total_cost: 128833.73\n",
      "total_trades: 73711\n",
      "Sharpe: 0.096\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 723        |\n",
      "|    time_elapsed         | 5969       |\n",
      "|    total_timesteps      | 1480704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01018781 |\n",
      "|    clip_fraction        | 0.0832     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -118       |\n",
      "|    explained_variance   | 0.0844     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.02e+03   |\n",
      "|    n_updates            | 7220       |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    reward               | 26.043749  |\n",
      "|    std                  | 5.54       |\n",
      "|    value_loss           | 3.63e+03   |\n",
      "----------------------------------------\n",
      "Episode: 764\n",
      "day: 1940, episode: 764\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10086053.93\n",
      "total_reward: 86053.93\n",
      "total_cost: 131748.07\n",
      "total_trades: 73710\n",
      "Sharpe: 0.170\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 5977        |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016337354 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0925      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.32e+03    |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    reward               | 1.7337598   |\n",
      "|    std                  | 5.56        |\n",
      "|    value_loss           | 3.65e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 765\n",
      "day: 1940, episode: 765\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 10113647.22\n",
      "total_reward: 113647.22\n",
      "total_cost: 124337.78\n",
      "total_trades: 73711\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 5985        |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019607214 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.23e+03    |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    reward               | -24.768633  |\n",
      "|    std                  | 5.57        |\n",
      "|    value_loss           | 4.12e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 766\n",
      "day: 1940, episode: 766\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8646016.82\n",
      "total_reward: -1353983.18\n",
      "total_cost: 120480.18\n",
      "total_trades: 73715\n",
      "Sharpe: 0.125\n",
      "=================================\n",
      "Episode: 767\n",
      "day: 1940, episode: 767\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 8526821.76\n",
      "total_reward: -1473178.24\n",
      "total_cost: 122746.24\n",
      "total_trades: 73711\n",
      "Sharpe: 0.127\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 248        |\n",
      "|    iterations           | 726        |\n",
      "|    time_elapsed         | 5993       |\n",
      "|    total_timesteps      | 1486848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01614674 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -119       |\n",
      "|    explained_variance   | 0.0846     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.05e+03   |\n",
      "|    n_updates            | 7250       |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    reward               | -7.786302  |\n",
      "|    std                  | 5.59       |\n",
      "|    value_loss           | 3.34e+03   |\n",
      "----------------------------------------\n",
      "Episode: 768\n",
      "day: 1940, episode: 768\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9635720.51\n",
      "total_reward: -364279.49\n",
      "total_cost: 116247.49\n",
      "total_trades: 73714\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 6001        |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011732612 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.57e+03    |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 3.7103493   |\n",
      "|    std                  | 5.6         |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 769\n",
      "day: 1940, episode: 769\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12461903.20\n",
      "total_reward: 2461903.20\n",
      "total_cost: 139454.80\n",
      "total_trades: 73711\n",
      "Sharpe: 0.250\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 6009        |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011669049 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0576      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.69e+03    |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | 0.47272006  |\n",
      "|    std                  | 5.63        |\n",
      "|    value_loss           | 3.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 770\n",
      "day: 1940, episode: 770\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13180242.68\n",
      "total_reward: 3180242.68\n",
      "total_cost: 143363.32\n",
      "total_trades: 73710\n",
      "Sharpe: 0.276\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 6017        |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009217164 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0608      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.37138507  |\n",
      "|    std                  | 5.64        |\n",
      "|    value_loss           | 5.22e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 771\n",
      "day: 1940, episode: 771\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 12490534.86\n",
      "total_reward: 2490534.86\n",
      "total_cost: 132440.14\n",
      "total_trades: 73713\n",
      "Sharpe: 0.253\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 6026        |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011938075 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.0677      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.33e+03    |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    reward               | 9.729825    |\n",
      "|    std                  | 5.65        |\n",
      "|    value_loss           | 5.85e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 772\n",
      "day: 1940, episode: 772\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 9611361.50\n",
      "total_reward: -388638.50\n",
      "total_cost: 111889.50\n",
      "total_trades: 73714\n",
      "Sharpe: 0.165\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 6034        |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013490977 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.22e+03    |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    reward               | -7.7251625  |\n",
      "|    std                  | 5.66        |\n",
      "|    value_loss           | 5.48e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 773\n",
      "day: 1940, episode: 773\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 11531569.28\n",
      "total_reward: 1531569.28\n",
      "total_cost: 141042.72\n",
      "total_trades: 73715\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 6042        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015216289 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    reward               | 17.81373    |\n",
      "|    std                  | 5.68        |\n",
      "|    value_loss           | 4.63e+03    |\n",
      "-----------------------------------------\n",
      "Episode: 774\n",
      "day: 1940, episode: 774\n",
      "begin_total_asset: 10000000.00\n",
      "end_total_asset: 13299718.86\n",
      "total_reward: 3299718.86\n",
      "total_cost: 137840.14\n",
      "total_trades: 73712\n",
      "Sharpe: 0.281\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 733         |\n",
      "|    time_elapsed         | 6050        |\n",
      "|    total_timesteps      | 1501184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011299962 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -119        |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.99e+03    |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    reward               | -2.7224846  |\n",
      "|    std                  | 5.69        |\n",
      "|    value_loss           | 4.55e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                            #   tb_log_name='ddpg',\n",
    "                            #   total_timesteps=150000)\n",
    "\n",
    "# trained_sac = agent.train_model(model = model_sac,\n",
    "#                                     tb_log_name = 'sac',\n",
    "#                                     total_timesteps = 100000)\n",
    "\n",
    "# trained_a2c = agent.train_model(model = model_a2c,\n",
    "#                                     tb_log_name = 'a2c',\n",
    "#                                     total_timesteps = 1000000)\n",
    "\n",
    "trained_ppo = agent.train_model(model = model_ppo,\n",
    "                                    tb_log_name = 'ppo',\n",
    "                                    total_timesteps = 1500000)\n",
    "\n",
    "# trained_sac.save('trained_models/sac')\n",
    "# trained_a2c.save('trained_models/a2c')\n",
    "# trained_ddpg.save('trained_models/ddpg')\n",
    "trained_ppo.save('trained_models/ppo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0767b826"
   },
   "source": [
    "## Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.stablebaselines3_models import PPO\n",
    "trained_ppo = PPO.load('trained_models/ppo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:35:58.328183Z",
     "start_time": "2022-10-13T04:35:58.281829Z"
    },
    "collapsed": true,
    "id": "responsible-equity"
   },
   "outputs": [],
   "source": [
    "trade = ts_processor.data_split(ts_processor.dataframe, trade_start_date, trade_stop_date)\n",
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000, \n",
    "    \"initial_amount\": 1e6, \n",
    "    \"buy_cost_pct\":6.87e-5,\n",
    "    \"sell_cost_pct\":2e-4,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space, \n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\":False,\n",
    "    \"hundred_each_trade\":True\n",
    "}\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:01.897346Z",
     "start_time": "2022-10-13T04:35:59.665241Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "first-hierarchy",
    "outputId": "2e8d17c8-11ba-47ce-a938-93ae7f21f3bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 666, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1743457.79\n",
      "total_reward: 743457.79\n",
      "total_cost: 64382.21\n",
      "total_trades: 17505\n",
      "Sharpe: 0.840\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,\n",
    "                       environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:08.006544Z",
     "start_time": "2022-10-13T04:36:07.983050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>9.990798e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>9.990255e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>1.001660e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>9.924351e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>1.003916e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>1.002522e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>1.014264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>1.011179e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>1.002892e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>1.000139e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>1.017141e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>1.015114e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>1.006224e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1.009103e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>9.805643e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>9.151319e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>9.329845e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>9.600196e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>9.731475e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>9.750491e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>9.817413e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>9.876559e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>1.003562e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>1.010525e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>1.913979e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>1.899784e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>1.884870e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>1.900264e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>1.901292e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>1.872672e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>1.845518e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>1.842180e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>1.869809e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>1.871064e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>1.864496e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>1.889219e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>1.887257e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2022-09-14</td>\n",
       "      <td>1.863629e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>1.845579e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>1.799500e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>1.787162e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>1.796142e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>1.801299e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>1.791240e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>1.773325e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>1.734565e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>1.770655e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>1.732441e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>1.743458e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>667 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "0    2020-01-02   1.000000e+06\n",
       "1    2020-01-03   9.990798e+05\n",
       "2    2020-01-06   9.990255e+05\n",
       "3    2020-01-07   1.001660e+06\n",
       "4    2020-01-08   9.924351e+05\n",
       "5    2020-01-09   1.003916e+06\n",
       "6    2020-01-10   1.002522e+06\n",
       "7    2020-01-13   1.014264e+06\n",
       "8    2020-01-14   1.011179e+06\n",
       "9    2020-01-15   1.002892e+06\n",
       "10   2020-01-16   1.000139e+06\n",
       "11   2020-01-17   1.017141e+06\n",
       "12   2020-01-20   1.015114e+06\n",
       "13   2020-01-21   1.006224e+06\n",
       "14   2020-01-22   1.009103e+06\n",
       "15   2020-01-23   9.805643e+05\n",
       "16   2020-02-03   9.151319e+05\n",
       "17   2020-02-04   9.329845e+05\n",
       "18   2020-02-05   9.600196e+05\n",
       "19   2020-02-06   9.731475e+05\n",
       "20   2020-02-07   9.750491e+05\n",
       "21   2020-02-10   9.817413e+05\n",
       "22   2020-02-11   9.876559e+05\n",
       "23   2020-02-12   1.003562e+06\n",
       "24   2020-02-13   1.010525e+06\n",
       "..          ...            ...\n",
       "642  2022-08-25   1.913979e+06\n",
       "643  2022-08-26   1.899784e+06\n",
       "644  2022-08-29   1.884870e+06\n",
       "645  2022-08-30   1.900264e+06\n",
       "646  2022-08-31   1.901292e+06\n",
       "647  2022-09-01   1.872672e+06\n",
       "648  2022-09-02   1.845518e+06\n",
       "649  2022-09-05   1.842180e+06\n",
       "650  2022-09-06   1.869809e+06\n",
       "651  2022-09-07   1.871064e+06\n",
       "652  2022-09-08   1.864496e+06\n",
       "653  2022-09-09   1.889219e+06\n",
       "654  2022-09-13   1.887257e+06\n",
       "655  2022-09-14   1.863629e+06\n",
       "656  2022-09-15   1.845579e+06\n",
       "657  2022-09-16   1.799500e+06\n",
       "658  2022-09-19   1.787162e+06\n",
       "659  2022-09-20   1.796142e+06\n",
       "660  2022-09-21   1.801299e+06\n",
       "661  2022-09-22   1.791240e+06\n",
       "662  2022-09-23   1.773325e+06\n",
       "663  2022-09-26   1.734565e+06\n",
       "664  2022-09-27   1.770655e+06\n",
       "665  2022-09-28   1.732441e+06\n",
       "666  2022-09-29   1.743458e+06\n",
       "\n",
       "[667 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:08.838436Z",
     "start_time": "2022-10-13T04:36:08.785645Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "8b9d6c2b",
    "outputId": "3bee87a7-ec13-4b20-9698-040a8e3ecd4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>600010.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600048.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600111.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600436.SH</th>\n",
       "      <th>600438.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "      <th>600585.SH</th>\n",
       "      <th>600588.SH</th>\n",
       "      <th>600690.SH</th>\n",
       "      <th>600809.SH</th>\n",
       "      <th>600837.SH</th>\n",
       "      <th>600887.SH</th>\n",
       "      <th>600893.SH</th>\n",
       "      <th>600900.SH</th>\n",
       "      <th>601012.SH</th>\n",
       "      <th>601088.SH</th>\n",
       "      <th>601166.SH</th>\n",
       "      <th>601288.SH</th>\n",
       "      <th>601318.SH</th>\n",
       "      <th>601398.SH</th>\n",
       "      <th>601601.SH</th>\n",
       "      <th>601628.SH</th>\n",
       "      <th>601633.SH</th>\n",
       "      <th>601668.SH</th>\n",
       "      <th>601688.SH</th>\n",
       "      <th>601857.SH</th>\n",
       "      <th>601888.SH</th>\n",
       "      <th>601899.SH</th>\n",
       "      <th>601919.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>400</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>800</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-10</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-13</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>800</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-14</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-15</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-16</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20</th>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21</th>\n",
       "      <td>300</td>\n",
       "      <td>-800</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-500</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>300</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04</th>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-05</th>\n",
       "      <td>700</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-06</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-07</th>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>900</td>\n",
       "      <td>-700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-10</th>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>900</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-11</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-12</th>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>900</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>700</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>0</td>\n",
       "      <td>-700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-500</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>400</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-05</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>600</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>-1000</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>-1000</td>\n",
       "      <td>300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>1000</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-200</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>-1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>-300</td>\n",
       "      <td>0</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-900</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-700</td>\n",
       "      <td>1000</td>\n",
       "      <td>-100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-23</th>\n",
       "      <td>1000</td>\n",
       "      <td>-800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-26</th>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-300</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-400</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-27</th>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>-400</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>100</td>\n",
       "      <td>-600</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-900</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>600</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-600</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            600010.SH  600028.SH  600030.SH  600031.SH  600036.SH  600048.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02          0          0          0       1000          0          0   \n",
       "2020-01-03        500       1000       1000      -1000          0          0   \n",
       "2020-01-06       1000        100       1000          0          0          0   \n",
       "2020-01-07          0       1000       1000       1000       1000          0   \n",
       "2020-01-08       1000      -1000        800       1000      -1000       1000   \n",
       "2020-01-09      -1000       -300       1000       1000        500       1000   \n",
       "2020-01-10          0       1000          0      -1000       -500       1000   \n",
       "2020-01-13       1000       1000      -1000      -1000       1000      -1000   \n",
       "2020-01-14       1000          0          0      -1000      -1000       1000   \n",
       "2020-01-15      -1000      -1000      -1000       1000          0       1000   \n",
       "2020-01-16      -1000      -1000      -1000      -1000          0       1000   \n",
       "2020-01-17       1000       1000      -1000       1000          0      -1000   \n",
       "2020-01-20        100      -1000       1000      -1000       1000      -1000   \n",
       "2020-01-21        300       -800       -900       1000      -1000       1000   \n",
       "2020-01-22        200       1000       -900          0          0       1000   \n",
       "2020-01-23        300       -800          0      -1000          0      -1000   \n",
       "2020-02-03        100       1000          0          0          0       1000   \n",
       "2020-02-04        200      -1000          0          0          0       1000   \n",
       "2020-02-05        700       -200       1000          0       1000       1000   \n",
       "2020-02-06      -1000          0      -1000          0      -1000          0   \n",
       "2020-02-07       -600       1000          0          0          0       -600   \n",
       "2020-02-10       -600      -1000       1000          0        200       1000   \n",
       "2020-02-11      -1000          0      -1000          0       -200        500   \n",
       "2020-02-12        300          0          0          0          0       1000   \n",
       "2020-02-13      -1000          0          0          0          0      -1000   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24      -1000          0       -600      -1000          0       1000   \n",
       "2022-08-25       1000       1000       -400      -1000          0      -1000   \n",
       "2022-08-26       1000      -1000          0      -1000          0          0   \n",
       "2022-08-29       1000          0       1000       1000          0          0   \n",
       "2022-08-30      -1000          0      -1000      -1000          0          0   \n",
       "2022-08-31       1000       1000       1000       1000          0          0   \n",
       "2022-09-01          0       -700      -1000      -1000       1000          0   \n",
       "2022-09-02      -1000       -300       1000       1000       1000          0   \n",
       "2022-09-05       1000          0      -1000      -1000          0          0   \n",
       "2022-09-06      -1000          0       1000       1000      -1000          0   \n",
       "2022-09-07      -1000          0      -1000        300      -1000          0   \n",
       "2022-09-08       1000          0          0          0          0        900   \n",
       "2022-09-09      -1000          0          0      -1000          0       -900   \n",
       "2022-09-13       1000          0       1000       -400          0          0   \n",
       "2022-09-14      -1000        300      -1000          0          0          0   \n",
       "2022-09-15       1000       -200          0          0          0       1000   \n",
       "2022-09-16      -1000       -100          0          0          0      -1000   \n",
       "2022-09-19        300          0          0          0       1000          0   \n",
       "2022-09-20       1000          0          0          0       1000       1000   \n",
       "2022-09-21       1000        500       1000       1000      -1000      -1000   \n",
       "2022-09-22          0        300      -1000      -1000          0          0   \n",
       "2022-09-23       1000       -800          0          0      -1000       1000   \n",
       "2022-09-26        200          0       1000       1000          0      -1000   \n",
       "2022-09-27      -1000          0        500       -400          0       1000   \n",
       "2022-09-28       1000       1000      -1000       -600        100       1000   \n",
       "\n",
       "            600104.SH  600111.SH  600196.SH  600276.SH  600309.SH  600436.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02          0          0       1000       1000          0          0   \n",
       "2020-01-03          0          0       1000      -1000          0          0   \n",
       "2020-01-06          0       1000      -1000          0          0          0   \n",
       "2020-01-07       1000      -1000      -1000       1000       1000       1000   \n",
       "2020-01-08      -1000        500          0      -1000      -1000      -1000   \n",
       "2020-01-09       1000        600          0          0          0        200   \n",
       "2020-01-10      -1000      -1000          0       1000          0       -200   \n",
       "2020-01-13          0       -100          0      -1000       1000          0   \n",
       "2020-01-14          0          0          0       1000       1000          0   \n",
       "2020-01-15          0          0          0       1000       -100          0   \n",
       "2020-01-16       1000          0          0       1000      -1000          0   \n",
       "2020-01-17       -500       1000          0        300        100          0   \n",
       "2020-01-20       1000       1000       1000        200      -1000          0   \n",
       "2020-01-21      -1000      -1000      -1000          0          0          0   \n",
       "2020-01-22       -500      -1000          0       1000          0          0   \n",
       "2020-01-23          0          0       1000      -1000          0          0   \n",
       "2020-02-03          0          0       1000       1000       1000          0   \n",
       "2020-02-04       1000          0      -1000      -1000      -1000       1000   \n",
       "2020-02-05       1000          0          0        800        100      -1000   \n",
       "2020-02-06      -1000          0       1000      -1000       -100        700   \n",
       "2020-02-07       1000          0       1000      -1000          0       -700   \n",
       "2020-02-10        900       1000       1000      -1000          0          0   \n",
       "2020-02-11       1000      -1000       1000      -1000       1000          0   \n",
       "2020-02-12       1000          0       1000       -300      -1000          0   \n",
       "2020-02-13       1000        800        600          0          0          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24        600      -1000       1000       -300          0          0   \n",
       "2022-08-25      -1000          0      -1000      -1000          0        300   \n",
       "2022-08-26      -1000       1000          0      -1000       1000       -300   \n",
       "2022-08-29       -900      -1000       -700      -1000       -100          0   \n",
       "2022-08-30          0          0      -1000      -1000       -900       1000   \n",
       "2022-08-31          0      -1000       1000       1000          0          0   \n",
       "2022-09-01          0       1000       1000       1000          0          0   \n",
       "2022-09-02          0       1000      -1000      -1000          0      -1000   \n",
       "2022-09-05          0      -1000        700      -1000          0          0   \n",
       "2022-09-06          0       1000      -1000      -1000          0       1000   \n",
       "2022-09-07          0      -1000       -700       1000          0      -1000   \n",
       "2022-09-08          0       1000          0      -1000       1000       1000   \n",
       "2022-09-09        400      -1000          0       -100       1000       -700   \n",
       "2022-09-13       1000       1000       1000       1000      -1000       -300   \n",
       "2022-09-14          0      -1000      -1000          0      -1000          0   \n",
       "2022-09-15      -1000          0       1000      -1000          0          0   \n",
       "2022-09-16       -400        500          0          0          0          0   \n",
       "2022-09-19          0      -1000       -700          0       1000        300   \n",
       "2022-09-20          0       1000       1000          0      -1000       -300   \n",
       "2022-09-21       1000       1000       1000       1000          0          0   \n",
       "2022-09-22      -1000      -1000      -1000          0          0          0   \n",
       "2022-09-23          0          0      -1000       1000          0          0   \n",
       "2022-09-26          0       1000       -300       1000          0        900   \n",
       "2022-09-27          0      -1000        100       -600          0       -900   \n",
       "2022-09-28       1000       1000       1000       1000          0          0   \n",
       "\n",
       "            600438.SH  600519.SH  600570.SH  600585.SH  600588.SH  600690.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02       1000          0          0          0       1000        500   \n",
       "2020-01-03       1000        700          0          0      -1000          0   \n",
       "2020-01-06      -1000       -700        500       1000       1000       -500   \n",
       "2020-01-07       1000        300        100      -1000          0          0   \n",
       "2020-01-08      -1000       -300       1000          0       1000          0   \n",
       "2020-01-09      -1000          0      -1000          0       1000       1000   \n",
       "2020-01-10       1000        300        400          0      -1000      -1000   \n",
       "2020-01-13       1000       -300      -1000       1000       1000          0   \n",
       "2020-01-14       1000          0       1000          0      -1000          0   \n",
       "2020-01-15      -1000          0       1000      -1000      -1000          0   \n",
       "2020-01-16       1000          0      -1000       1000       -500          0   \n",
       "2020-01-17          0          0          0          0       -500          0   \n",
       "2020-01-20          0          0          0      -1000          0          0   \n",
       "2020-01-21       1000          0      -1000          0       1000          0   \n",
       "2020-01-22       1000          0       1000          0        800          0   \n",
       "2020-01-23       -700          0       1000       1000      -1000        600   \n",
       "2020-02-03       -700          0      -1000      -1000       -800       1000   \n",
       "2020-02-04       1000          0      -1000          0          0        100   \n",
       "2020-02-05          0          0          0          0          0          0   \n",
       "2020-02-06      -1000          0          0          0          0      -1000   \n",
       "2020-02-07       1000          0          0       1000        900       -700   \n",
       "2020-02-10        300          0          0      -1000       -900          0   \n",
       "2020-02-11       1000        100          0          0       1000          0   \n",
       "2020-02-12       1000       -100          0          0       1000       1000   \n",
       "2020-02-13      -1000          0       1000          0      -1000      -1000   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24          0          0          0       1000          0          0   \n",
       "2022-08-25      -1000          0          0       1000          0       1000   \n",
       "2022-08-26      -1000          0          0      -1000       1000      -1000   \n",
       "2022-08-29      -1000        100          0      -1000      -1000       1000   \n",
       "2022-08-30       1000       -100          0      -1000          0      -1000   \n",
       "2022-08-31        400          0          0        100          0       1000   \n",
       "2022-09-01          0          0        400          0          0      -1000   \n",
       "2022-09-02      -1000          0       -400       1000          0          0   \n",
       "2022-09-05       1000        200       1000      -1000       1000          0   \n",
       "2022-09-06      -1000       -200      -1000      -1000       1000          0   \n",
       "2022-09-07      -1000          0          0        200       1000       1000   \n",
       "2022-09-08       -800          0          0       1000       1000      -1000   \n",
       "2022-09-09          0          0          0      -1000       -400       1000   \n",
       "2022-09-13       1000          0          0       -300      -1000      -1000   \n",
       "2022-09-14          0          0          0          0      -1000          0   \n",
       "2022-09-15      -1000          0          0          0       -200       1000   \n",
       "2022-09-16          0          0          0          0      -1000      -1000   \n",
       "2022-09-19        100          0          0        100          0          0   \n",
       "2022-09-20       1000          0       1000        800       1000       1000   \n",
       "2022-09-21       1000          0      -1000       -900       1000      -1000   \n",
       "2022-09-22          0          0          0          0      -1000          0   \n",
       "2022-09-23       1000          0          0        800      -1000       1000   \n",
       "2022-09-26        200          0          0        100       -400      -1000   \n",
       "2022-09-27      -1000          0          0       -900          0       1000   \n",
       "2022-09-28       1000          0       1000       1000          0      -1000   \n",
       "\n",
       "            600809.SH  600837.SH  600887.SH  600893.SH  600900.SH  601012.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02          0          0          0          0          0        600   \n",
       "2020-01-03          0       1000          0          0          0          0   \n",
       "2020-01-06          0       1000          0          0       1000       -600   \n",
       "2020-01-07          0      -1000          0          0       1000          0   \n",
       "2020-01-08       1000       -200          0       1000      -1000       1000   \n",
       "2020-01-09      -1000       1000          0       1000      -1000      -1000   \n",
       "2020-01-10          0          0          0      -1000          0          0   \n",
       "2020-01-13          0       -300        800       1000          0          0   \n",
       "2020-01-14          0      -1000       -800      -1000       1000          0   \n",
       "2020-01-15          0       1000       1000      -1000       1000          0   \n",
       "2020-01-16          0       1000      -1000          0       1000          0   \n",
       "2020-01-17       1000      -1000          0        100      -1000          0   \n",
       "2020-01-20          0      -1000          0       -100          0          0   \n",
       "2020-01-21      -1000       1000          0          0      -1000       1000   \n",
       "2020-01-22          0          0          0          0          0          0   \n",
       "2020-01-23          0          0          0          0          0          0   \n",
       "2020-02-03          0          0          0       1000      -1000      -1000   \n",
       "2020-02-04       1000      -1000          0          0          0          0   \n",
       "2020-02-05          0       -500          0      -1000          0          0   \n",
       "2020-02-06       1000          0          0          0          0          0   \n",
       "2020-02-07      -1000       1000       1000          0       1000          0   \n",
       "2020-02-10      -1000      -1000      -1000       1000      -1000       1000   \n",
       "2020-02-11          0        100          0      -1000       1000      -1000   \n",
       "2020-02-12          0       1000       1000          0      -1000          0   \n",
       "2020-02-13          0      -1000       1000       1000       1000          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24          0       1000       1000       1000       1000      -1000   \n",
       "2022-08-25          0       1000      -1000        500       1000          0   \n",
       "2022-08-26        400      -1000          0      -1000       1000       1000   \n",
       "2022-08-29       -400       1000          0       1000      -1000      -1000   \n",
       "2022-08-30          0       1000          0      -1000        500          0   \n",
       "2022-08-31          0      -1000       1000      -1000      -1000       1000   \n",
       "2022-09-01          0      -1000          0       -500          0      -1000   \n",
       "2022-09-02          0      -1000      -1000          0      -1000          0   \n",
       "2022-09-05          0      -1000          0          0      -1000          0   \n",
       "2022-09-06          0       1000       1000          0       1000          0   \n",
       "2022-09-07          0       1000       1000          0      -1000          0   \n",
       "2022-09-08          0          0      -1000          0       1000          0   \n",
       "2022-09-09          0      -1000       1000          0       1000       1000   \n",
       "2022-09-13          0      -1000      -1000       1000       1000      -1000   \n",
       "2022-09-14          0      -1000          0          0          0       1000   \n",
       "2022-09-15       1000          0       1000      -1000       1000      -1000   \n",
       "2022-09-16        700          0       -300          0       -800          0   \n",
       "2022-09-19          0          0       -600          0          0          0   \n",
       "2022-09-20      -1000       1000      -1000          0      -1000       1000   \n",
       "2022-09-21       -700       1000       -100       1000       1000      -1000   \n",
       "2022-09-22       1000          0          0      -1000      -1000          0   \n",
       "2022-09-23      -1000      -1000          0          0      -1000          0   \n",
       "2022-09-26          0          0          0          0          0       1000   \n",
       "2022-09-27          0      -1000          0          0       1000       1000   \n",
       "2022-09-28          0          0       1000          0       -100      -1000   \n",
       "\n",
       "            601088.SH  601166.SH  601288.SH  601318.SH  601398.SH  601601.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02       1000          0          0          0          0       1000   \n",
       "2020-01-03       1000          0          0          0          0       -300   \n",
       "2020-01-06      -1000       1000          0          0          0        600   \n",
       "2020-01-07      -1000      -1000          0          0          0          0   \n",
       "2020-01-08          0          0          0          0          0      -1000   \n",
       "2020-01-09          0        100          0          0          0       1000   \n",
       "2020-01-10       1000          0          0          0          0          0   \n",
       "2020-01-13       1000       -100          0          0        200      -1000   \n",
       "2020-01-14       1000       1000          0       1000       -200       1000   \n",
       "2020-01-15       1000       1000       1000      -1000          0      -1000   \n",
       "2020-01-16      -1000      -1000      -1000          0        900       -300   \n",
       "2020-01-17          0       1000          0          0       -900          0   \n",
       "2020-01-20       1000          0          0          0          0          0   \n",
       "2020-01-21      -1000       1000          0          0       1000          0   \n",
       "2020-01-22       1000      -1000          0          0      -1000          0   \n",
       "2020-01-23          0      -1000       1000          0          0          0   \n",
       "2020-02-03      -1000          0      -1000          0          0          0   \n",
       "2020-02-04          0       1000          0          0          0          0   \n",
       "2020-02-05       1000      -1000          0          0          0          0   \n",
       "2020-02-06       -600          0       1000          0          0          0   \n",
       "2020-02-07       1000      -1000       1000          0       1000          0   \n",
       "2020-02-10       1000          0       1000          0      -1000       1000   \n",
       "2020-02-11      -1000          0       1000          0       1000      -1000   \n",
       "2020-02-12       -900          0      -1000       1000      -1000          0   \n",
       "2020-02-13       1000        900       1000      -1000          0          0   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24          0          0      -1000          0          0          0   \n",
       "2022-08-25          0       1000      -1000        200       1000          0   \n",
       "2022-08-26          0      -1000       1000       -200       1000        600   \n",
       "2022-08-29        100       1000       1000          0      -1000       1000   \n",
       "2022-08-30       -100      -1000       1000       1000      -1000      -1000   \n",
       "2022-08-31          0       1000       1000      -1000       1000       -600   \n",
       "2022-09-01          0       1000          0          0      -1000          0   \n",
       "2022-09-02          0       -300       1000          0       1000        400   \n",
       "2022-09-05       1000       1000        100          0      -1000          0   \n",
       "2022-09-06       1000       1000       1000          0       1000       -400   \n",
       "2022-09-07       1000      -1000      -1000       1000       1000          0   \n",
       "2022-09-08       1000      -1000      -1000       1000       1000       1000   \n",
       "2022-09-09       1000      -1000      -1000       1000       1000      -1000   \n",
       "2022-09-13      -1000       1000      -1000      -1000       1000        200   \n",
       "2022-09-14          0      -1000      -1000          0       -900       -200   \n",
       "2022-09-15      -1000       1000       1000      -1000          0          0   \n",
       "2022-09-16      -1000       -900      -1000      -1000          0          0   \n",
       "2022-09-19       1000       -700      -1000          0          0          0   \n",
       "2022-09-20        600       1000       1000          0      -1000          0   \n",
       "2022-09-21      -1000      -1000      -1000          0      -1000       1000   \n",
       "2022-09-22      -1000          0          0        400          0      -1000   \n",
       "2022-09-23      -1000       1000      -1000       -400      -1000          0   \n",
       "2022-09-26       -600          0          0          0      -1000          0   \n",
       "2022-09-27       1000       1000       1000        600       -100          0   \n",
       "2022-09-28      -1000      -1000      -1000       1000          0        100   \n",
       "\n",
       "            601628.SH  601633.SH  601668.SH  601688.SH  601857.SH  601888.SH  \\\n",
       "date                                                                           \n",
       "2020-01-02          0       1000        700          0       1000          0   \n",
       "2020-01-03          0          0          0          0      -1000          0   \n",
       "2020-01-06          0          0       -700          0          0        100   \n",
       "2020-01-07          0          0          0          0          0          0   \n",
       "2020-01-08          0      -1000        600       1000       1000       -100   \n",
       "2020-01-09       1000          0       -600       1000        500       1000   \n",
       "2020-01-10      -1000          0          0       -600        100      -1000   \n",
       "2020-01-13          0       1000          0       1000      -1000          0   \n",
       "2020-01-14       1000        300          0      -1000       1000          0   \n",
       "2020-01-15      -1000      -1000          0      -1000       1000          0   \n",
       "2020-01-16          0       -300          0       -400       1000          0   \n",
       "2020-01-17          0          0          0          0       -100          0   \n",
       "2020-01-20          0          0          0          0        100          0   \n",
       "2020-01-21       1000          0          0          0      -1000          0   \n",
       "2020-01-22       -900          0          0          0      -1000          0   \n",
       "2020-01-23          0          0          0          0          0          0   \n",
       "2020-02-03          0          0          0          0          0          0   \n",
       "2020-02-04       -100          0          0          0          0          0   \n",
       "2020-02-05          0          0          0          0      -1000          0   \n",
       "2020-02-06          0          0          0          0       1000          0   \n",
       "2020-02-07          0          0       1000       1000       1000          0   \n",
       "2020-02-10       1000          0      -1000       -700        100          0   \n",
       "2020-02-11      -1000       1000          0       -300      -1000       1000   \n",
       "2020-02-12          0        100          0          0          0          0   \n",
       "2020-02-13          0      -1000          0        900      -1000      -1000   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2022-08-24          0          0          0          0        100          0   \n",
       "2022-08-25          0       -500          0       1000       -100          0   \n",
       "2022-08-26          0       -500       1000      -1000       1000          0   \n",
       "2022-08-29          0          0       1000          0      -1000          0   \n",
       "2022-08-30       1000          0      -1000        100       1000        700   \n",
       "2022-08-31       1000          0       1000       -100      -1000       -700   \n",
       "2022-09-01      -1000          0       -100          0          0          0   \n",
       "2022-09-02       -100          0       1000          0        800          0   \n",
       "2022-09-05          0          0        300          0       -800          0   \n",
       "2022-09-06       -900       1000      -1000          0          0        600   \n",
       "2022-09-07          0      -1000      -1000          0       1000       -600   \n",
       "2022-09-08          0          0        100          0      -1000          0   \n",
       "2022-09-09          0          0      -1000          0          0          0   \n",
       "2022-09-13          0          0          0          0          0        900   \n",
       "2022-09-14          0          0       -300          0          0       1000   \n",
       "2022-09-15          0          0       1000        200          0      -1000   \n",
       "2022-09-16          0          0        100       -200          0          0   \n",
       "2022-09-19          0          0      -1000          0          0       -900   \n",
       "2022-09-20       1000          0       -100       1000          0          0   \n",
       "2022-09-21       1000          0       1000       1000          0       1000   \n",
       "2022-09-22      -1000          0      -1000      -1000          0          0   \n",
       "2022-09-23      -1000       1000          0      -1000       1000       1000   \n",
       "2022-09-26          0          0          0          0          0      -1000   \n",
       "2022-09-27       1000      -1000          0          0      -1000      -1000   \n",
       "2022-09-28       -100          0          0          0       1000       1000   \n",
       "\n",
       "            601899.SH  601919.SH  \n",
       "date                              \n",
       "2020-01-02          0          0  \n",
       "2020-01-03       1000       1000  \n",
       "2020-01-06        400       1000  \n",
       "2020-01-07          0       1000  \n",
       "2020-01-08       1000       1000  \n",
       "2020-01-09        400       1000  \n",
       "2020-01-10       1000       1000  \n",
       "2020-01-13       1000       1000  \n",
       "2020-01-14          0       1000  \n",
       "2020-01-15       1000       1000  \n",
       "2020-01-16       1000       1000  \n",
       "2020-01-17      -1000       -100  \n",
       "2020-01-20      -1000       1000  \n",
       "2020-01-21       -600       1000  \n",
       "2020-01-22        500       1000  \n",
       "2020-01-23        300       1000  \n",
       "2020-02-03        500       1000  \n",
       "2020-02-04        200      -1000  \n",
       "2020-02-05      -1000       1000  \n",
       "2020-02-06        900          0  \n",
       "2020-02-07       1000      -1000  \n",
       "2020-02-10       1000       1000  \n",
       "2020-02-11      -1000       1000  \n",
       "2020-02-12      -1000      -1000  \n",
       "2020-02-13      -1000       1000  \n",
       "...               ...        ...  \n",
       "2022-08-24      -1000       1000  \n",
       "2022-08-25       1000      -1000  \n",
       "2022-08-26       1000       1000  \n",
       "2022-08-29       1000      -1000  \n",
       "2022-08-30       1000       1000  \n",
       "2022-08-31       1000      -1000  \n",
       "2022-09-01          0       1000  \n",
       "2022-09-02      -1000      -1000  \n",
       "2022-09-05       1000       -600  \n",
       "2022-09-06       -300      -1000  \n",
       "2022-09-07      -1000        400  \n",
       "2022-09-08       1000      -1000  \n",
       "2022-09-09       1000      -1000  \n",
       "2022-09-13          0       1000  \n",
       "2022-09-14      -1000          0  \n",
       "2022-09-15       1000          0  \n",
       "2022-09-16      -1000      -1000  \n",
       "2022-09-19       -600       1000  \n",
       "2022-09-20       1000        900  \n",
       "2022-09-21       -600       1000  \n",
       "2022-09-22          0      -1000  \n",
       "2022-09-23       1000       1000  \n",
       "2022-09-26      -1000       1000  \n",
       "2022-09-27       1000      -1000  \n",
       "2022-09-28       1000      -1000  \n",
       "\n",
       "[666 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.to_csv(\"./results/ppo/action.csv\",index=False)\n",
    "df_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ea8a81c"
   },
   "source": [
    "## Backtesting\n",
    "回测在评估交易策略的表现方面起着关键作用。自动回测工具是首选，因为它减少了人为错误。在量化金融中通常使用[Quantopian Pyfolio](https://github.com/quantopian/pyfolio)软件包来回测我们的交易策略。它很容易使用，由各种单独的图表组成，提供了交易策略表现的全面图像。\n",
    "\n",
    "### Backtesting Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:44.348532Z",
     "start_time": "2022-10-13T04:36:44.313157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.233695\n",
      "Cumulative returns     0.743458\n",
      "Annual volatility      0.306626\n",
      "Sharpe ratio           0.840366\n",
      "Calmar ratio           0.612391\n",
      "Stability              0.560671\n",
      "Max drawdown          -0.381611\n",
      "Omega ratio            1.149555\n",
      "Sortino ratio          1.173858\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.984182\n",
      "Daily value at risk   -0.037609\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./results/ppo/\"+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:45.842322Z",
     "start_time": "2022-10-13T04:36:45.836886Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotter = ReturnPlotter(df_account_value, trade, '20200101', '20220928', token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:46.592457Z",
     "start_time": "2022-10-13T04:36:46.362627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "Annual return         -0.061707\n",
      "Cumulative returns    -0.154926\n",
      "Annual volatility      0.205370\n",
      "Sharpe ratio          -0.207751\n",
      "Calmar ratio          -0.175489\n",
      "Stability              0.039829\n",
      "Max drawdown          -0.351629\n",
      "Omega ratio            0.965096\n",
      "Sortino ratio         -0.284098\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.921966\n",
      "Daily value at risk   -0.026043\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = plotter.get_baseline(\"000016.SH\") # 沪深300 399300.SZ 上证50 000016.SH\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
    "base_stats = pd.DataFrame(stats)\n",
    "base_stats.to_csv(\"./results/\"+\"base_stats\"+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:47.511799Z",
     "start_time": "2022-10-13T04:36:47.465613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_code</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3107.5172</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3063.2190</td>\n",
       "      <td>27.6141</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>50036392.0</td>\n",
       "      <td>9.477373e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>3097.2518</td>\n",
       "      <td>3097.4088</td>\n",
       "      <td>3072.1137</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>-12.5538</td>\n",
       "      <td>-0.4062</td>\n",
       "      <td>37185493.0</td>\n",
       "      <td>7.234679e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>3062.2801</td>\n",
       "      <td>3090.8402</td>\n",
       "      <td>3040.1945</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>-21.4434</td>\n",
       "      <td>-0.6966</td>\n",
       "      <td>47707827.0</td>\n",
       "      <td>7.777039e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>3063.7464</td>\n",
       "      <td>3080.2714</td>\n",
       "      <td>3061.5608</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>17.1793</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>34371788.0</td>\n",
       "      <td>5.688658e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>3058.3585</td>\n",
       "      <td>3058.6969</td>\n",
       "      <td>3030.1048</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>-36.1627</td>\n",
       "      <td>-1.1764</td>\n",
       "      <td>37653773.0</td>\n",
       "      <td>5.985484e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>3060.7743</td>\n",
       "      <td>3071.5392</td>\n",
       "      <td>3055.9906</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>29.6931</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>33150515.0</td>\n",
       "      <td>5.767682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>3079.0765</td>\n",
       "      <td>3081.9568</td>\n",
       "      <td>3058.1642</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>28542389.0</td>\n",
       "      <td>5.163493e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>3069.6784</td>\n",
       "      <td>3090.1310</td>\n",
       "      <td>3054.8783</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>22.2474</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>29330835.0</td>\n",
       "      <td>5.705225e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>3097.7248</td>\n",
       "      <td>3108.1770</td>\n",
       "      <td>3078.4579</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>-9.5268</td>\n",
       "      <td>-0.3083</td>\n",
       "      <td>35129017.0</td>\n",
       "      <td>5.696145e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>3078.2528</td>\n",
       "      <td>3086.9662</td>\n",
       "      <td>3052.7047</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>-22.5938</td>\n",
       "      <td>-0.7334</td>\n",
       "      <td>28116086.0</td>\n",
       "      <td>4.697157e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>3067.9500</td>\n",
       "      <td>3068.1971</td>\n",
       "      <td>3039.0726</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>-14.9147</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>28312318.0</td>\n",
       "      <td>4.549775e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>3054.0361</td>\n",
       "      <td>3067.5589</td>\n",
       "      <td>3042.5897</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>10.0798</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>23304514.0</td>\n",
       "      <td>4.622461e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>3070.6701</td>\n",
       "      <td>3072.2888</td>\n",
       "      <td>3054.4484</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>12.8177</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>27274849.0</td>\n",
       "      <td>5.562321e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>3048.9459</td>\n",
       "      <td>3050.8233</td>\n",
       "      <td>3011.1846</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>-53.8783</td>\n",
       "      <td>-1.7573</td>\n",
       "      <td>32801291.0</td>\n",
       "      <td>5.974027e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>2996.8099</td>\n",
       "      <td>3023.9019</td>\n",
       "      <td>2965.6635</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>5.7662</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>33159760.0</td>\n",
       "      <td>6.050915e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2910.3942</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>-85.3853</td>\n",
       "      <td>-2.8293</td>\n",
       "      <td>42839352.0</td>\n",
       "      <td>7.550661e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2755.8448</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>-205.4001</td>\n",
       "      <td>-7.0043</td>\n",
       "      <td>58609184.0</td>\n",
       "      <td>9.613125e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2796.7145</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>67.5675</td>\n",
       "      <td>2.4776</td>\n",
       "      <td>57016369.0</td>\n",
       "      <td>9.185602e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>2803.7374</td>\n",
       "      <td>2833.2097</td>\n",
       "      <td>2782.4231</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>18.2387</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>44182070.0</td>\n",
       "      <td>7.342200e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>2829.5111</td>\n",
       "      <td>2866.3906</td>\n",
       "      <td>2809.3661</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>41.9885</td>\n",
       "      <td>1.4927</td>\n",
       "      <td>42134251.0</td>\n",
       "      <td>7.041728e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>2836.7992</td>\n",
       "      <td>2851.8244</td>\n",
       "      <td>2819.6678</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>-3.1773</td>\n",
       "      <td>-0.1113</td>\n",
       "      <td>34443628.0</td>\n",
       "      <td>5.906509e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>2826.7970</td>\n",
       "      <td>2854.8289</td>\n",
       "      <td>2817.7707</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>-1.6463</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>33654934.0</td>\n",
       "      <td>5.664824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>2858.9245</td>\n",
       "      <td>2893.0673</td>\n",
       "      <td>2854.0722</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>29.7933</td>\n",
       "      <td>1.0454</td>\n",
       "      <td>36028244.0</td>\n",
       "      <td>5.851942e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>2876.6708</td>\n",
       "      <td>2895.9268</td>\n",
       "      <td>2870.7680</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>15.7284</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>31230750.0</td>\n",
       "      <td>5.212694e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>2875.4794</td>\n",
       "      <td>2898.3985</td>\n",
       "      <td>2906.7218</td>\n",
       "      <td>2871.2649</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>-20.1065</td>\n",
       "      <td>-0.6944</td>\n",
       "      <td>37434764.0</td>\n",
       "      <td>5.784494e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>2708.0902</td>\n",
       "      <td>2738.3837</td>\n",
       "      <td>2750.8719</td>\n",
       "      <td>2706.1522</td>\n",
       "      <td>2735.6660</td>\n",
       "      <td>-27.5758</td>\n",
       "      <td>-1.0080</td>\n",
       "      <td>30925306.0</td>\n",
       "      <td>6.473540e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>2715.6384</td>\n",
       "      <td>2756.9393</td>\n",
       "      <td>2707.4573</td>\n",
       "      <td>2708.0902</td>\n",
       "      <td>44.4658</td>\n",
       "      <td>1.6420</td>\n",
       "      <td>31964009.0</td>\n",
       "      <td>6.690695e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>2758.5070</td>\n",
       "      <td>2763.6428</td>\n",
       "      <td>2745.5172</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>-0.9666</td>\n",
       "      <td>-0.0351</td>\n",
       "      <td>26031347.0</td>\n",
       "      <td>5.915288e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>2721.8592</td>\n",
       "      <td>2736.5962</td>\n",
       "      <td>2718.9674</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>-19.3839</td>\n",
       "      <td>-0.7045</td>\n",
       "      <td>24890507.0</td>\n",
       "      <td>4.933771e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>2731.9805</td>\n",
       "      <td>2741.5952</td>\n",
       "      <td>2705.0459</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>-5.5453</td>\n",
       "      <td>-0.2030</td>\n",
       "      <td>25930522.0</td>\n",
       "      <td>4.997384e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2779.6158</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>35.1229</td>\n",
       "      <td>1.2881</td>\n",
       "      <td>39886395.0</td>\n",
       "      <td>8.449570e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>2750.0334</td>\n",
       "      <td>2757.8794</td>\n",
       "      <td>2731.6963</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>-29.3841</td>\n",
       "      <td>-1.0640</td>\n",
       "      <td>25422479.0</td>\n",
       "      <td>5.389230e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>2737.1969</td>\n",
       "      <td>2740.6630</td>\n",
       "      <td>2698.3276</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>-21.1348</td>\n",
       "      <td>-0.7735</td>\n",
       "      <td>22781335.0</td>\n",
       "      <td>4.629397e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>2700.1077</td>\n",
       "      <td>2706.9588</td>\n",
       "      <td>2676.6046</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>-13.4977</td>\n",
       "      <td>-0.4978</td>\n",
       "      <td>24938690.0</td>\n",
       "      <td>5.355364e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>2706.0966</td>\n",
       "      <td>2726.7159</td>\n",
       "      <td>2703.9982</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>26.7315</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>29124448.0</td>\n",
       "      <td>5.935016e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>2709.7667</td>\n",
       "      <td>2718.1716</td>\n",
       "      <td>2703.0843</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>-13.8118</td>\n",
       "      <td>-0.5069</td>\n",
       "      <td>23454754.0</td>\n",
       "      <td>5.220405e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>2714.0277</td>\n",
       "      <td>2725.2493</td>\n",
       "      <td>2707.4661</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>-2.4080</td>\n",
       "      <td>-0.0888</td>\n",
       "      <td>24209022.0</td>\n",
       "      <td>4.556862e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>2719.0141</td>\n",
       "      <td>2763.1682</td>\n",
       "      <td>2710.7661</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>49.2877</td>\n",
       "      <td>1.8199</td>\n",
       "      <td>32485640.0</td>\n",
       "      <td>6.684816e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>2769.4104</td>\n",
       "      <td>2781.3967</td>\n",
       "      <td>2751.0927</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>11.6689</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>29928992.0</td>\n",
       "      <td>6.246759e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-14</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>2734.9100</td>\n",
       "      <td>2760.4016</td>\n",
       "      <td>2732.7832</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>-23.8064</td>\n",
       "      <td>-0.8597</td>\n",
       "      <td>24848499.0</td>\n",
       "      <td>4.615128e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>2753.1287</td>\n",
       "      <td>2769.4571</td>\n",
       "      <td>2728.8354</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>-1.6398</td>\n",
       "      <td>-0.0597</td>\n",
       "      <td>33698861.0</td>\n",
       "      <td>6.522469e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2731.9648</td>\n",
       "      <td>2738.6483</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>-65.7555</td>\n",
       "      <td>-2.3965</td>\n",
       "      <td>38441774.0</td>\n",
       "      <td>6.550020e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>2677.3329</td>\n",
       "      <td>2695.4014</td>\n",
       "      <td>2669.0870</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>1.5526</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>27260379.0</td>\n",
       "      <td>4.697462e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>2688.1681</td>\n",
       "      <td>2691.5533</td>\n",
       "      <td>2666.6566</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>-5.7053</td>\n",
       "      <td>-0.2129</td>\n",
       "      <td>23751394.0</td>\n",
       "      <td>4.343682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>2667.1680</td>\n",
       "      <td>2670.0647</td>\n",
       "      <td>2641.7189</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>-21.6662</td>\n",
       "      <td>-0.8103</td>\n",
       "      <td>23960147.0</td>\n",
       "      <td>4.560560e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>2631.9968</td>\n",
       "      <td>2645.5662</td>\n",
       "      <td>2621.8224</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>-22.8441</td>\n",
       "      <td>-0.8613</td>\n",
       "      <td>24229236.0</td>\n",
       "      <td>4.345603e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>2625.2488</td>\n",
       "      <td>2649.8066</td>\n",
       "      <td>2618.9402</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>30277934.0</td>\n",
       "      <td>4.635576e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>2612.6673</td>\n",
       "      <td>2650.2542</td>\n",
       "      <td>2611.5292</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>-14.9091</td>\n",
       "      <td>-0.5669</td>\n",
       "      <td>34384533.0</td>\n",
       "      <td>5.579267e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>2616.0501</td>\n",
       "      <td>2645.7366</td>\n",
       "      <td>2605.2407</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>28.0214</td>\n",
       "      <td>1.0716</td>\n",
       "      <td>26144970.0</td>\n",
       "      <td>5.021519e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>2611.9815</td>\n",
       "      <td>2635.2559</td>\n",
       "      <td>2637.0155</td>\n",
       "      <td>2608.6405</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>-30.9397</td>\n",
       "      <td>-1.1707</td>\n",
       "      <td>24732086.0</td>\n",
       "      <td>4.772510e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>666 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ts_code       date      close       open       high        low  \\\n",
       "665  000016.SH 2020-01-02  3090.8331  3073.9313  3107.5172  3073.9313   \n",
       "664  000016.SH 2020-01-03  3078.2793  3097.2518  3097.4088  3072.1137   \n",
       "663  000016.SH 2020-01-06  3056.8359  3062.2801  3090.8402  3040.1945   \n",
       "662  000016.SH 2020-01-07  3074.0152  3063.7464  3080.2714  3061.5608   \n",
       "661  000016.SH 2020-01-08  3037.8525  3058.3585  3058.6969  3030.1048   \n",
       "660  000016.SH 2020-01-09  3067.5456  3060.7743  3071.5392  3055.9906   \n",
       "659  000016.SH 2020-01-10  3067.8810  3079.0765  3081.9568  3058.1642   \n",
       "658  000016.SH 2020-01-13  3090.1284  3069.6784  3090.1310  3054.8783   \n",
       "657  000016.SH 2020-01-14  3080.6016  3097.7248  3108.1770  3078.4579   \n",
       "656  000016.SH 2020-01-15  3058.0078  3078.2528  3086.9662  3052.7047   \n",
       "655  000016.SH 2020-01-16  3043.0931  3067.9500  3068.1971  3039.0726   \n",
       "654  000016.SH 2020-01-17  3053.1729  3054.0361  3067.5589  3042.5897   \n",
       "653  000016.SH 2020-01-20  3065.9906  3070.6701  3072.2888  3054.4484   \n",
       "652  000016.SH 2020-01-21  3012.1123  3048.9459  3050.8233  3011.1846   \n",
       "651  000016.SH 2020-01-22  3017.8785  2996.8099  3023.9019  2965.6635   \n",
       "650  000016.SH 2020-01-23  2932.4932  2993.7726  2993.7726  2910.3942   \n",
       "649  000016.SH 2020-02-03  2727.0931  2676.0073  2755.8448  2676.0073   \n",
       "648  000016.SH 2020-02-04  2794.6606  2724.1314  2796.7145  2724.1314   \n",
       "647  000016.SH 2020-02-05  2812.8993  2803.7374  2833.2097  2782.4231   \n",
       "646  000016.SH 2020-02-06  2854.8878  2829.5111  2866.3906  2809.3661   \n",
       "645  000016.SH 2020-02-07  2851.7105  2836.7992  2851.8244  2819.6678   \n",
       "644  000016.SH 2020-02-10  2850.0642  2826.7970  2854.8289  2817.7707   \n",
       "643  000016.SH 2020-02-11  2879.8575  2858.9245  2893.0673  2854.0722   \n",
       "642  000016.SH 2020-02-12  2895.5859  2876.6708  2895.9268  2870.7680   \n",
       "641  000016.SH 2020-02-13  2875.4794  2898.3985  2906.7218  2871.2649   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "24   000016.SH 2022-08-24  2708.0902  2738.3837  2750.8719  2706.1522   \n",
       "23   000016.SH 2022-08-25  2752.5560  2715.6384  2756.9393  2707.4573   \n",
       "22   000016.SH 2022-08-26  2751.5894  2758.5070  2763.6428  2745.5172   \n",
       "21   000016.SH 2022-08-29  2732.2055  2721.8592  2736.5962  2718.9674   \n",
       "20   000016.SH 2022-08-30  2726.6602  2731.9805  2741.5952  2705.0459   \n",
       "19   000016.SH 2022-08-31  2761.7831  2713.2938  2779.6158  2713.2938   \n",
       "18   000016.SH 2022-09-01  2732.3990  2750.0334  2757.8794  2731.6963   \n",
       "17   000016.SH 2022-09-02  2711.2642  2737.1969  2740.6630  2698.3276   \n",
       "16   000016.SH 2022-09-05  2697.7665  2700.1077  2706.9588  2676.6046   \n",
       "15   000016.SH 2022-09-06  2724.4980  2706.0966  2726.7159  2703.9982   \n",
       "14   000016.SH 2022-09-07  2710.6862  2709.7667  2718.1716  2703.0843   \n",
       "13   000016.SH 2022-09-08  2708.2782  2714.0277  2725.2493  2707.4661   \n",
       "12   000016.SH 2022-09-09  2757.5659  2719.0141  2763.1682  2710.7661   \n",
       "11   000016.SH 2022-09-13  2769.2348  2769.4104  2781.3967  2751.0927   \n",
       "10   000016.SH 2022-09-14  2745.4284  2734.9100  2760.4016  2732.7832   \n",
       "9    000016.SH 2022-09-15  2743.7886  2753.1287  2769.4571  2728.8354   \n",
       "8    000016.SH 2022-09-16  2678.0331  2731.9648  2738.6483  2678.0331   \n",
       "7    000016.SH 2022-09-19  2679.5857  2677.3329  2695.4014  2669.0870   \n",
       "6    000016.SH 2022-09-20  2673.8804  2688.1681  2691.5533  2666.6566   \n",
       "5    000016.SH 2022-09-21  2652.2142  2667.1680  2670.0647  2641.7189   \n",
       "4    000016.SH 2022-09-22  2629.3701  2631.9968  2645.5662  2621.8224   \n",
       "3    000016.SH 2022-09-23  2629.8089  2625.2488  2649.8066  2618.9402   \n",
       "2    000016.SH 2022-09-26  2614.8998  2612.6673  2650.2542  2611.5292   \n",
       "1    000016.SH 2022-09-27  2642.9212  2616.0501  2645.7366  2605.2407   \n",
       "0    000016.SH 2022-09-28  2611.9815  2635.2559  2637.0155  2608.6405   \n",
       "\n",
       "     pre_close    change  pct_chg         vol        amount  \n",
       "665  3063.2190   27.6141   0.9015  50036392.0  9.477373e+07  \n",
       "664  3090.8331  -12.5538  -0.4062  37185493.0  7.234679e+07  \n",
       "663  3078.2793  -21.4434  -0.6966  47707827.0  7.777039e+07  \n",
       "662  3056.8359   17.1793   0.5620  34371788.0  5.688658e+07  \n",
       "661  3074.0152  -36.1627  -1.1764  37653773.0  5.985484e+07  \n",
       "660  3037.8525   29.6931   0.9774  33150515.0  5.767682e+07  \n",
       "659  3067.5456    0.3354   0.0109  28542389.0  5.163493e+07  \n",
       "658  3067.8810   22.2474   0.7252  29330835.0  5.705225e+07  \n",
       "657  3090.1284   -9.5268  -0.3083  35129017.0  5.696145e+07  \n",
       "656  3080.6016  -22.5938  -0.7334  28116086.0  4.697157e+07  \n",
       "655  3058.0078  -14.9147  -0.4877  28312318.0  4.549775e+07  \n",
       "654  3043.0931   10.0798   0.3312  23304514.0  4.622461e+07  \n",
       "653  3053.1729   12.8177   0.4198  27274849.0  5.562321e+07  \n",
       "652  3065.9906  -53.8783  -1.7573  32801291.0  5.974027e+07  \n",
       "651  3012.1123    5.7662   0.1914  33159760.0  6.050915e+07  \n",
       "650  3017.8785  -85.3853  -2.8293  42839352.0  7.550661e+07  \n",
       "649  2932.4932 -205.4001  -7.0043  58609184.0  9.613125e+07  \n",
       "648  2727.0931   67.5675   2.4776  57016369.0  9.185602e+07  \n",
       "647  2794.6606   18.2387   0.6526  44182070.0  7.342200e+07  \n",
       "646  2812.8993   41.9885   1.4927  42134251.0  7.041728e+07  \n",
       "645  2854.8878   -3.1773  -0.1113  34443628.0  5.906509e+07  \n",
       "644  2851.7105   -1.6463  -0.0577  33654934.0  5.664824e+07  \n",
       "643  2850.0642   29.7933   1.0454  36028244.0  5.851942e+07  \n",
       "642  2879.8575   15.7284   0.5462  31230750.0  5.212694e+07  \n",
       "641  2895.5859  -20.1065  -0.6944  37434764.0  5.784494e+07  \n",
       "..         ...       ...      ...         ...           ...  \n",
       "24   2735.6660  -27.5758  -1.0080  30925306.0  6.473540e+07  \n",
       "23   2708.0902   44.4658   1.6420  31964009.0  6.690695e+07  \n",
       "22   2752.5560   -0.9666  -0.0351  26031347.0  5.915288e+07  \n",
       "21   2751.5894  -19.3839  -0.7045  24890507.0  4.933771e+07  \n",
       "20   2732.2055   -5.5453  -0.2030  25930522.0  4.997384e+07  \n",
       "19   2726.6602   35.1229   1.2881  39886395.0  8.449570e+07  \n",
       "18   2761.7831  -29.3841  -1.0640  25422479.0  5.389230e+07  \n",
       "17   2732.3990  -21.1348  -0.7735  22781335.0  4.629397e+07  \n",
       "16   2711.2642  -13.4977  -0.4978  24938690.0  5.355364e+07  \n",
       "15   2697.7665   26.7315   0.9909  29124448.0  5.935016e+07  \n",
       "14   2724.4980  -13.8118  -0.5069  23454754.0  5.220405e+07  \n",
       "13   2710.6862   -2.4080  -0.0888  24209022.0  4.556862e+07  \n",
       "12   2708.2782   49.2877   1.8199  32485640.0  6.684816e+07  \n",
       "11   2757.5659   11.6689   0.4232  29928992.0  6.246759e+07  \n",
       "10   2769.2348  -23.8064  -0.8597  24848499.0  4.615128e+07  \n",
       "9    2745.4284   -1.6398  -0.0597  33698861.0  6.522469e+07  \n",
       "8    2743.7886  -65.7555  -2.3965  38441774.0  6.550020e+07  \n",
       "7    2678.0331    1.5526   0.0580  27260379.0  4.697462e+07  \n",
       "6    2679.5857   -5.7053  -0.2129  23751394.0  4.343682e+07  \n",
       "5    2673.8804  -21.6662  -0.8103  23960147.0  4.560560e+07  \n",
       "4    2652.2142  -22.8441  -0.8613  24229236.0  4.345603e+07  \n",
       "3    2629.3701    0.4388   0.0167  30277934.0  4.635576e+07  \n",
       "2    2629.8089  -14.9091  -0.5669  34384533.0  5.579267e+07  \n",
       "1    2614.8998   28.0214   1.0716  26144970.0  5.021519e+07  \n",
       "0    2642.9212  -30.9397  -1.1707  24732086.0  4.772510e+07  \n",
       "\n",
       "[666 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:36:51.032707Z",
     "start_time": "2022-10-13T04:36:50.986460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ts_code</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>change</th>\n",
       "      <th>pct_chg</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3107.5172</td>\n",
       "      <td>3073.9313</td>\n",
       "      <td>3063.2190</td>\n",
       "      <td>27.6141</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>50036392.0</td>\n",
       "      <td>9.477373e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>3097.2518</td>\n",
       "      <td>3097.4088</td>\n",
       "      <td>3072.1137</td>\n",
       "      <td>3090.8331</td>\n",
       "      <td>-12.5538</td>\n",
       "      <td>-0.4062</td>\n",
       "      <td>37185493.0</td>\n",
       "      <td>7.234679e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>3062.2801</td>\n",
       "      <td>3090.8402</td>\n",
       "      <td>3040.1945</td>\n",
       "      <td>3078.2793</td>\n",
       "      <td>-21.4434</td>\n",
       "      <td>-0.6966</td>\n",
       "      <td>47707827.0</td>\n",
       "      <td>7.777039e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>3063.7464</td>\n",
       "      <td>3080.2714</td>\n",
       "      <td>3061.5608</td>\n",
       "      <td>3056.8359</td>\n",
       "      <td>17.1793</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>34371788.0</td>\n",
       "      <td>5.688658e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>3058.3585</td>\n",
       "      <td>3058.6969</td>\n",
       "      <td>3030.1048</td>\n",
       "      <td>3074.0152</td>\n",
       "      <td>-36.1627</td>\n",
       "      <td>-1.1764</td>\n",
       "      <td>37653773.0</td>\n",
       "      <td>5.985484e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>3060.7743</td>\n",
       "      <td>3071.5392</td>\n",
       "      <td>3055.9906</td>\n",
       "      <td>3037.8525</td>\n",
       "      <td>29.6931</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>33150515.0</td>\n",
       "      <td>5.767682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>3079.0765</td>\n",
       "      <td>3081.9568</td>\n",
       "      <td>3058.1642</td>\n",
       "      <td>3067.5456</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>28542389.0</td>\n",
       "      <td>5.163493e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>3069.6784</td>\n",
       "      <td>3090.1310</td>\n",
       "      <td>3054.8783</td>\n",
       "      <td>3067.8810</td>\n",
       "      <td>22.2474</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>29330835.0</td>\n",
       "      <td>5.705225e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>3097.7248</td>\n",
       "      <td>3108.1770</td>\n",
       "      <td>3078.4579</td>\n",
       "      <td>3090.1284</td>\n",
       "      <td>-9.5268</td>\n",
       "      <td>-0.3083</td>\n",
       "      <td>35129017.0</td>\n",
       "      <td>5.696145e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>3078.2528</td>\n",
       "      <td>3086.9662</td>\n",
       "      <td>3052.7047</td>\n",
       "      <td>3080.6016</td>\n",
       "      <td>-22.5938</td>\n",
       "      <td>-0.7334</td>\n",
       "      <td>28116086.0</td>\n",
       "      <td>4.697157e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>3067.9500</td>\n",
       "      <td>3068.1971</td>\n",
       "      <td>3039.0726</td>\n",
       "      <td>3058.0078</td>\n",
       "      <td>-14.9147</td>\n",
       "      <td>-0.4877</td>\n",
       "      <td>28312318.0</td>\n",
       "      <td>4.549775e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>3054.0361</td>\n",
       "      <td>3067.5589</td>\n",
       "      <td>3042.5897</td>\n",
       "      <td>3043.0931</td>\n",
       "      <td>10.0798</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>23304514.0</td>\n",
       "      <td>4.622461e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>3070.6701</td>\n",
       "      <td>3072.2888</td>\n",
       "      <td>3054.4484</td>\n",
       "      <td>3053.1729</td>\n",
       "      <td>12.8177</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>27274849.0</td>\n",
       "      <td>5.562321e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>3048.9459</td>\n",
       "      <td>3050.8233</td>\n",
       "      <td>3011.1846</td>\n",
       "      <td>3065.9906</td>\n",
       "      <td>-53.8783</td>\n",
       "      <td>-1.7573</td>\n",
       "      <td>32801291.0</td>\n",
       "      <td>5.974027e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>2996.8099</td>\n",
       "      <td>3023.9019</td>\n",
       "      <td>2965.6635</td>\n",
       "      <td>3012.1123</td>\n",
       "      <td>5.7662</td>\n",
       "      <td>0.1914</td>\n",
       "      <td>33159760.0</td>\n",
       "      <td>6.050915e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2993.7726</td>\n",
       "      <td>2910.3942</td>\n",
       "      <td>3017.8785</td>\n",
       "      <td>-85.3853</td>\n",
       "      <td>-2.8293</td>\n",
       "      <td>42839352.0</td>\n",
       "      <td>7.550661e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2755.8448</td>\n",
       "      <td>2676.0073</td>\n",
       "      <td>2932.4932</td>\n",
       "      <td>-205.4001</td>\n",
       "      <td>-7.0043</td>\n",
       "      <td>58609184.0</td>\n",
       "      <td>9.613125e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2796.7145</td>\n",
       "      <td>2724.1314</td>\n",
       "      <td>2727.0931</td>\n",
       "      <td>67.5675</td>\n",
       "      <td>2.4776</td>\n",
       "      <td>57016369.0</td>\n",
       "      <td>9.185602e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>2803.7374</td>\n",
       "      <td>2833.2097</td>\n",
       "      <td>2782.4231</td>\n",
       "      <td>2794.6606</td>\n",
       "      <td>18.2387</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>44182070.0</td>\n",
       "      <td>7.342200e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>2829.5111</td>\n",
       "      <td>2866.3906</td>\n",
       "      <td>2809.3661</td>\n",
       "      <td>2812.8993</td>\n",
       "      <td>41.9885</td>\n",
       "      <td>1.4927</td>\n",
       "      <td>42134251.0</td>\n",
       "      <td>7.041728e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>2836.7992</td>\n",
       "      <td>2851.8244</td>\n",
       "      <td>2819.6678</td>\n",
       "      <td>2854.8878</td>\n",
       "      <td>-3.1773</td>\n",
       "      <td>-0.1113</td>\n",
       "      <td>34443628.0</td>\n",
       "      <td>5.906509e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>2826.7970</td>\n",
       "      <td>2854.8289</td>\n",
       "      <td>2817.7707</td>\n",
       "      <td>2851.7105</td>\n",
       "      <td>-1.6463</td>\n",
       "      <td>-0.0577</td>\n",
       "      <td>33654934.0</td>\n",
       "      <td>5.664824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>2858.9245</td>\n",
       "      <td>2893.0673</td>\n",
       "      <td>2854.0722</td>\n",
       "      <td>2850.0642</td>\n",
       "      <td>29.7933</td>\n",
       "      <td>1.0454</td>\n",
       "      <td>36028244.0</td>\n",
       "      <td>5.851942e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>2876.6708</td>\n",
       "      <td>2895.9268</td>\n",
       "      <td>2870.7680</td>\n",
       "      <td>2879.8575</td>\n",
       "      <td>15.7284</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>31230750.0</td>\n",
       "      <td>5.212694e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2875.4794</td>\n",
       "      <td>2898.3985</td>\n",
       "      <td>2906.7218</td>\n",
       "      <td>2871.2649</td>\n",
       "      <td>2895.5859</td>\n",
       "      <td>-20.1065</td>\n",
       "      <td>-0.6944</td>\n",
       "      <td>37434764.0</td>\n",
       "      <td>5.784494e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>2715.6384</td>\n",
       "      <td>2756.9393</td>\n",
       "      <td>2707.4573</td>\n",
       "      <td>2708.0902</td>\n",
       "      <td>44.4658</td>\n",
       "      <td>1.6420</td>\n",
       "      <td>31964009.0</td>\n",
       "      <td>6.690695e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>2758.5070</td>\n",
       "      <td>2763.6428</td>\n",
       "      <td>2745.5172</td>\n",
       "      <td>2752.5560</td>\n",
       "      <td>-0.9666</td>\n",
       "      <td>-0.0351</td>\n",
       "      <td>26031347.0</td>\n",
       "      <td>5.915288e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>2721.8592</td>\n",
       "      <td>2736.5962</td>\n",
       "      <td>2718.9674</td>\n",
       "      <td>2751.5894</td>\n",
       "      <td>-19.3839</td>\n",
       "      <td>-0.7045</td>\n",
       "      <td>24890507.0</td>\n",
       "      <td>4.933771e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>2731.9805</td>\n",
       "      <td>2741.5952</td>\n",
       "      <td>2705.0459</td>\n",
       "      <td>2732.2055</td>\n",
       "      <td>-5.5453</td>\n",
       "      <td>-0.2030</td>\n",
       "      <td>25930522.0</td>\n",
       "      <td>4.997384e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2779.6158</td>\n",
       "      <td>2713.2938</td>\n",
       "      <td>2726.6602</td>\n",
       "      <td>35.1229</td>\n",
       "      <td>1.2881</td>\n",
       "      <td>39886395.0</td>\n",
       "      <td>8.449570e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>2750.0334</td>\n",
       "      <td>2757.8794</td>\n",
       "      <td>2731.6963</td>\n",
       "      <td>2761.7831</td>\n",
       "      <td>-29.3841</td>\n",
       "      <td>-1.0640</td>\n",
       "      <td>25422479.0</td>\n",
       "      <td>5.389230e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>2737.1969</td>\n",
       "      <td>2740.6630</td>\n",
       "      <td>2698.3276</td>\n",
       "      <td>2732.3990</td>\n",
       "      <td>-21.1348</td>\n",
       "      <td>-0.7735</td>\n",
       "      <td>22781335.0</td>\n",
       "      <td>4.629397e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>2700.1077</td>\n",
       "      <td>2706.9588</td>\n",
       "      <td>2676.6046</td>\n",
       "      <td>2711.2642</td>\n",
       "      <td>-13.4977</td>\n",
       "      <td>-0.4978</td>\n",
       "      <td>24938690.0</td>\n",
       "      <td>5.355364e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>2706.0966</td>\n",
       "      <td>2726.7159</td>\n",
       "      <td>2703.9982</td>\n",
       "      <td>2697.7665</td>\n",
       "      <td>26.7315</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>29124448.0</td>\n",
       "      <td>5.935016e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2022-09-07</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>2709.7667</td>\n",
       "      <td>2718.1716</td>\n",
       "      <td>2703.0843</td>\n",
       "      <td>2724.4980</td>\n",
       "      <td>-13.8118</td>\n",
       "      <td>-0.5069</td>\n",
       "      <td>23454754.0</td>\n",
       "      <td>5.220405e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2022-09-08</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>2714.0277</td>\n",
       "      <td>2725.2493</td>\n",
       "      <td>2707.4661</td>\n",
       "      <td>2710.6862</td>\n",
       "      <td>-2.4080</td>\n",
       "      <td>-0.0888</td>\n",
       "      <td>24209022.0</td>\n",
       "      <td>4.556862e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>2719.0141</td>\n",
       "      <td>2763.1682</td>\n",
       "      <td>2710.7661</td>\n",
       "      <td>2708.2782</td>\n",
       "      <td>49.2877</td>\n",
       "      <td>1.8199</td>\n",
       "      <td>32485640.0</td>\n",
       "      <td>6.684816e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>2769.4104</td>\n",
       "      <td>2781.3967</td>\n",
       "      <td>2751.0927</td>\n",
       "      <td>2757.5659</td>\n",
       "      <td>11.6689</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>29928992.0</td>\n",
       "      <td>6.246759e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2022-09-14</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>2734.9100</td>\n",
       "      <td>2760.4016</td>\n",
       "      <td>2732.7832</td>\n",
       "      <td>2769.2348</td>\n",
       "      <td>-23.8064</td>\n",
       "      <td>-0.8597</td>\n",
       "      <td>24848499.0</td>\n",
       "      <td>4.615128e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2022-09-15</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>2753.1287</td>\n",
       "      <td>2769.4571</td>\n",
       "      <td>2728.8354</td>\n",
       "      <td>2745.4284</td>\n",
       "      <td>-1.6398</td>\n",
       "      <td>-0.0597</td>\n",
       "      <td>33698861.0</td>\n",
       "      <td>6.522469e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2731.9648</td>\n",
       "      <td>2738.6483</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>2743.7886</td>\n",
       "      <td>-65.7555</td>\n",
       "      <td>-2.3965</td>\n",
       "      <td>38441774.0</td>\n",
       "      <td>6.550020e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>2677.3329</td>\n",
       "      <td>2695.4014</td>\n",
       "      <td>2669.0870</td>\n",
       "      <td>2678.0331</td>\n",
       "      <td>1.5526</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>27260379.0</td>\n",
       "      <td>4.697462e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>2688.1681</td>\n",
       "      <td>2691.5533</td>\n",
       "      <td>2666.6566</td>\n",
       "      <td>2679.5857</td>\n",
       "      <td>-5.7053</td>\n",
       "      <td>-0.2129</td>\n",
       "      <td>23751394.0</td>\n",
       "      <td>4.343682e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>2667.1680</td>\n",
       "      <td>2670.0647</td>\n",
       "      <td>2641.7189</td>\n",
       "      <td>2673.8804</td>\n",
       "      <td>-21.6662</td>\n",
       "      <td>-0.8103</td>\n",
       "      <td>23960147.0</td>\n",
       "      <td>4.560560e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>2631.9968</td>\n",
       "      <td>2645.5662</td>\n",
       "      <td>2621.8224</td>\n",
       "      <td>2652.2142</td>\n",
       "      <td>-22.8441</td>\n",
       "      <td>-0.8613</td>\n",
       "      <td>24229236.0</td>\n",
       "      <td>4.345603e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>2625.2488</td>\n",
       "      <td>2649.8066</td>\n",
       "      <td>2618.9402</td>\n",
       "      <td>2629.3701</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>30277934.0</td>\n",
       "      <td>4.635576e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>2612.6673</td>\n",
       "      <td>2650.2542</td>\n",
       "      <td>2611.5292</td>\n",
       "      <td>2629.8089</td>\n",
       "      <td>-14.9091</td>\n",
       "      <td>-0.5669</td>\n",
       "      <td>34384533.0</td>\n",
       "      <td>5.579267e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>2616.0501</td>\n",
       "      <td>2645.7366</td>\n",
       "      <td>2605.2407</td>\n",
       "      <td>2614.8998</td>\n",
       "      <td>28.0214</td>\n",
       "      <td>1.0716</td>\n",
       "      <td>26144970.0</td>\n",
       "      <td>5.021519e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2611.9815</td>\n",
       "      <td>2635.2559</td>\n",
       "      <td>2637.0155</td>\n",
       "      <td>2608.6405</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>-30.9397</td>\n",
       "      <td>-1.1707</td>\n",
       "      <td>24732086.0</td>\n",
       "      <td>4.772510e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>000016.SH</td>\n",
       "      <td>2611.9815</td>\n",
       "      <td>2635.2559</td>\n",
       "      <td>2637.0155</td>\n",
       "      <td>2608.6405</td>\n",
       "      <td>2642.9212</td>\n",
       "      <td>-30.9397</td>\n",
       "      <td>-1.1707</td>\n",
       "      <td>24732086.0</td>\n",
       "      <td>4.772510e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>667 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    ts_code      close       open       high        low  \\\n",
       "0   2020-01-02  000016.SH  3090.8331  3073.9313  3107.5172  3073.9313   \n",
       "1   2020-01-03  000016.SH  3078.2793  3097.2518  3097.4088  3072.1137   \n",
       "2   2020-01-06  000016.SH  3056.8359  3062.2801  3090.8402  3040.1945   \n",
       "3   2020-01-07  000016.SH  3074.0152  3063.7464  3080.2714  3061.5608   \n",
       "4   2020-01-08  000016.SH  3037.8525  3058.3585  3058.6969  3030.1048   \n",
       "5   2020-01-09  000016.SH  3067.5456  3060.7743  3071.5392  3055.9906   \n",
       "6   2020-01-10  000016.SH  3067.8810  3079.0765  3081.9568  3058.1642   \n",
       "7   2020-01-13  000016.SH  3090.1284  3069.6784  3090.1310  3054.8783   \n",
       "8   2020-01-14  000016.SH  3080.6016  3097.7248  3108.1770  3078.4579   \n",
       "9   2020-01-15  000016.SH  3058.0078  3078.2528  3086.9662  3052.7047   \n",
       "10  2020-01-16  000016.SH  3043.0931  3067.9500  3068.1971  3039.0726   \n",
       "11  2020-01-17  000016.SH  3053.1729  3054.0361  3067.5589  3042.5897   \n",
       "12  2020-01-20  000016.SH  3065.9906  3070.6701  3072.2888  3054.4484   \n",
       "13  2020-01-21  000016.SH  3012.1123  3048.9459  3050.8233  3011.1846   \n",
       "14  2020-01-22  000016.SH  3017.8785  2996.8099  3023.9019  2965.6635   \n",
       "15  2020-01-23  000016.SH  2932.4932  2993.7726  2993.7726  2910.3942   \n",
       "16  2020-02-03  000016.SH  2727.0931  2676.0073  2755.8448  2676.0073   \n",
       "17  2020-02-04  000016.SH  2794.6606  2724.1314  2796.7145  2724.1314   \n",
       "18  2020-02-05  000016.SH  2812.8993  2803.7374  2833.2097  2782.4231   \n",
       "19  2020-02-06  000016.SH  2854.8878  2829.5111  2866.3906  2809.3661   \n",
       "20  2020-02-07  000016.SH  2851.7105  2836.7992  2851.8244  2819.6678   \n",
       "21  2020-02-10  000016.SH  2850.0642  2826.7970  2854.8289  2817.7707   \n",
       "22  2020-02-11  000016.SH  2879.8575  2858.9245  2893.0673  2854.0722   \n",
       "23  2020-02-12  000016.SH  2895.5859  2876.6708  2895.9268  2870.7680   \n",
       "24  2020-02-13  000016.SH  2875.4794  2898.3985  2906.7218  2871.2649   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "642 2022-08-25  000016.SH  2752.5560  2715.6384  2756.9393  2707.4573   \n",
       "643 2022-08-26  000016.SH  2751.5894  2758.5070  2763.6428  2745.5172   \n",
       "644 2022-08-29  000016.SH  2732.2055  2721.8592  2736.5962  2718.9674   \n",
       "645 2022-08-30  000016.SH  2726.6602  2731.9805  2741.5952  2705.0459   \n",
       "646 2022-08-31  000016.SH  2761.7831  2713.2938  2779.6158  2713.2938   \n",
       "647 2022-09-01  000016.SH  2732.3990  2750.0334  2757.8794  2731.6963   \n",
       "648 2022-09-02  000016.SH  2711.2642  2737.1969  2740.6630  2698.3276   \n",
       "649 2022-09-05  000016.SH  2697.7665  2700.1077  2706.9588  2676.6046   \n",
       "650 2022-09-06  000016.SH  2724.4980  2706.0966  2726.7159  2703.9982   \n",
       "651 2022-09-07  000016.SH  2710.6862  2709.7667  2718.1716  2703.0843   \n",
       "652 2022-09-08  000016.SH  2708.2782  2714.0277  2725.2493  2707.4661   \n",
       "653 2022-09-09  000016.SH  2757.5659  2719.0141  2763.1682  2710.7661   \n",
       "654 2022-09-13  000016.SH  2769.2348  2769.4104  2781.3967  2751.0927   \n",
       "655 2022-09-14  000016.SH  2745.4284  2734.9100  2760.4016  2732.7832   \n",
       "656 2022-09-15  000016.SH  2743.7886  2753.1287  2769.4571  2728.8354   \n",
       "657 2022-09-16  000016.SH  2678.0331  2731.9648  2738.6483  2678.0331   \n",
       "658 2022-09-19  000016.SH  2679.5857  2677.3329  2695.4014  2669.0870   \n",
       "659 2022-09-20  000016.SH  2673.8804  2688.1681  2691.5533  2666.6566   \n",
       "660 2022-09-21  000016.SH  2652.2142  2667.1680  2670.0647  2641.7189   \n",
       "661 2022-09-22  000016.SH  2629.3701  2631.9968  2645.5662  2621.8224   \n",
       "662 2022-09-23  000016.SH  2629.8089  2625.2488  2649.8066  2618.9402   \n",
       "663 2022-09-26  000016.SH  2614.8998  2612.6673  2650.2542  2611.5292   \n",
       "664 2022-09-27  000016.SH  2642.9212  2616.0501  2645.7366  2605.2407   \n",
       "665 2022-09-28  000016.SH  2611.9815  2635.2559  2637.0155  2608.6405   \n",
       "666 2022-09-29  000016.SH  2611.9815  2635.2559  2637.0155  2608.6405   \n",
       "\n",
       "     pre_close    change  pct_chg         vol        amount  \n",
       "0    3063.2190   27.6141   0.9015  50036392.0  9.477373e+07  \n",
       "1    3090.8331  -12.5538  -0.4062  37185493.0  7.234679e+07  \n",
       "2    3078.2793  -21.4434  -0.6966  47707827.0  7.777039e+07  \n",
       "3    3056.8359   17.1793   0.5620  34371788.0  5.688658e+07  \n",
       "4    3074.0152  -36.1627  -1.1764  37653773.0  5.985484e+07  \n",
       "5    3037.8525   29.6931   0.9774  33150515.0  5.767682e+07  \n",
       "6    3067.5456    0.3354   0.0109  28542389.0  5.163493e+07  \n",
       "7    3067.8810   22.2474   0.7252  29330835.0  5.705225e+07  \n",
       "8    3090.1284   -9.5268  -0.3083  35129017.0  5.696145e+07  \n",
       "9    3080.6016  -22.5938  -0.7334  28116086.0  4.697157e+07  \n",
       "10   3058.0078  -14.9147  -0.4877  28312318.0  4.549775e+07  \n",
       "11   3043.0931   10.0798   0.3312  23304514.0  4.622461e+07  \n",
       "12   3053.1729   12.8177   0.4198  27274849.0  5.562321e+07  \n",
       "13   3065.9906  -53.8783  -1.7573  32801291.0  5.974027e+07  \n",
       "14   3012.1123    5.7662   0.1914  33159760.0  6.050915e+07  \n",
       "15   3017.8785  -85.3853  -2.8293  42839352.0  7.550661e+07  \n",
       "16   2932.4932 -205.4001  -7.0043  58609184.0  9.613125e+07  \n",
       "17   2727.0931   67.5675   2.4776  57016369.0  9.185602e+07  \n",
       "18   2794.6606   18.2387   0.6526  44182070.0  7.342200e+07  \n",
       "19   2812.8993   41.9885   1.4927  42134251.0  7.041728e+07  \n",
       "20   2854.8878   -3.1773  -0.1113  34443628.0  5.906509e+07  \n",
       "21   2851.7105   -1.6463  -0.0577  33654934.0  5.664824e+07  \n",
       "22   2850.0642   29.7933   1.0454  36028244.0  5.851942e+07  \n",
       "23   2879.8575   15.7284   0.5462  31230750.0  5.212694e+07  \n",
       "24   2895.5859  -20.1065  -0.6944  37434764.0  5.784494e+07  \n",
       "..         ...       ...      ...         ...           ...  \n",
       "642  2708.0902   44.4658   1.6420  31964009.0  6.690695e+07  \n",
       "643  2752.5560   -0.9666  -0.0351  26031347.0  5.915288e+07  \n",
       "644  2751.5894  -19.3839  -0.7045  24890507.0  4.933771e+07  \n",
       "645  2732.2055   -5.5453  -0.2030  25930522.0  4.997384e+07  \n",
       "646  2726.6602   35.1229   1.2881  39886395.0  8.449570e+07  \n",
       "647  2761.7831  -29.3841  -1.0640  25422479.0  5.389230e+07  \n",
       "648  2732.3990  -21.1348  -0.7735  22781335.0  4.629397e+07  \n",
       "649  2711.2642  -13.4977  -0.4978  24938690.0  5.355364e+07  \n",
       "650  2697.7665   26.7315   0.9909  29124448.0  5.935016e+07  \n",
       "651  2724.4980  -13.8118  -0.5069  23454754.0  5.220405e+07  \n",
       "652  2710.6862   -2.4080  -0.0888  24209022.0  4.556862e+07  \n",
       "653  2708.2782   49.2877   1.8199  32485640.0  6.684816e+07  \n",
       "654  2757.5659   11.6689   0.4232  29928992.0  6.246759e+07  \n",
       "655  2769.2348  -23.8064  -0.8597  24848499.0  4.615128e+07  \n",
       "656  2745.4284   -1.6398  -0.0597  33698861.0  6.522469e+07  \n",
       "657  2743.7886  -65.7555  -2.3965  38441774.0  6.550020e+07  \n",
       "658  2678.0331    1.5526   0.0580  27260379.0  4.697462e+07  \n",
       "659  2679.5857   -5.7053  -0.2129  23751394.0  4.343682e+07  \n",
       "660  2673.8804  -21.6662  -0.8103  23960147.0  4.560560e+07  \n",
       "661  2652.2142  -22.8441  -0.8613  24229236.0  4.345603e+07  \n",
       "662  2629.3701    0.4388   0.0167  30277934.0  4.635576e+07  \n",
       "663  2629.8089  -14.9091  -0.5669  34384533.0  5.579267e+07  \n",
       "664  2614.8998   28.0214   1.0716  26144970.0  5.021519e+07  \n",
       "665  2642.9212  -30.9397  -1.1707  24732086.0  4.772510e+07  \n",
       "666  2642.9212  -30.9397  -1.1707  24732086.0  4.772510e+07  \n",
       "\n",
       "[667 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the baseline and backtest results have the same time period\n",
    "df_account_value['date'] = pd.to_datetime(df_account_value['date'])\n",
    "baseline_df[\"date\"] = pd.to_datetime(baseline_df[\"date\"], format=\"%Y%m%d\")\n",
    "baseline_df = pd.merge(df_account_value[['date']], baseline_df, on='date', how='left')\n",
    "baseline_df = baseline_df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-13T04:37:02.997649Z",
     "start_time": "2022-10-13T04:36:54.128917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-01-02</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2022-09-29</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>31</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>23.37%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>74.346%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>30.663%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-38.161%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-3.761%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.16</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.31</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-03-24</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.35</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.48</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.03</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.10%</td>\n",
       "      <td>-11.39%</td>\n",
       "      <td>5.66%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"870.936422pt\" height=\"3576.760469pt\" viewBox=\"0 0 870.936422 3576.760469\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-10-19T17:02:52.560775</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 3576.760469 \nL 870.936422 3576.760469 \nL 870.936422 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 78.254578 526.818509 \nL 859.454578 526.818509 \nL 859.454578 23.229937 \nL 78.254578 23.229937 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m9cb947725a\" d=\"M 0 0 \nL 0 6 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"526.818509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m29b6c6ad8b\" d=\"M 0 0 \nL 0 4 \n\" style=\"stroke: #000000\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"526.818509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <defs>\n       <path id=\"ma8bca00fb6\" d=\"M 0 0 \nL -6 0 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"522.053956\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.75 -->\n      <g transform=\"translate(41.813172 526.651011)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"464.056812\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.00 -->\n      <g transform=\"translate(41.813172 468.653867)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"406.059669\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1.25 -->\n      <g transform=\"translate(41.813172 410.656723)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"348.062525\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1.50 -->\n      <g transform=\"translate(41.813172 352.65958)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"290.065381\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 1.75 -->\n      <g transform=\"translate(41.813172 294.662436)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_20\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"232.068238\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2.00 -->\n      <g transform=\"translate(41.813172 236.665293)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_21\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"174.071094\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2.25 -->\n      <g transform=\"translate(41.813172 178.668149)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"116.073951\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2.50 -->\n      <g transform=\"translate(41.813172 120.671005)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_23\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"58.076807\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2.75 -->\n      <g transform=\"translate(41.813172 62.673862)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(35.067984 338.405879)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_24\">\n    <path d=\"M 113.763669 464.056812 \nL 114.473141 464.999063 \nL 116.601558 466.608539 \nL 117.311031 465.319113 \nL 118.020503 468.033376 \nL 118.729975 465.804702 \nL 119.439448 465.779527 \nL 121.567865 464.109705 \nL 122.277337 464.824758 \nL 122.98681 466.52058 \nL 123.696282 467.640032 \nL 124.405754 466.883473 \nL 126.534171 465.921415 \nL 127.243644 469.965357 \nL 127.953116 469.532564 \nL 128.662588 475.941326 \nL 136.466784 491.358035 \nL 137.176256 486.286623 \nL 137.885729 484.917682 \nL 138.595201 481.766152 \nL 139.304673 482.004631 \nL 141.433091 482.128197 \nL 142.142563 479.892002 \nL 142.852035 478.711476 \nL 143.561508 480.220609 \nL 144.27098 478.750618 \nL 146.399397 474.622072 \nL 147.108869 476.54892 \nL 147.818342 476.596566 \nL 148.527814 472.511995 \nL 149.237286 473.265928 \nL 151.365703 476.125966 \nL 152.075176 477.680336 \nL 152.784648 478.254567 \nL 153.49412 477.476751 \nL 154.203593 484.306523 \nL 156.33201 477.788245 \nL 157.041482 476.770683 \nL 157.750954 474.809962 \nL 158.460427 469.518183 \nL 159.169899 473.513863 \nL 161.298316 480.719715 \nL 162.007789 476.56255 \nL 162.717261 479.25374 \nL 164.136206 485.978222 \nL 166.264623 493.840185 \nL 166.974095 494.47308 \nL 168.39304 503.164797 \nL 169.102512 498.764432 \nL 171.230929 503.928119 \nL 171.940401 497.94126 \nL 172.649874 493.377563 \nL 173.359346 494.19615 \nL 174.068818 493.283127 \nL 176.197235 494.138979 \nL 176.906708 494.188742 \nL 177.61618 494.73662 \nL 178.325653 491.898949 \nL 179.035125 492.729214 \nL 181.873014 489.082811 \nL 182.582487 490.097574 \nL 183.291959 489.444465 \nL 184.001431 489.650227 \nL 186.129848 490.451835 \nL 186.839321 486.957678 \nL 187.548793 488.551265 \nL 188.258265 488.268052 \nL 188.967738 485.20467 \nL 191.096155 484.400202 \nL 191.805627 487.046785 \nL 192.515099 485.567825 \nL 193.224572 486.061408 \nL 193.934044 487.685393 \nL 196.062461 485.494052 \nL 198.190878 481.23926 \nL 202.447712 481.093837 \nL 203.157185 481.801039 \nL 203.866657 480.405767 \nL 205.995074 480.493201 \nL 207.414019 480.803584 \nL 208.123491 483.293937 \nL 208.832963 484.40791 \nL 210.96138 483.095839 \nL 211.670853 481.332293 \nL 212.380325 481.672181 \nL 213.089797 482.371404 \nL 213.79927 487.701522 \nL 215.927687 486.658238 \nL 216.637159 485.222218 \nL 217.346632 486.225069 \nL 218.056104 485.160454 \nL 218.765576 485.385662 \nL 220.893993 480.605171 \nL 221.603466 479.436909 \nL 222.312938 479.197643 \nL 223.02241 479.628867 \nL 223.731883 478.654163 \nL 225.8603 477.660618 \nL 226.569772 476.255732 \nL 227.279244 477.744037 \nL 227.988717 480.14303 \nL 228.698189 479.572394 \nL 230.826606 482.98811 \nL 231.536078 479.956934 \nL 232.245551 479.796334 \nL 232.955023 479.208984 \nL 233.664495 476.433519 \nL 235.792913 476.737057 \nL 236.502385 476.472519 \nL 237.211857 475.117193 \nL 240.759219 476.46746 \nL 241.468691 475.222212 \nL 242.887636 464.551813 \nL 245.725525 442.792939 \nL 246.434998 442.22066 \nL 247.14447 438.604107 \nL 247.853942 437.697749 \nL 248.563415 444.470928 \nL 250.691832 441.593619 \nL 251.401304 444.752302 \nL 252.110776 447.324249 \nL 252.820249 458.713356 \nL 253.529721 456.922062 \nL 255.658138 449.264442 \nL 256.367611 449.347034 \nL 257.077083 449.005833 \nL 257.786555 449.550011 \nL 258.496028 458.994047 \nL 260.624445 458.622875 \nL 261.333917 456.922099 \nL 262.043389 452.606736 \nL 262.752862 453.497332 \nL 263.462334 452.159952 \nL 265.590751 449.775865 \nL 266.300223 447.446667 \nL 267.009696 448.934611 \nL 267.719168 448.9428 \nL 268.42864 451.078531 \nL 270.557057 449.426174 \nL 271.26653 451.147666 \nL 271.976002 452.129884 \nL 272.685475 452.722346 \nL 273.394947 449.219475 \nL 275.523364 443.189796 \nL 276.232836 443.303695 \nL 276.942309 447.782494 \nL 277.651781 451.019431 \nL 278.361253 449.503746 \nL 280.48967 448.453413 \nL 281.199143 447.543843 \nL 281.908615 450.01688 \nL 282.618087 449.048991 \nL 283.32756 443.220599 \nL 285.455977 445.06327 \nL 286.165449 444.222039 \nL 286.874921 444.806868 \nL 287.584394 445.774525 \nL 288.293866 447.666133 \nL 290.422283 451.853089 \nL 291.131755 449.114388 \nL 291.841228 453.183301 \nL 292.5507 452.447855 \nL 293.260173 450.947099 \nL 295.38859 448.796409 \nL 296.098062 447.033358 \nL 296.807534 448.68886 \nL 297.517007 451.00791 \nL 298.226479 444.771276 \nL 300.354896 447.487198 \nL 301.064368 450.570133 \nL 301.773841 450.178358 \nL 302.483313 454.458309 \nL 303.192785 453.628111 \nL 305.321202 452.072563 \nL 306.740147 453.429856 \nL 313.125398 449.343837 \nL 315.253815 441.761011 \nL 315.963288 441.835453 \nL 316.67276 443.141084 \nL 317.382232 442.998205 \nL 318.091705 442.340143 \nL 320.220122 444.281222 \nL 320.929594 443.591035 \nL 321.639066 442.546122 \nL 322.348539 443.138667 \nL 323.058011 444.859123 \nL 325.186428 448.00434 \nL 325.8959 448.801107 \nL 326.605373 447.364269 \nL 327.314845 446.523008 \nL 328.024317 449.829733 \nL 330.152735 450.917099 \nL 330.862207 447.795607 \nL 331.571679 445.941287 \nL 332.281152 443.140701 \nL 332.990624 443.920062 \nL 335.119041 439.479992 \nL 335.828513 439.640201 \nL 336.537986 440.008829 \nL 337.247458 441.050252 \nL 337.95693 445.481938 \nL 340.085347 442.569735 \nL 340.79482 442.407297 \nL 341.504292 441.824066 \nL 342.213764 440.094078 \nL 342.923237 439.956079 \nL 345.051654 435.612359 \nL 345.761126 437.645029 \nL 346.470598 439.328655 \nL 347.180071 437.418665 \nL 347.889543 433.446643 \nL 350.01796 435.641391 \nL 350.727433 429.291864 \nL 352.146377 430.582806 \nL 352.85585 430.229551 \nL 355.693739 433.416747 \nL 356.403211 435.708259 \nL 357.112684 436.420723 \nL 357.822156 438.760856 \nL 359.950573 435.765303 \nL 360.660045 435.685615 \nL 361.369518 434.441448 \nL 362.07899 430.378223 \nL 362.788462 432.747457 \nL 364.916879 431.675065 \nL 365.626352 435.529961 \nL 366.335824 433.752282 \nL 367.045296 434.15103 \nL 367.754769 432.408807 \nL 369.883186 431.556858 \nL 370.592658 432.043745 \nL 371.302131 427.781958 \nL 372.011603 422.790054 \nL 374.849492 422.585876 \nL 375.558965 419.583282 \nL 376.268437 415.583901 \nL 376.977909 410.22322 \nL 377.687382 411.705625 \nL 379.815799 412.590532 \nL 380.525271 402.863658 \nL 381.234743 405.332582 \nL 381.944216 409.986437 \nL 382.653688 409.482783 \nL 384.782105 407.121213 \nL 385.491577 410.176347 \nL 386.20105 409.72903 \nL 386.910522 407.071848 \nL 387.619995 407.346661 \nL 389.748412 403.462253 \nL 390.457884 409.83137 \nL 391.167356 409.457736 \nL 391.876829 415.705066 \nL 392.586301 417.340302 \nL 394.714718 414.85407 \nL 395.42419 412.970267 \nL 396.133663 412.651095 \nL 396.843135 410.707465 \nL 397.552607 407.769097 \nL 399.681024 404.038833 \nL 400.390497 399.358115 \nL 401.099969 393.676205 \nL 406.775748 394.742374 \nL 407.48522 394.732444 \nL 409.613637 404.68412 \nL 410.32311 403.494595 \nL 411.032582 410.418188 \nL 411.742054 406.99881 \nL 412.451527 414.066872 \nL 414.579944 411.739371 \nL 415.289416 416.925477 \nL 415.998888 409.52194 \nL 416.708361 417.684551 \nL 417.417833 419.184099 \nL 419.54625 427.834475 \nL 420.255722 432.624408 \nL 420.965195 430.940235 \nL 421.674667 423.940955 \nL 422.384139 423.39505 \nL 424.512557 428.326376 \nL 425.222029 425.902989 \nL 425.931501 426.528266 \nL 426.640974 425.419615 \nL 427.350446 432.443776 \nL 429.478863 430.461762 \nL 430.188335 432.117856 \nL 430.897808 435.894753 \nL 431.60728 436.057589 \nL 432.316752 431.114675 \nL 434.445169 430.51551 \nL 435.154642 427.548328 \nL 435.864114 430.391021 \nL 436.573586 427.142532 \nL 437.283059 424.582061 \nL 440.120948 426.23739 \nL 440.83042 428.957493 \nL 441.539893 427.864048 \nL 442.249365 432.286885 \nL 444.377782 435.067385 \nL 445.087255 436.238739 \nL 445.796727 435.659787 \nL 446.506199 438.487904 \nL 447.215672 437.241125 \nL 449.344089 432.340573 \nL 450.053561 432.586114 \nL 450.763033 432.137747 \nL 451.472506 434.289667 \nL 452.181978 431.542995 \nL 454.310395 435.773289 \nL 455.019867 435.124699 \nL 455.72934 435.369602 \nL 456.438812 432.054223 \nL 457.148284 434.007408 \nL 461.405118 437.103448 \nL 462.114591 440.378049 \nL 464.243008 440.852814 \nL 464.95248 438.02102 \nL 465.661953 437.259327 \nL 466.371425 439.809245 \nL 467.080897 433.118036 \nL 469.209314 430.350272 \nL 469.918787 430.516613 \nL 470.628259 432.485275 \nL 471.337731 431.660865 \nL 472.047204 434.707375 \nL 474.175621 433.515095 \nL 474.885093 422.741049 \nL 475.594565 421.547793 \nL 476.304038 420.965959 \nL 477.01351 421.389731 \nL 479.141927 422.070587 \nL 479.851399 422.019631 \nL 481.270344 426.504083 \nL 481.979817 424.886958 \nL 484.108234 425.757041 \nL 484.817706 427.32014 \nL 485.527178 426.776089 \nL 486.236651 425.263909 \nL 486.946123 427.583312 \nL 489.784012 431.194228 \nL 490.493485 434.375195 \nL 491.202957 434.727002 \nL 491.912429 436.754433 \nL 494.040846 438.505985 \nL 494.750319 435.995067 \nL 495.459791 435.497034 \nL 496.169263 434.553703 \nL 496.878736 430.717601 \nL 499.007153 431.789047 \nL 499.716625 434.64197 \nL 500.426098 433.447423 \nL 501.13557 430.7003 \nL 501.845042 440.233444 \nL 503.973459 440.492105 \nL 504.682932 440.45547 \nL 505.392404 439.021064 \nL 506.101876 442.859042 \nL 506.811349 443.734274 \nL 509.649238 441.471501 \nL 510.35871 445.401559 \nL 511.068183 440.004378 \nL 511.777655 443.110941 \nL 513.906072 441.950035 \nL 514.615544 442.455708 \nL 515.325017 441.713327 \nL 516.034489 441.398358 \nL 516.743961 444.04558 \nL 518.872379 453.733724 \nL 519.581851 461.389092 \nL 521.000796 457.154355 \nL 521.710268 460.905365 \nL 523.838685 455.026633 \nL 524.548157 454.07479 \nL 525.25763 453.378464 \nL 525.967102 453.809577 \nL 526.676574 456.186121 \nL 528.804991 453.22059 \nL 529.514464 449.209177 \nL 530.223936 451.166378 \nL 530.933408 453.903075 \nL 531.642881 454.524314 \nL 533.771298 454.165121 \nL 534.48077 459.625058 \nL 535.190242 456.572229 \nL 535.899715 460.038149 \nL 536.609187 465.413737 \nL 538.737604 463.377277 \nL 539.447077 459.783414 \nL 540.156549 458.88011 \nL 540.866021 464.207054 \nL 541.575494 461.638784 \nL 543.703911 462.415384 \nL 544.413383 463.58956 \nL 545.122855 458.487285 \nL 545.832328 458.33266 \nL 546.5418 457.673517 \nL 548.670217 455.022587 \nL 549.379689 452.256408 \nL 550.089162 454.868068 \nL 550.798634 455.541967 \nL 551.508106 451.935749 \nL 553.636523 452.70795 \nL 554.345996 456.744192 \nL 555.055468 459.868588 \nL 555.76494 461.222999 \nL 556.474413 458.721087 \nL 560.021775 461.692217 \nL 560.731247 461.280635 \nL 563.569136 455.864974 \nL 564.278609 455.025905 \nL 564.988081 455.921177 \nL 565.697553 456.088959 \nL 571.373332 451.640272 \nL 573.501749 450.12819 \nL 574.211221 451.406222 \nL 574.920694 448.90061 \nL 575.630166 450.557148 \nL 576.339639 448.745175 \nL 578.468056 453.63904 \nL 579.177528 451.609747 \nL 579.887 451.735084 \nL 580.596473 449.967958 \nL 581.305945 446.996783 \nL 583.434362 447.433945 \nL 584.143834 449.105223 \nL 584.853307 452.328147 \nL 585.562779 452.890039 \nL 586.272251 450.815561 \nL 588.400668 452.04155 \nL 589.110141 454.960455 \nL 589.819613 457.255345 \nL 590.529085 455.317869 \nL 591.238558 455.747022 \nL 593.366975 456.14303 \nL 594.076447 456.841991 \nL 594.78592 458.084416 \nL 595.495392 453.358409 \nL 596.204864 454.320797 \nL 599.042754 454.19883 \nL 599.752226 455.204383 \nL 600.461698 457.861407 \nL 601.171171 454.894262 \nL 603.299588 454.951028 \nL 604.00906 454.050104 \nL 604.718532 453.473607 \nL 605.428005 454.508192 \nL 606.137477 456.811953 \nL 608.265894 456.835176 \nL 608.975366 458.463829 \nL 609.684839 457.332841 \nL 610.394311 456.54821 \nL 611.103783 454.255182 \nL 613.232201 453.750807 \nL 613.941673 451.772515 \nL 615.360618 443.840179 \nL 616.07009 444.332058 \nL 618.198507 443.398529 \nL 618.907979 444.567204 \nL 619.617452 446.932789 \nL 620.326924 446.041413 \nL 621.036396 449.941193 \nL 623.164813 451.708559 \nL 623.874286 450.381567 \nL 624.583758 451.316792 \nL 625.29323 449.319031 \nL 626.002703 449.090257 \nL 628.13112 449.975869 \nL 628.840592 448.102169 \nL 629.550064 452.797358 \nL 630.259537 451.225027 \nL 630.969009 450.284774 \nL 633.806899 451.054498 \nL 634.516371 451.789035 \nL 635.225843 455.083586 \nL 635.935316 454.116725 \nL 638.063733 453.152295 \nL 638.773205 454.772595 \nL 639.482677 453.137899 \nL 640.901622 460.438151 \nL 643.030039 459.788653 \nL 643.739511 456.799456 \nL 644.448984 456.824398 \nL 645.158456 453.333573 \nL 645.867928 454.456868 \nL 647.996345 455.131683 \nL 648.705818 459.995037 \nL 649.41529 458.589572 \nL 650.124762 461.924781 \nL 650.834235 466.819825 \nL 657.928958 462.298438 \nL 658.638431 462.129972 \nL 659.347903 460.399249 \nL 660.057375 459.982757 \nL 660.766848 460.14795 \nL 662.895265 463.06877 \nL 664.314209 460.660559 \nL 665.023682 460.428258 \nL 665.733154 458.653581 \nL 667.861571 460.001349 \nL 668.571043 463.194273 \nL 669.280516 462.014925 \nL 669.989988 466.398004 \nL 670.699461 465.201123 \nL 672.827878 464.811563 \nL 673.53735 461.440521 \nL 674.246822 462.825323 \nL 674.956295 463.587286 \nL 675.665767 466.192236 \nL 677.794184 472.775198 \nL 678.503656 475.891 \nL 679.213129 477.841401 \nL 679.922601 475.868678 \nL 680.632073 475.701834 \nL 682.76049 481.992141 \nL 683.469963 493.177409 \nL 684.179435 483.803056 \nL 684.888907 480.090025 \nL 685.59838 477.390511 \nL 687.726797 478.972599 \nL 688.436269 478.322553 \nL 689.145742 477.141119 \nL 689.855214 478.108686 \nL 690.564686 481.650572 \nL 692.693103 481.894192 \nL 693.402576 482.72198 \nL 694.112048 477.217489 \nL 694.82152 478.468276 \nL 695.530993 475.134426 \nL 699.078354 476.038517 \nL 699.787827 478.193891 \nL 700.497299 476.466867 \nL 702.625716 482.404722 \nL 703.335188 478.811122 \nL 704.044661 479.710267 \nL 704.754133 476.233823 \nL 705.463605 476.085045 \nL 707.592022 479.301807 \nL 709.010967 483.232473 \nL 709.72044 486.071308 \nL 710.429912 484.825512 \nL 712.558329 494.636554 \nL 713.267801 494.815535 \nL 713.977274 490.799071 \nL 715.396218 485.485368 \nL 719.653052 485.816129 \nL 720.362525 491.908353 \nL 722.490942 493.756901 \nL 723.909886 490.296782 \nL 724.619359 491.757579 \nL 725.328831 489.771046 \nL 727.457248 491.859986 \nL 728.166721 489.132829 \nL 728.876193 489.974375 \nL 729.585665 490.048149 \nL 730.295138 485.289762 \nL 732.423555 487.195774 \nL 733.133027 490.825191 \nL 733.842499 490.132843 \nL 734.551972 490.021624 \nL 735.261444 488.657591 \nL 737.389861 487.503289 \nL 738.099333 484.893701 \nL 738.808806 486.030867 \nL 739.518278 486.612686 \nL 742.356167 483.960615 \nL 743.06564 482.372462 \nL 743.775112 479.932998 \nL 744.484584 480.750196 \nL 745.194057 478.411804 \nL 747.322474 482.529046 \nL 748.741419 476.579633 \nL 749.450891 479.030506 \nL 750.160363 475.663112 \nL 752.28878 476.510115 \nL 752.998253 476.393034 \nL 753.707725 478.959149 \nL 755.12667 472.769381 \nL 757.255087 469.827575 \nL 757.964559 467.916227 \nL 758.674031 470.181251 \nL 759.383504 466.491323 \nL 760.092976 467.476738 \nL 762.930865 466.963153 \nL 763.640338 471.120064 \nL 764.34981 471.684477 \nL 765.059283 471.376879 \nL 767.1877 475.205565 \nL 767.897172 476.728576 \nL 768.606644 477.307235 \nL 769.316117 478.73301 \nL 770.025589 482.9291 \nL 772.154006 479.983437 \nL 772.863478 480.961909 \nL 773.572951 480.325831 \nL 774.282423 483.134163 \nL 774.991895 482.250405 \nL 777.120312 483.089271 \nL 777.829785 481.784849 \nL 778.539257 483.640032 \nL 779.248729 483.851317 \nL 779.958202 486.461649 \nL 782.086619 487.260743 \nL 782.796091 491.083162 \nL 783.505564 492.586666 \nL 784.924508 487.812194 \nL 787.052925 488.801295 \nL 787.762398 488.582811 \nL 788.47187 491.067738 \nL 789.181342 486.856869 \nL 789.890815 486.119389 \nL 792.019232 487.186902 \nL 792.728704 488.193048 \nL 793.438176 486.947703 \nL 794.147649 488.941103 \nL 794.857121 489.591389 \nL 796.985538 489.16069 \nL 797.69501 490.71458 \nL 798.404483 492.784336 \nL 799.113955 489.446867 \nL 799.823427 489.519417 \nL 802.661317 491.390528 \nL 803.370789 488.754309 \nL 804.080262 490.959791 \nL 804.789734 492.546105 \nL 806.918151 493.559201 \nL 807.627623 491.552816 \nL 808.337096 492.589488 \nL 809.046568 492.770225 \nL 809.75604 489.070839 \nL 812.59393 488.195007 \nL 813.303402 489.981843 \nL 814.012874 490.104922 \nL 814.722347 495.040331 \nL 816.850764 494.923797 \nL 817.560236 495.35202 \nL 818.979181 498.692828 \nL 819.688653 498.659893 \nL 821.81707 499.778925 \nL 822.526543 497.675723 \nL 823.236015 499.997964 \nL 823.945487 499.997964 \nL 823.945487 499.997964 \n\" clip-path=\"url(#p9b8c24c311)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_25\">\n    <path d=\"M 113.763669 464.056812 \nL 114.473141 464.27029 \nL 116.601558 464.282884 \nL 117.311031 463.671742 \nL 118.020503 465.811781 \nL 118.729975 463.148328 \nL 119.439448 463.471803 \nL 121.567865 460.747729 \nL 122.277337 461.463413 \nL 122.98681 463.385899 \nL 123.696282 464.024463 \nL 124.405754 460.080332 \nL 126.534171 460.550462 \nL 127.243644 462.612857 \nL 127.953116 461.945032 \nL 128.662588 468.565673 \nL 136.466784 483.745248 \nL 137.176256 479.603649 \nL 137.885729 473.331818 \nL 138.595201 470.286289 \nL 139.304673 469.845128 \nL 141.433091 468.292621 \nL 142.142563 466.920501 \nL 142.852035 463.230416 \nL 143.561508 461.61509 \nL 144.27098 460.833862 \nL 146.399397 455.151724 \nL 147.108869 455.189827 \nL 147.818342 457.552005 \nL 148.527814 453.902532 \nL 149.237286 453.280836 \nL 151.365703 454.756997 \nL 152.075176 452.14561 \nL 152.784648 455.420449 \nL 153.49412 454.564943 \nL 154.203593 463.313115 \nL 156.33201 458.909386 \nL 157.041482 456.485157 \nL 157.750954 455.519524 \nL 158.460427 451.676125 \nL 159.169899 455.148164 \nL 161.298316 464.813321 \nL 162.007789 460.115824 \nL 162.717261 460.992483 \nL 163.426733 466.668724 \nL 164.136206 469.505731 \nL 166.264623 478.984328 \nL 166.974095 478.89789 \nL 167.683567 481.97464 \nL 168.39304 484.008716 \nL 169.102512 481.602531 \nL 171.230929 489.177648 \nL 171.940401 481.889276 \nL 172.649874 477.819789 \nL 173.359346 478.843295 \nL 174.068818 476.720352 \nL 176.197235 478.782476 \nL 176.906708 477.511394 \nL 177.61618 478.112504 \nL 178.325653 473.889416 \nL 179.035125 474.118213 \nL 181.873014 469.390965 \nL 182.582487 470.231662 \nL 183.291959 471.280063 \nL 184.001431 474.060688 \nL 186.129848 475.138238 \nL 186.839321 469.44871 \nL 187.548793 471.197975 \nL 188.258265 469.898395 \nL 188.967738 466.326028 \nL 191.096155 465.718131 \nL 191.805627 468.004192 \nL 192.515099 465.75884 \nL 193.224572 465.534097 \nL 193.934044 468.574078 \nL 196.062461 468.752639 \nL 196.771933 464.365538 \nL 197.481406 462.992714 \nL 198.190878 459.040928 \nL 202.447712 459.594814 \nL 203.157185 460.804152 \nL 203.866657 459.749908 \nL 205.995074 461.637761 \nL 206.704546 460.484662 \nL 207.414019 461.436492 \nL 208.123491 465.128949 \nL 208.832963 467.216906 \nL 210.96138 465.085448 \nL 211.670853 461.120877 \nL 212.380325 462.660437 \nL 213.089797 467.057678 \nL 213.79927 473.531394 \nL 215.927687 472.243149 \nL 216.637159 469.390803 \nL 217.346632 471.148891 \nL 218.056104 471.594348 \nL 218.765576 470.557621 \nL 220.893993 463.608373 \nL 221.603466 463.22698 \nL 222.312938 461.767956 \nL 223.02241 463.124638 \nL 223.731883 462.205461 \nL 226.569772 455.967045 \nL 227.279244 457.075746 \nL 227.988717 457.78072 \nL 228.698189 459.863365 \nL 230.826606 462.453005 \nL 231.536078 458.989395 \nL 232.245551 459.470475 \nL 233.664495 455.556344 \nL 235.792913 452.674539 \nL 236.502385 451.475545 \nL 237.211857 446.707241 \nL 240.759219 446.541067 \nL 241.468691 444.7267 \nL 242.178164 434.637817 \nL 243.597108 421.465537 \nL 245.725525 406.560934 \nL 246.434998 407.246025 \nL 247.853942 391.852073 \nL 248.563415 400.587277 \nL 250.691832 392.35331 \nL 251.401304 393.468543 \nL 252.110776 391.579189 \nL 252.820249 409.978665 \nL 253.529721 405.512892 \nL 256.367611 382.848133 \nL 257.077083 380.564499 \nL 257.786555 365.093891 \nL 258.496028 381.509237 \nL 260.624445 374.074782 \nL 261.333917 376.737939 \nL 262.752862 358.712873 \nL 263.462334 356.805989 \nL 265.590751 352.786286 \nL 266.300223 357.980143 \nL 267.009696 353.642755 \nL 267.719168 359.798972 \nL 268.42864 356.356415 \nL 270.557057 352.771311 \nL 271.976002 373.984875 \nL 272.685475 373.526441 \nL 273.394947 367.914622 \nL 276.232836 356.928316 \nL 277.651781 370.691948 \nL 278.361253 365.280669 \nL 280.48967 357.066049 \nL 281.199143 359.748209 \nL 281.908615 366.122503 \nL 282.618087 359.850137 \nL 283.32756 350.977988 \nL 285.455977 344.366489 \nL 286.165449 336.347329 \nL 286.874921 332.598614 \nL 287.584394 336.713601 \nL 288.293866 345.777467 \nL 290.422283 349.358184 \nL 291.131755 345.535773 \nL 291.841228 353.998664 \nL 292.5507 354.032233 \nL 293.260173 347.151008 \nL 295.38859 345.196616 \nL 296.098062 344.028788 \nL 296.807534 344.08365 \nL 297.517007 346.564182 \nL 298.226479 341.541126 \nL 300.354896 345.177818 \nL 301.064368 351.036155 \nL 301.773841 344.387955 \nL 302.483313 355.703016 \nL 303.192785 355.085772 \nL 305.321202 345.875683 \nL 306.030675 343.880774 \nL 306.740147 346.251141 \nL 313.125398 332.187761 \nL 315.963288 310.379424 \nL 316.67276 310.327025 \nL 317.382232 318.431074 \nL 318.091705 322.378916 \nL 320.220122 331.677361 \nL 320.929594 326.350206 \nL 321.639066 327.076648 \nL 322.348539 329.097189 \nL 323.058011 332.95142 \nL 325.186428 329.990957 \nL 326.605373 320.385311 \nL 327.314845 316.334949 \nL 328.024317 315.525876 \nL 330.152735 313.339005 \nL 330.862207 310.332605 \nL 331.571679 315.477572 \nL 332.281152 298.149045 \nL 332.990624 305.071707 \nL 335.828513 286.573015 \nL 336.537986 297.235248 \nL 337.247458 300.653739 \nL 337.95693 309.067514 \nL 340.085347 304.374634 \nL 340.79482 304.90034 \nL 341.504292 304.676742 \nL 342.213764 297.891903 \nL 342.923237 282.491597 \nL 345.051654 273.496081 \nL 345.761126 278.44602 \nL 346.470598 285.563089 \nL 347.180071 285.09187 \nL 347.889543 283.094745 \nL 350.01796 285.294777 \nL 350.727433 277.526955 \nL 351.436905 280.639639 \nL 352.146377 284.530199 \nL 352.85585 283.540329 \nL 355.693739 290.524649 \nL 356.403211 294.870551 \nL 357.112684 289.387543 \nL 357.822156 295.921917 \nL 359.950573 294.595705 \nL 360.660045 287.957693 \nL 361.369518 282.66974 \nL 362.07899 267.373294 \nL 362.788462 260.181951 \nL 364.916879 253.377248 \nL 365.626352 268.296493 \nL 366.335824 257.147526 \nL 367.045296 257.158249 \nL 367.754769 241.609225 \nL 369.883186 231.258059 \nL 370.592658 239.478952 \nL 371.302131 234.431794 \nL 372.011603 222.100998 \nL 374.849492 200.350318 \nL 375.558965 190.058776 \nL 376.268437 186.888046 \nL 376.977909 171.113191 \nL 377.687382 167.573646 \nL 379.815799 170.358795 \nL 380.525271 161.605436 \nL 381.234743 147.126146 \nL 381.944216 174.784193 \nL 382.653688 184.118895 \nL 384.782105 171.204129 \nL 385.491577 192.685184 \nL 386.20105 186.209521 \nL 386.910522 173.618009 \nL 387.619995 164.491352 \nL 389.748412 163.796094 \nL 390.457884 173.613337 \nL 391.167356 166.001486 \nL 391.876829 192.828805 \nL 392.586301 208.271941 \nL 394.714718 210.166362 \nL 395.42419 193.345464 \nL 396.133663 192.854036 \nL 396.843135 203.636498 \nL 397.552607 206.44046 \nL 399.681024 198.300053 \nL 400.390497 175.363973 \nL 401.099969 159.038976 \nL 406.775748 143.734843 \nL 407.48522 149.388663 \nL 409.613637 157.326234 \nL 410.32311 161.277019 \nL 411.032582 186.421888 \nL 411.742054 182.985511 \nL 412.451527 202.32094 \nL 414.579944 192.963926 \nL 415.289416 210.19882 \nL 415.998888 205.665525 \nL 416.708361 233.709648 \nL 419.54625 267.252688 \nL 420.255722 271.978085 \nL 420.965195 270.053562 \nL 421.674667 251.845883 \nL 422.384139 249.882601 \nL 424.512557 256.099009 \nL 425.222029 252.401875 \nL 426.640974 241.25127 \nL 427.350446 253.366713 \nL 429.478863 249.233859 \nL 430.188335 260.806902 \nL 430.897808 277.993439 \nL 431.60728 272.49975 \nL 432.316752 252.628036 \nL 434.445169 254.55239 \nL 435.864114 242.509779 \nL 436.573586 234.554377 \nL 437.283059 229.358709 \nL 440.120948 224.647196 \nL 440.83042 218.833833 \nL 441.539893 218.339765 \nL 442.249365 219.18209 \nL 444.377782 234.558691 \nL 445.087255 243.711826 \nL 445.796727 240.040339 \nL 446.506199 240.18411 \nL 447.215672 235.648068 \nL 449.344089 226.493111 \nL 450.053561 225.338951 \nL 450.763033 210.325547 \nL 451.472506 202.682417 \nL 452.181978 198.874173 \nL 454.310395 196.771373 \nL 455.019867 184.763912 \nL 455.72934 184.092411 \nL 456.438812 171.371855 \nL 457.148284 175.688618 \nL 461.405118 163.422958 \nL 462.114591 163.077204 \nL 464.243008 151.922193 \nL 464.95248 169.396409 \nL 465.661953 160.217181 \nL 466.371425 170.254202 \nL 467.080897 159.633353 \nL 469.918787 128.595013 \nL 470.628259 124.045355 \nL 471.337731 141.773251 \nL 472.047204 130.628145 \nL 474.175621 136.848064 \nL 474.885093 124.668039 \nL 475.594565 130.496157 \nL 476.304038 131.343548 \nL 477.01351 120.57203 \nL 479.141927 114.988258 \nL 479.851399 108.501233 \nL 480.560872 123.404592 \nL 481.270344 131.002537 \nL 481.979817 129.19152 \nL 484.108234 119.601855 \nL 484.817706 127.838759 \nL 485.527178 118.834367 \nL 486.236651 94.778869 \nL 486.946123 86.646797 \nL 489.784012 92.443594 \nL 490.493485 114.082207 \nL 491.202957 94.192409 \nL 491.912429 88.451132 \nL 494.040846 92.734579 \nL 494.750319 82.708495 \nL 495.459791 89.538589 \nL 496.169263 86.432454 \nL 496.878736 64.196716 \nL 499.007153 56.135332 \nL 499.716625 57.095161 \nL 500.426098 46.120327 \nL 501.13557 47.139136 \nL 501.845042 57.544653 \nL 503.973459 96.695813 \nL 504.682932 100.317715 \nL 505.392404 79.279726 \nL 506.101876 87.692716 \nL 506.811349 112.089182 \nL 508.939766 104.72328 \nL 509.649238 84.037034 \nL 510.35871 153.739893 \nL 511.068183 151.686559 \nL 511.777655 158.713451 \nL 513.906072 143.109843 \nL 514.615544 147.550324 \nL 515.325017 137.144352 \nL 516.034489 133.805927 \nL 516.743961 150.000503 \nL 518.872379 163.627003 \nL 519.581851 182.894526 \nL 520.291323 183.523692 \nL 521.000796 166.854178 \nL 521.710268 161.351002 \nL 523.838685 140.019471 \nL 524.548157 127.53462 \nL 525.25763 111.690312 \nL 525.967102 113.023384 \nL 526.676574 113.385858 \nL 528.804991 116.799793 \nL 529.514464 112.863869 \nL 530.223936 113.655774 \nL 530.933408 102.947155 \nL 531.642881 109.674417 \nL 533.771298 117.536958 \nL 534.48077 126.287095 \nL 535.190242 120.317259 \nL 535.899715 124.991133 \nL 536.609187 146.019938 \nL 538.737604 121.469574 \nL 539.447077 118.259818 \nL 540.156549 106.595649 \nL 540.866021 110.159714 \nL 541.575494 104.753638 \nL 543.703911 94.620676 \nL 544.413383 97.803018 \nL 545.122855 102.246375 \nL 545.832328 102.127786 \nL 546.5418 112.596017 \nL 548.670217 108.222464 \nL 549.379689 90.498195 \nL 550.089162 86.332969 \nL 550.798634 91.425191 \nL 551.508106 68.953288 \nL 553.636523 51.599938 \nL 555.055468 75.307699 \nL 555.76494 88.42984 \nL 556.474413 77.138548 \nL 560.021775 74.490372 \nL 560.731247 71.345578 \nL 561.440719 69.323262 \nL 563.569136 92.846201 \nL 564.278609 104.290821 \nL 564.988081 123.933341 \nL 565.697553 115.136675 \nL 571.373332 114.591997 \nL 573.501749 114.269106 \nL 574.211221 116.771007 \nL 574.920694 109.95483 \nL 575.630166 118.193045 \nL 576.339639 122.890774 \nL 578.468056 123.056539 \nL 579.177528 113.917695 \nL 579.887 121.802141 \nL 580.596473 119.973446 \nL 581.305945 120.994601 \nL 583.434362 112.375701 \nL 584.143834 115.12668 \nL 584.853307 121.368944 \nL 585.562779 130.241703 \nL 586.272251 118.817717 \nL 588.400668 130.224749 \nL 589.110141 140.369862 \nL 589.819613 140.786175 \nL 590.529085 137.733481 \nL 591.238558 146.787294 \nL 593.366975 144.318037 \nL 594.076447 146.058619 \nL 594.78592 153.44988 \nL 595.495392 150.048324 \nL 596.204864 149.603531 \nL 598.333281 158.890626 \nL 599.042754 155.109048 \nL 599.752226 154.514119 \nL 600.461698 156.306572 \nL 601.171171 154.053731 \nL 603.299588 148.496396 \nL 604.00906 144.390706 \nL 604.718532 148.622805 \nL 605.428005 150.358227 \nL 606.137477 151.004781 \nL 608.265894 140.000548 \nL 608.975366 130.334237 \nL 609.684839 131.600065 \nL 610.394311 126.648034 \nL 611.103783 130.890617 \nL 613.232201 124.724531 \nL 613.941673 120.705518 \nL 614.651145 111.819061 \nL 615.360618 107.315079 \nL 616.07009 98.708132 \nL 618.198507 99.260516 \nL 618.907979 114.748844 \nL 619.617452 112.835826 \nL 620.326924 108.894344 \nL 621.036396 115.701821 \nL 623.164813 116.074407 \nL 623.874286 111.96268 \nL 624.583758 121.487148 \nL 625.29323 115.338046 \nL 626.002703 131.130681 \nL 628.13112 132.267159 \nL 628.840592 119.948686 \nL 629.550064 129.124305 \nL 630.259537 136.08206 \nL 630.969009 123.156568 \nL 633.806899 122.786149 \nL 634.516371 133.328586 \nL 635.225843 141.940799 \nL 635.935316 140.744121 \nL 638.063733 145.176379 \nL 638.773205 150.211097 \nL 639.482677 140.570611 \nL 640.19215 150.407051 \nL 640.901622 151.865197 \nL 643.030039 160.447271 \nL 643.739511 151.173111 \nL 644.448984 160.207899 \nL 645.158456 163.474625 \nL 645.867928 170.020429 \nL 647.996345 164.947827 \nL 648.705818 181.158533 \nL 649.41529 172.240985 \nL 650.834235 195.842844 \nL 657.928958 176.376586 \nL 658.638431 173.869563 \nL 659.347903 170.338057 \nL 660.057375 170.014071 \nL 660.766848 173.319375 \nL 662.895265 184.720199 \nL 663.604737 180.099434 \nL 665.023682 168.80686 \nL 665.733154 167.197918 \nL 667.861571 168.939871 \nL 668.571043 168.678022 \nL 669.280516 162.194514 \nL 669.989988 172.598148 \nL 670.699461 169.958226 \nL 673.53735 148.471398 \nL 674.246822 145.385224 \nL 674.956295 139.77619 \nL 675.665767 144.953026 \nL 677.794184 158.575722 \nL 678.503656 170.43807 \nL 679.213129 174.993761 \nL 680.632073 155.925472 \nL 682.76049 174.916917 \nL 683.469963 198.899277 \nL 684.179435 174.796099 \nL 684.888907 175.679592 \nL 685.59838 170.12811 \nL 687.726797 167.576176 \nL 688.436269 165.390985 \nL 689.145742 169.156862 \nL 689.855214 170.342675 \nL 690.564686 183.624957 \nL 692.693103 179.384704 \nL 693.402576 174.836956 \nL 694.112048 166.238795 \nL 694.82152 179.085602 \nL 695.530993 160.06125 \nL 699.078354 174.270142 \nL 699.787827 183.381153 \nL 700.497299 182.761754 \nL 702.625716 200.005733 \nL 703.335188 189.087145 \nL 704.044661 186.463963 \nL 704.754133 175.810678 \nL 705.463605 186.477101 \nL 708.301495 193.31837 \nL 709.010967 199.63822 \nL 709.72044 213.252565 \nL 710.429912 211.604669 \nL 712.558329 240.732407 \nL 713.267801 242.517324 \nL 713.977274 225.207736 \nL 714.686746 220.74038 \nL 715.396218 210.208622 \nL 719.653052 206.621919 \nL 720.362525 227.009906 \nL 722.490942 229.74867 \nL 723.200414 229.472773 \nL 723.909886 226.472609 \nL 724.619359 229.246478 \nL 725.328831 225.625699 \nL 727.457248 229.582775 \nL 728.166721 223.456092 \nL 728.876193 225.845773 \nL 729.585665 230.327213 \nL 730.295138 215.049614 \nL 732.423555 210.515629 \nL 733.133027 219.700113 \nL 733.842499 215.798192 \nL 734.551972 216.312833 \nL 735.261444 213.055971 \nL 737.389861 213.555122 \nL 738.099333 212.710232 \nL 738.808806 214.175368 \nL 739.518278 213.760778 \nL 742.356167 205.853952 \nL 743.06564 196.855099 \nL 743.775112 196.858157 \nL 744.484584 205.410521 \nL 745.194057 202.723677 \nL 747.322474 210.385985 \nL 748.031946 206.925592 \nL 748.741419 199.294582 \nL 749.450891 203.83105 \nL 750.160363 200.262875 \nL 752.28878 202.91383 \nL 752.998253 212.177814 \nL 753.707725 213.955424 \nL 755.12667 204.316709 \nL 757.255087 200.870269 \nL 757.964559 196.529484 \nL 758.674031 206.48226 \nL 759.383504 198.799821 \nL 760.092976 196.634432 \nL 762.221393 193.924945 \nL 762.930865 191.076266 \nL 763.640338 203.673281 \nL 764.34981 196.749503 \nL 765.059283 197.477423 \nL 767.1877 209.200716 \nL 767.897172 214.893641 \nL 768.606644 215.807842 \nL 769.316117 219.286274 \nL 770.025589 228.754877 \nL 772.154006 219.025414 \nL 772.863478 223.220397 \nL 773.572951 224.618294 \nL 774.282423 233.605213 \nL 774.991895 231.836149 \nL 777.120312 238.021755 \nL 777.829785 232.711858 \nL 778.539257 236.535039 \nL 779.248729 238.417383 \nL 779.958202 240.922684 \nL 782.086619 245.646224 \nL 782.796091 262.112064 \nL 783.505564 266.12008 \nL 784.215036 262.583778 \nL 784.924508 256.574832 \nL 787.052925 254.989597 \nL 787.762398 252.445024 \nL 788.47187 256.332575 \nL 789.181342 249.08406 \nL 789.890815 249.307848 \nL 792.019232 251.297489 \nL 792.728704 253.607651 \nL 793.438176 251.225335 \nL 794.147649 256.148102 \nL 794.857121 251.164261 \nL 796.985538 247.991115 \nL 797.69501 253.089624 \nL 798.404483 259.310404 \nL 799.113955 252.024221 \nL 799.823427 255.317299 \nL 801.951844 258.777112 \nL 802.661317 255.205807 \nL 803.370789 254.967257 \nL 804.789734 267.906259 \nL 806.918151 268.680628 \nL 807.627623 262.271109 \nL 808.337096 261.979924 \nL 809.046568 263.503656 \nL 809.75604 257.768157 \nL 812.59393 258.223329 \nL 813.303402 263.704865 \nL 814.012874 267.892253 \nL 814.722347 278.58199 \nL 816.850764 281.444143 \nL 817.560236 279.360971 \nL 818.269708 278.164593 \nL 818.979181 280.498225 \nL 819.688653 284.654319 \nL 821.81707 293.646163 \nL 822.526543 285.273773 \nL 823.236015 294.138963 \nL 823.945487 291.583099 \nL 823.945487 291.583099 \n\" clip-path=\"url(#p9b8c24c311)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_26\">\n    <path d=\"M 78.254578 464.056812 \nL 859.454578 464.056812 \n\" clip-path=\"url(#p9b8c24c311)\" style=\"fill: none; stroke-dasharray: 7.4,3.2; stroke-dashoffset: 0; stroke: #000000; stroke-width: 2\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 78.254578 526.818509 \nL 78.254578 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 859.454578 526.818509 \nL 859.454578 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 78.254578 526.818509 \nL 859.454578 526.818509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 78.254578 23.229937 \nL 859.454578 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_11\">\n    <!-- Cumulative returns -->\n    <g transform=\"translate(405.472922 17.229937)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 740.243109 68.767531 \nL 850.984578 68.767531 \nQ 853.404578 68.767531 853.404578 66.347531 \nL 853.404578 31.699938 \nQ 853.404578 29.279937 850.984578 29.279937 \nL 740.243109 29.279937 \nQ 737.823109 29.279937 737.823109 31.699938 \nL 737.823109 66.347531 \nQ 737.823109 68.767531 740.243109 68.767531 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_27\">\n     <path d=\"M 742.663109 39.079047 \nL 754.763109 39.079047 \nL 766.863109 39.079047 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- daily_return -->\n     <g transform=\"translate(776.543109 43.314047)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-64\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"152.539062\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"180.322266\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"289.501953\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"328.365234\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"389.888672\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"429.097656\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"492.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"531.839844\"/>\n     </g>\n    </g>\n    <g id=\"line2d_28\">\n     <path d=\"M 742.663109 57.176109 \nL 754.763109 57.176109 \nL 766.863109 57.176109 \n\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- Backtest -->\n     <g transform=\"translate(776.543109 61.411109)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-42\" d=\"M 1259 2228 \nL 1259 519 \nL 2272 519 \nQ 2781 519 3026 730 \nQ 3272 941 3272 1375 \nQ 3272 1813 3026 2020 \nQ 2781 2228 2272 2228 \nL 1259 2228 \nz\nM 1259 4147 \nL 1259 2741 \nL 2194 2741 \nQ 2656 2741 2882 2914 \nQ 3109 3088 3109 3444 \nQ 3109 3797 2882 3972 \nQ 2656 4147 2194 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2241 4666 \nQ 2963 4666 3353 4366 \nQ 3744 4066 3744 3513 \nQ 3744 3084 3544 2831 \nQ 3344 2578 2956 2516 \nQ 3422 2416 3680 2098 \nQ 3938 1781 3938 1306 \nQ 3938 681 3513 340 \nQ 3088 0 2303 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"129.882812\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"184.863281\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"242.773438\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"281.982422\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"343.505859\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"395.605469\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 78.254578 828.971652 \nL 859.454578 828.971652 \nL 859.454578 627.536223 \nL 78.254578 627.536223 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_15\">\n     <g id=\"line2d_29\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_31\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_32\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_33\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_34\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_35\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_36\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_37\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"828.971652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_38\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_39\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_40\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_27\">\n     <g id=\"line2d_41\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_28\">\n     <g id=\"line2d_42\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"828.971652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_10\">\n     <g id=\"line2d_43\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"824.116399\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.80 -->\n      <g transform=\"translate(41.813172 828.713453)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_44\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"793.540305\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.00 -->\n      <g transform=\"translate(41.813172 798.13736)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_45\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"762.964212\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.20 -->\n      <g transform=\"translate(41.813172 767.561267)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_46\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"732.388119\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1.40 -->\n      <g transform=\"translate(41.813172 736.985174)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_47\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"701.812026\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 1.60 -->\n      <g transform=\"translate(41.813172 706.40908)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_15\">\n     <g id=\"line2d_48\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"671.235932\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 1.80 -->\n      <g transform=\"translate(41.813172 675.832987)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_16\">\n     <g id=\"line2d_49\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"640.659839\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 2.00 -->\n      <g transform=\"translate(41.813172 645.256894)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_21\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(35.067984 791.635594)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_50\">\n    <path d=\"M 113.763669 793.540305 \nL 114.473141 794.161248 \nL 116.601558 795.221893 \nL 117.311031 794.372161 \nL 118.020503 796.160861 \nL 118.729975 794.692164 \nL 119.439448 794.675575 \nL 121.567865 793.575162 \nL 122.277337 794.046381 \nL 122.98681 795.163928 \nL 123.696282 795.901647 \nL 124.405754 795.403075 \nL 126.534171 794.769079 \nL 127.243644 797.434036 \nL 127.953116 797.148825 \nL 128.662588 801.3722 \nL 136.466784 811.531811 \nL 137.176256 808.18975 \nL 137.885729 807.287618 \nL 138.595201 805.21076 \nL 139.304673 805.367917 \nL 141.433091 805.449348 \nL 142.142563 803.975695 \nL 142.852035 803.197728 \nL 143.561508 804.192247 \nL 146.399397 800.502811 \nL 147.108869 801.772604 \nL 147.818342 801.804003 \nL 148.527814 799.112271 \nL 149.237286 799.609112 \nL 151.365703 801.493877 \nL 152.075176 802.518207 \nL 152.784648 802.896625 \nL 153.49412 802.384045 \nL 154.203593 806.884864 \nL 156.33201 802.589319 \nL 157.041482 801.918746 \nL 157.750954 800.626631 \nL 158.460427 797.139348 \nL 159.169899 799.772502 \nL 161.298316 804.521158 \nL 162.007789 801.781586 \nL 162.717261 803.555081 \nL 164.136206 807.986514 \nL 166.264623 813.167547 \nL 166.974095 813.584625 \nL 168.39304 819.312467 \nL 169.102512 816.412626 \nL 171.230929 819.815496 \nL 171.940401 815.870156 \nL 172.649874 812.86268 \nL 173.359346 813.402128 \nL 174.068818 812.800446 \nL 176.197235 813.364453 \nL 176.906708 813.397246 \nL 177.61618 813.758298 \nL 178.325653 811.888273 \nL 179.035125 812.435417 \nL 181.873014 810.032438 \nL 182.582487 810.701167 \nL 183.291959 810.270768 \nL 184.001431 810.406365 \nL 186.129848 810.934625 \nL 186.839321 808.631975 \nL 187.548793 809.682149 \nL 188.258265 809.495512 \nL 188.967738 807.476743 \nL 191.096155 806.946599 \nL 191.805627 808.690697 \nL 192.515099 807.716063 \nL 193.224572 808.041333 \nL 193.934044 809.111539 \nL 196.062461 807.667446 \nL 198.190878 804.863538 \nL 202.447712 804.767704 \nL 203.157185 805.23375 \nL 203.866657 804.314266 \nL 206.704546 804.483191 \nL 207.414019 804.576428 \nL 208.123491 806.21757 \nL 208.832963 806.951678 \nL 210.96138 806.087024 \nL 211.670853 804.924847 \nL 212.380325 805.148833 \nL 213.089797 805.609621 \nL 213.79927 809.122169 \nL 215.927687 808.434644 \nL 216.637159 807.488307 \nL 217.346632 808.149186 \nL 218.056104 807.447605 \nL 218.765576 807.596017 \nL 220.893993 804.445673 \nL 221.603466 803.675789 \nL 222.312938 803.518112 \nL 223.02241 803.802289 \nL 223.731883 803.159959 \nL 225.8603 802.505213 \nL 226.569772 801.579393 \nL 227.279244 802.560186 \nL 227.988717 804.141123 \nL 228.698189 803.765074 \nL 230.826606 806.01603 \nL 231.536078 804.018485 \nL 232.245551 803.91265 \nL 232.955023 803.525586 \nL 233.664495 801.696555 \nL 235.792913 801.896587 \nL 236.502385 801.722256 \nL 237.211857 800.829096 \nL 240.759219 801.718922 \nL 241.468691 800.898304 \nL 242.887636 793.866511 \nL 245.725525 779.527413 \nL 246.434998 779.150281 \nL 247.14447 776.766973 \nL 247.853942 776.169683 \nL 248.563415 780.633208 \nL 250.691832 778.737061 \nL 251.401304 780.818633 \nL 252.110776 782.513546 \nL 252.820249 790.018968 \nL 253.529721 788.838505 \nL 255.658138 783.792133 \nL 256.367611 783.846562 \nL 257.077083 783.62171 \nL 257.786555 783.980323 \nL 258.496028 790.203943 \nL 260.624445 789.959341 \nL 261.333917 788.83853 \nL 262.043389 785.994705 \nL 262.752862 786.581608 \nL 263.462334 785.700275 \nL 265.590751 784.129161 \nL 266.300223 782.59422 \nL 267.009696 783.574775 \nL 267.719168 783.580172 \nL 268.42864 784.987618 \nL 270.557057 783.898715 \nL 271.26653 785.033178 \nL 271.976002 785.68046 \nL 272.685475 786.070892 \nL 273.394947 783.7625 \nL 275.523364 779.788942 \nL 276.232836 779.864001 \nL 276.942309 782.81553 \nL 277.651781 784.948671 \nL 278.361253 783.949835 \nL 280.48967 783.257666 \nL 281.199143 782.658259 \nL 281.908615 784.28799 \nL 282.618087 783.650151 \nL 283.32756 779.809241 \nL 285.455977 781.023561 \nL 286.165449 780.46919 \nL 286.874921 780.854592 \nL 287.584394 781.492278 \nL 288.293866 782.738848 \nL 290.422283 785.498052 \nL 291.131755 783.693248 \nL 291.841228 786.374662 \nL 292.5507 785.890003 \nL 293.260173 784.901004 \nL 295.38859 783.4837 \nL 296.098062 782.321849 \nL 296.807534 783.412825 \nL 297.517007 784.941079 \nL 298.226479 780.831137 \nL 300.354896 782.62093 \nL 301.064368 784.652584 \nL 301.773841 784.394404 \nL 302.483313 787.214892 \nL 303.192785 786.667792 \nL 305.321202 785.642685 \nL 306.740147 786.537141 \nL 313.125398 783.844455 \nL 315.253815 778.847373 \nL 315.963288 778.89643 \nL 316.67276 779.756841 \nL 317.382232 779.662684 \nL 318.091705 779.229021 \nL 320.220122 780.508191 \nL 320.929594 780.053359 \nL 321.639066 779.364761 \nL 322.348539 779.755248 \nL 323.058011 780.889028 \nL 325.186428 782.961726 \nL 325.8959 783.486796 \nL 326.605373 782.53992 \nL 327.314845 781.985529 \nL 328.024317 784.16466 \nL 330.152735 784.881234 \nL 330.862207 782.824171 \nL 331.571679 781.602174 \nL 332.281152 779.756588 \nL 332.990624 780.270188 \nL 335.119041 777.344181 \nL 335.828513 777.449759 \nL 336.537986 777.692685 \nL 337.247458 778.378982 \nL 337.95693 781.299464 \nL 340.085347 779.380322 \nL 340.79482 779.273275 \nL 341.504292 778.888926 \nL 342.213764 777.748864 \nL 342.923237 777.657922 \nL 345.051654 774.795411 \nL 346.470598 777.24445 \nL 347.180071 775.985767 \nL 347.889543 773.368204 \nL 350.01796 774.814543 \nL 350.727433 770.630205 \nL 352.146377 771.480936 \nL 352.85585 771.248141 \nL 355.693739 773.348503 \nL 356.403211 774.858609 \nL 357.112684 775.328123 \nL 357.822156 776.870271 \nL 359.950573 774.896201 \nL 360.660045 774.843687 \nL 361.369518 774.023781 \nL 362.07899 771.346116 \nL 362.788462 772.907441 \nL 364.916879 772.200735 \nL 365.626352 774.741111 \nL 366.335824 773.56962 \nL 367.045296 773.832395 \nL 367.754769 772.684271 \nL 369.883186 772.122836 \nL 370.592658 772.443695 \nL 371.302131 769.635177 \nL 372.011603 766.345512 \nL 374.849492 766.210959 \nL 375.558965 764.23225 \nL 376.268437 761.596658 \nL 376.977909 758.063969 \nL 377.687382 759.040874 \nL 379.815799 759.624027 \nL 380.525271 753.214018 \nL 381.234743 754.841039 \nL 381.944216 757.907929 \nL 382.653688 757.576021 \nL 384.782105 756.019746 \nL 385.491577 758.033079 \nL 386.20105 757.738298 \nL 386.910522 755.987215 \nL 387.619995 756.168317 \nL 389.748412 753.608492 \nL 390.457884 757.80574 \nL 391.167356 757.559515 \nL 391.876829 761.676505 \nL 392.586301 762.754126 \nL 394.714718 761.115699 \nL 395.42419 759.874273 \nL 396.133663 759.663939 \nL 396.843135 758.383086 \nL 397.552607 756.446702 \nL 399.681024 753.988458 \nL 400.390497 750.903865 \nL 401.099969 747.159486 \nL 407.48522 747.855548 \nL 409.613637 754.413702 \nL 410.32311 753.629805 \nL 411.032582 758.192453 \nL 411.742054 755.939083 \nL 412.451527 760.596936 \nL 414.579944 759.063112 \nL 415.289416 762.480756 \nL 415.998888 757.601825 \nL 416.708361 762.980986 \nL 417.417833 763.969188 \nL 419.54625 769.669786 \nL 420.255722 772.826352 \nL 420.965195 771.716482 \nL 421.674667 767.103956 \nL 422.384139 766.744205 \nL 424.512557 769.993948 \nL 425.222029 768.396936 \nL 425.931501 768.808994 \nL 426.640974 768.078393 \nL 427.350446 772.707315 \nL 429.478863 771.401168 \nL 430.188335 772.492534 \nL 430.897808 774.981509 \nL 431.60728 775.088818 \nL 432.316752 771.831437 \nL 434.445169 771.436588 \nL 435.154642 769.481215 \nL 435.864114 771.354549 \nL 436.573586 769.213796 \nL 437.283059 767.526445 \nL 440.120948 768.617307 \nL 440.83042 770.409854 \nL 441.539893 769.689274 \nL 442.249365 772.603924 \nL 444.377782 774.436273 \nL 445.087255 775.208196 \nL 445.796727 774.826666 \nL 446.506199 776.690395 \nL 447.215672 775.868768 \nL 449.344089 772.639304 \nL 450.053561 772.801116 \nL 450.763033 772.505642 \nL 451.472506 773.923757 \nL 452.181978 772.1137 \nL 454.310395 774.901464 \nL 455.019867 774.474043 \nL 455.72934 774.635434 \nL 456.438812 772.4506 \nL 457.148284 773.737749 \nL 461.405118 775.778039 \nL 462.114591 777.936001 \nL 464.243008 778.248871 \nL 464.95248 776.382719 \nL 465.661953 775.880763 \nL 466.371425 777.561159 \nL 467.080897 773.151652 \nL 469.209314 771.327696 \nL 469.918787 771.437315 \nL 470.628259 772.734663 \nL 471.337731 772.191376 \nL 472.047204 774.199026 \nL 474.175621 773.413314 \nL 474.885093 766.313218 \nL 475.594565 765.526863 \nL 476.304038 765.143434 \nL 477.01351 765.422699 \nL 479.141927 765.871384 \nL 479.851399 765.837804 \nL 481.270344 768.793057 \nL 481.979817 767.727372 \nL 484.108234 768.300757 \nL 484.817706 769.330839 \nL 485.527178 768.97231 \nL 486.236651 767.975783 \nL 486.946123 769.504269 \nL 489.784012 771.883863 \nL 490.493485 773.98012 \nL 491.202957 774.211961 \nL 491.912429 775.548038 \nL 494.040846 776.702311 \nL 494.750319 775.047616 \nL 495.459791 774.719412 \nL 496.169263 774.097757 \nL 496.878736 771.569766 \nL 499.007153 772.275849 \nL 499.716625 774.155925 \nL 500.426098 773.368718 \nL 501.13557 771.558365 \nL 501.845042 777.840706 \nL 504.682932 777.987021 \nL 505.392404 777.041748 \nL 506.101876 779.570975 \nL 506.811349 780.147753 \nL 509.649238 778.656586 \nL 510.35871 781.246494 \nL 511.068183 777.689751 \nL 511.777655 779.736976 \nL 513.906072 778.971939 \nL 514.615544 779.305178 \nL 515.325017 778.815949 \nL 516.034489 778.608385 \nL 516.743961 780.352904 \nL 518.872379 786.73739 \nL 519.581851 791.782278 \nL 521.000796 788.991586 \nL 521.710268 791.463502 \nL 523.838685 787.589417 \nL 524.548157 786.962153 \nL 525.25763 786.503274 \nL 525.967102 786.787377 \nL 526.676574 788.35352 \nL 528.804991 786.399235 \nL 529.514464 783.755714 \nL 530.223936 785.045509 \nL 530.933408 786.848993 \nL 531.642881 787.258389 \nL 533.771298 787.021681 \nL 534.48077 790.61978 \nL 535.190242 788.607965 \nL 535.899715 790.892007 \nL 536.609187 794.434519 \nL 538.737604 793.092491 \nL 539.447077 790.724136 \nL 540.156549 790.128859 \nL 540.866021 793.639315 \nL 541.575494 791.946825 \nL 543.703911 792.458604 \nL 544.413383 793.232386 \nL 545.122855 789.869987 \nL 545.832328 789.768089 \nL 546.5418 789.333714 \nL 548.670217 787.586751 \nL 549.379689 785.763839 \nL 550.089162 787.484923 \nL 550.798634 787.929022 \nL 551.508106 785.552525 \nL 553.636523 786.061406 \nL 554.345996 788.721288 \nL 555.055468 790.780266 \nL 555.76494 791.672822 \nL 556.474413 790.024063 \nL 560.021775 791.982037 \nL 560.731247 791.710805 \nL 564.278609 787.588938 \nL 564.988081 788.178922 \nL 565.697553 788.28949 \nL 573.501749 784.361343 \nL 574.211221 785.203567 \nL 574.920694 783.552369 \nL 575.630166 784.644027 \nL 576.339639 783.449937 \nL 578.468056 786.674993 \nL 579.177528 785.337689 \nL 579.887 785.420287 \nL 580.596473 784.255751 \nL 581.305945 782.297746 \nL 583.434362 782.585836 \nL 584.143834 783.687208 \nL 584.853307 785.811115 \nL 585.562779 786.181402 \nL 586.272251 784.814321 \nL 588.400668 785.622247 \nL 589.110141 787.545806 \nL 589.819613 789.058138 \nL 590.529085 787.781342 \nL 591.238558 788.064154 \nL 593.366975 788.325123 \nL 594.076447 788.785738 \nL 594.78592 789.604497 \nL 595.495392 786.490058 \nL 596.204864 787.124272 \nL 599.042754 787.043895 \nL 599.752226 787.706555 \nL 600.461698 789.457533 \nL 601.171171 787.502185 \nL 603.299588 787.539594 \nL 604.00906 786.945885 \nL 604.718532 786.565973 \nL 605.428005 787.247765 \nL 606.137477 788.765943 \nL 608.265894 788.781247 \nL 608.975366 789.85453 \nL 609.684839 789.109208 \nL 610.394311 788.592137 \nL 611.103783 787.081031 \nL 613.232201 786.748648 \nL 613.941673 785.444954 \nL 615.360618 780.217545 \nL 616.07009 780.541692 \nL 618.198507 779.926497 \nL 618.907979 780.696654 \nL 619.617452 782.255574 \nL 620.326924 781.668157 \nL 621.036396 784.238112 \nL 623.164813 785.402807 \nL 623.874286 784.528319 \nL 624.583758 785.144632 \nL 625.29323 783.828107 \nL 626.002703 783.677346 \nL 628.13112 784.260964 \nL 628.840592 783.026196 \nL 629.550064 786.120325 \nL 630.259537 785.084159 \nL 630.969009 784.464532 \nL 633.806899 784.97178 \nL 634.516371 785.455841 \nL 635.225843 787.626949 \nL 635.935316 786.989788 \nL 638.063733 786.354229 \nL 638.773205 787.422006 \nL 639.482677 786.344742 \nL 640.901622 791.155607 \nL 643.030039 790.727588 \nL 643.739511 788.757708 \nL 644.448984 788.774144 \nL 645.158456 786.473691 \nL 645.867928 787.213942 \nL 647.996345 787.658645 \nL 648.705818 790.863595 \nL 649.41529 789.937394 \nL 650.124762 792.135297 \nL 650.834235 795.36113 \nL 657.928958 792.381536 \nL 658.638431 792.270518 \nL 659.347903 791.129971 \nL 660.057375 790.855503 \nL 660.766848 790.964365 \nL 662.895265 792.889185 \nL 664.314209 791.302175 \nL 665.023682 791.149088 \nL 665.733154 789.979576 \nL 667.861571 790.867755 \nL 668.571043 792.971892 \nL 669.280516 792.194702 \nL 669.989988 795.083151 \nL 670.699461 794.294406 \nL 672.827878 794.037686 \nL 673.53735 791.81617 \nL 674.246822 792.728754 \nL 674.956295 793.230887 \nL 675.665767 794.947549 \nL 677.794184 799.285721 \nL 678.503656 801.339035 \nL 679.213129 802.624349 \nL 679.922601 801.324325 \nL 680.632073 801.214374 \nL 682.76049 805.359687 \nL 683.469963 812.730778 \nL 684.179435 806.553079 \nL 684.888907 804.106192 \nL 685.59838 802.327212 \nL 687.726797 803.369809 \nL 688.436269 802.941428 \nL 689.145742 802.162863 \nL 689.855214 802.80049 \nL 690.564686 805.134593 \nL 692.693103 805.295138 \nL 693.402576 805.840651 \nL 694.112048 802.213191 \nL 694.82152 803.03746 \nL 695.530993 800.840452 \nL 699.078354 801.436249 \nL 699.787827 802.85664 \nL 700.497299 801.718531 \nL 702.625716 805.631577 \nL 703.335188 803.263395 \nL 704.044661 803.855931 \nL 704.754133 801.564955 \nL 705.463605 801.46691 \nL 707.592022 803.586756 \nL 709.010967 806.177065 \nL 709.72044 808.047857 \nL 710.429912 807.226878 \nL 712.558329 813.692355 \nL 713.267801 813.810303 \nL 713.977274 811.163453 \nL 715.396218 807.661723 \nL 719.653052 807.879695 \nL 720.362525 811.89447 \nL 722.490942 813.112663 \nL 723.909886 810.832445 \nL 724.619359 811.79511 \nL 725.328831 810.485985 \nL 727.457248 811.862597 \nL 728.166721 810.0654 \nL 728.876193 810.619979 \nL 729.585665 810.668596 \nL 730.295138 807.532819 \nL 732.423555 808.78888 \nL 733.133027 811.180666 \nL 733.842499 810.724409 \nL 734.551972 810.651115 \nL 735.261444 809.752218 \nL 737.389861 808.991533 \nL 738.099333 807.271815 \nL 738.808806 808.021207 \nL 739.518278 808.404626 \nL 742.356167 806.656911 \nL 743.06564 805.610318 \nL 743.775112 804.002712 \nL 744.484584 804.541245 \nL 745.194057 803.000244 \nL 747.322474 805.713507 \nL 748.741419 801.792844 \nL 749.450891 803.407969 \nL 750.160363 801.188857 \nL 752.28878 801.747032 \nL 752.998253 801.669875 \nL 753.707725 803.360945 \nL 755.12667 799.281888 \nL 757.255087 797.343238 \nL 757.964559 796.083659 \nL 758.674031 797.57631 \nL 759.383504 795.144648 \nL 760.092976 795.794036 \nL 762.930865 795.455584 \nL 763.640338 798.194988 \nL 764.34981 798.566936 \nL 765.059283 798.364229 \nL 767.897172 801.890997 \nL 768.606644 802.272334 \nL 769.316117 803.211919 \nL 770.025589 805.977143 \nL 772.154006 804.03595 \nL 772.863478 804.680764 \nL 773.572951 804.261589 \nL 774.282423 806.112279 \nL 774.991895 805.529882 \nL 777.120312 806.082696 \nL 777.829785 805.223081 \nL 778.539257 806.445647 \nL 779.248729 806.584884 \nL 779.958202 808.305092 \nL 782.086619 808.831695 \nL 782.796091 811.350669 \nL 783.505564 812.341478 \nL 784.924508 809.195101 \nL 787.052925 809.846919 \nL 787.762398 809.702938 \nL 788.47187 811.340505 \nL 789.181342 808.565542 \nL 789.890815 808.079543 \nL 792.019232 808.783034 \nL 792.728704 809.446084 \nL 793.438176 808.625402 \nL 794.147649 809.939053 \nL 794.857121 810.367591 \nL 796.985538 810.08376 \nL 797.69501 811.107773 \nL 798.404483 812.471743 \nL 799.113955 810.272351 \nL 799.823427 810.320162 \nL 802.661317 811.553223 \nL 803.370789 809.815955 \nL 804.080262 811.269368 \nL 804.789734 812.314749 \nL 806.918151 812.982379 \nL 807.627623 811.660171 \nL 808.337096 812.343338 \nL 809.046568 812.462444 \nL 809.75604 810.024549 \nL 812.59393 809.447375 \nL 813.303402 810.6249 \nL 814.012874 810.706009 \nL 814.722347 813.958443 \nL 816.850764 813.881648 \nL 817.560236 814.163846 \nL 818.979181 816.365439 \nL 819.688653 816.343735 \nL 821.81707 817.081177 \nL 822.526543 815.695167 \nL 823.236015 817.225523 \nL 823.945487 817.225523 \nL 823.945487 817.225523 \n\" clip-path=\"url(#pd7898e59a1)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_51\">\n    <path d=\"M 113.763669 793.540305 \nL 114.473141 793.634459 \nL 116.601558 793.640016 \nL 117.311031 793.370386 \nL 118.020503 794.313728 \nL 118.729975 793.136052 \nL 119.439448 793.278539 \nL 121.567865 792.078062 \nL 122.277337 792.392251 \nL 122.98681 793.237082 \nL 123.696282 793.518464 \nL 124.405754 791.778908 \nL 126.534171 791.985112 \nL 127.243644 792.890299 \nL 127.953116 792.596333 \nL 128.662588 795.507879 \nL 136.466784 802.247627 \nL 137.176256 800.365268 \nL 137.885729 797.532757 \nL 138.595201 796.170132 \nL 141.433091 795.282555 \nL 142.142563 794.673154 \nL 142.852035 793.03752 \nL 143.561508 792.325278 \nL 144.27098 791.981598 \nL 146.399397 789.484641 \nL 147.108869 789.501255 \nL 147.818342 790.531245 \nL 148.527814 788.934737 \nL 149.237286 788.664124 \nL 151.365703 789.306126 \nL 152.075176 788.168101 \nL 152.784648 789.5902 \nL 153.49412 789.217025 \nL 154.203593 793.028548 \nL 156.33201 791.086018 \nL 157.041482 790.023234 \nL 157.750954 789.601316 \nL 158.460427 787.924235 \nL 159.169899 789.431392 \nL 161.298316 793.646878 \nL 162.007789 791.569728 \nL 162.717261 791.954818 \nL 163.426733 794.4513 \nL 164.136206 795.709263 \nL 166.264623 799.929594 \nL 166.974095 799.890552 \nL 167.683567 801.280072 \nL 168.39304 802.203067 \nL 169.102512 801.107758 \nL 171.230929 804.5432 \nL 171.940401 801.19777 \nL 172.649874 799.350864 \nL 173.359346 799.812509 \nL 174.068818 798.853477 \nL 176.197235 799.782052 \nL 176.906708 799.207887 \nL 177.61618 799.478895 \nL 178.325653 797.5732 \nL 179.035125 797.675797 \nL 181.873014 795.555286 \nL 183.291959 796.397412 \nL 184.001431 797.639557 \nL 186.129848 798.122909 \nL 186.839321 795.566668 \nL 187.548793 796.346067 \nL 188.258265 795.765539 \nL 188.967738 794.172781 \nL 191.096155 793.903141 \nL 191.805627 794.916265 \nL 192.515099 793.917883 \nL 193.224572 793.818274 \nL 193.934044 795.165191 \nL 196.062461 795.244655 \nL 196.771933 793.291775 \nL 197.481406 792.684501 \nL 198.190878 790.93982 \nL 202.447712 791.183008 \nL 203.157185 791.714388 \nL 203.866657 791.250368 \nL 205.995074 792.08007 \nL 206.704546 791.571939 \nL 207.414019 791.990698 \nL 208.123491 793.617383 \nL 208.832963 794.542081 \nL 210.96138 793.595269 \nL 211.670853 791.839547 \nL 212.380325 792.51754 \nL 213.089797 794.458227 \nL 213.79927 797.333495 \nL 215.927687 796.755822 \nL 216.637159 795.479212 \nL 217.346632 796.262796 \nL 218.056104 796.46185 \nL 218.765576 795.99828 \nL 220.893993 792.895665 \nL 221.603466 792.727069 \nL 222.312938 792.082452 \nL 223.02241 792.680618 \nL 223.731883 792.274569 \nL 226.569772 789.526798 \nL 227.279244 790.011715 \nL 227.988717 790.320527 \nL 228.698189 791.233713 \nL 230.826606 792.372516 \nL 231.536078 790.843797 \nL 232.245551 791.055104 \nL 233.664495 789.337057 \nL 236.502385 787.555165 \nL 237.211857 785.482204 \nL 240.759219 785.410418 \nL 241.468691 784.626806 \nL 242.178164 780.279893 \nL 243.597108 774.699507 \nL 245.725525 768.461064 \nL 246.434998 768.742932 \nL 247.853942 762.431421 \nL 248.563415 765.967455 \nL 250.691832 762.601732 \nL 251.401304 763.053508 \nL 252.110776 762.287206 \nL 252.820249 769.73452 \nL 253.529721 767.888517 \nL 256.367611 758.612652 \nL 257.077083 757.696171 \nL 257.786555 751.502285 \nL 258.496028 757.972804 \nL 260.624445 754.991746 \nL 261.333917 756.05146 \nL 262.752862 748.891845 \nL 263.462334 748.144541 \nL 265.590751 746.572157 \nL 266.300223 748.595966 \nL 267.009696 746.897296 \nL 267.719168 749.29818 \nL 268.42864 747.947476 \nL 270.557057 746.545558 \nL 271.976002 754.855836 \nL 272.685475 754.673339 \nL 273.394947 752.440392 \nL 276.232836 748.102728 \nL 277.651781 753.508097 \nL 278.361253 751.360734 \nL 280.48967 748.118555 \nL 281.199143 749.168676 \nL 281.908615 751.670927 \nL 282.618087 749.192954 \nL 283.32756 745.709535 \nL 285.455977 743.135775 \nL 286.165449 740.033443 \nL 286.874921 738.593891 \nL 287.584394 740.168706 \nL 288.293866 743.650608 \nL 290.422283 745.037919 \nL 291.131755 743.551907 \nL 291.841228 746.8301 \nL 292.5507 746.84321 \nL 293.260173 744.155793 \nL 295.38859 743.397497 \nL 296.098062 742.94522 \nL 296.807534 742.966443 \nL 297.517007 743.926102 \nL 298.226479 741.97824 \nL 300.354896 743.381883 \nL 301.064368 745.650759 \nL 301.773841 743.061517 \nL 302.483313 747.440784 \nL 303.192785 747.199265 \nL 305.321202 743.597649 \nL 306.030675 742.824323 \nL 306.740147 743.741473 \nL 313.125398 738.287829 \nL 315.963288 729.968959 \nL 316.67276 729.949277 \nL 317.382232 732.993194 \nL 318.091705 734.486546 \nL 320.220122 738.016163 \nL 320.929594 735.97695 \nL 321.639066 736.253704 \nL 322.348539 737.023974 \nL 323.058011 738.495958 \nL 325.186428 737.361347 \nL 326.605373 733.697625 \nL 327.314845 732.162606 \nL 330.152735 731.031779 \nL 330.862207 729.899366 \nL 331.571679 731.832312 \nL 332.281152 725.292936 \nL 332.990624 727.867757 \nL 335.828513 720.967141 \nL 336.537986 724.896133 \nL 337.247458 726.166973 \nL 337.95693 729.303775 \nL 340.085347 727.541606 \nL 340.79482 727.738226 \nL 341.504292 727.654561 \nL 342.213764 725.116312 \nL 342.923237 719.387438 \nL 345.051654 716.082342 \nL 345.761126 717.888223 \nL 346.470598 720.494915 \nL 347.180071 720.321337 \nL 347.889543 719.585956 \nL 350.01796 720.394756 \nL 350.727433 717.534007 \nL 351.436905 718.673315 \nL 352.146377 720.100872 \nL 352.85585 719.736525 \nL 355.693739 722.308177 \nL 356.403211 723.915611 \nL 357.112684 721.880325 \nL 357.822156 724.295061 \nL 359.950573 723.802321 \nL 360.660045 721.338731 \nL 361.369518 719.386752 \nL 362.07899 713.764155 \nL 362.788462 711.15199 \nL 364.916879 708.693756 \nL 365.626352 714.05601 \nL 366.335824 710.002639 \nL 367.045296 710.006505 \nL 367.754769 704.400877 \nL 369.883186 700.711375 \nL 370.592658 703.619994 \nL 371.302131 701.823633 \nL 372.011603 697.450787 \nL 374.849492 689.803757 \nL 375.558965 686.238001 \nL 376.268437 685.146814 \nL 376.977909 679.729178 \nL 377.687382 678.525657 \nL 379.815799 679.47057 \nL 380.525271 676.495628 \nL 381.234743 671.601312 \nL 381.944216 680.868775 \nL 382.653688 684.05147 \nL 384.782105 679.621586 \nL 385.491577 686.929821 \nL 386.20105 684.695591 \nL 386.910522 680.369523 \nL 387.619995 677.258871 \nL 389.748412 677.02325 \nL 390.457884 680.348838 \nL 391.167356 677.754301 \nL 391.876829 686.855094 \nL 392.586301 692.186333 \nL 394.714718 692.847168 \nL 395.42419 686.971931 \nL 396.133663 686.802183 \nL 396.843135 690.525422 \nL 397.552607 691.500657 \nL 399.681024 688.664013 \nL 400.390497 680.714832 \nL 401.099969 675.139347 \nL 406.775748 669.96507 \nL 407.48522 671.85909 \nL 409.613637 674.527258 \nL 410.32311 675.861763 \nL 411.032582 684.376005 \nL 411.742054 683.193434 \nL 412.451527 689.832655 \nL 414.579944 686.578115 \nL 415.289416 692.535849 \nL 415.998888 690.950401 \nL 416.708361 700.728403 \nL 419.54625 712.712748 \nL 420.255722 714.436461 \nL 420.965195 713.731853 \nL 421.674667 707.075607 \nL 422.384139 706.367613 \nL 424.512557 708.606097 \nL 425.222029 707.268564 \nL 426.640974 703.253862 \nL 427.350446 707.589263 \nL 429.478863 706.096972 \nL 430.188335 710.262982 \nL 430.897808 716.504119 \nL 431.60728 714.48201 \nL 432.316752 707.199035 \nL 434.445169 707.893857 \nL 435.864114 703.549054 \nL 436.573586 700.697852 \nL 437.283059 698.84635 \nL 440.120948 697.173561 \nL 440.83042 695.116391 \nL 441.539893 694.94226 \nL 442.249365 695.23903 \nL 444.377782 700.659724 \nL 445.087255 703.922026 \nL 445.796727 702.6047 \nL 446.506199 702.656147 \nL 447.215672 701.032786 \nL 449.344089 697.767079 \nL 450.053561 697.358028 \nL 450.763033 692.041377 \nL 451.472506 689.362409 \nL 452.181978 688.034432 \nL 454.310395 687.30302 \nL 455.019867 683.132313 \nL 455.72934 682.900883 \nL 456.438812 678.518708 \nL 457.148284 679.99389 \nL 461.405118 675.790806 \nL 462.114591 675.673228 \nL 464.243008 671.880658 \nL 464.95248 677.7814 \nL 465.661953 674.647718 \nL 466.371425 678.054827 \nL 467.080897 674.426773 \nL 469.918787 663.926904 \nL 470.628259 662.41104 \nL 471.337731 668.302116 \nL 472.047204 664.55936 \nL 474.175621 666.63452 \nL 474.885093 662.555932 \nL 475.594565 664.493769 \nL 476.304038 664.776485 \nL 477.01351 661.180988 \nL 479.141927 659.328681 \nL 479.851399 657.183577 \nL 480.560872 662.093766 \nL 481.270344 664.618597 \nL 481.979817 664.014111 \nL 484.108234 660.816633 \nL 484.817706 663.54795 \nL 485.527178 660.547822 \nL 486.236651 652.574246 \nL 486.946123 649.914409 \nL 489.784012 651.802057 \nL 490.493485 658.870757 \nL 491.202957 652.293443 \nL 491.912429 650.415624 \nL 494.040846 651.812247 \nL 494.750319 648.535553 \nL 495.459791 650.755675 \nL 496.169263 649.742266 \nL 496.878736 642.499844 \nL 499.007153 639.904724 \nL 499.716625 640.212425 \nL 500.426098 636.692379 \nL 501.13557 637.017325 \nL 501.845042 640.337853 \nL 503.973459 652.898808 \nL 504.682932 654.085936 \nL 505.392404 647.176583 \nL 506.101876 649.908429 \nL 506.811349 657.866625 \nL 508.939766 655.430648 \nL 509.649238 648.617682 \nL 510.35871 671.317522 \nL 511.068183 670.620395 \nL 511.777655 673.003116 \nL 513.906072 667.689266 \nL 514.615544 669.18737 \nL 515.325017 665.667264 \nL 516.034489 664.544904 \nL 516.743961 669.978739 \nL 518.872379 674.595745 \nL 519.581851 681.179332 \nL 520.291323 681.396984 \nL 521.000796 675.628046 \nL 521.710268 673.743364 \nL 523.838685 666.462785 \nL 524.548157 662.255697 \nL 525.25763 656.955335 \nL 525.967102 657.397285 \nL 526.676574 657.517546 \nL 528.804991 658.65045 \nL 529.514464 657.34178 \nL 530.223936 657.604495 \nL 530.933408 654.050296 \nL 531.642881 656.269747 \nL 533.771298 658.873591 \nL 534.48077 661.784406 \nL 535.190242 659.788397 \nL 535.899715 661.345743 \nL 536.609187 668.371558 \nL 538.737604 660.065458 \nL 539.447077 658.99485 \nL 540.156549 655.111439 \nL 540.866021 656.290276 \nL 541.575494 654.498585 \nL 543.703911 651.150458 \nL 544.413383 652.196106 \nL 545.122855 653.658665 \nL 545.832328 653.619534 \nL 546.5418 657.073519 \nL 548.670217 655.621905 \nL 549.379689 649.753571 \nL 550.089162 648.387855 \nL 550.798634 650.053747 \nL 551.508106 642.681711 \nL 553.636523 637.056317 \nL 555.055468 644.696728 \nL 555.76494 648.965538 \nL 556.474413 645.266092 \nL 560.021775 644.403686 \nL 560.731247 643.380995 \nL 561.440719 642.72443 \nL 563.569136 650.353234 \nL 564.278609 654.112749 \nL 564.988081 660.606515 \nL 565.697553 657.665338 \nL 573.501749 657.376751 \nL 574.211221 658.208665 \nL 574.920694 655.938961 \nL 575.630166 658.671635 \nL 576.339639 660.237251 \nL 578.468056 660.292646 \nL 579.177528 657.238386 \nL 579.887 659.859736 \nL 580.596473 659.248987 \nL 581.305945 659.589675 \nL 583.434362 656.712461 \nL 584.143834 657.626325 \nL 584.853307 659.703226 \nL 585.562779 662.665942 \nL 586.272251 658.831559 \nL 588.400668 662.63519 \nL 589.110141 666.040595 \nL 589.819613 666.181183 \nL 590.529085 665.150043 \nL 591.238558 668.202711 \nL 593.366975 667.365614 \nL 594.076447 667.954811 \nL 594.78592 670.459414 \nL 595.495392 669.301569 \nL 596.204864 669.15048 \nL 598.333281 672.304319 \nL 599.042754 671.012776 \nL 599.752226 670.810056 \nL 600.461698 671.420606 \nL 601.171171 670.652395 \nL 603.299588 668.75997 \nL 604.00906 667.366562 \nL 604.718532 668.799336 \nL 605.428005 669.388363 \nL 606.137477 669.608044 \nL 608.265894 665.86765 \nL 608.975366 662.603528 \nL 609.684839 663.028558 \nL 610.394311 661.364571 \nL 611.103783 662.786068 \nL 613.232201 660.714964 \nL 613.941673 659.369851 \nL 614.651145 656.402537 \nL 615.360618 654.90616 \nL 616.07009 652.053871 \nL 618.198507 652.236056 \nL 618.907979 657.345894 \nL 619.617452 656.709198 \nL 620.326924 655.398807 \nL 621.036396 657.657007 \nL 623.164813 657.781082 \nL 623.874286 656.411543 \nL 624.583758 659.576578 \nL 625.29323 657.521994 \nL 626.002703 662.780269 \nL 628.13112 663.162166 \nL 628.840592 659.019957 \nL 629.550064 662.083531 \nL 630.259537 664.419035 \nL 630.969009 660.062516 \nL 633.806899 659.938598 \nL 634.516371 663.464643 \nL 635.225843 666.36295 \nL 635.935316 665.958156 \nL 638.063733 667.456363 \nL 638.773205 669.162744 \nL 639.482677 665.885395 \nL 640.19215 669.210165 \nL 640.901622 669.705965 \nL 643.030039 672.626634 \nL 643.739511 669.453707 \nL 644.448984 672.527338 \nL 645.158456 673.644874 \nL 645.867928 675.888715 \nL 647.996345 674.142718 \nL 648.705818 679.704841 \nL 649.41529 676.613243 \nL 650.834235 684.780626 \nL 657.928958 677.966011 \nL 658.638431 677.099243 \nL 659.347903 675.880212 \nL 660.057375 675.768625 \nL 660.766848 676.906807 \nL 662.895265 680.840892 \nL 663.604737 679.234645 \nL 665.023682 675.327812 \nL 665.733154 674.774141 \nL 667.861571 675.37298 \nL 668.571043 675.282865 \nL 669.280516 673.051928 \nL 669.989988 676.617379 \nL 670.699461 675.706698 \nL 673.53735 668.323717 \nL 674.246822 667.27472 \nL 674.956295 665.371731 \nL 675.665767 667.12223 \nL 677.794184 671.742929 \nL 678.503656 675.800262 \nL 679.213129 677.370097 \nL 680.632073 670.799929 \nL 682.76049 677.285977 \nL 683.469963 685.575267 \nL 684.179435 677.1113 \nL 684.888907 677.416799 \nL 685.59838 675.4961 \nL 687.726797 674.616266 \nL 688.436269 673.864077 \nL 689.145742 675.158606 \nL 689.855214 675.567195 \nL 690.564686 680.147215 \nL 692.693103 678.672549 \nL 693.402576 677.095236 \nL 694.112048 674.121708 \nL 694.82152 678.540712 \nL 695.530993 671.942992 \nL 699.078354 676.812845 \nL 699.787827 679.96361 \nL 700.497299 679.748151 \nL 702.625716 685.744113 \nL 703.335188 681.903924 \nL 704.044661 680.987893 \nL 704.754133 677.274038 \nL 705.463605 680.96729 \nL 708.301495 683.354458 \nL 709.010967 685.567757 \nL 709.72044 690.355766 \nL 710.429912 689.770815 \nL 712.558329 700.098611 \nL 713.267801 700.744878 \nL 713.977274 694.469419 \nL 714.686746 692.869506 \nL 715.396218 689.109447 \nL 719.653052 687.8381 \nL 720.362525 695.047337 \nL 722.490942 696.029693 \nL 723.200414 695.93054 \nL 723.909886 694.852545 \nL 724.619359 695.847124 \nL 725.328831 694.546331 \nL 727.457248 695.964322 \nL 728.166721 693.762708 \nL 728.876193 694.617754 \nL 729.585665 696.223943 \nL 730.295138 690.730887 \nL 732.423555 689.117819 \nL 733.133027 692.375316 \nL 733.842499 690.982581 \nL 734.551972 691.165781 \nL 735.261444 690.006003 \nL 737.389861 690.183356 \nL 738.099333 689.883056 \nL 738.808806 690.403509 \nL 739.518278 690.256088 \nL 742.356167 687.445363 \nL 743.06564 684.263509 \nL 743.775112 684.264584 \nL 744.484584 687.270543 \nL 745.194057 686.320735 \nL 747.322474 689.024507 \nL 748.031946 687.797079 \nL 748.741419 685.096633 \nL 749.450891 686.693833 \nL 750.160363 685.433721 \nL 752.28878 686.367685 \nL 752.998253 689.637306 \nL 753.707725 690.268666 \nL 755.12667 686.846677 \nL 757.255087 685.629071 \nL 757.964559 684.099028 \nL 758.674031 687.597106 \nL 759.383504 684.878823 \nL 760.092976 684.116556 \nL 762.221393 683.164123 \nL 762.930865 682.164548 \nL 763.640338 686.576476 \nL 764.34981 684.131001 \nL 765.059283 684.386923 \nL 767.1877 688.510584 \nL 767.897172 690.529015 \nL 768.606644 690.854414 \nL 769.316117 692.0933 \nL 770.025589 695.473797 \nL 772.154006 691.976889 \nL 772.863478 693.474455 \nL 773.572951 693.974954 \nL 774.282423 697.195762 \nL 774.991895 696.557675 \nL 777.120312 698.785961 \nL 777.829785 696.864594 \nL 778.539257 698.242755 \nL 779.248729 698.923159 \nL 779.958202 699.829975 \nL 782.086619 701.542813 \nL 782.796091 707.534323 \nL 783.505564 709.011044 \nL 784.215036 707.704106 \nL 784.924508 705.489325 \nL 787.052925 704.90768 \nL 787.762398 703.975151 \nL 788.47187 705.397148 \nL 789.181342 702.738017 \nL 789.890815 702.819674 \nL 792.019232 703.545783 \nL 792.728704 704.390112 \nL 793.438176 703.517908 \nL 794.147649 705.317018 \nL 794.857121 703.488846 \nL 796.985538 702.329185 \nL 797.69501 704.188127 \nL 798.404483 706.464888 \nL 799.113955 703.785634 \nL 799.823427 704.989983 \nL 801.951844 706.258438 \nL 802.661317 704.945681 \nL 803.370789 704.858229 \nL 804.789734 709.612485 \nL 806.918151 709.899141 \nL 807.627623 707.525047 \nL 808.337096 707.417718 \nL 809.046568 707.979228 \nL 809.75604 705.86318 \nL 812.59393 706.030384 \nL 813.303402 708.044674 \nL 814.012874 709.589859 \nL 814.722347 713.547228 \nL 816.850764 714.615778 \nL 817.560236 713.836276 \nL 818.269708 713.389343 \nL 818.979181 714.260296 \nL 819.688653 715.814306 \nL 821.81707 719.187689 \nL 822.526543 716.023487 \nL 823.236015 719.351349 \nL 823.945487 718.384916 \nL 823.945487 718.384916 \n\" clip-path=\"url(#pd7898e59a1)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_52\">\n    <path d=\"M 78.254578 793.540305 \nL 859.454578 793.540305 \n\" clip-path=\"url(#pd7898e59a1)\" style=\"fill: none; stroke-dasharray: 7.4,3.2; stroke-dashoffset: 0; stroke: #000000; stroke-width: 2\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 78.254578 828.971652 \nL 78.254578 627.536223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 859.454578 828.971652 \nL 859.454578 627.536223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 78.254578 828.971652 \nL 859.454578 828.971652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 78.254578 627.536223 \nL 859.454578 627.536223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_22\">\n    <!-- Cumulative returns volatility matched to benchmark -->\n    <g transform=\"translate(295.674703 621.536223)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"960.355469\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"992.142578\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1051.322266\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1112.503906\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1140.287109\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1201.566406\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1240.775391\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1268.558594\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1296.341797\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1324.125\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1363.333984\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1422.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"1454.300781\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1551.712891\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1612.992188\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1652.201172\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1707.181641\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1770.560547\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"1832.083984\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1895.560547\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1927.347656\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1966.556641\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"2027.738281\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"2059.525391\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"2123.001953\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"2184.525391\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"2247.904297\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"2302.884766\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"2366.263672\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"2463.675781\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"2524.955078\"/>\n     <use xlink:href=\"#DejaVuSans-6b\" x=\"2566.068359\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_3\">\n   <g id=\"patch_13\">\n    <path d=\"M 78.254578 1131.124795 \nL 859.454578 1131.124795 \nL 859.454578 929.689366 \nL 78.254578 929.689366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_5\">\n    <g id=\"xtick_29\">\n     <g id=\"line2d_53\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_30\">\n     <g id=\"line2d_54\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_31\">\n     <g id=\"line2d_55\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_32\">\n     <g id=\"line2d_56\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_33\">\n     <g id=\"line2d_57\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_34\">\n     <g id=\"line2d_58\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_35\">\n     <g id=\"line2d_59\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_36\">\n     <g id=\"line2d_60\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_37\">\n     <g id=\"line2d_61\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"1131.124795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_38\">\n     <g id=\"line2d_62\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_39\">\n     <g id=\"line2d_63\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_40\">\n     <g id=\"line2d_64\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_41\">\n     <g id=\"line2d_65\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_42\">\n     <g id=\"line2d_66\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"1131.124795\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_6\">\n    <g id=\"ytick_17\">\n     <g id=\"line2d_67\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1093.633276\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 1.00 -->\n      <g transform=\"translate(41.813172 1098.230331)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_18\">\n     <g id=\"line2d_68\">\n      <defs>\n       <path id=\"meddc933ee5\" d=\"M 0 0 \nL -4 0 \n\" style=\"stroke: #000000\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#meddc933ee5\" x=\"78.254578\" y=\"1127.16165\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_19\">\n     <g id=\"line2d_69\">\n      <g>\n       <use xlink:href=\"#meddc933ee5\" x=\"78.254578\" y=\"1109.464192\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_20\">\n     <g id=\"line2d_70\">\n      <g>\n       <use xlink:href=\"#meddc933ee5\" x=\"78.254578\" y=\"989.484635\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- $\\mathdefault{2\\times10^{0}}$ -->\n      <g transform=\"translate(27.052578 994.08169)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-d7\" d=\"M 4488 3438 \nL 3059 2003 \nL 4488 575 \nL 4116 197 \nL 2681 1631 \nL 1247 197 \nL 878 575 \nL 2303 2003 \nL 878 3438 \nL 1247 3816 \nL 2681 2381 \nL 4116 3816 \nL 4488 3438 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-d7\" transform=\"translate(83.105469 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(186.376953 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(250 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(314.580078 39.046875)scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_25\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(20.307391 1093.788737)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_71\">\n    <path d=\"M 113.763669 1093.633276 \nL 114.473141 1094.244797 \nL 116.601558 1095.295139 \nL 117.311031 1094.453078 \nL 118.020503 1096.231153 \nL 118.729975 1094.769638 \nL 119.439448 1094.753211 \nL 121.567865 1093.667538 \nL 122.277337 1094.131485 \nL 122.98681 1095.237547 \nL 123.696282 1095.972172 \nL 124.405754 1095.475297 \nL 126.534171 1094.845825 \nL 127.243644 1097.509709 \nL 127.953116 1097.222346 \nL 128.662588 1101.534824 \nL 136.466784 1112.445833 \nL 137.176256 1108.768435 \nL 137.885729 1107.791018 \nL 138.595201 1105.564722 \nL 139.304673 1105.732039 \nL 141.433091 1105.818806 \nL 142.142563 1104.256263 \nL 142.852035 1103.437877 \nL 143.561508 1104.484862 \nL 144.27098 1103.464941 \nL 146.399397 1100.63692 \nL 147.108869 1101.950174 \nL 147.818342 1101.982793 \nL 148.527814 1099.211831 \nL 149.237286 1099.719466 \nL 151.365703 1101.660922 \nL 152.075176 1102.72668 \nL 152.784648 1103.122322 \nL 153.49412 1102.58666 \nL 154.203593 1107.356699 \nL 156.33201 1102.800949 \nL 157.041482 1102.102057 \nL 157.750954 1100.764473 \nL 158.460427 1097.212807 \nL 159.169899 1099.886781 \nL 161.298316 1104.832736 \nL 162.007789 1101.959504 \nL 162.717261 1103.813242 \nL 164.136206 1108.547682 \nL 166.264623 1114.27904 \nL 166.974095 1114.75007 \nL 168.39304 1121.372828 \nL 169.102512 1117.983444 \nL 171.230929 1121.968639 \nL 171.940401 1117.357797 \nL 172.649874 1113.935668 \nL 173.359346 1114.543784 \nL 174.068818 1113.865671 \nL 176.197235 1114.501233 \nL 176.906708 1114.53827 \nL 177.61618 1114.946645 \nL 178.325653 1112.843426 \nL 179.035125 1113.455759 \nL 181.873014 1110.784874 \nL 182.582487 1111.523404 \nL 183.291959 1111.047665 \nL 184.001431 1111.197384 \nL 186.129848 1111.782087 \nL 186.839321 1109.249896 \nL 187.548793 1110.399467 \nL 188.258265 1110.194521 \nL 188.967738 1107.9954 \nL 191.096155 1107.42319 \nL 191.805627 1109.313944 \nL 192.515099 1108.254424 \nL 193.224572 1108.607194 \nL 193.934044 1109.773759 \nL 196.062461 1108.201769 \nL 198.190878 1105.195714 \nL 202.447712 1105.094026 \nL 203.157185 1105.589187 \nL 203.866657 1104.613822 \nL 206.704546 1104.792539 \nL 207.414019 1104.891271 \nL 208.123491 1106.639857 \nL 208.832963 1107.428663 \nL 210.96138 1106.500017 \nL 211.670853 1105.260803 \nL 212.380325 1105.498843 \nL 213.089797 1105.989731 \nL 213.79927 1109.785391 \nL 215.927687 1109.034866 \nL 216.637159 1108.007906 \nL 217.346632 1108.724349 \nL 218.056104 1107.963893 \nL 218.765576 1108.124439 \nL 220.893993 1104.752828 \nL 221.603466 1103.940247 \nL 222.312938 1103.774367 \nL 223.02241 1104.073462 \nL 223.731883 1103.398258 \nL 225.8603 1102.713113 \nL 226.569772 1101.749608 \nL 227.279244 1102.770518 \nL 227.988717 1104.430862 \nL 228.698189 1104.034259 \nL 230.826606 1106.424024 \nL 231.536078 1104.301406 \nL 232.245551 1104.189777 \nL 232.955023 1103.782225 \nL 233.664495 1101.871198 \nL 235.792913 1102.079017 \nL 236.502385 1101.897883 \nL 237.211857 1100.973278 \nL 240.759219 1101.894422 \nL 241.468691 1101.04472 \nL 245.725525 1080.456134 \nL 246.434998 1080.116984 \nL 247.14447 1077.991229 \nL 247.853942 1077.463165 \nL 248.563415 1081.454998 \nL 250.691832 1079.746257 \nL 251.401304 1081.623145 \nL 252.110776 1083.168903 \nL 252.820249 1090.211674 \nL 253.529721 1089.081865 \nL 255.658138 1084.345587 \nL 256.367611 1084.395883 \nL 257.077083 1084.188213 \nL 257.786555 1084.519559 \nL 258.496028 1090.389484 \nL 260.624445 1090.154401 \nL 261.333917 1089.081889 \nL 262.043389 1086.394478 \nL 262.752862 1086.945178 \nL 263.462334 1086.118968 \nL 265.590751 1084.657294 \nL 266.300223 1083.242875 \nL 267.009696 1084.144901 \nL 267.719168 1084.14988 \nL 268.42864 1085.454191 \nL 270.557057 1084.444092 \nL 271.26653 1085.496602 \nL 271.976002 1086.100444 \nL 272.685475 1086.465852 \nL 273.394947 1084.318211 \nL 275.523364 1080.691774 \nL 276.232836 1080.759471 \nL 276.942309 1083.445989 \nL 277.651781 1085.417945 \nL 278.361253 1084.49136 \nL 280.48967 1083.852595 \nL 281.199143 1083.301621 \nL 281.908615 1084.804416 \nL 282.618087 1084.214465 \nL 283.32756 1080.710079 \nL 285.455977 1081.809196 \nL 286.165449 1081.306421 \nL 286.874921 1081.655775 \nL 287.584394 1082.235605 \nL 288.293866 1083.375581 \nL 290.422283 1085.930032 \nL 291.131755 1084.254253 \nL 291.841228 1086.750767 \nL 292.5507 1086.296446 \nL 293.260173 1085.373596 \nL 295.38859 1084.060891 \nL 296.098062 1082.993276 \nL 296.807534 1083.995547 \nL 297.517007 1085.41088 \nL 298.226479 1081.63449 \nL 300.354896 1083.267374 \nL 301.064368 1085.142679 \nL 301.773841 1084.903066 \nL 302.483313 1087.541671 \nL 303.192785 1087.026216 \nL 305.321202 1086.065138 \nL 306.740147 1086.903383 \nL 313.125398 1084.393935 \nL 315.253815 1079.845135 \nL 315.963288 1079.889128 \nL 316.67276 1080.66283 \nL 317.382232 1080.577968 \nL 318.091705 1080.18773 \nL 320.220122 1081.341737 \nL 320.929594 1080.930392 \nL 321.639066 1080.309769 \nL 322.348539 1080.661395 \nL 323.058011 1081.687029 \nL 325.8959 1084.063746 \nL 326.605373 1083.193082 \nL 327.314845 1082.685644 \nL 328.024317 1084.690164 \nL 330.152735 1085.355206 \nL 330.862207 1083.453925 \nL 331.571679 1082.335757 \nL 332.281152 1080.662603 \nL 332.990624 1081.126349 \nL 335.119041 1078.503307 \nL 335.828513 1078.597161 \nL 336.537986 1078.813334 \nL 337.247458 1079.425738 \nL 337.95693 1082.060048 \nL 340.085347 1080.323765 \nL 340.79482 1080.227506 \nL 341.504292 1079.882399 \nL 342.213764 1078.863371 \nL 342.923237 1078.782381 \nL 345.051654 1076.255173 \nL 346.470598 1078.414704 \nL 347.180071 1077.300937 \nL 347.889543 1075.010847 \nL 350.01796 1076.271923 \nL 350.727433 1072.652161 \nL 352.146377 1073.381077 \nL 352.85585 1073.181264 \nL 355.693739 1074.993742 \nL 356.403211 1076.310512 \nL 357.112684 1076.722277 \nL 357.822156 1078.082742 \nL 359.950573 1076.343438 \nL 360.660045 1076.297443 \nL 361.369518 1075.581139 \nL 362.07899 1073.265326 \nL 362.788462 1074.611316 \nL 364.916879 1074.000583 \nL 365.626352 1076.207642 \nL 366.335824 1075.185831 \nL 367.045296 1075.414427 \nL 367.754769 1074.418185 \nL 369.883186 1073.933415 \nL 370.592658 1074.210268 \nL 372.011603 1069.033794 \nL 374.849492 1068.921565 \nL 375.558965 1067.280755 \nL 376.268437 1065.122699 \nL 376.977909 1062.277864 \nL 377.687382 1063.059182 \nL 379.815799 1063.527526 \nL 380.525271 1058.457964 \nL 381.234743 1059.728638 \nL 381.944216 1062.153441 \nL 382.653688 1061.889125 \nL 384.782105 1060.655946 \nL 385.491577 1062.253225 \nL 386.20105 1062.018296 \nL 386.910522 1060.630276 \nL 387.619995 1060.773236 \nL 389.748412 1058.765055 \nL 390.457884 1062.072012 \nL 391.167356 1061.875992 \nL 391.876829 1065.187626 \nL 392.586301 1066.066634 \nL 394.714718 1064.732206 \nL 395.42419 1063.728952 \nL 396.133663 1063.559633 \nL 396.843135 1062.532644 \nL 397.552607 1060.993256 \nL 399.681024 1059.061448 \nL 400.390497 1056.67204 \nL 401.099969 1053.821692 \nL 407.48522 1054.347483 \nL 409.613637 1059.393854 \nL 410.32311 1058.781665 \nL 411.032582 1062.380392 \nL 411.742054 1060.592304 \nL 412.451527 1064.312154 \nL 414.579944 1063.077015 \nL 415.289416 1065.843161 \nL 415.998888 1061.909657 \nL 416.708361 1066.252339 \nL 417.417833 1067.063959 \nL 419.54625 1071.833489 \nL 420.255722 1074.541113 \nL 420.965195 1073.583522 \nL 421.674667 1069.667976 \nL 422.384139 1069.366832 \nL 424.512557 1072.10931 \nL 425.222029 1070.755327 \nL 425.931501 1071.103512 \nL 426.640974 1070.486711 \nL 427.350446 1074.438116 \nL 429.478863 1073.31258 \nL 430.188335 1074.252454 \nL 430.897808 1076.418186 \nL 431.60728 1076.512265 \nL 432.316752 1073.682423 \nL 434.445169 1073.342992 \nL 435.154642 1071.673272 \nL 435.864114 1073.272564 \nL 436.573586 1071.446354 \nL 437.283059 1070.02241 \nL 440.120948 1070.941438 \nL 440.83042 1072.463937 \nL 441.539893 1071.850057 \nL 442.249365 1074.348713 \nL 444.377782 1075.941083 \nL 445.087255 1076.616993 \nL 445.796727 1076.282539 \nL 446.506199 1077.923422 \nL 447.215672 1077.197827 \nL 449.344089 1074.379301 \nL 450.053561 1074.519272 \nL 450.763033 1074.263778 \nL 451.472506 1075.493988 \nL 452.181978 1073.92554 \nL 454.310395 1076.348049 \nL 455.019867 1075.974084 \nL 455.72934 1076.115181 \nL 456.438812 1074.216232 \nL 457.148284 1075.332051 \nL 461.405118 1077.117917 \nL 462.114591 1079.030167 \nL 464.243008 1079.309444 \nL 464.95248 1077.651296 \nL 465.661953 1077.208395 \nL 466.371425 1078.696254 \nL 467.080897 1074.822941 \nL 469.209314 1073.249518 \nL 469.918787 1073.343616 \nL 470.628259 1074.461773 \nL 471.337731 1073.992512 \nL 472.047204 1075.733954 \nL 474.175621 1075.050019 \nL 474.885093 1069.00685 \nL 475.594565 1068.352261 \nL 476.304038 1068.034113 \nL 477.01351 1068.265766 \nL 479.141927 1068.638702 \nL 479.851399 1068.610759 \nL 481.270344 1071.090031 \nL 481.979817 1070.191264 \nL 484.108234 1070.674171 \nL 484.817706 1071.545629 \nL 485.527178 1071.241736 \nL 486.236651 1070.400286 \nL 486.946123 1071.69285 \nL 489.784012 1073.727548 \nL 490.493485 1075.543091 \nL 491.202957 1075.745239 \nL 491.912429 1076.915532 \nL 494.040846 1077.933971 \nL 494.750319 1076.476135 \nL 495.459791 1076.188652 \nL 496.169263 1075.645628 \nL 496.878736 1073.457392 \nL 499.007153 1074.065378 \nL 499.716625 1075.696355 \nL 500.426098 1075.011294 \nL 501.13557 1073.447595 \nL 501.845042 1078.945207 \nL 504.682932 1079.075674 \nL 505.392404 1078.234781 \nL 506.101876 1080.495358 \nL 506.811349 1081.015669 \nL 509.649238 1079.674163 \nL 510.35871 1082.011855 \nL 511.068183 1078.810722 \nL 511.777655 1080.644923 \nL 513.906072 1079.956869 \nL 514.615544 1080.256188 \nL 515.325017 1079.816962 \nL 516.034489 1079.630999 \nL 516.743961 1081.20117 \nL 518.872379 1087.091691 \nL 519.581851 1091.915302 \nL 521.000796 1089.227899 \nL 521.710268 1091.605882 \nL 523.838685 1087.895555 \nL 524.548157 1087.303331 \nL 525.25763 1086.871559 \nL 525.967102 1087.138733 \nL 526.676574 1088.620142 \nL 528.804991 1086.773838 \nL 529.514464 1084.311942 \nL 530.223936 1085.508083 \nL 530.933408 1087.19674 \nL 531.642881 1087.582728 \nL 533.771298 1087.359434 \nL 534.48077 1090.789983 \nL 535.190242 1088.862206 \nL 535.899715 1091.052749 \nL 536.609187 1094.514712 \nL 538.737604 1093.193797 \nL 539.447077 1090.890658 \nL 540.156549 1090.317283 \nL 540.866021 1093.730616 \nL 541.575494 1092.07527 \nL 543.703911 1092.573897 \nL 544.413383 1093.33095 \nL 545.122855 1090.068616 \nL 545.832328 1089.970848 \nL 546.5418 1089.554791 \nL 548.670217 1087.893033 \nL 549.379689 1086.178405 \nL 550.089162 1087.796736 \nL 550.798634 1088.217166 \nL 551.508106 1085.980903 \nL 553.636523 1086.456962 \nL 554.345996 1088.970141 \nL 555.055468 1090.944836 \nL 555.76494 1091.808987 \nL 556.474413 1090.216568 \nL 560.021775 1092.109524 \nL 560.731247 1091.845871 \nL 563.569136 1088.419101 \nL 564.278609 1087.895101 \nL 564.988081 1088.454265 \nL 565.697553 1088.559289 \nL 573.501749 1084.87241 \nL 574.211221 1085.655321 \nL 574.920694 1084.124228 \nL 575.630166 1085.134731 \nL 576.339639 1084.029759 \nL 578.468056 1087.032989 \nL 579.177528 1085.780375 \nL 579.887 1085.85744 \nL 580.596473 1084.774541 \nL 581.305945 1082.971208 \nL 583.434362 1083.235186 \nL 584.143834 1084.248677 \nL 584.853307 1086.222626 \nL 585.562779 1086.569439 \nL 586.272251 1085.29298 \nL 588.400668 1086.046039 \nL 589.110141 1087.854305 \nL 589.819613 1089.291432 \nL 590.529085 1088.077226 \nL 591.238558 1088.345329 \nL 593.366975 1088.593151 \nL 594.076447 1089.03156 \nL 594.78592 1089.814019 \nL 595.495392 1086.859142 \nL 596.204864 1087.45617 \nL 599.042754 1087.380374 \nL 599.752226 1088.006408 \nL 600.461698 1089.673271 \nL 601.171171 1087.813056 \nL 603.299588 1087.848429 \nL 604.00906 1087.288003 \nL 604.718532 1086.930481 \nL 605.428005 1087.572698 \nL 606.137477 1089.012694 \nL 608.265894 1089.02728 \nL 608.975366 1090.053782 \nL 609.684839 1089.340203 \nL 610.394311 1088.847137 \nL 611.103783 1087.415389 \nL 613.232201 1087.102284 \nL 613.941673 1085.880462 \nL 615.360618 1081.07875 \nL 616.07009 1081.37208 \nL 618.198507 1080.815861 \nL 618.907979 1081.51251 \nL 619.617452 1082.932605 \nL 620.326924 1082.395922 \nL 621.036396 1084.758199 \nL 623.164813 1085.841127 \nL 623.874286 1085.027303 \nL 624.583758 1085.600403 \nL 625.29323 1084.378828 \nL 626.002703 1084.23957 \nL 628.13112 1084.779371 \nL 628.840592 1083.639589 \nL 629.550064 1086.51218 \nL 630.259537 1085.544074 \nL 630.969009 1084.968113 \nL 633.806899 1085.43945 \nL 634.516371 1085.890624 \nL 635.225843 1087.931065 \nL 635.935316 1087.329373 \nL 638.063733 1086.731585 \nL 638.773205 1087.737268 \nL 639.482677 1086.72268 \nL 640.901622 1091.307627 \nL 643.030039 1090.89399 \nL 643.739511 1089.004845 \nL 644.448984 1089.02051 \nL 645.158456 1086.843766 \nL 645.867928 1087.540774 \nL 647.996345 1087.961059 \nL 648.705818 1091.025304 \nL 649.41529 1090.133327 \nL 650.124762 1092.258706 \nL 650.834235 1095.433571 \nL 657.928958 1092.498704 \nL 658.638431 1092.390452 \nL 659.347903 1091.28282 \nL 660.057375 1091.017488 \nL 660.766848 1091.12267 \nL 662.895265 1092.994698 \nL 664.314209 1091.449532 \nL 665.023682 1091.301318 \nL 665.733154 1090.173835 \nL 667.861571 1091.029322 \nL 668.571043 1093.075661 \nL 669.280516 1092.31657 \nL 669.989988 1095.157327 \nL 670.699461 1094.376259 \nL 672.827878 1094.122911 \nL 673.53735 1091.948237 \nL 674.246822 1092.837773 \nL 674.956295 1093.32948 \nL 675.665767 1095.022756 \nL 677.794184 1099.388855 \nL 678.503656 1101.500473 \nL 679.213129 1102.837547 \nL 679.922601 1101.485239 \nL 680.632073 1101.371423 \nL 682.76049 1105.723272 \nL 683.469963 1113.78735 \nL 684.179435 1106.999851 \nL 684.888907 1104.393978 \nL 685.59838 1102.527386 \nL 687.726797 1103.618514 \nL 688.436269 1103.169234 \nL 689.145742 1102.356107 \nL 689.855214 1103.021712 \nL 690.564686 1105.483698 \nL 692.693103 1105.654532 \nL 693.402576 1106.236458 \nL 694.112048 1102.408537 \nL 694.82152 1103.269834 \nL 695.530993 1100.984999 \nL 699.078354 1101.601187 \nL 699.787827 1103.080467 \nL 700.497299 1101.894016 \nL 702.625716 1106.013162 \nL 703.335188 1103.506783 \nL 704.044661 1104.129987 \nL 704.754133 1101.734631 \nL 705.463605 1101.632967 \nL 707.592022 1103.84656 \nL 709.010967 1106.596455 \nL 709.72044 1108.614278 \nL 710.429912 1107.725437 \nL 712.558329 1114.871975 \nL 713.267801 1115.005558 \nL 713.977274 1112.036073 \nL 715.396218 1108.195571 \nL 719.653052 1108.431787 \nL 720.362525 1112.850348 \nL 722.490942 1114.217167 \nL 723.909886 1111.668812 \nL 724.619359 1112.739412 \nL 725.328831 1111.285365 \nL 727.457248 1112.814752 \nL 728.166721 1110.821192 \nL 728.876193 1111.433548 \nL 729.585665 1111.487349 \nL 730.295138 1108.056053 \nL 732.423555 1109.421094 \nL 733.133027 1112.055196 \nL 733.842499 1111.549137 \nL 734.551972 1111.468002 \nL 735.261444 1110.476481 \nL 737.389861 1109.642496 \nL 738.099333 1107.773953 \nL 738.808806 1108.585342 \nL 739.518278 1109.002182 \nL 742.356167 1107.111435 \nL 743.06564 1105.990476 \nL 743.775112 1104.284764 \nL 744.484584 1104.854007 \nL 745.194057 1103.23084 \nL 747.322474 1106.100626 \nL 748.741419 1101.9712 \nL 749.450891 1103.658601 \nL 750.160363 1101.345021 \nL 752.28878 1101.923613 \nL 752.998253 1101.843501 \nL 753.707725 1103.609204 \nL 755.12667 1099.38494 \nL 757.255087 1097.418166 \nL 757.964559 1096.153974 \nL 758.674031 1097.653262 \nL 759.383504 1095.218396 \nL 760.092976 1095.864788 \nL 762.930865 1095.52755 \nL 763.640338 1098.279103 \nL 764.34981 1098.656617 \nL 765.059283 1098.450759 \nL 767.1877 1101.033392 \nL 767.897172 1102.073206 \nL 768.606644 1102.470172 \nL 769.316117 1103.452765 \nL 770.025589 1106.382414 \nL 772.154006 1104.319836 \nL 772.863478 1105.001835 \nL 773.572951 1104.558134 \nL 774.282423 1106.52706 \nL 774.991895 1105.904669 \nL 777.120312 1106.495383 \nL 777.829785 1105.577833 \nL 778.539257 1106.884485 \nL 779.248729 1107.034021 \nL 779.958202 1108.893862 \nL 782.086619 1109.467843 \nL 782.796091 1112.244192 \nL 783.505564 1113.35045 \nL 784.924508 1109.865227 \nL 787.052925 1110.580633 \nL 787.762398 1110.422313 \nL 788.47187 1112.232885 \nL 789.181342 1109.17747 \nL 789.890815 1108.648689 \nL 792.019232 1109.414711 \nL 792.728704 1110.140291 \nL 793.438176 1109.242728 \nL 794.147649 1110.68203 \nL 794.857121 1111.154556 \nL 796.985538 1110.841425 \nL 797.69501 1111.974232 \nL 798.404483 1113.496501 \nL 799.113955 1111.049412 \nL 799.823427 1111.102185 \nL 802.661317 1112.469686 \nL 803.370789 1110.546571 \nL 804.080262 1112.153777 \nL 804.789734 1113.320499 \nL 806.918151 1114.070392 \nL 807.627623 1112.588883 \nL 808.337096 1113.352534 \nL 809.046568 1113.48607 \nL 809.75604 1110.776183 \nL 812.59393 1110.141708 \nL 813.303402 1111.438993 \nL 814.012874 1111.528765 \nL 814.722347 1115.173502 \nL 816.850764 1115.086417 \nL 817.560236 1115.406676 \nL 818.979181 1117.928918 \nL 819.688653 1117.903845 \nL 821.81707 1118.758104 \nL 822.526543 1117.156532 \nL 823.236015 1118.925886 \nL 823.945487 1118.925886 \nL 823.945487 1118.925886 \n\" clip-path=\"url(#pbcac90addc)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_72\">\n    <path d=\"M 113.763669 1093.633276 \nL 114.473141 1093.771606 \nL 116.601558 1093.77977 \nL 117.311031 1093.38408 \nL 118.020503 1094.774258 \nL 118.729975 1093.046017 \nL 119.439448 1093.254853 \nL 121.567865 1091.505185 \nL 122.277337 1091.962899 \nL 122.98681 1093.199365 \nL 123.696282 1093.612326 \nL 124.405754 1091.079607 \nL 126.534171 1091.379269 \nL 127.243644 1092.700951 \nL 127.953116 1092.271703 \nL 128.662588 1096.582335 \nL 136.466784 1106.958932 \nL 137.176256 1104.055954 \nL 137.885729 1099.763913 \nL 138.595201 1097.723155 \nL 139.304673 1097.429825 \nL 141.433091 1096.402086 \nL 142.142563 1095.499577 \nL 142.852035 1093.098985 \nL 143.561508 1092.060082 \nL 144.27098 1091.560198 \nL 146.399397 1087.973559 \nL 147.108869 1087.997328 \nL 147.818342 1089.478216 \nL 148.527814 1087.196403 \nL 149.237286 1086.811122 \nL 151.365703 1087.727554 \nL 152.075176 1086.110132 \nL 152.784648 1088.141267 \nL 153.49412 1087.608006 \nL 154.203593 1093.152368 \nL 156.33201 1090.335832 \nL 157.041482 1088.807584 \nL 157.750954 1088.203146 \nL 158.460427 1085.821183 \nL 161.298316 1094.124053 \nL 162.007789 1091.102209 \nL 162.717261 1091.66156 \nL 163.426733 1095.334559 \nL 164.136206 1097.204548 \nL 166.264623 1103.626633 \nL 166.974095 1103.56681 \nL 167.683567 1105.710987 \nL 168.39304 1107.145517 \nL 169.102512 1105.450033 \nL 171.230929 1110.853742 \nL 171.940401 1105.651082 \nL 172.649874 1102.822667 \nL 173.359346 1103.529038 \nL 174.068818 1102.067572 \nL 176.197235 1103.486971 \nL 176.906708 1102.610477 \nL 177.61618 1103.024345 \nL 178.325653 1100.140571 \nL 179.035125 1100.295397 \nL 181.873014 1097.128447 \nL 183.291959 1098.386024 \nL 184.001431 1100.256454 \nL 186.129848 1100.987592 \nL 186.839321 1097.166732 \nL 187.548793 1098.331159 \nL 188.258265 1097.465212 \nL 188.967738 1095.110241 \nL 191.096155 1094.713153 \nL 191.805627 1096.211922 \nL 192.515099 1094.739712 \nL 193.224572 1094.593146 \nL 193.934044 1096.587887 \nL 196.062461 1096.70588 \nL 196.771933 1093.833365 \nL 197.481406 1092.945655 \nL 198.190878 1090.419202 \nL 202.447712 1090.770763 \nL 203.157185 1091.54122 \nL 203.866657 1090.869351 \nL 205.995074 1092.074614 \nL 206.704546 1091.337292 \nL 207.414019 1091.945656 \nL 208.123491 1094.329289 \nL 208.832963 1095.694079 \nL 210.96138 1094.300986 \nL 211.670853 1091.743657 \nL 212.380325 1092.73158 \nL 213.089797 1095.589562 \nL 213.79927 1099.898618 \nL 215.927687 1099.031227 \nL 216.637159 1097.12834 \nL 217.346632 1098.298362 \nL 218.056104 1098.596269 \nL 218.765576 1097.903849 \nL 220.893993 1093.343111 \nL 221.603466 1093.096768 \nL 222.312938 1092.158091 \nL 223.02241 1093.030734 \nL 223.731883 1092.43895 \nL 226.569772 1088.482969 \nL 227.279244 1089.178464 \nL 227.988717 1089.62238 \nL 228.698189 1090.941513 \nL 230.826606 1092.598094 \nL 231.536078 1090.386536 \nL 232.245551 1090.691772 \nL 233.664495 1088.226148 \nL 236.502385 1085.697904 \nL 237.211857 1082.796624 \nL 240.759219 1082.696519 \nL 241.468691 1081.607837 \nL 242.178164 1075.693968 \nL 242.887636 1071.678803 \nL 243.597108 1068.307243 \nL 245.725525 1060.364856 \nL 246.434998 1060.720868 \nL 247.14447 1056.475945 \nL 247.853942 1052.917959 \nL 248.563415 1057.295831 \nL 250.691832 1053.165747 \nL 251.401304 1053.718536 \nL 252.110776 1052.78323 \nL 252.820249 1062.149358 \nL 253.529721 1059.82186 \nL 256.367611 1048.53506 \nL 257.077083 1047.443473 \nL 257.786555 1040.25022 \nL 258.496028 1047.894101 \nL 260.624445 1044.383964 \nL 261.333917 1045.631954 \nL 262.752862 1037.380759 \nL 263.462334 1036.533786 \nL 265.590751 1034.763859 \nL 266.300223 1037.05474 \nL 267.009696 1035.139229 \nL 267.719168 1037.865311 \nL 268.42864 1036.334795 \nL 270.557057 1034.757304 \nL 271.976002 1044.342013 \nL 272.685475 1044.128286 \nL 273.394947 1041.536344 \nL 276.232836 1036.587977 \nL 277.651781 1042.813525 \nL 278.361253 1040.335043 \nL 280.48967 1036.649015 \nL 281.199143 1037.842628 \nL 281.908615 1040.717945 \nL 282.618087 1037.888176 \nL 283.32756 1033.974391 \nL 285.455977 1031.122739 \nL 286.165449 1027.735034 \nL 286.874921 1026.177207 \nL 287.584394 1027.888113 \nL 288.293866 1031.726792 \nL 290.422283 1033.270721 \nL 291.131755 1031.623148 \nL 291.841228 1035.295492 \nL 292.5507 1035.310239 \nL 293.260173 1032.317159 \nL 295.38859 1031.47783 \nL 296.098062 1030.978526 \nL 296.807534 1031.001945 \nL 297.517007 1032.064649 \nL 298.226479 1029.920427 \nL 300.354896 1031.46978 \nL 301.064368 1033.999721 \nL 301.773841 1031.131911 \nL 302.483313 1036.046054 \nL 303.192785 1035.773799 \nL 305.321202 1031.76893 \nL 306.030675 1030.915361 \nL 306.740147 1031.930122 \nL 313.125398 1026.00745 \nL 315.963288 1017.261279 \nL 316.67276 1017.240865 \nL 317.382232 1020.431394 \nL 318.091705 1022.01053 \nL 320.220122 1025.796828 \nL 320.929594 1023.615969 \nL 321.639066 1023.911506 \nL 322.348539 1024.73659 \nL 323.058011 1026.323134 \nL 325.186428 1025.103009 \nL 326.605373 1021.211015 \nL 327.314845 1019.599641 \nL 330.152735 1018.418773 \nL 330.862207 1017.243039 \nL 331.571679 1019.260752 \nL 332.281152 1012.570339 \nL 332.990624 1015.207502 \nL 335.828513 1008.261348 \nL 336.537986 1012.225664 \nL 337.247458 1013.519158 \nL 337.95693 1016.751028 \nL 340.085347 1014.939849 \nL 340.79482 1015.141659 \nL 341.504292 1015.05579 \nL 342.213764 1012.473268 \nL 342.923237 1006.771098 \nL 345.051654 1003.537834 \nL 345.761126 1005.308379 \nL 346.470598 1007.891215 \nL 347.180071 1007.718826 \nL 347.889543 1006.990397 \nL 350.01796 1007.793033 \nL 350.727433 1004.978057 \nL 351.436905 1006.099736 \nL 352.146377 1007.513606 \nL 352.85585 1007.152613 \nL 355.693739 1009.718431 \nL 356.403211 1011.337378 \nL 357.112684 1009.297697 \nL 357.822156 1011.73167 \nL 359.950573 1011.234473 \nL 360.660045 1008.770312 \nL 361.369518 1006.835836 \nL 362.07899 1001.376249 \nL 362.788462 998.876507 \nL 364.916879 996.548852 \nL 365.626352 1001.700191 \nL 366.335824 997.834077 \nL 367.045296 997.837748 \nL 367.754769 992.606606 \nL 369.883186 989.222495 \nL 370.592658 991.903899 \nL 371.302131 990.252007 \nL 372.011603 986.291017 \nL 374.849492 979.548943 \nL 375.558965 976.461321 \nL 376.268437 975.522698 \nL 376.977909 970.938123 \nL 377.687382 969.928377 \nL 379.815799 970.722342 \nL 380.525271 968.241009 \nL 381.234743 964.224407 \nL 381.944216 971.992589 \nL 382.653688 974.707722 \nL 384.782105 970.964155 \nL 385.491577 977.243274 \nL 386.20105 975.322595 \nL 386.910522 971.656809 \nL 387.619995 969.054567 \nL 389.748412 968.858166 \nL 390.457884 971.655465 \nL 391.167356 969.482045 \nL 391.876829 977.286152 \nL 392.586301 981.969533 \nL 394.714718 982.55423 \nL 395.42419 977.440499 \nL 396.133663 977.293685 \nL 396.843135 980.548364 \nL 397.552607 981.406416 \nL 399.681024 978.92875 \nL 400.390497 972.159805 \nL 401.099969 967.521191 \nL 406.775748 963.298967 \nL 407.48522 964.845002 \nL 409.613637 967.042727 \nL 410.32311 968.148705 \nL 411.032582 975.385195 \nL 411.742054 974.375432 \nL 412.451527 980.147467 \nL 414.579944 977.326503 \nL 415.289416 982.564268 \nL 415.998888 981.168785 \nL 416.708361 990.017133 \nL 419.54625 1001.333981 \nL 420.255722 1002.999016 \nL 420.965195 1002.318665 \nL 421.674667 996.029958 \nL 422.384139 995.367322 \nL 424.512557 997.47555 \nL 425.222029 996.218145 \nL 426.640974 992.488299 \nL 427.350446 996.545276 \nL 429.478863 995.149003 \nL 430.188335 999.0921 \nL 430.897808 1005.145625 \nL 431.60728 1003.183965 \nL 432.316752 996.294762 \nL 434.445169 996.94826 \nL 435.864114 992.904661 \nL 436.573586 990.291913 \nL 437.283059 988.609731 \nL 440.120948 987.100416 \nL 440.83042 985.258781 \nL 441.539893 985.103299 \nL 442.249365 985.368473 \nL 444.377782 990.293318 \nL 445.087255 993.303423 \nL 445.796727 992.088763 \nL 446.506199 992.136144 \nL 447.215672 990.648425 \nL 449.344089 987.689942 \nL 450.053561 987.321069 \nL 450.763033 982.603465 \nL 451.472506 980.257515 \nL 452.181978 979.10216 \nL 454.310395 978.467993 \nL 455.019867 974.89716 \nL 455.72934 974.699949 \nL 456.438812 971.01218 \nL 457.148284 972.253518 \nL 461.405118 968.752866 \nL 462.114591 968.655359 \nL 464.243008 965.54299 \nL 464.95248 970.447519 \nL 465.661953 967.851215 \nL 466.371425 970.69245 \nL 467.080897 967.68759 \nL 469.209314 961.071204 \nL 469.918787 959.235654 \nL 470.628259 958.035758 \nL 471.337731 962.766266 \nL 472.047204 959.774972 \nL 474.175621 961.437021 \nL 474.885093 958.199415 \nL 475.594565 959.739902 \nL 476.304038 959.965205 \nL 477.01351 957.126133 \nL 479.141927 955.675251 \nL 479.851399 954.007075 \nL 480.560872 957.867534 \nL 481.270344 959.874497 \nL 481.979817 959.393686 \nL 484.108234 956.873036 \nL 484.817706 959.03554 \nL 485.527178 956.673117 \nL 486.236651 950.53816 \nL 486.946123 948.519599 \nL 489.784012 949.955712 \nL 490.493485 955.441139 \nL 491.202957 950.391677 \nL 491.912429 948.96514 \nL 494.040846 950.028165 \nL 494.750319 947.551686 \nL 495.459791 949.234303 \nL 496.169263 948.466759 \nL 496.878736 943.083778 \nL 499.007153 941.178893 \nL 499.716625 941.404436 \nL 500.426098 938.845522 \nL 501.13557 939.081243 \nL 501.845042 941.510175 \nL 503.973459 951.017964 \nL 504.682932 951.928716 \nL 505.392404 946.714049 \nL 506.101876 948.777705 \nL 506.811349 954.927447 \nL 508.939766 953.044019 \nL 509.649238 947.877504 \nL 510.35871 966.045772 \nL 511.068183 965.477936 \nL 511.777655 967.430136 \nL 513.906072 963.129034 \nL 514.615544 964.340562 \nL 515.325017 961.516653 \nL 516.034489 960.621822 \nL 516.743961 965.013267 \nL 518.872379 968.810439 \nL 519.581851 974.348789 \nL 520.291323 974.533127 \nL 521.000796 969.723957 \nL 521.710268 968.169494 \nL 523.838685 962.291594 \nL 524.548157 958.955136 \nL 525.25763 954.824851 \nL 525.967102 955.168014 \nL 526.676574 955.261459 \nL 528.804991 956.144425 \nL 529.514464 955.12691 \nL 530.223936 955.33108 \nL 530.933408 952.593383 \nL 531.642881 954.307398 \nL 533.771298 956.335765 \nL 534.48077 958.625782 \nL 535.190242 957.059628 \nL 535.899715 958.284403 \nL 536.609187 963.921912 \nL 538.737604 957.360663 \nL 539.447077 956.523629 \nL 540.156549 953.520542 \nL 540.866021 954.431804 \nL 541.575494 953.051733 \nL 543.703911 950.498633 \nL 544.413383 951.295793 \nL 545.122855 952.415953 \nL 545.832328 952.385948 \nL 546.5418 955.057915 \nL 548.670217 953.935801 \nL 549.379689 949.472222 \nL 550.089162 948.442241 \nL 550.798634 949.702414 \nL 551.508106 944.219179 \nL 553.636523 940.117712 \nL 555.055468 945.749497 \nL 555.76494 948.959875 \nL 556.474413 946.193324 \nL 560.021775 945.551787 \nL 560.731247 944.793481 \nL 561.440719 944.307853 \nL 563.569136 950.055967 \nL 564.278609 952.934171 \nL 564.988081 958.006336 \nL 565.697553 955.713635 \nL 573.501749 955.489401 \nL 574.211221 956.136958 \nL 574.920694 954.379269 \nL 575.630166 956.506266 \nL 576.339639 957.732775 \nL 578.468056 957.776237 \nL 579.177528 955.39867 \nL 579.887 957.447656 \nL 580.596473 956.969925 \nL 581.305945 957.236506 \nL 583.434362 955.001188 \nL 584.143834 955.711049 \nL 584.853307 957.33435 \nL 585.562779 959.672314 \nL 586.272251 956.668783 \nL 588.400668 959.667812 \nL 589.110141 962.38631 \nL 589.819613 962.498923 \nL 590.529085 961.675118 \nL 591.238558 964.131682 \nL 593.366975 963.457708 \nL 594.076447 963.932479 \nL 594.78592 965.96544 \nL 595.495392 965.026427 \nL 596.204864 964.904072 \nL 598.333281 967.479688 \nL 599.042754 966.425598 \nL 599.752226 966.260437 \nL 600.461698 966.758601 \nL 601.171171 966.132751 \nL 603.299588 964.599952 \nL 604.00906 963.477499 \nL 604.718532 964.634645 \nL 605.428005 965.111734 \nL 606.137477 965.289868 \nL 608.265894 962.286481 \nL 608.975366 959.696889 \nL 609.684839 960.033474 \nL 610.394311 958.720998 \nL 611.103783 959.844738 \nL 613.232201 958.214272 \nL 613.941673 957.16099 \nL 614.651145 954.85796 \nL 615.360618 953.704042 \nL 616.07009 951.523294 \nL 618.198507 951.662305 \nL 618.907979 955.613354 \nL 619.617452 955.119685 \nL 620.326924 954.107641 \nL 621.036396 955.859884 \nL 623.164813 955.95638 \nL 623.874286 954.894901 \nL 624.583758 957.365258 \nL 625.29323 955.765729 \nL 626.002703 959.908576 \nL 628.13112 960.211159 \nL 628.840592 956.963467 \nL 629.550064 959.375871 \nL 630.259537 961.231338 \nL 630.969009 957.80247 \nL 633.806899 957.705349 \nL 634.516371 960.49431 \nL 635.225843 962.811693 \nL 635.935316 962.487544 \nL 638.063733 963.691646 \nL 638.773205 965.071227 \nL 639.482677 962.440602 \nL 640.19215 965.125178 \nL 640.901622 965.527252 \nL 643.030039 967.91575 \nL 643.739511 965.33628 \nL 644.448984 967.848612 \nL 645.158456 968.767442 \nL 645.867928 970.62566 \nL 647.996345 969.183654 \nL 648.705818 973.841334 \nL 649.41529 971.261286 \nL 650.834235 978.188815 \nL 657.928958 972.452302 \nL 658.638431 971.729176 \nL 659.347903 970.716415 \nL 660.057375 970.623843 \nL 660.766848 971.570944 \nL 662.895265 974.884314 \nL 663.604737 973.532584 \nL 665.023682 970.279413 \nL 665.733154 969.821588 \nL 667.861571 970.317324 \nL 668.571043 970.242701 \nL 669.280516 968.406717 \nL 669.989988 971.363774 \nL 670.699461 970.607893 \nL 673.53735 964.593093 \nL 674.246822 963.748622 \nL 674.956295 962.225867 \nL 675.665767 963.630737 \nL 677.794184 967.391628 \nL 678.503656 970.745003 \nL 679.213129 972.053009 \nL 680.632073 966.652546 \nL 682.76049 972.030852 \nL 683.469963 979.109747 \nL 684.179435 971.996021 \nL 684.888907 972.250912 \nL 685.59838 970.656421 \nL 687.726797 969.929096 \nL 688.436269 969.309082 \nL 689.145742 970.379191 \nL 689.855214 970.717735 \nL 690.564686 974.562817 \nL 692.693103 973.324583 \nL 693.402576 972.007799 \nL 694.112048 969.549331 \nL 694.82152 973.237624 \nL 695.530993 967.807496 \nL 699.078354 971.844485 \nL 699.787827 974.491345 \nL 700.497299 974.309917 \nL 702.625716 979.444529 \nL 703.335188 976.173068 \nL 704.044661 975.397601 \nL 704.754133 972.288767 \nL 705.463605 975.401475 \nL 708.301495 977.432401 \nL 709.010967 979.333247 \nL 709.72044 983.511661 \nL 710.429912 982.999677 \nL 712.558329 992.316975 \nL 713.267801 992.90716 \nL 713.977274 987.27919 \nL 714.686746 985.860278 \nL 715.396218 982.567299 \nL 719.653052 981.462114 \nL 720.362525 987.855406 \nL 722.490942 988.735336 \nL 723.200414 988.64646 \nL 723.909886 987.683382 \nL 724.619359 988.573601 \nL 725.328831 987.41263 \nL 727.457248 988.681889 \nL 728.166721 986.721239 \nL 728.876193 987.48294 \nL 729.585665 988.921875 \nL 730.295138 984.071982 \nL 732.423555 982.662278 \nL 733.133027 985.531786 \nL 733.842499 984.306007 \nL 734.551972 984.467109 \nL 735.261444 983.45049 \nL 737.389861 983.605852 \nL 738.099333 983.342971 \nL 738.808806 983.799131 \nL 739.518278 983.669911 \nL 742.356167 981.226531 \nL 743.06564 978.493192 \nL 743.775112 978.494113 \nL 744.484584 981.09067 \nL 745.194057 980.270081 \nL 747.322474 982.622162 \nL 748.031946 981.555372 \nL 748.741419 979.229269 \nL 749.450891 980.607741 \nL 750.160363 979.52244 \nL 752.28878 980.328009 \nL 752.998253 983.177549 \nL 753.707725 983.730564 \nL 755.12667 980.756068 \nL 757.255087 979.706633 \nL 757.964559 978.395215 \nL 758.674031 981.419245 \nL 759.383504 979.079691 \nL 760.092976 978.426787 \nL 762.221393 977.613804 \nL 762.930865 976.763773 \nL 763.640338 980.559588 \nL 764.34981 978.461412 \nL 765.059283 978.680627 \nL 767.1877 982.255907 \nL 767.897172 984.023267 \nL 768.606644 984.309026 \nL 769.316117 985.401304 \nL 770.025589 988.415447 \nL 772.154006 985.319114 \nL 772.863478 986.646321 \nL 773.572951 987.091203 \nL 774.282423 989.983196 \nL 774.991895 989.409494 \nL 777.120312 991.425103 \nL 777.829785 989.69321 \nL 778.539257 990.938176 \nL 779.248729 991.554945 \nL 779.958202 992.37978 \nL 782.086619 993.947363 \nL 782.796091 999.54335 \nL 783.505564 1000.937623 \nL 784.215036 999.706776 \nL 784.924508 997.638145 \nL 787.052925 997.09713 \nL 787.762398 996.23276 \nL 788.47187 997.555341 \nL 789.181342 995.098637 \nL 789.890815 995.173886 \nL 792.019232 995.844572 \nL 792.728704 996.627077 \nL 793.438176 995.820198 \nL 794.147649 997.492317 \nL 794.857121 995.799569 \nL 796.985538 994.73167 \nL 797.69501 996.451255 \nL 798.404483 998.576359 \nL 799.113955 996.090294 \nL 799.823427 997.20881 \nL 801.951844 998.392997 \nL 802.661317 997.170804 \nL 803.370789 997.089519 \nL 804.789734 1001.563176 \nL 806.918151 1001.835186 \nL 807.627623 999.598431 \nL 808.337096 999.497602 \nL 809.046568 1000.02598 \nL 809.75604 998.046698 \nL 812.59393 998.202825 \nL 813.303402 1000.095891 \nL 814.012874 1001.558261 \nL 814.722347 1005.357309 \nL 816.850764 1006.391012 \nL 817.560236 1005.637944 \nL 818.269708 1005.207153 \nL 818.979181 1006.048594 \nL 819.688653 1007.558932 \nL 821.81707 1010.879498 \nL 822.526543 1007.785349 \nL 823.236015 1011.063621 \nL 823.945487 1010.111124 \nL 823.945487 1010.111124 \n\" clip-path=\"url(#pbcac90addc)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_73\">\n    <path d=\"M 78.254578 1093.633276 \nL 859.454578 1093.633276 \n\" clip-path=\"url(#pbcac90addc)\" style=\"fill: none; stroke-dasharray: 7.4,3.2; stroke-dashoffset: 0; stroke: #000000; stroke-width: 2\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 78.254578 1131.124795 \nL 78.254578 929.689366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 859.454578 1131.124795 \nL 859.454578 929.689366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 78.254578 1131.124795 \nL 859.454578 1131.124795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 78.254578 929.689366 \nL 859.454578 929.689366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_26\">\n    <!-- Cumulative returns on logarithmic scale -->\n    <g transform=\"translate(336.638016 923.689366)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"960.355469\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"992.142578\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1053.324219\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1116.703125\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1148.490234\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1176.273438\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"1237.455078\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1300.931641\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1362.210938\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1403.324219\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1431.107422\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1470.316406\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"1533.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1631.107422\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1658.890625\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1713.871094\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1745.658203\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1797.757812\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1852.738281\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1914.017578\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1941.800781\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_18\">\n     <path d=\"M 740.243109 975.22696 \nL 850.984578 975.22696 \nQ 853.404578 975.22696 853.404578 972.80696 \nL 853.404578 938.159366 \nQ 853.404578 935.739366 850.984578 935.739366 \nL 740.243109 935.739366 \nQ 737.823109 935.739366 737.823109 938.159366 \nL 737.823109 972.80696 \nQ 737.823109 975.22696 740.243109 975.22696 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_74\">\n     <path d=\"M 742.663109 945.538475 \nL 754.763109 945.538475 \nL 766.863109 945.538475 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_27\">\n     <!-- daily_return -->\n     <g transform=\"translate(776.543109 949.773475)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-64\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"152.539062\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"180.322266\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"289.501953\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"328.365234\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"389.888672\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"429.097656\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"492.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"531.839844\"/>\n     </g>\n    </g>\n    <g id=\"line2d_75\">\n     <path d=\"M 742.663109 963.635538 \nL 754.763109 963.635538 \nL 766.863109 963.635538 \n\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_28\">\n     <!-- Backtest -->\n     <g transform=\"translate(776.543109 967.870538)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"129.882812\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"184.863281\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"242.773438\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"281.982422\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"343.505859\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"395.605469\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_4\">\n   <g id=\"patch_19\">\n    <path d=\"M 78.254578 1433.277937 \nL 859.454578 1433.277937 \nL 859.454578 1231.842509 \nL 78.254578 1231.842509 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_7\">\n    <g id=\"xtick_43\">\n     <g id=\"line2d_76\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_44\">\n     <g id=\"line2d_77\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_45\">\n     <g id=\"line2d_78\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_46\">\n     <g id=\"line2d_79\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_47\">\n     <g id=\"line2d_80\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_48\">\n     <g id=\"line2d_81\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_49\">\n     <g id=\"line2d_82\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_50\">\n     <g id=\"line2d_83\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_51\">\n     <g id=\"line2d_84\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"1433.277937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_52\">\n     <g id=\"line2d_85\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_53\">\n     <g id=\"line2d_86\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_54\">\n     <g id=\"line2d_87\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_55\">\n     <g id=\"line2d_88\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_56\">\n     <g id=\"line2d_89\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"1433.277937\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_8\">\n    <g id=\"ytick_21\">\n     <g id=\"line2d_90\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1409.197742\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_29\">\n      <!-- −0.100 -->\n      <g transform=\"translate(23.975125 1413.794796)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"306.445312\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_22\">\n     <g id=\"line2d_91\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1382.340497\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_30\">\n      <!-- −0.075 -->\n      <g transform=\"translate(23.975125 1386.937551)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"242.822266\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"306.445312\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_23\">\n     <g id=\"line2d_92\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1355.483252\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_31\">\n      <!-- −0.050 -->\n      <g transform=\"translate(23.975125 1360.080307)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"306.445312\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_24\">\n     <g id=\"line2d_93\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1328.626007\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_32\">\n      <!-- −0.025 -->\n      <g transform=\"translate(23.975125 1333.223062)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"242.822266\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"306.445312\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_25\">\n     <g id=\"line2d_94\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1301.768763\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_33\">\n      <!-- 0.000 -->\n      <g transform=\"translate(34.114547 1306.365817)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_26\">\n     <g id=\"line2d_95\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1274.911518\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_34\">\n      <!-- 0.025 -->\n      <g transform=\"translate(34.114547 1279.508572)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_27\">\n     <g id=\"line2d_96\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1248.054273\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_35\">\n      <!-- 0.050 -->\n      <g transform=\"translate(34.114547 1252.651328)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_36\">\n     <!-- Returns -->\n     <g transform=\"translate(17.229937 1357.899067)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-52\" d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_97\">\n    <path d=\"M 114.473141 1302.757334 \nL 116.601558 1301.827137 \nL 117.311031 1298.935933 \nL 118.020503 1311.662403 \nL 118.729975 1289.340864 \nL 119.439448 1303.260862 \nL 121.567865 1289.185885 \nL 122.277337 1305.036335 \nL 122.98681 1310.572964 \nL 123.696282 1304.717292 \nL 124.405754 1283.506874 \nL 127.243644 1311.177075 \nL 127.953116 1298.695338 \nL 128.662588 1332.150976 \nL 136.466784 1373.455427 \nL 137.176256 1280.811276 \nL 137.885729 1270.639074 \nL 138.595201 1287.078232 \nL 139.304673 1299.669466 \nL 141.433091 1294.395461 \nL 142.142563 1295.296594 \nL 142.852035 1284.46719 \nL 143.561508 1294.315082 \nL 144.27098 1298.188743 \nL 146.399397 1275.816536 \nL 147.108869 1301.938689 \nL 147.818342 1312.3048 \nL 148.527814 1285.329768 \nL 149.237286 1299.010549 \nL 151.365703 1308.301118 \nL 152.075176 1290.142071 \nL 152.784648 1316.193234 \nL 153.49412 1297.949288 \nL 154.203593 1340.687328 \nL 156.33201 1281.441193 \nL 157.041482 1290.786354 \nL 157.750954 1297.438453 \nL 158.460427 1284.602523 \nL 159.169899 1317.032454 \nL 161.298316 1344.870872 \nL 162.007789 1279.944486 \nL 163.426733 1327.711554 \nL 164.136206 1315.055937 \nL 166.264623 1346.717889 \nL 166.974095 1301.340957 \nL 167.683567 1316.990313 \nL 168.39304 1311.976541 \nL 169.102512 1289.577759 \nL 171.230929 1339.717664 \nL 171.940401 1263.919342 \nL 172.649874 1281.354647 \nL 173.359346 1306.807316 \nL 174.068818 1291.268607 \nL 176.197235 1311.869382 \nL 176.906708 1295.483702 \nL 177.61618 1304.723756 \nL 178.325653 1280.951252 \nL 179.035125 1302.875168 \nL 181.873014 1278.885425 \nL 182.582487 1305.753472 \nL 183.291959 1306.756439 \nL 184.001431 1315.059056 \nL 186.129848 1306.983544 \nL 186.839321 1274.100112 \nL 187.548793 1310.061991 \nL 188.258265 1295.559548 \nL 188.967738 1284.798574 \nL 191.096155 1298.925913 \nL 191.805627 1312.43138 \nL 192.515099 1291.191034 \nL 193.224572 1300.720334 \nL 193.934044 1315.936487 \nL 196.062461 1302.612058 \nL 196.771933 1281.033312 \nL 197.481406 1295.403036 \nL 198.190878 1283.552435 \nL 203.157185 1307.263268 \nL 203.866657 1296.954285 \nL 205.995074 1310.351668 \nL 206.704546 1296.484111 \nL 207.414019 1306.109642 \nL 208.123491 1318.676772 \nL 208.832963 1311.48254 \nL 210.96138 1291.762125 \nL 211.670853 1283.327908 \nL 212.380325 1308.809038 \nL 213.089797 1322.009621 \nL 213.79927 1332.140029 \nL 215.927687 1295.549162 \nL 216.637159 1288.077002 \nL 217.346632 1310.10169 \nL 218.765576 1296.806676 \nL 220.893993 1268.660512 \nL 221.603466 1300.006017 \nL 222.312938 1295.036415 \nL 223.02241 1307.989888 \nL 223.731883 1297.529288 \nL 225.8603 1280.32442 \nL 226.569772 1294.69426 \nL 227.279244 1306.729916 \nL 227.988717 1304.93798 \nL 228.698189 1311.159011 \nL 230.826606 1313.547914 \nL 231.536078 1285.839643 \nL 232.245551 1303.94892 \nL 232.955023 1293.484365 \nL 235.792913 1288.89544 \nL 236.502385 1296.476153 \nL 237.211857 1280.823657 \nL 240.759219 1301.052791 \nL 241.468691 1293.95665 \nL 242.178164 1258.642705 \nL 242.887636 1272.67417 \nL 243.597108 1277.390322 \nL 245.725525 1243.454712 \nL 246.434998 1304.311166 \nL 247.14447 1270.985662 \nL 247.853942 1276.026331 \nL 248.563415 1332.618029 \nL 250.691832 1271.829945 \nL 251.401304 1305.713822 \nL 252.110776 1295.060669 \nL 252.820249 1366.690154 \nL 253.529721 1284.998079 \nL 255.658138 1240.998665 \nL 256.367611 1279.965683 \nL 257.077083 1293.935729 \nL 257.786555 1249.087549 \nL 258.496028 1355.054029 \nL 260.624445 1276.376579 \nL 261.333917 1310.654674 \nL 262.043389 1272.493149 \nL 262.752862 1271.232331 \nL 263.462334 1295.695982 \nL 265.590751 1289.039328 \nL 266.300223 1318.023852 \nL 267.009696 1287.985589 \nL 267.719168 1321.083924 \nL 268.42864 1290.769971 \nL 270.557057 1290.430623 \nL 271.26653 1334.893818 \nL 271.976002 1336.090691 \nL 272.685475 1300.239575 \nL 273.394947 1283.076153 \nL 275.523364 1275.200798 \nL 276.232836 1292.594787 \nL 276.942309 1322.426082 \nL 277.651781 1325.163131 \nL 278.361253 1283.901175 \nL 280.48967 1275.08852 \nL 281.199143 1310.269037 \nL 281.908615 1322.131225 \nL 282.618087 1281.344782 \nL 283.32756 1273.418396 \nL 285.455977 1281.185344 \nL 286.165449 1277.272264 \nL 286.874921 1290.572689 \nL 287.584394 1313.931998 \nL 288.293866 1328.86689 \nL 290.422283 1312.751008 \nL 291.131755 1289.924143 \nL 291.841228 1327.706988 \nL 292.5507 1301.874195 \nL 293.260173 1280.154304 \nL 295.38859 1295.750942 \nL 296.098062 1298.192903 \nL 296.807534 1301.936192 \nL 297.517007 1309.340069 \nL 298.226479 1286.328112 \nL 300.354896 1312.789394 \nL 301.064368 1319.705876 \nL 301.773841 1281.067597 \nL 302.483313 1336.335512 \nL 303.192785 1299.820435 \nL 305.321202 1272.74977 \nL 306.030675 1295.648556 \nL 306.740147 1308.999647 \nL 313.125398 1258.577241 \nL 315.253815 1253.790516 \nL 315.963288 1286.05947 \nL 316.67276 1301.622802 \nL 317.382232 1324.339889 \nL 318.091705 1313.000132 \nL 320.220122 1328.501758 \nL 320.929594 1286.062368 \nL 321.639066 1303.879717 \nL 322.348539 1307.651772 \nL 323.058011 1313.052536 \nL 325.8959 1287.017625 \nL 327.314845 1290.185784 \nL 328.024317 1299.479704 \nL 330.152735 1295.594749 \nL 330.862207 1293.329537 \nL 331.571679 1316.098558 \nL 332.281152 1252.852752 \nL 332.990624 1320.459421 \nL 335.119041 1264.118295 \nL 335.828513 1289.036074 \nL 336.537986 1329.742147 \nL 337.247458 1310.97728 \nL 337.95693 1324.629216 \nL 340.085347 1288.740854 \nL 340.79482 1303.210688 \nL 341.504292 1301.154646 \nL 342.213764 1283.144675 \nL 342.923237 1260.215965 \nL 345.051654 1278.401085 \nL 345.761126 1314.353494 \nL 346.470598 1320.077686 \nL 347.180071 1300.535514 \nL 347.889543 1296.548001 \nL 350.01796 1307.492139 \nL 350.727433 1281.452562 \nL 351.436905 1309.758673 \nL 352.146377 1311.830223 \nL 352.85585 1299.184635 \nL 354.984267 1314.874091 \nL 355.693739 1306.915536 \nL 356.403211 1313.281755 \nL 357.112684 1287.08604 \nL 357.822156 1319.030966 \nL 359.950573 1298.208023 \nL 360.660045 1284.005269 \nL 361.369518 1287.848241 \nL 362.07899 1262.016018 \nL 362.788462 1283.746629 \nL 364.916879 1284.996943 \nL 365.626352 1337.975552 \nL 366.335824 1273.768172 \nL 367.045296 1301.795009 \nL 367.754769 1263.708505 \nL 369.883186 1277.298545 \nL 370.592658 1320.770187 \nL 371.302131 1289.89292 \nL 372.011603 1273.07193 \nL 374.849492 1252.466495 \nL 375.558965 1279.46453 \nL 376.268437 1295.036799 \nL 376.977909 1268.484815 \nL 377.687382 1294.524976 \nL 379.815799 1307.430479 \nL 380.525271 1283.880454 \nL 381.234743 1272.663615 \nL 381.944216 1355.898324 \nL 382.653688 1321.007055 \nL 384.782105 1274.666822 \nL 385.491577 1345.738016 \nL 386.20105 1287.948165 \nL 386.910522 1275.236826 \nL 387.619995 1283.001227 \nL 389.748412 1300.363621 \nL 390.457884 1321.583845 \nL 391.167356 1286.116328 \nL 391.876829 1356.142212 \nL 392.586301 1334.737476 \nL 394.714718 1305.941103 \nL 395.42419 1264.577369 \nL 396.133663 1300.71856 \nL 396.843135 1324.78881 \nL 397.552607 1307.886175 \nL 399.681024 1283.907103 \nL 400.390497 1252.265543 \nL 401.099969 1268.086406 \nL 406.775748 1271.152601 \nL 407.48522 1312.765911 \nL 409.613637 1317.367678 \nL 410.32311 1309.647243 \nL 411.032582 1352.281989 \nL 411.742054 1294.524856 \nL 412.451527 1342.254981 \nL 414.579944 1281.408935 \nL 415.289416 1338.572486 \nL 415.998888 1291.744871 \nL 416.708361 1363.20586 \nL 417.417833 1321.137918 \nL 419.54625 1361.41611 \nL 420.255722 1313.607691 \nL 420.965195 1296.893367 \nL 421.674667 1255.851629 \nL 422.384139 1297.020594 \nL 424.512557 1316.736895 \nL 425.222029 1292.74086 \nL 425.931501 1287.189986 \nL 426.640974 1289.512497 \nL 427.350446 1330.387201 \nL 429.478863 1291.739177 \nL 430.188335 1329.594371 \nL 430.897808 1344.189921 \nL 431.60728 1287.651346 \nL 432.316752 1251.365741 \nL 434.445169 1306.430992 \nL 435.154642 1288.020523 \nL 435.864114 1286.410136 \nL 436.573586 1282.924803 \nL 437.283059 1289.673938 \nL 440.120948 1290.923091 \nL 440.83042 1288.520438 \nL 441.539893 1300.656526 \nL 442.249365 1303.663027 \nL 444.377782 1336.409563 \nL 445.087255 1323.076245 \nL 445.796727 1293.048999 \nL 446.506199 1302.107468 \nL 447.215672 1291.079056 \nL 449.344089 1280.406612 \nL 450.053561 1299.128156 \nL 450.763033 1267.503783 \nL 451.472506 1284.864088 \nL 452.181978 1293.476373 \nL 454.310395 1297.225022 \nL 455.019867 1275.932265 \nL 455.72934 1300.357823 \nL 456.438812 1275.075757 \nL 457.148284 1310.607506 \nL 461.405118 1276.445997 \nL 462.114591 1301.071382 \nL 464.243008 1279.283904 \nL 464.95248 1336.268987 \nL 465.661953 1283.044429 \nL 466.371425 1321.892131 \nL 467.080897 1280.068381 \nL 469.209314 1253.405994 \nL 469.918787 1288.564477 \nL 470.628259 1293.155408 \nL 471.337731 1335.064035 \nL 472.047204 1280.167327 \nL 474.175621 1313.586577 \nL 474.885093 1278.369371 \nL 475.594565 1312.726648 \nL 476.304038 1303.378426 \nL 477.01351 1281.277008 \nL 479.141927 1291.345014 \nL 479.851399 1289.775201 \nL 480.560872 1329.018675 \nL 481.270344 1316.022716 \nL 481.979817 1298.32556 \nL 484.108234 1283.594627 \nL 484.817706 1317.11948 \nL 486.236651 1256.997311 \nL 486.946123 1287.239096 \nL 489.784012 1311.987754 \nL 490.493485 1340.281142 \nL 491.202957 1265.052682 \nL 491.912429 1291.520754 \nL 494.040846 1309.342342 \nL 494.750319 1283.915742 \nL 495.459791 1313.732009 \nL 496.169263 1296.266946 \nL 496.878736 1262.583855 \nL 499.007153 1288.062535 \nL 499.716625 1303.380136 \nL 500.426098 1283.316383 \nL 501.13557 1303.452796 \nL 503.973459 1367.641345 \nL 504.682932 1308.260754 \nL 505.392404 1263.83046 \nL 506.101876 1316.422608 \nL 506.811349 1344.850475 \nL 508.939766 1288.217895 \nL 509.649238 1264.186837 \nL 510.35871 1424.121782 \nL 511.068183 1297.701175 \nL 511.777655 1315.636304 \nL 513.906072 1270.572408 \nL 514.615544 1310.396104 \nL 515.325017 1281.387486 \nL 516.034489 1295.351821 \nL 516.743961 1332.71228 \nL 518.872379 1328.577567 \nL 519.581851 1340.645901 \nL 521.000796 1266.828021 \nL 521.710268 1290.596986 \nL 523.838685 1258.910175 \nL 524.548157 1277.646959 \nL 525.25763 1271.828471 \nL 525.967102 1304.219507 \nL 526.676574 1302.436667 \nL 528.804991 1308.06327 \nL 529.514464 1294.469057 \nL 530.223936 1303.227544 \nL 530.933408 1282.015388 \nL 531.642881 1313.953978 \nL 533.771298 1316.173717 \nL 534.48077 1318.017762 \nL 535.190242 1290.512526 \nL 535.899715 1310.490058 \nL 536.609187 1341.32898 \nL 538.737604 1253.817879 \nL 539.447077 1295.767451 \nL 540.156549 1280.08131 \nL 540.866021 1308.264378 \nL 541.575494 1291.85609 \nL 543.703911 1283.358668 \nL 544.413383 1307.453194 \nL 545.122855 1309.747891 \nL 545.832328 1301.554214 \nL 546.5418 1320.703904 \nL 548.670217 1293.715855 \nL 549.379689 1269.376354 \nL 550.089162 1294.379314 \nL 550.798634 1310.741061 \nL 551.508106 1261.840662 \nL 553.636523 1272.040231 \nL 554.345996 1320.914247 \nL 555.055468 1322.513795 \nL 555.76494 1324.47881 \nL 556.474413 1281.805284 \nL 560.021775 1297.172095 \nL 560.731247 1296.333331 \nL 561.440719 1298.291007 \nL 563.569136 1342.090385 \nL 564.278609 1322.151479 \nL 564.988081 1337.428408 \nL 565.697553 1285.250725 \nL 571.373332 1300.761475 \nL 573.501749 1301.172191 \nL 574.211221 1306.388694 \nL 574.920694 1289.127863 \nL 575.630166 1316.869211 \nL 576.339639 1310.502347 \nL 578.468056 1302.079464 \nL 579.177528 1284.634455 \nL 579.887 1316.319145 \nL 580.596473 1298.347653 \nL 581.305945 1303.673067 \nL 583.434362 1285.667235 \nL 584.143834 1306.832154 \nL 584.853307 1313.312548 \nL 585.562779 1318.355339 \nL 586.272251 1280.078074 \nL 588.400668 1322.998614 \nL 589.110141 1321.030682 \nL 589.819613 1302.573621 \nL 590.529085 1295.862552 \nL 591.238558 1319.189882 \nL 593.366975 1296.939162 \nL 594.076447 1305.157917 \nL 594.78592 1316.206122 \nL 595.495392 1295.03399 \nL 596.204864 1300.893599 \nL 598.333281 1320.026938 \nL 599.042754 1294.205746 \nL 599.752226 1300.587244 \nL 600.461698 1305.324632 \nL 601.171171 1297.284732 \nL 603.299588 1290.753486 \nL 604.00906 1293.713409 \nL 604.718532 1310.010334 \nL 605.428005 1305.174442 \nL 606.137477 1303.041626 \nL 608.265894 1280.079122 \nL 608.975366 1283.093256 \nL 609.684839 1304.17258 \nL 610.394311 1292.343728 \nL 611.103783 1309.773301 \nL 613.232201 1290.047791 \nL 613.941673 1294.211564 \nL 614.651145 1285.175735 \nL 615.360618 1293.48673 \nL 616.07009 1286.063174 \nL 618.198507 1302.762205 \nL 618.907979 1329.649753 \nL 619.617452 1298.233328 \nL 620.326924 1294.508433 \nL 621.036396 1314.224166 \nL 623.164813 1302.458466 \nL 623.874286 1294.152542 \nL 624.583758 1319.286896 \nL 625.29323 1290.271378 \nL 626.002703 1330.984626 \nL 628.13112 1303.929986 \nL 628.840592 1278.295686 \nL 629.550064 1318.879213 \nL 630.259537 1314.953392 \nL 630.969009 1276.971203 \nL 633.806899 1301.074148 \nL 634.516371 1321.525326 \nL 635.225843 1318.210448 \nL 635.935316 1299.448659 \nL 638.063733 1310.34344 \nL 638.773205 1311.587334 \nL 639.482677 1282.794732 \nL 640.19215 1320.792466 \nL 640.901622 1304.63966 \nL 643.030039 1318.711009 \nL 643.739511 1283.166875 \nL 644.448984 1319.582074 \nL 645.158456 1308.318156 \nL 645.867928 1314.972812 \nL 647.996345 1291.409094 \nL 648.705818 1334.55934 \nL 649.41529 1283.162673 \nL 650.124762 1325.681193 \nL 650.834235 1326.819863 \nL 657.928958 1259.960894 \nL 658.638431 1296.5861 \nL 659.347903 1294.503275 \nL 660.766848 1308.519036 \nL 662.895265 1325.19937 \nL 663.604737 1292.060575 \nL 664.314209 1290.204824 \nL 665.023682 1289.94684 \nL 665.733154 1298.490417 \nL 667.861571 1305.307329 \nL 668.571043 1301.235092 \nL 669.280516 1288.561335 \nL 669.989988 1322.704417 \nL 670.699461 1296.350755 \nL 672.827878 1267.782053 \nL 673.53735 1292.181855 \nL 674.246822 1295.713973 \nL 674.956295 1290.826028 \nL 675.665767 1311.76648 \nL 677.794184 1328.324608 \nL 678.503656 1325.479122 \nL 679.213129 1311.080149 \nL 679.922601 1283.323852 \nL 680.632073 1281.251473 \nL 682.76049 1339.54244 \nL 683.469963 1351.207636 \nL 684.179435 1249.683878 \nL 684.888907 1303.589633 \nL 685.59838 1290.307786 \nL 687.726797 1296.555934 \nL 688.436269 1297.326634 \nL 689.145742 1309.392637 \nL 689.855214 1304.186555 \nL 690.564686 1328.911518 \nL 692.693103 1292.87907 \nL 693.402576 1292.312654 \nL 694.112048 1284.046646 \nL 694.82152 1327.818257 \nL 695.530993 1262.234416 \nL 699.078354 1330.248089 \nL 699.787827 1320.527541 \nL 700.497299 1300.470809 \nL 702.625716 1337.859979 \nL 703.335188 1278.122007 \nL 704.044661 1296.210006 \nL 704.754133 1279.309712 \nL 705.463605 1323.795031 \nL 707.592022 1312.660027 \nL 708.301495 1305.336673 \nL 709.010967 1315.273806 \nL 709.72044 1331.231978 \nL 710.429912 1298.101936 \nL 712.558329 1366.362077 \nL 713.267801 1305.98019 \nL 713.977274 1260.766861 \nL 714.686746 1291.57579 \nL 715.396218 1277.964762 \nL 719.653052 1293.837789 \nL 720.362525 1346.520614 \nL 722.490942 1308.041693 \nL 723.909886 1294.860844 \nL 724.619359 1308.114826 \nL 725.328831 1293.43591 \nL 727.457248 1310.805474 \nL 728.166721 1287.658664 \nL 728.876193 1307.200986 \nL 729.585665 1312.007744 \nL 730.295138 1266.527344 \nL 732.423555 1291.642242 \nL 733.133027 1322.090477 \nL 733.842499 1292.968855 \nL 734.551972 1302.919991 \nL 735.261444 1294.475502 \nL 737.389861 1302.879 \nL 738.099333 1299.887571 \nL 738.808806 1305.025262 \nL 742.356167 1284.156293 \nL 743.06564 1282.047129 \nL 744.484584 1320.174115 \nL 745.194057 1295.885673 \nL 747.322474 1318.454707 \nL 748.031946 1294.114295 \nL 748.741419 1285.008213 \nL 749.450891 1311.579478 \nL 750.160363 1293.980991 \nL 752.28878 1307.513002 \nL 752.998253 1321.950402 \nL 754.417197 1290.728396 \nL 755.12667 1291.436391 \nL 757.255087 1294.239254 \nL 757.964559 1292.351363 \nL 758.674031 1323.173819 \nL 759.383504 1284.910536 \nL 760.092976 1297.09048 \nL 762.930865 1295.673996 \nL 763.640338 1328.568112 \nL 764.34981 1286.66201 \nL 765.059283 1303.33496 \nL 767.1877 1327.029541 \nL 767.897172 1314.330985 \nL 768.606644 1303.80994 \nL 769.316117 1309.550004 \nL 770.025589 1323.104533 \nL 772.154006 1279.400958 \nL 772.863478 1311.216224 \nL 773.572951 1304.944876 \nL 774.282423 1322.248186 \nL 774.991895 1297.65907 \nL 777.120312 1316.083716 \nL 777.829785 1289.314452 \nL 778.539257 1310.63323 \nL 779.248729 1306.169495 \nL 779.958202 1307.650001 \nL 782.086619 1312.918394 \nL 782.796091 1341.043 \nL 783.505564 1311.691418 \nL 784.215036 1292.932314 \nL 784.924508 1286.876209 \nL 787.052925 1297.893643 \nL 787.762398 1295.570887 \nL 788.47187 1311.183443 \nL 789.181342 1284.059465 \nL 789.890815 1302.306645 \nL 792.019232 1306.553341 \nL 792.728704 1307.348966 \nL 793.438176 1295.984225 \nL 794.147649 1313.657789 \nL 794.857121 1289.597537 \nL 796.985538 1294.106313 \nL 797.69501 1313.993346 \nL 798.404483 1316.855867 \nL 799.113955 1283.846059 \nL 799.823427 1309.736221 \nL 801.951844 1310.202176 \nL 802.661317 1292.994705 \nL 803.370789 1301.187436 \nL 804.080262 1317.940472 \nL 804.789734 1317.345769 \nL 806.918151 1303.711815 \nL 807.627623 1285.656809 \nL 808.337096 1301.047612 \nL 809.046568 1305.53992 \nL 809.75604 1287.523692 \nL 812.59393 1302.884464 \nL 813.303402 1315.21888 \nL 814.012874 1312.173681 \nL 814.722347 1328.59065 \nL 816.850764 1309.134154 \nL 817.560236 1296.370974 \nL 818.269708 1298.684277 \nL 818.979181 1307.768075 \nL 819.688653 1312.513269 \nL 821.81707 1325.249697 \nL 822.526543 1279.416897 \nL 823.236015 1324.953866 \nL 823.945487 1294.936979 \nL 823.945487 1294.936979 \n\" clip-path=\"url(#p4a26e2549c)\" style=\"fill: none; stroke: #008000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 78.254578 1433.277937 \nL 78.254578 1231.842509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 859.454578 1433.277937 \nL 859.454578 1231.842509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 78.254578 1433.277937 \nL 859.454578 1433.277937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 78.254578 1231.842509 \nL 859.454578 1231.842509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_37\">\n    <!-- Returns -->\n    <g transform=\"translate(443.515734 1225.842509)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_5\">\n   <g id=\"patch_24\">\n    <path d=\"M 78.254578 1735.43108 \nL 859.454578 1735.43108 \nL 859.454578 1533.995652 \nL 78.254578 1533.995652 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_9\">\n    <g id=\"xtick_57\">\n     <g id=\"line2d_98\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_58\">\n     <g id=\"line2d_99\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_59\">\n     <g id=\"line2d_100\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_60\">\n     <g id=\"line2d_101\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_61\">\n     <g id=\"line2d_102\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_62\">\n     <g id=\"line2d_103\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_63\">\n     <g id=\"line2d_104\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_64\">\n     <g id=\"line2d_105\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_65\">\n     <g id=\"line2d_106\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_66\">\n     <g id=\"line2d_107\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_67\">\n     <g id=\"line2d_108\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_68\">\n     <g id=\"line2d_109\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_69\">\n     <g id=\"line2d_110\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_70\">\n     <g id=\"line2d_111\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"1735.43108\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_10\">\n    <g id=\"ytick_28\">\n     <g id=\"line2d_112\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1735.43108\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_38\">\n      <!-- -1.00 -->\n      <g transform=\"translate(37.447719 1740.028135)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_29\">\n     <g id=\"line2d_113\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1710.251652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_39\">\n      <!-- -0.75 -->\n      <g transform=\"translate(37.447719 1714.848706)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_30\">\n     <g id=\"line2d_114\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1685.072223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_40\">\n      <!-- -0.50 -->\n      <g transform=\"translate(37.447719 1689.669278)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_31\">\n     <g id=\"line2d_115\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1659.892795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_41\">\n      <!-- -0.25 -->\n      <g transform=\"translate(37.447719 1664.489849)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_32\">\n     <g id=\"line2d_116\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1634.713366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_42\">\n      <!-- 0.00 -->\n      <g transform=\"translate(41.813172 1639.310421)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_33\">\n     <g id=\"line2d_117\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1609.533937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_43\">\n      <!-- 0.25 -->\n      <g transform=\"translate(41.813172 1614.130992)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_34\">\n     <g id=\"line2d_118\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1584.354509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_44\">\n      <!-- 0.50 -->\n      <g transform=\"translate(41.813172 1588.951564)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_35\">\n     <g id=\"line2d_119\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1559.17508\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_45\">\n      <!-- 0.75 -->\n      <g transform=\"translate(41.813172 1563.772135)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_36\">\n     <g id=\"line2d_120\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1533.995652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_46\">\n      <!-- 1.00 -->\n      <g transform=\"translate(41.813172 1538.592706)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_47\">\n     <!-- Beta -->\n     <g transform=\"translate(30.702531 1649.934616)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"130.126953\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"169.335938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_121\">\n    <path d=\"M 251.401304 1536.677221 \nL 252.110776 1537.203246 \nL 252.820249 1534.671683 \nL 253.529721 1534.404279 \nL 255.658138 1532.168645 \nL 257.077083 1532.175709 \nL 257.786555 1532.607705 \nL 258.496028 1531.199252 \nL 260.624445 1531.149565 \nL 261.333917 1531.563523 \nL 262.043389 1531.236881 \nL 262.752862 1531.688049 \nL 263.462334 1531.632269 \nL 265.590751 1531.290326 \nL 266.300223 1531.95741 \nL 267.009696 1532.442839 \nL 267.719168 1531.824171 \nL 268.42864 1531.760415 \nL 270.557057 1532.098468 \nL 271.26653 1531.173179 \nL 271.976002 1530.623799 \nL 272.685475 1530.616654 \nL 273.394947 1530.368328 \nL 275.523364 1530.681958 \nL 278.361253 1529.401504 \nL 280.48967 1529.244953 \nL 281.199143 1529.00408 \nL 283.32756 1527.690605 \nL 285.455977 1528.589836 \nL 286.165449 1528.447047 \nL 286.874921 1529.206158 \nL 287.584394 1527.35583 \nL 288.293866 1526.785033 \nL 290.422283 1526.93822 \nL 291.841228 1525.339479 \nL 292.5507 1526.282963 \nL 293.260173 1525.87096 \nL 295.38859 1525.670809 \nL 296.098062 1526.425557 \nL 296.807534 1526.459078 \nL 297.517007 1527.117388 \nL 298.226479 1528.542042 \nL 300.354896 1527.761553 \nL 301.773841 1524.980146 \nL 302.483313 1524.779792 \nL 303.192785 1524.702354 \nL 305.321202 1523.478225 \nL 306.030675 1523.676321 \nL 306.740147 1523.593896 \nL 313.125398 1522.423018 \nL 315.253815 1521.362329 \nL 316.67276 1521.690032 \nL 317.382232 1521.52901 \nL 318.091705 1521.506007 \nL 320.220122 1520.739745 \nL 320.929594 1520.623952 \nL 321.639066 1520.885726 \nL 322.348539 1520.861352 \nL 323.058011 1520.972101 \nL 325.8959 1522.617226 \nL 326.605373 1522.361156 \nL 327.314845 1522.274518 \nL 328.024317 1523.137914 \nL 330.152735 1523.32604 \nL 330.862207 1523.773693 \nL 331.571679 1524.737556 \nL 332.281152 1522.785201 \nL 332.990624 1522.656093 \nL 335.119041 1521.625165 \nL 335.828513 1521.867545 \nL 336.537986 1521.53281 \nL 337.247458 1521.454394 \nL 337.95693 1520.964649 \nL 340.085347 1521.209322 \nL 340.79482 1521.164354 \nL 342.213764 1521.385071 \nL 342.923237 1521.729447 \nL 345.761126 1521.632293 \nL 346.470598 1521.289836 \nL 347.180071 1521.936602 \nL 347.889543 1523.269521 \nL 350.01796 1523.274197 \nL 350.727433 1524.405869 \nL 351.436905 1524.418449 \nL 352.146377 1524.092307 \nL 352.85585 1524.049294 \nL 354.984267 1524.085093 \nL 356.403211 1523.695642 \nL 357.112684 1524.056264 \nL 357.822156 1523.586207 \nL 359.950573 1524.302107 \nL 361.369518 1524.229438 \nL 362.07899 1522.844932 \nL 362.788462 1523.87515 \nL 364.916879 1523.550047 \nL 365.626352 1521.83407 \nL 366.335824 1521.506034 \nL 367.045296 1521.491248 \nL 367.754769 1520.490624 \nL 369.883186 1520.244917 \nL 370.592658 1519.959122 \nL 371.302131 1520.822111 \nL 372.011603 1520.496698 \nL 374.849492 1520.642998 \nL 375.558965 1521.43448 \nL 376.268437 1521.77499 \nL 376.977909 1520.468003 \nL 377.687382 1510.765485 \nL 379.815799 1510.580669 \nL 380.525271 1516.331749 \nL 381.234743 1518.231117 \nL 381.944216 1515.22138 \nL 382.653688 1515.942326 \nL 384.782105 1514.87047 \nL 385.491577 1511.859933 \nL 386.20105 1514.050464 \nL 386.910522 1513.669819 \nL 387.619995 1517.007141 \nL 389.748412 1518.194909 \nL 390.457884 1518.782893 \nL 391.167356 1517.700989 \nL 391.876829 1515.34718 \nL 392.586301 1514.107612 \nL 394.714718 1514.214039 \nL 395.42419 1513.716741 \nL 396.133663 1512.658578 \nL 397.552607 1514.93344 \nL 399.681024 1513.388229 \nL 400.390497 1509.95617 \nL 401.099969 1509.477147 \nL 407.48522 1509.111254 \nL 409.613637 1515.735469 \nL 410.32311 1516.990645 \nL 411.032582 1513.654679 \nL 411.742054 1514.124039 \nL 412.451527 1511.559774 \nL 414.579944 1511.20522 \nL 415.289416 1509.546218 \nL 415.998888 1513.955379 \nL 416.708361 1510.068523 \nL 417.417833 1509.942062 \nL 419.54625 1506.670755 \nL 420.255722 1508.0861 \nL 420.965195 1508.450513 \nL 421.674667 1506.811016 \nL 422.384139 1505.687342 \nL 424.512557 1506.696408 \nL 425.222029 1506.691674 \nL 425.931501 1507.095784 \nL 426.640974 1507.721151 \nL 427.350446 1507.503579 \nL 429.478863 1507.319012 \nL 430.188335 1507.040254 \nL 430.897808 1505.293085 \nL 431.60728 1505.682347 \nL 432.316752 1503.456968 \nL 435.154642 1503.187143 \nL 435.864114 1504.490796 \nL 436.573586 1501.968127 \nL 437.283059 1501.949261 \nL 440.120948 1502.661054 \nL 442.249365 1506.694615 \nL 444.377782 1506.018043 \nL 445.087255 1505.481089 \nL 445.796727 1505.530452 \nL 446.506199 1507.651232 \nL 447.215672 1508.306763 \nL 449.344089 1508.782464 \nL 450.763033 1508.434555 \nL 451.472506 1509.324477 \nL 452.181978 1510.447241 \nL 454.310395 1512.394439 \nL 455.019867 1512.000664 \nL 455.72934 1512.070079 \nL 456.438812 1511.8141 \nL 457.148284 1510.341434 \nL 461.405118 1512.298543 \nL 462.114591 1513.25955 \nL 464.243008 1513.544228 \nL 464.95248 1515.095925 \nL 465.661953 1514.731866 \nL 466.371425 1513.63666 \nL 467.080897 1514.499239 \nL 469.209314 1514.584149 \nL 469.918787 1514.928961 \nL 470.628259 1516.480171 \nL 471.337731 1516.959261 \nL 472.047204 1519.020827 \nL 474.175621 1519.56837 \nL 474.885093 1525.151672 \nL 477.01351 1525.500483 \nL 479.141927 1525.860448 \nL 479.851399 1525.864442 \nL 480.560872 1525.193711 \nL 481.270344 1525.144127 \nL 481.979817 1525.693844 \nL 484.108234 1525.703255 \nL 484.817706 1524.366428 \nL 485.527178 1524.219344 \nL 486.236651 1522.0879 \nL 486.946123 1523.055406 \nL 489.784012 1523.325318 \nL 490.493485 1521.809701 \nL 491.202957 1522.25486 \nL 491.912429 1522.885532 \nL 494.040846 1522.977543 \nL 494.750319 1522.68724 \nL 495.459791 1523.251624 \nL 496.169263 1522.559822 \nL 496.878736 1521.393017 \nL 499.007153 1521.767789 \nL 499.716625 1523.360526 \nL 500.426098 1522.150111 \nL 501.13557 1523.137446 \nL 501.845042 1527.95693 \nL 506.101876 1528.525349 \nL 506.811349 1528.084659 \nL 508.939766 1527.333716 \nL 509.649238 1527.347766 \nL 510.35871 1520.657198 \nL 511.068183 1523.271815 \nL 511.777655 1522.433297 \nL 513.906072 1522.623233 \nL 515.325017 1522.149265 \nL 516.034489 1517.992678 \nL 516.743961 1515.838317 \nL 518.872379 1521.451648 \nL 519.581851 1520.789297 \nL 520.291323 1522.038564 \nL 521.000796 1522.368046 \nL 521.710268 1524.127017 \nL 523.838685 1523.527262 \nL 524.548157 1523.190722 \nL 525.25763 1521.736875 \nL 525.967102 1521.420845 \nL 526.676574 1521.841305 \nL 528.804991 1525.875206 \nL 529.514464 1527.524425 \nL 530.223936 1526.952624 \nL 530.933408 1529.044123 \nL 531.642881 1528.942011 \nL 533.771298 1528.024779 \nL 534.48077 1527.566733 \nL 535.190242 1527.954424 \nL 535.899715 1530.243207 \nL 536.609187 1529.588241 \nL 538.737604 1527.82305 \nL 539.447077 1528.732697 \nL 540.156549 1525.890133 \nL 540.866021 1526.953195 \nL 541.575494 1529.737151 \nL 543.703911 1529.335328 \nL 544.413383 1530.927885 \nL 545.122855 1534.792286 \nL 545.832328 1536.329981 \nL 546.5418 1534.168387 \nL 548.670217 1538.875758 \nL 549.379689 1538.250419 \nL 550.089162 1543.47662 \nL 550.798634 1543.241681 \nL 551.508106 1541.472274 \nL 553.636523 1543.909474 \nL 556.474413 1541.631792 \nL 560.021775 1542.477132 \nL 560.731247 1543.378904 \nL 561.440719 1543.515099 \nL 563.569136 1549.774643 \nL 564.278609 1552.626952 \nL 564.988081 1552.04776 \nL 565.697553 1555.123603 \nL 571.373332 1556.710481 \nL 573.501749 1557.055512 \nL 574.211221 1555.900765 \nL 574.920694 1556.20965 \nL 575.630166 1555.902588 \nL 576.339639 1556.250913 \nL 578.468056 1556.668984 \nL 579.177528 1556.204849 \nL 579.887 1555.441188 \nL 580.596473 1557.087493 \nL 581.305945 1558.415523 \nL 583.434362 1558.582944 \nL 584.143834 1558.193312 \nL 584.853307 1558.085532 \nL 585.562779 1558.274171 \nL 586.272251 1557.696755 \nL 588.400668 1557.601724 \nL 589.110141 1556.101199 \nL 589.819613 1556.214386 \nL 590.529085 1555.050097 \nL 591.238558 1555.289826 \nL 593.366975 1555.315031 \nL 594.076447 1556.304972 \nL 594.78592 1556.17485 \nL 595.495392 1555.344116 \nL 596.204864 1554.736265 \nL 598.333281 1554.625746 \nL 599.042754 1551.930398 \nL 599.752226 1552.280333 \nL 600.461698 1553.170503 \nL 601.171171 1553.403482 \nL 603.299588 1555.706171 \nL 604.00906 1555.607298 \nL 604.718532 1555.252429 \nL 605.428005 1554.507523 \nL 606.137477 1552.987488 \nL 608.265894 1552.459485 \nL 608.975366 1549.889559 \nL 610.394311 1549.414228 \nL 611.103783 1550.471672 \nL 613.232201 1550.201732 \nL 613.941673 1550.307159 \nL 614.651145 1551.013631 \nL 615.360618 1552.140402 \nL 616.07009 1552.169355 \nL 618.198507 1551.984483 \nL 618.907979 1551.731809 \nL 619.617452 1552.510066 \nL 620.326924 1553.826921 \nL 621.036396 1552.893941 \nL 623.164813 1553.006962 \nL 623.874286 1554.834475 \nL 624.583758 1554.351519 \nL 625.29323 1553.422327 \nL 626.002703 1553.700978 \nL 628.13112 1554.283939 \nL 628.840592 1553.31731 \nL 629.550064 1553.29242 \nL 630.259537 1556.378953 \nL 630.969009 1555.474862 \nL 633.806899 1555.063069 \nL 634.516371 1555.257352 \nL 635.225843 1554.281807 \nL 635.935316 1551.152273 \nL 638.063733 1551.734723 \nL 638.773205 1551.567517 \nL 639.482677 1552.220785 \nL 640.19215 1551.887029 \nL 640.901622 1553.455267 \nL 643.030039 1554.190375 \nL 643.739511 1554.119901 \nL 644.448984 1564.33127 \nL 645.158456 1564.29989 \nL 645.867928 1564.400741 \nL 647.996345 1565.459148 \nL 648.705818 1563.336294 \nL 649.41529 1563.158539 \nL 650.124762 1562.139368 \nL 650.834235 1562.408914 \nL 657.928958 1558.27925 \nL 658.638431 1561.140776 \nL 659.347903 1560.539994 \nL 660.057375 1562.266577 \nL 660.766848 1559.646066 \nL 662.895265 1562.695597 \nL 664.314209 1563.423012 \nL 665.023682 1563.328449 \nL 667.861571 1561.559849 \nL 668.571043 1562.060097 \nL 669.280516 1561.379692 \nL 669.989988 1558.285691 \nL 670.699461 1558.369684 \nL 673.53735 1557.514433 \nL 674.246822 1558.080524 \nL 674.956295 1558.060463 \nL 675.665767 1561.786642 \nL 677.794184 1563.648229 \nL 678.503656 1561.682419 \nL 679.213129 1562.183078 \nL 679.922601 1559.370987 \nL 680.632073 1559.311009 \nL 682.76049 1555.906148 \nL 683.469963 1554.376284 \nL 684.179435 1547.720438 \nL 684.888907 1549.469169 \nL 685.59838 1549.05644 \nL 687.726797 1549.351299 \nL 688.436269 1550.78014 \nL 689.145742 1550.249602 \nL 689.855214 1550.358452 \nL 690.564686 1551.678202 \nL 692.693103 1551.287276 \nL 693.402576 1551.819766 \nL 694.112048 1552.990727 \nL 694.82152 1552.899537 \nL 695.530993 1551.317055 \nL 699.787827 1549.403557 \nL 700.497299 1549.604904 \nL 702.625716 1542.947092 \nL 703.335188 1541.738958 \nL 704.044661 1542.392464 \nL 704.754133 1541.818491 \nL 705.463605 1540.28134 \nL 707.592022 1540.36847 \nL 708.301495 1540.586773 \nL 709.010967 1540.556853 \nL 710.429912 1539.187642 \nL 712.558329 1533.88203 \nL 713.267801 1534.276987 \nL 713.977274 1532.285139 \nL 714.686746 1532.356957 \nL 715.396218 1530.821455 \nL 719.653052 1530.793794 \nL 720.362525 1529.209431 \nL 722.490942 1529.179412 \nL 723.200414 1529.632606 \nL 723.909886 1530.261099 \nL 725.328831 1530.953477 \nL 728.166721 1530.602483 \nL 729.585665 1530.652513 \nL 730.295138 1529.675178 \nL 732.423555 1530.521823 \nL 733.133027 1529.034243 \nL 734.551972 1528.778908 \nL 737.389861 1528.988707 \nL 738.099333 1529.333907 \nL 738.808806 1528.82685 \nL 739.518278 1528.891329 \nL 742.356167 1528.785876 \nL 743.06564 1528.242167 \nL 743.775112 1528.910252 \nL 744.484584 1528.387561 \nL 745.194057 1528.752419 \nL 747.322474 1528.451505 \nL 748.031946 1528.697002 \nL 748.741419 1528.740405 \nL 749.450891 1528.098225 \nL 750.160363 1528.830953 \nL 752.998253 1528.8481 \nL 753.707725 1528.520292 \nL 754.417197 1528.819698 \nL 755.12667 1528.967945 \nL 757.255087 1529.691709 \nL 757.964559 1529.173857 \nL 759.383504 1528.60286 \nL 760.092976 1528.542594 \nL 762.221393 1528.553239 \nL 762.930865 1528.697469 \nL 763.640338 1528.388969 \nL 765.059283 1528.336997 \nL 767.1877 1528.466007 \nL 768.606644 1527.452444 \nL 769.316117 1527.83527 \nL 770.025589 1527.872952 \nL 772.863478 1527.584646 \nL 773.572951 1527.639317 \nL 774.282423 1527.145803 \nL 777.120312 1527.42865 \nL 777.829785 1527.281884 \nL 778.539257 1526.602646 \nL 779.248729 1526.328222 \nL 779.958202 1526.944076 \nL 782.086619 1526.811525 \nL 782.796091 1524.159306 \nL 784.215036 1524.352164 \nL 784.924508 1524.980817 \nL 787.052925 1525.44458 \nL 788.47187 1526.054317 \nL 789.181342 1528.134663 \nL 789.890815 1528.236005 \nL 793.438176 1528.238595 \nL 794.147649 1528.633393 \nL 794.857121 1528.87565 \nL 797.69501 1528.942756 \nL 798.404483 1528.641788 \nL 799.113955 1528.616352 \nL 799.823427 1527.817293 \nL 802.661317 1528.001164 \nL 803.370789 1528.750435 \nL 804.080262 1528.938375 \nL 804.789734 1528.389111 \nL 806.918151 1528.193704 \nL 807.627623 1527.799166 \nL 808.337096 1527.770835 \nL 809.046568 1526.950567 \nL 809.75604 1527.771436 \nL 812.59393 1527.803911 \nL 813.303402 1528.073634 \nL 814.012874 1528.171799 \nL 814.722347 1528.818694 \nL 816.850764 1526.118439 \nL 817.560236 1526.199667 \nL 818.269708 1524.721045 \nL 818.979181 1524.788557 \nL 819.688653 1524.303834 \nL 821.81707 1523.924139 \nL 822.526543 1522.80727 \nL 823.236015 1522.246499 \nL 823.945487 1522.772013 \nL 823.945487 1522.772013 \n\" clip-path=\"url(#p7972b0b8e2)\" style=\"fill: none; stroke: #4682b4; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_122\">\n    <path d=\"M 382.653688 1528.650177 \nL 384.782105 1528.436601 \nL 385.491577 1527.663233 \nL 386.20105 1527.568869 \nL 386.910522 1527.300579 \nL 387.619995 1527.340379 \nL 390.457884 1527.828496 \nL 391.167356 1527.841507 \nL 391.876829 1526.487379 \nL 392.586301 1526.168156 \nL 394.714718 1526.418513 \nL 395.42419 1526.177966 \nL 396.133663 1526.121286 \nL 396.843135 1526.188179 \nL 397.552607 1526.540211 \nL 399.681024 1526.515181 \nL 400.390497 1524.552493 \nL 401.099969 1523.696782 \nL 406.775748 1524.275464 \nL 407.48522 1524.083954 \nL 409.613637 1525.597738 \nL 410.32311 1525.661841 \nL 411.032582 1524.206396 \nL 411.742054 1524.484179 \nL 412.451527 1523.536391 \nL 414.579944 1523.33726 \nL 415.289416 1522.709843 \nL 415.998888 1523.756104 \nL 416.708361 1522.058296 \nL 417.417833 1521.602083 \nL 419.54625 1520.080129 \nL 420.255722 1520.18359 \nL 420.965195 1519.946117 \nL 421.674667 1519.447304 \nL 422.384139 1519.43501 \nL 424.512557 1519.778341 \nL 425.222029 1518.7118 \nL 425.931501 1518.837695 \nL 426.640974 1518.667775 \nL 427.350446 1518.101588 \nL 430.188335 1517.939385 \nL 430.897808 1516.978072 \nL 431.60728 1516.757969 \nL 432.316752 1516.104409 \nL 435.154642 1515.984022 \nL 435.864114 1516.630196 \nL 437.283059 1515.342742 \nL 440.120948 1514.74544 \nL 440.83042 1515.744193 \nL 441.539893 1515.532675 \nL 442.249365 1515.672776 \nL 445.087255 1514.883708 \nL 445.796727 1514.953291 \nL 446.506199 1515.248686 \nL 447.215672 1515.240512 \nL 450.053561 1515.440759 \nL 450.763033 1515.321698 \nL 451.472506 1515.840347 \nL 452.181978 1515.940897 \nL 454.310395 1516.859742 \nL 455.019867 1516.823483 \nL 455.72934 1516.960288 \nL 456.438812 1516.768467 \nL 457.148284 1516.731216 \nL 461.405118 1517.677278 \nL 462.114591 1518.061452 \nL 464.243008 1518.132374 \nL 464.95248 1519.286088 \nL 466.371425 1519.104724 \nL 467.080897 1519.489006 \nL 469.209314 1518.925644 \nL 469.918787 1518.897653 \nL 470.628259 1519.260251 \nL 471.337731 1519.459731 \nL 472.047204 1520.396921 \nL 474.175621 1520.486957 \nL 474.885093 1523.016848 \nL 477.01351 1523.443016 \nL 479.851399 1523.62314 \nL 480.560872 1523.318209 \nL 481.270344 1523.22246 \nL 481.979817 1523.465907 \nL 484.108234 1523.848723 \nL 484.817706 1523.656584 \nL 485.527178 1523.665034 \nL 486.236651 1523.394084 \nL 486.946123 1523.741887 \nL 489.784012 1523.804203 \nL 490.493485 1523.180862 \nL 491.202957 1523.268123 \nL 491.912429 1523.567154 \nL 496.169263 1523.58241 \nL 496.878736 1523.038769 \nL 499.007153 1523.031816 \nL 499.716625 1523.16544 \nL 500.426098 1522.964596 \nL 501.13557 1523.198648 \nL 501.845042 1524.891526 \nL 503.973459 1524.647693 \nL 505.392404 1524.071659 \nL 506.101876 1524.058978 \nL 506.811349 1523.818114 \nL 509.649238 1523.599767 \nL 510.35871 1520.597468 \nL 511.068183 1521.511401 \nL 511.777655 1521.069055 \nL 513.906072 1516.47897 \nL 514.615544 1516.391374 \nL 516.034489 1516.779358 \nL 516.743961 1516.30002 \nL 518.872379 1518.345413 \nL 519.581851 1517.924012 \nL 520.291323 1517.859054 \nL 521.000796 1518.571571 \nL 521.710268 1519.707131 \nL 523.838685 1520.589314 \nL 525.967102 1519.96693 \nL 526.676574 1521.060775 \nL 530.223936 1522.472342 \nL 530.933408 1523.029871 \nL 531.642881 1522.911236 \nL 533.771298 1522.944595 \nL 534.48077 1522.686079 \nL 535.190242 1522.635937 \nL 535.899715 1522.845396 \nL 536.609187 1521.634104 \nL 538.737604 1520.886556 \nL 539.447077 1521.920574 \nL 540.156549 1522.095918 \nL 540.866021 1523.025818 \nL 541.575494 1523.144008 \nL 544.413383 1522.929012 \nL 545.122855 1525.01438 \nL 546.5418 1525.656535 \nL 548.670217 1526.059791 \nL 549.379689 1525.46764 \nL 550.089162 1526.186669 \nL 550.798634 1526.253283 \nL 551.508106 1525.427466 \nL 553.636523 1525.197083 \nL 554.345996 1525.23935 \nL 555.055468 1524.923182 \nL 555.76494 1524.764239 \nL 556.474413 1525.016928 \nL 560.021775 1525.270092 \nL 560.731247 1525.155001 \nL 561.440719 1525.617265 \nL 563.569136 1528.245247 \nL 564.278609 1528.65078 \nL 564.988081 1528.211092 \nL 565.697553 1528.112809 \nL 571.373332 1529.039525 \nL 573.501749 1529.154174 \nL 574.211221 1528.16868 \nL 575.630166 1528.260883 \nL 576.339639 1528.670125 \nL 578.468056 1530.369005 \nL 579.177528 1530.224649 \nL 579.887 1530.502239 \nL 580.596473 1530.572152 \nL 581.305945 1531.126503 \nL 583.434362 1532.11863 \nL 584.143834 1533.062703 \nL 584.853307 1533.07161 \nL 585.562779 1532.935498 \nL 586.272251 1532.672964 \nL 588.400668 1532.344512 \nL 590.529085 1532.743618 \nL 591.238558 1532.701301 \nL 593.366975 1532.818483 \nL 594.076447 1532.173648 \nL 594.78592 1531.908756 \nL 595.495392 1532.815278 \nL 596.204864 1532.898336 \nL 600.461698 1531.862434 \nL 601.171171 1533.185734 \nL 603.299588 1533.315293 \nL 604.00906 1534.042024 \nL 605.428005 1534.192735 \nL 606.137477 1534.42539 \nL 608.265894 1534.689647 \nL 608.975366 1535.053433 \nL 609.684839 1535.16297 \nL 610.394311 1535.10489 \nL 611.103783 1535.764832 \nL 613.232201 1535.789451 \nL 614.651145 1536.18439 \nL 615.360618 1536.869672 \nL 616.07009 1536.790402 \nL 618.198507 1536.35953 \nL 618.907979 1536.047864 \nL 619.617452 1535.871988 \nL 623.164813 1536.115988 \nL 623.874286 1536.243795 \nL 624.583758 1536.130071 \nL 628.13112 1536.402589 \nL 628.840592 1535.81687 \nL 629.550064 1535.881495 \nL 630.259537 1536.338324 \nL 630.969009 1537.013303 \nL 633.806899 1536.461057 \nL 634.516371 1536.452057 \nL 635.225843 1537.145776 \nL 635.935316 1537.53267 \nL 638.063733 1537.685703 \nL 638.773205 1538.14128 \nL 640.901622 1538.153763 \nL 643.030039 1538.730228 \nL 643.739511 1538.729296 \nL 644.448984 1539.041442 \nL 645.867928 1540.125936 \nL 647.996345 1540.057806 \nL 648.705818 1539.413975 \nL 649.41529 1537.547334 \nL 650.124762 1536.441389 \nL 650.834235 1537.759607 \nL 657.928958 1536.525861 \nL 658.638431 1536.921132 \nL 659.347903 1537.827585 \nL 660.057375 1537.907479 \nL 660.766848 1538.323484 \nL 662.895265 1537.961264 \nL 663.604737 1537.407469 \nL 664.314209 1537.223614 \nL 665.023682 1537.25053 \nL 665.733154 1539.224729 \nL 668.571043 1539.716455 \nL 669.280516 1540.186815 \nL 669.989988 1540.027051 \nL 670.699461 1539.414192 \nL 672.827878 1538.681501 \nL 673.53735 1539.074319 \nL 674.246822 1540.65165 \nL 674.956295 1541.446099 \nL 675.665767 1541.21746 \nL 677.794184 1541.238155 \nL 678.503656 1539.460637 \nL 679.213129 1539.244865 \nL 679.922601 1540.742364 \nL 680.632073 1540.435424 \nL 682.76049 1540.755074 \nL 683.469963 1541.201267 \nL 684.179435 1541.515325 \nL 684.888907 1541.250957 \nL 685.59838 1543.701032 \nL 687.726797 1544.044035 \nL 688.436269 1546.459031 \nL 689.145742 1546.547078 \nL 689.855214 1546.494427 \nL 690.564686 1547.317901 \nL 693.402576 1547.412912 \nL 694.112048 1547.932399 \nL 694.82152 1547.587616 \nL 695.530993 1546.697811 \nL 699.078354 1546.847334 \nL 699.787827 1546.616854 \nL 700.497299 1547.126036 \nL 702.625716 1547.35816 \nL 703.335188 1547.075798 \nL 704.044661 1548.717216 \nL 704.754133 1548.389366 \nL 705.463605 1548.534123 \nL 707.592022 1547.979507 \nL 708.301495 1548.259228 \nL 709.010967 1548.177233 \nL 709.72044 1547.392624 \nL 710.429912 1546.939317 \nL 712.558329 1544.457845 \nL 713.977274 1543.522077 \nL 714.686746 1543.795913 \nL 715.396218 1543.504549 \nL 719.653052 1543.302663 \nL 720.362525 1542.194954 \nL 722.490942 1542.296082 \nL 723.909886 1542.747371 \nL 724.619359 1542.332487 \nL 725.328831 1542.307156 \nL 727.457248 1541.612748 \nL 728.166721 1541.788435 \nL 728.876193 1541.772054 \nL 729.585665 1542.217507 \nL 730.295138 1541.589071 \nL 732.423555 1541.005391 \nL 733.133027 1540.515702 \nL 733.842499 1540.408138 \nL 734.551972 1539.130038 \nL 737.389861 1539.600093 \nL 738.099333 1539.616335 \nL 738.808806 1540.638458 \nL 739.518278 1540.660824 \nL 742.356167 1540.270136 \nL 743.775112 1539.20618 \nL 744.484584 1538.887857 \nL 745.194057 1537.095293 \nL 747.322474 1537.00242 \nL 748.031946 1537.205508 \nL 749.450891 1537.10241 \nL 750.160363 1537.470856 \nL 752.998253 1537.956662 \nL 755.12667 1538.402147 \nL 757.255087 1538.697766 \nL 757.964559 1539.255071 \nL 758.674031 1538.569703 \nL 759.383504 1538.448919 \nL 760.092976 1539.242698 \nL 762.221393 1539.141606 \nL 763.640338 1538.482962 \nL 764.34981 1538.761261 \nL 767.1877 1538.418278 \nL 767.897172 1539.214996 \nL 769.316117 1538.832472 \nL 770.025589 1538.955878 \nL 772.154006 1538.350192 \nL 772.863478 1536.606165 \nL 773.572951 1536.720654 \nL 774.282423 1536.511355 \nL 774.991895 1536.995365 \nL 777.120312 1536.873333 \nL 779.248729 1537.402096 \nL 779.958202 1541.384584 \nL 782.086619 1540.384334 \nL 782.796091 1539.54046 \nL 783.505564 1539.847981 \nL 784.924508 1540.005984 \nL 787.052925 1540.116488 \nL 787.762398 1540.570051 \nL 788.47187 1539.526953 \nL 789.181342 1540.222194 \nL 789.890815 1540.01399 \nL 792.019232 1540.637494 \nL 792.728704 1539.573089 \nL 793.438176 1540.748549 \nL 794.147649 1540.940185 \nL 794.857121 1541.29068 \nL 796.985538 1541.250072 \nL 797.69501 1540.942392 \nL 798.404483 1540.216242 \nL 799.113955 1539.737882 \nL 799.823427 1539.609807 \nL 801.951844 1538.72331 \nL 802.661317 1538.813037 \nL 803.370789 1539.154487 \nL 804.080262 1538.605721 \nL 804.789734 1538.418541 \nL 806.918151 1538.215579 \nL 807.627623 1538.970888 \nL 808.337096 1540.031992 \nL 809.046568 1539.640808 \nL 809.75604 1540.034366 \nL 812.59393 1539.083217 \nL 814.722347 1538.700373 \nL 816.850764 1536.910553 \nL 818.979181 1536.982598 \nL 819.688653 1537.712058 \nL 822.526543 1536.615679 \nL 823.236015 1537.394676 \nL 823.945487 1537.156936 \nL 823.945487 1537.156936 \n\" clip-path=\"url(#p7972b0b8e2)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.4; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_123\">\n    <path d=\"M 78.254578 1531.402615 \nL 859.454578 1531.402615 \n\" clip-path=\"url(#p7972b0b8e2)\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n   </g>\n   <g id=\"line2d_124\">\n    <path d=\"M 78.254578 1634.713366 \nL 859.454578 1634.713366 \n\" clip-path=\"url(#p7972b0b8e2)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 78.254578 1735.43108 \nL 78.254578 1533.995652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 859.454578 1735.43108 \nL 859.454578 1533.995652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 78.254578 1735.43108 \nL 859.454578 1735.43108 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 78.254578 1533.995652 \nL 859.454578 1533.995652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_48\">\n    <!-- Rolling portfolio beta to daily_return -->\n    <g transform=\"translate(349.874109 1527.995652)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.164062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"153.947266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"181.730469\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"209.513672\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"272.892578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"336.369141\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"368.15625\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"431.632812\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"492.814453\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"533.927734\"/>\n     <use xlink:href=\"#DejaVuSans-66\" x=\"573.136719\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"608.341797\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"669.523438\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"697.306641\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"725.089844\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"786.271484\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"818.058594\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"881.535156\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"943.058594\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"982.267578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1043.546875\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1075.333984\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1114.542969\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1175.724609\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"1207.511719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1270.988281\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1332.267578\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1360.050781\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1387.833984\"/>\n     <use xlink:href=\"#DejaVuSans-5f\" x=\"1447.013672\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1497.013672\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1535.876953\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1597.400391\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"1636.609375\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1699.988281\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1739.351562\"/>\n    </g>\n   </g>\n   <g id=\"legend_3\">\n    <g id=\"patch_29\">\n     <path d=\"M 86.724578 1579.196714 \nL 164.397125 1579.196714 \nQ 166.817125 1579.196714 166.817125 1576.776714 \nL 166.817125 1542.465652 \nQ 166.817125 1540.045652 164.397125 1540.045652 \nL 86.724578 1540.045652 \nQ 84.304578 1540.045652 84.304578 1542.465652 \nL 84.304578 1576.776714 \nQ 84.304578 1579.196714 86.724578 1579.196714 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_125\">\n     <path d=\"M 89.144578 1549.844761 \nL 101.244578 1549.844761 \nL 113.344578 1549.844761 \n\" style=\"fill: none; stroke: #4682b4; stroke-opacity: 0.6; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_49\">\n     <!-- 6-mo -->\n     <g transform=\"translate(123.024578 1554.079761)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-36\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" x=\"63.623047\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"99.707031\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"197.119141\"/>\n     </g>\n    </g>\n    <g id=\"line2d_126\">\n     <path d=\"M 89.144578 1567.605292 \nL 101.244578 1567.605292 \nL 113.344578 1567.605292 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.4; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_50\">\n     <!-- 12-mo -->\n     <g transform=\"translate(123.024578 1571.840292)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" x=\"127.246094\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"163.330078\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"260.742188\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_6\">\n   <g id=\"patch_30\">\n    <path d=\"M 78.254578 2037.584223 \nL 859.454578 2037.584223 \nL 859.454578 1836.148795 \nL 78.254578 1836.148795 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_11\">\n    <g id=\"xtick_71\">\n     <g id=\"line2d_127\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_72\">\n     <g id=\"line2d_128\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_73\">\n     <g id=\"line2d_129\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_74\">\n     <g id=\"line2d_130\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_75\">\n     <g id=\"line2d_131\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_76\">\n     <g id=\"line2d_132\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_77\">\n     <g id=\"line2d_133\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_78\">\n     <g id=\"line2d_134\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_79\">\n     <g id=\"line2d_135\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"2037.584223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_80\">\n     <g id=\"line2d_136\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_81\">\n     <g id=\"line2d_137\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_82\">\n     <g id=\"line2d_138\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_83\">\n     <g id=\"line2d_139\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_84\">\n     <g id=\"line2d_140\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"2037.584223\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_12\">\n    <g id=\"ytick_37\">\n     <g id=\"line2d_141\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2028.428067\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_51\">\n      <!-- 0.00 -->\n      <g transform=\"translate(41.813172 2033.025122)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_38\">\n     <g id=\"line2d_142\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2005.929926\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_52\">\n      <!-- 0.05 -->\n      <g transform=\"translate(41.813172 2010.526981)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_39\">\n     <g id=\"line2d_143\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1983.431784\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_53\">\n      <!-- 0.10 -->\n      <g transform=\"translate(41.813172 1988.028839)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_40\">\n     <g id=\"line2d_144\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1960.933643\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_54\">\n      <!-- 0.15 -->\n      <g transform=\"translate(41.813172 1965.530698)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_41\">\n     <g id=\"line2d_145\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1938.435501\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_55\">\n      <!-- 0.20 -->\n      <g transform=\"translate(41.813172 1943.032556)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_42\">\n     <g id=\"line2d_146\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1915.93736\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_56\">\n      <!-- 0.25 -->\n      <g transform=\"translate(41.813172 1920.534415)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_43\">\n     <g id=\"line2d_147\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1893.439218\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_57\">\n      <!-- 0.30 -->\n      <g transform=\"translate(41.813172 1898.036273)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_44\">\n     <g id=\"line2d_148\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1870.941077\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_58\">\n      <!-- 0.35 -->\n      <g transform=\"translate(41.813172 1875.538131)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_45\">\n     <g id=\"line2d_149\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"1848.442935\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_59\">\n      <!-- 0.40 -->\n      <g transform=\"translate(41.813172 1853.03999)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_60\">\n     <!-- Volatility -->\n     <g transform=\"translate(35.067984 1965.368196)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-56\" d=\"M 1831 0 \nL 50 4666 \nL 709 4666 \nL 2188 738 \nL 3669 4666 \nL 4325 4666 \nL 2547 0 \nL 1831 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.839844\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"149.623047\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"210.902344\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"250.111328\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"277.894531\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"305.677734\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"333.460938\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"372.669922\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_150\">\n    <path d=\"M 251.401304 1907.596119 \nL 252.110776 1907.586912 \nL 252.820249 1901.167378 \nL 253.529721 1900.866389 \nL 255.658138 1896.421917 \nL 256.367611 1896.059707 \nL 257.077083 1896.049223 \nL 257.786555 1892.906259 \nL 258.496028 1888.895274 \nL 261.333917 1888.290628 \nL 262.043389 1887.713859 \nL 262.752862 1886.809331 \nL 263.462334 1887.003087 \nL 265.590751 1886.895399 \nL 266.300223 1887.846562 \nL 267.009696 1895.104188 \nL 267.719168 1894.753392 \nL 268.42864 1895.672378 \nL 270.557057 1895.75491 \nL 271.976002 1892.140853 \nL 273.394947 1892.098283 \nL 275.523364 1891.415161 \nL 276.942309 1891.312039 \nL 277.651781 1890.437803 \nL 278.361253 1890.380524 \nL 281.199143 1889.725805 \nL 281.908615 1889.149505 \nL 282.618087 1888.856797 \nL 283.32756 1888.440146 \nL 285.455977 1888.065738 \nL 286.165449 1889.81492 \nL 286.874921 1890.09196 \nL 287.584394 1889.835061 \nL 288.293866 1888.643389 \nL 290.422283 1888.628431 \nL 291.131755 1888.972264 \nL 291.841228 1890.636023 \nL 292.5507 1891.053448 \nL 293.260173 1890.701731 \nL 296.098062 1892.209895 \nL 296.807534 1895.349826 \nL 297.517007 1895.18297 \nL 298.226479 1895.530326 \nL 300.354896 1895.497656 \nL 301.064368 1894.918517 \nL 301.773841 1896.97031 \nL 302.483313 1896.428859 \nL 303.192785 1896.781387 \nL 305.321202 1896.063924 \nL 306.740147 1896.210531 \nL 313.125398 1894.217422 \nL 315.253815 1891.853693 \nL 315.963288 1892.030218 \nL 316.67276 1892.04773 \nL 317.382232 1891.508847 \nL 318.091705 1891.281872 \nL 320.220122 1890.149706 \nL 320.929594 1890.389709 \nL 321.639066 1890.455186 \nL 322.348539 1891.010596 \nL 323.058011 1890.902181 \nL 326.605373 1890.847777 \nL 327.314845 1891.076963 \nL 330.152735 1891.129639 \nL 330.862207 1891.566024 \nL 331.571679 1891.140101 \nL 332.281152 1888.97107 \nL 332.990624 1888.280977 \nL 335.119041 1887.146223 \nL 335.828513 1887.135869 \nL 336.537986 1885.928749 \nL 337.247458 1885.690085 \nL 337.95693 1884.974602 \nL 340.79482 1884.939577 \nL 341.504292 1885.493379 \nL 342.213764 1885.519883 \nL 342.923237 1883.912155 \nL 345.051654 1883.723113 \nL 345.761126 1883.519643 \nL 346.470598 1883.635086 \nL 347.180071 1885.179613 \nL 350.727433 1885.072555 \nL 351.436905 1884.919941 \nL 352.146377 1884.625298 \nL 352.85585 1885.575129 \nL 357.112684 1884.762333 \nL 357.822156 1884.505434 \nL 360.660045 1884.416371 \nL 361.369518 1884.394572 \nL 362.07899 1883.185444 \nL 362.788462 1883.353233 \nL 364.916879 1883.331055 \nL 365.626352 1881.303603 \nL 366.335824 1880.699268 \nL 367.045296 1880.683199 \nL 367.754769 1879.482344 \nL 369.883186 1879.062323 \nL 370.592658 1878.628754 \nL 371.302131 1878.606417 \nL 372.011603 1877.982619 \nL 374.849492 1877.395279 \nL 376.268437 1878.127445 \nL 376.977909 1880.525185 \nL 377.687382 1880.595468 \nL 380.525271 1881.550795 \nL 381.234743 1882.441442 \nL 381.944216 1878.963854 \nL 382.653688 1878.372258 \nL 384.782105 1877.791952 \nL 385.491577 1880.743814 \nL 386.20105 1880.816255 \nL 386.910522 1884.030387 \nL 387.619995 1884.145946 \nL 389.748412 1884.144493 \nL 390.457884 1886.299256 \nL 391.167356 1890.336486 \nL 391.876829 1886.541493 \nL 392.586301 1885.057144 \nL 394.714718 1885.789315 \nL 395.42419 1885.290709 \nL 396.133663 1885.290222 \nL 396.843135 1884.533955 \nL 397.552607 1884.896296 \nL 399.681024 1884.771447 \nL 400.390497 1882.850967 \nL 401.099969 1881.846254 \nL 406.775748 1881.068534 \nL 407.48522 1882.479371 \nL 409.613637 1883.82398 \nL 410.32311 1883.645753 \nL 411.032582 1880.274422 \nL 411.742054 1880.875019 \nL 412.451527 1878.595895 \nL 414.579944 1878.959745 \nL 415.289416 1877.890697 \nL 415.998888 1878.080916 \nL 416.708361 1873.864268 \nL 417.417833 1873.447234 \nL 419.54625 1869.668645 \nL 420.255722 1869.806638 \nL 420.965195 1870.565342 \nL 421.674667 1868.810479 \nL 422.384139 1869.355777 \nL 424.512557 1869.129904 \nL 425.222029 1869.296896 \nL 425.931501 1870.085163 \nL 426.640974 1870.181212 \nL 427.350446 1869.207045 \nL 429.478863 1870.036512 \nL 430.188335 1869.024708 \nL 430.897808 1867.262363 \nL 431.60728 1867.11632 \nL 432.316752 1864.577406 \nL 436.573586 1864.407585 \nL 437.283059 1864.774609 \nL 440.120948 1865.050727 \nL 440.83042 1866.467701 \nL 441.539893 1866.46473 \nL 442.249365 1867.177181 \nL 445.087255 1865.150803 \nL 445.796727 1866.924029 \nL 446.506199 1869.248594 \nL 447.215672 1869.37582 \nL 449.344089 1868.956815 \nL 450.053561 1869.629778 \nL 450.763033 1868.701162 \nL 451.472506 1869.436565 \nL 452.181978 1869.587975 \nL 454.310395 1869.611739 \nL 455.019867 1869.117735 \nL 455.72934 1869.345753 \nL 456.438812 1868.770425 \nL 457.148284 1868.755196 \nL 461.405118 1868.325822 \nL 462.114591 1868.39638 \nL 464.243008 1867.988802 \nL 464.95248 1866.442816 \nL 466.371425 1865.950268 \nL 467.080897 1867.879943 \nL 469.209314 1866.153687 \nL 469.918787 1867.33932 \nL 470.628259 1867.407442 \nL 471.337731 1867.013539 \nL 472.047204 1866.811789 \nL 474.175621 1867.313056 \nL 474.885093 1866.977442 \nL 475.594565 1866.776192 \nL 477.01351 1866.691209 \nL 479.141927 1868.243302 \nL 479.851399 1868.609187 \nL 480.560872 1867.866377 \nL 481.270344 1868.038532 \nL 481.979817 1868.041792 \nL 484.108234 1867.79547 \nL 484.817706 1867.507079 \nL 485.527178 1867.62028 \nL 486.236651 1865.870022 \nL 486.946123 1865.939503 \nL 489.784012 1865.733508 \nL 490.493485 1864.126685 \nL 491.202957 1863.022748 \nL 491.912429 1863.226576 \nL 494.040846 1863.217577 \nL 494.750319 1863.48082 \nL 495.459791 1863.212306 \nL 496.169263 1863.419027 \nL 496.878736 1862.192252 \nL 499.007153 1863.467196 \nL 499.716625 1863.659938 \nL 500.426098 1863.609248 \nL 501.13557 1865.29556 \nL 501.845042 1865.465064 \nL 503.973459 1860.376017 \nL 504.682932 1861.599741 \nL 505.392404 1860.786638 \nL 506.101876 1860.966096 \nL 506.811349 1858.874875 \nL 508.939766 1859.472255 \nL 509.649238 1860.488568 \nL 510.35871 1845.458199 \nL 511.068183 1845.481186 \nL 511.777655 1846.300578 \nL 513.906072 1845.438726 \nL 515.325017 1845.30495 \nL 516.034489 1846.056346 \nL 516.743961 1848.008672 \nL 518.872379 1847.656769 \nL 519.581851 1846.844319 \nL 520.291323 1848.762748 \nL 521.000796 1847.77598 \nL 521.710268 1848.325562 \nL 525.25763 1845.994512 \nL 525.967102 1846.182843 \nL 526.676574 1849.220128 \nL 528.804991 1850.346488 \nL 529.514464 1850.352988 \nL 530.223936 1851.59513 \nL 530.933408 1851.268501 \nL 531.642881 1851.688229 \nL 534.48077 1851.432955 \nL 535.190242 1853.666886 \nL 535.899715 1854.653673 \nL 538.737604 1851.803294 \nL 539.447077 1852.047449 \nL 540.156549 1851.700428 \nL 540.866021 1854.349005 \nL 541.575494 1854.310752 \nL 543.703911 1855.849423 \nL 544.413383 1856.140048 \nL 545.122855 1857.583933 \nL 545.832328 1857.647617 \nL 546.5418 1861.412231 \nL 548.670217 1861.880284 \nL 549.379689 1865.135551 \nL 550.089162 1865.366069 \nL 550.798634 1865.204673 \nL 551.508106 1865.720332 \nL 554.345996 1864.781715 \nL 555.76494 1863.628345 \nL 556.474413 1863.40981 \nL 560.021775 1864.485549 \nL 560.731247 1864.530826 \nL 561.440719 1865.577444 \nL 563.569136 1865.78173 \nL 564.278609 1865.301757 \nL 564.988081 1866.15773 \nL 565.697553 1866.001356 \nL 571.373332 1866.134725 \nL 573.501749 1866.312219 \nL 574.211221 1866.558139 \nL 574.920694 1866.546032 \nL 575.630166 1866.305458 \nL 578.468056 1866.31672 \nL 579.177528 1866.079705 \nL 579.887 1867.250628 \nL 580.596473 1867.858578 \nL 581.305945 1867.884604 \nL 584.143834 1867.700309 \nL 584.853307 1867.90179 \nL 585.562779 1867.52545 \nL 586.272251 1868.250744 \nL 588.400668 1867.934744 \nL 589.110141 1867.521278 \nL 589.819613 1867.529115 \nL 590.529085 1868.177428 \nL 591.238558 1867.805721 \nL 593.366975 1868.528212 \nL 594.076447 1868.610631 \nL 594.78592 1869.038547 \nL 595.495392 1868.994827 \nL 596.204864 1869.536945 \nL 599.042754 1870.826066 \nL 600.461698 1871.793109 \nL 601.171171 1874.419228 \nL 604.00906 1874.491088 \nL 604.718532 1875.693708 \nL 605.428005 1876.218946 \nL 606.137477 1876.379053 \nL 608.265894 1876.468656 \nL 608.975366 1876.211804 \nL 609.684839 1876.207648 \nL 610.394311 1876.587628 \nL 611.103783 1876.636044 \nL 613.232201 1876.64357 \nL 613.941673 1877.456056 \nL 615.360618 1877.340609 \nL 618.198507 1877.730713 \nL 618.907979 1877.109095 \nL 619.617452 1879.441437 \nL 620.326924 1879.630464 \nL 621.036396 1879.570689 \nL 623.164813 1881.347323 \nL 623.874286 1882.90056 \nL 624.583758 1882.664885 \nL 625.29323 1882.566075 \nL 626.002703 1881.951519 \nL 628.13112 1882.108495 \nL 628.840592 1881.466559 \nL 629.550064 1883.034587 \nL 630.259537 1883.10433 \nL 630.969009 1882.309533 \nL 633.806899 1882.75491 \nL 634.516371 1882.325309 \nL 635.225843 1882.355435 \nL 635.935316 1887.578141 \nL 638.063733 1887.54109 \nL 638.773205 1889.315184 \nL 639.482677 1889.070769 \nL 640.19215 1890.950571 \nL 640.901622 1891.195059 \nL 643.030039 1892.755735 \nL 643.739511 1913.220653 \nL 644.448984 1912.753766 \nL 645.158456 1912.983172 \nL 645.867928 1914.228958 \nL 647.996345 1914.165465 \nL 648.705818 1913.20586 \nL 649.41529 1912.719613 \nL 650.124762 1913.301163 \nL 650.834235 1913.439094 \nL 658.638431 1913.024656 \nL 659.347903 1914.812419 \nL 660.057375 1915.004962 \nL 660.766848 1917.865049 \nL 662.895265 1918.007091 \nL 663.604737 1919.355489 \nL 665.023682 1918.852244 \nL 668.571043 1918.965962 \nL 669.280516 1919.330924 \nL 669.989988 1918.884965 \nL 670.699461 1919.123948 \nL 672.827878 1917.613868 \nL 674.246822 1917.722527 \nL 674.956295 1920.058737 \nL 675.665767 1923.711268 \nL 677.794184 1922.627525 \nL 679.213129 1922.511055 \nL 679.922601 1922.083787 \nL 680.632073 1921.941831 \nL 682.76049 1919.747209 \nL 683.469963 1916.099227 \nL 684.179435 1911.721845 \nL 684.888907 1912.21435 \nL 685.59838 1912.104696 \nL 687.726797 1913.745669 \nL 689.145742 1913.839058 \nL 689.855214 1916.477991 \nL 690.564686 1916.998443 \nL 692.693103 1917.302852 \nL 693.402576 1917.703818 \nL 694.112048 1917.871034 \nL 694.82152 1917.60336 \nL 695.530993 1915.031801 \nL 699.078354 1913.951702 \nL 699.787827 1913.529603 \nL 700.497299 1915.87277 \nL 702.625716 1914.551198 \nL 703.335188 1915.452539 \nL 704.044661 1915.864262 \nL 705.463605 1914.32597 \nL 707.592022 1914.195077 \nL 708.301495 1914.478655 \nL 709.010967 1914.543727 \nL 709.72044 1913.399886 \nL 710.429912 1913.363377 \nL 712.558329 1907.936401 \nL 713.267801 1908.163655 \nL 713.977274 1905.548424 \nL 714.686746 1905.351629 \nL 715.396218 1904.879173 \nL 719.653052 1904.775608 \nL 720.362525 1902.263576 \nL 722.490942 1902.550336 \nL 723.200414 1903.305578 \nL 724.619359 1904.173156 \nL 725.328831 1904.041862 \nL 729.585665 1903.984153 \nL 730.295138 1902.376595 \nL 732.423555 1902.288337 \nL 733.133027 1901.766072 \nL 733.842499 1902.056142 \nL 734.551972 1902.1544 \nL 735.261444 1902.067656 \nL 738.099333 1902.107173 \nL 739.518278 1902.405734 \nL 742.356167 1902.002851 \nL 743.06564 1901.432229 \nL 743.775112 1901.432423 \nL 744.484584 1901.698577 \nL 745.194057 1902.171713 \nL 747.322474 1901.83256 \nL 748.031946 1901.880351 \nL 748.741419 1901.506688 \nL 749.450891 1901.625002 \nL 750.160363 1901.61936 \nL 752.28878 1902.031986 \nL 752.998253 1901.669319 \nL 753.707725 1902.079036 \nL 754.417197 1901.855757 \nL 755.12667 1902.644392 \nL 757.964559 1902.510388 \nL 759.383504 1901.660793 \nL 760.092976 1901.720657 \nL 762.930865 1902.180182 \nL 763.640338 1902.363051 \nL 764.34981 1902.004644 \nL 765.059283 1902.84241 \nL 767.1877 1902.382199 \nL 767.897172 1902.402712 \nL 768.606644 1903.356141 \nL 770.025589 1903.218746 \nL 772.863478 1902.676473 \nL 773.572951 1902.747743 \nL 774.282423 1902.330071 \nL 774.991895 1902.866802 \nL 777.120312 1903.070215 \nL 777.829785 1902.808585 \nL 778.539257 1903.075649 \nL 779.248729 1903.617609 \nL 779.958202 1903.975555 \nL 782.086619 1903.876205 \nL 782.796091 1902.048502 \nL 783.505564 1902.149066 \nL 784.215036 1903.380295 \nL 784.924508 1903.570193 \nL 787.052925 1904.264529 \nL 787.762398 1905.017981 \nL 788.47187 1907.578734 \nL 789.181342 1907.115276 \nL 789.890815 1907.219183 \nL 792.728704 1907.223066 \nL 793.438176 1907.878905 \nL 797.69501 1907.846752 \nL 798.404483 1907.579128 \nL 799.113955 1907.040477 \nL 799.823427 1907.288434 \nL 801.951844 1907.773226 \nL 802.661317 1907.690005 \nL 803.370789 1909.540863 \nL 804.789734 1909.237234 \nL 806.918151 1909.487764 \nL 807.627623 1909.096323 \nL 809.046568 1910.725547 \nL 809.75604 1910.450661 \nL 812.59393 1911.042637 \nL 813.303402 1911.571023 \nL 814.012874 1913.445257 \nL 814.722347 1916.02627 \nL 816.850764 1920.599692 \nL 817.560236 1920.514784 \nL 818.269708 1920.764246 \nL 818.979181 1920.81907 \nL 819.688653 1920.760935 \nL 821.81707 1920.06297 \nL 822.526543 1919.093897 \nL 823.236015 1919.391362 \nL 823.945487 1919.456885 \nL 823.945487 1919.456885 \n\" clip-path=\"url(#p7d900ebc36)\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_151\">\n    <path d=\"M 251.401304 1916.760528 \nL 252.110776 1916.582862 \nL 252.820249 1912.829956 \nL 253.529721 1912.787919 \nL 255.658138 1911.32246 \nL 256.367611 1911.463419 \nL 257.786555 1911.524877 \nL 258.496028 1908.948571 \nL 261.333917 1909.019324 \nL 262.043389 1908.510819 \nL 262.752862 1908.502285 \nL 263.462334 1909.028251 \nL 265.590751 1908.892011 \nL 266.300223 1910.236447 \nL 267.009696 1919.293237 \nL 267.719168 1920.305493 \nL 268.42864 1920.16741 \nL 270.557057 1920.463167 \nL 271.976002 1920.301819 \nL 272.685475 1920.443329 \nL 275.523364 1919.26257 \nL 276.232836 1919.31243 \nL 276.942309 1919.23961 \nL 277.651781 1919.047254 \nL 278.361253 1919.00021 \nL 280.48967 1919.561265 \nL 281.199143 1919.582509 \nL 282.618087 1919.824793 \nL 283.32756 1918.913203 \nL 285.455977 1918.787147 \nL 286.165449 1920.775926 \nL 286.874921 1922.404184 \nL 288.293866 1922.352877 \nL 290.422283 1922.771843 \nL 291.131755 1923.222092 \nL 291.841228 1924.802776 \nL 292.5507 1925.457079 \nL 293.260173 1925.753537 \nL 295.38859 1926.230091 \nL 296.098062 1926.712916 \nL 296.807534 1929.671995 \nL 297.517007 1929.467688 \nL 298.226479 1929.51708 \nL 300.354896 1930.305823 \nL 301.064368 1930.781226 \nL 301.773841 1932.447014 \nL 303.192785 1934.476837 \nL 306.740147 1934.502643 \nL 313.125398 1934.007474 \nL 315.253815 1932.259616 \nL 315.963288 1932.566294 \nL 316.67276 1932.537038 \nL 317.382232 1933.092894 \nL 318.091705 1933.185003 \nL 320.929594 1933.01519 \nL 321.639066 1933.069852 \nL 322.348539 1933.538898 \nL 323.058011 1933.56995 \nL 325.186428 1933.144993 \nL 325.8959 1933.479597 \nL 326.605373 1933.44997 \nL 327.314845 1933.859965 \nL 328.024317 1933.465847 \nL 332.990624 1933.311785 \nL 335.119041 1932.797557 \nL 337.247458 1932.809126 \nL 337.95693 1932.069672 \nL 340.79482 1931.862875 \nL 341.504292 1932.220213 \nL 342.923237 1932.30248 \nL 346.470598 1931.642732 \nL 347.180071 1933.077759 \nL 347.889543 1932.709088 \nL 350.01796 1932.542044 \nL 350.727433 1931.56322 \nL 352.146377 1931.521937 \nL 352.85585 1932.441297 \nL 357.112684 1931.966554 \nL 357.822156 1931.755973 \nL 359.950573 1931.588383 \nL 360.660045 1931.72852 \nL 361.369518 1932.039011 \nL 362.07899 1931.634787 \nL 362.788462 1932.043381 \nL 364.916879 1932.362927 \nL 365.626352 1931.807866 \nL 366.335824 1931.752626 \nL 367.045296 1932.000514 \nL 369.883186 1931.956954 \nL 370.592658 1931.978303 \nL 371.302131 1931.656469 \nL 372.011603 1931.09023 \nL 374.849492 1932.04835 \nL 375.558965 1933.000533 \nL 376.268437 1933.756607 \nL 376.977909 1943.159945 \nL 377.687382 1943.072115 \nL 379.815799 1943.460235 \nL 380.525271 1940.843465 \nL 381.234743 1942.38883 \nL 381.944216 1941.947667 \nL 382.653688 1942.3759 \nL 384.782105 1942.567614 \nL 385.491577 1947.672139 \nL 386.20105 1947.764086 \nL 386.910522 1950.0106 \nL 387.619995 1950.004333 \nL 389.748412 1949.624321 \nL 390.457884 1948.286593 \nL 391.167356 1952.410161 \nL 391.876829 1950.970141 \nL 392.586301 1950.924891 \nL 394.714718 1951.515675 \nL 396.133663 1951.548251 \nL 396.843135 1951.657963 \nL 399.681024 1951.401508 \nL 401.099969 1950.316438 \nL 406.775748 1950.312092 \nL 407.48522 1950.501097 \nL 409.613637 1947.502394 \nL 410.32311 1947.524538 \nL 411.032582 1946.378367 \nL 411.742054 1947.4403 \nL 412.451527 1945.825419 \nL 414.579944 1946.569601 \nL 415.289416 1946.135918 \nL 415.998888 1944.619103 \nL 416.708361 1942.532436 \nL 417.417833 1942.454002 \nL 420.255722 1939.54536 \nL 420.965195 1940.696438 \nL 421.674667 1939.301265 \nL 422.384139 1939.313378 \nL 424.512557 1938.533365 \nL 425.222029 1938.418249 \nL 425.931501 1938.552522 \nL 426.640974 1939.23915 \nL 427.350446 1937.869074 \nL 429.478863 1938.430339 \nL 430.188335 1938.331413 \nL 430.897808 1937.895754 \nL 431.60728 1938.046719 \nL 432.316752 1937.376017 \nL 435.154642 1937.471851 \nL 435.864114 1938.573228 \nL 436.573586 1938.562966 \nL 437.283059 1938.785403 \nL 440.120948 1938.676953 \nL 440.83042 1939.164368 \nL 441.539893 1939.155685 \nL 442.249365 1938.547503 \nL 445.087255 1938.25678 \nL 445.796727 1938.852121 \nL 446.506199 1940.689951 \nL 447.215672 1940.640358 \nL 449.344089 1939.906212 \nL 451.472506 1939.89023 \nL 454.310395 1939.08807 \nL 455.72934 1939.20624 \nL 456.438812 1939.249384 \nL 457.148284 1939.137149 \nL 461.405118 1938.857912 \nL 462.114591 1938.495829 \nL 464.243008 1938.903872 \nL 464.95248 1938.697838 \nL 465.661953 1939.027569 \nL 466.371425 1938.906568 \nL 467.080897 1937.668799 \nL 469.209314 1937.468289 \nL 469.918787 1938.130943 \nL 470.628259 1937.997709 \nL 471.337731 1937.986809 \nL 472.047204 1937.714672 \nL 474.175621 1938.385628 \nL 474.885093 1935.013061 \nL 476.304038 1934.984847 \nL 477.01351 1935.056125 \nL 479.141927 1935.034984 \nL 479.851399 1935.62484 \nL 481.979817 1935.589707 \nL 484.817706 1936.13942 \nL 485.527178 1937.430063 \nL 486.946123 1937.222727 \nL 491.202957 1936.688393 \nL 491.912429 1936.724051 \nL 494.750319 1936.615596 \nL 495.459791 1936.903679 \nL 496.169263 1936.876181 \nL 496.878736 1936.455149 \nL 499.007153 1936.945445 \nL 500.426098 1936.853112 \nL 501.13557 1937.097615 \nL 501.845042 1934.347777 \nL 505.392404 1934.402865 \nL 506.101876 1933.938364 \nL 506.811349 1934.504442 \nL 508.939766 1935.181259 \nL 509.649238 1935.169507 \nL 510.35871 1934.979973 \nL 511.068183 1934.405602 \nL 511.777655 1934.984042 \nL 514.615544 1934.969228 \nL 515.325017 1937.687974 \nL 516.034489 1937.800249 \nL 516.743961 1938.11054 \nL 518.872379 1935.027618 \nL 519.581851 1933.256141 \nL 520.291323 1933.195931 \nL 521.710268 1932.798899 \nL 523.838685 1931.318547 \nL 524.548157 1931.7221 \nL 525.25763 1932.571373 \nL 525.967102 1932.584446 \nL 526.676574 1933.333204 \nL 528.804991 1932.994688 \nL 529.514464 1932.550629 \nL 530.223936 1932.574744 \nL 530.933408 1932.369845 \nL 531.642881 1932.50375 \nL 533.771298 1932.772561 \nL 534.48077 1932.262772 \nL 535.190242 1932.475571 \nL 535.899715 1933.061158 \nL 536.609187 1932.142807 \nL 538.737604 1931.903493 \nL 539.447077 1933.354219 \nL 540.866021 1933.471669 \nL 541.575494 1933.521984 \nL 543.703911 1934.655525 \nL 544.413383 1934.833322 \nL 545.122855 1934.273073 \nL 546.5418 1937.570025 \nL 548.670217 1937.277477 \nL 549.379689 1939.022573 \nL 550.089162 1939.468508 \nL 550.798634 1939.572227 \nL 551.508106 1940.702875 \nL 553.636523 1940.708366 \nL 554.345996 1940.823686 \nL 556.474413 1940.408066 \nL 560.731247 1941.706888 \nL 561.440719 1941.678941 \nL 564.278609 1941.304862 \nL 564.988081 1942.189485 \nL 565.697553 1942.210515 \nL 571.373332 1941.669713 \nL 573.501749 1941.795623 \nL 574.211221 1942.134885 \nL 575.630166 1942.082558 \nL 576.339639 1942.143891 \nL 578.468056 1941.332597 \nL 579.177528 1941.733322 \nL 579.887 1941.971472 \nL 580.596473 1941.873206 \nL 581.305945 1941.527062 \nL 583.434362 1941.786842 \nL 584.143834 1941.749396 \nL 584.853307 1942.258215 \nL 585.562779 1942.251315 \nL 586.272251 1942.068627 \nL 589.110141 1942.14224 \nL 589.819613 1942.514208 \nL 590.529085 1942.356982 \nL 591.238558 1942.353818 \nL 594.78592 1943.120091 \nL 595.495392 1942.488211 \nL 596.204864 1942.462563 \nL 599.752226 1942.98076 \nL 600.461698 1944.431871 \nL 601.171171 1944.317494 \nL 604.718532 1944.39338 \nL 605.428005 1944.651424 \nL 606.137477 1944.522705 \nL 608.265894 1948.899928 \nL 610.394311 1948.780927 \nL 611.103783 1948.501941 \nL 613.941673 1948.398117 \nL 614.651145 1947.897583 \nL 615.360618 1947.247023 \nL 618.907979 1947.259168 \nL 619.617452 1947.156658 \nL 620.326924 1947.275349 \nL 621.036396 1947.124038 \nL 623.164813 1947.344882 \nL 623.874286 1947.259796 \nL 624.583758 1947.366626 \nL 625.29323 1947.288596 \nL 626.002703 1947.539716 \nL 628.13112 1947.526736 \nL 628.840592 1947.406095 \nL 629.550064 1947.128599 \nL 630.259537 1947.03396 \nL 630.969009 1947.254046 \nL 633.806899 1947.29955 \nL 634.516371 1947.58931 \nL 635.225843 1950.379754 \nL 638.063733 1950.281273 \nL 638.773205 1950.272555 \nL 639.482677 1950.695716 \nL 640.19215 1950.067852 \nL 640.901622 1949.717567 \nL 643.030039 1949.707994 \nL 643.739511 1949.849724 \nL 644.448984 1951.108455 \nL 645.158456 1950.882424 \nL 647.996345 1950.887652 \nL 648.705818 1949.897469 \nL 649.41529 1949.796816 \nL 650.124762 1949.575225 \nL 650.834235 1952.274204 \nL 659.347903 1954.165563 \nL 660.057375 1954.838967 \nL 660.766848 1956.594613 \nL 663.604737 1956.167408 \nL 664.314209 1956.092614 \nL 667.861571 1957.344592 \nL 668.571043 1957.011083 \nL 669.280516 1957.268652 \nL 669.989988 1956.314378 \nL 670.699461 1956.236753 \nL 672.827878 1957.652387 \nL 673.53735 1957.519302 \nL 674.246822 1958.019729 \nL 674.956295 1959.511956 \nL 675.665767 1959.36764 \nL 678.503656 1957.2568 \nL 679.213129 1958.45039 \nL 680.632073 1958.595361 \nL 682.76049 1956.392347 \nL 684.179435 1944.991605 \nL 684.888907 1944.209823 \nL 685.59838 1944.12617 \nL 687.726797 1944.389165 \nL 688.436269 1944.593245 \nL 689.145742 1944.512176 \nL 689.855214 1945.084702 \nL 690.564686 1944.520996 \nL 692.693103 1945.123485 \nL 693.402576 1945.470251 \nL 694.112048 1943.833854 \nL 694.82152 1944.073067 \nL 695.530993 1943.816007 \nL 699.078354 1943.794959 \nL 699.787827 1943.674702 \nL 700.497299 1944.286009 \nL 702.625716 1942.670531 \nL 703.335188 1941.954504 \nL 704.044661 1941.927171 \nL 705.463605 1942.248069 \nL 707.592022 1941.844448 \nL 708.301495 1941.986167 \nL 709.72044 1941.726925 \nL 710.429912 1942.432845 \nL 712.558329 1937.919334 \nL 713.267801 1937.920615 \nL 713.977274 1937.063523 \nL 714.686746 1937.01488 \nL 715.396218 1936.569122 \nL 719.653052 1936.636263 \nL 720.362525 1935.247418 \nL 723.909886 1934.938133 \nL 724.619359 1935.114158 \nL 725.328831 1935.008611 \nL 727.457248 1935.019883 \nL 728.166721 1934.561426 \nL 729.585665 1934.548892 \nL 730.295138 1933.334036 \nL 732.423555 1934.131113 \nL 733.133027 1933.58033 \nL 735.261444 1933.428058 \nL 738.099333 1933.546205 \nL 739.518278 1933.548215 \nL 744.484584 1932.868457 \nL 747.322474 1932.023053 \nL 748.031946 1931.637226 \nL 750.160363 1930.784372 \nL 752.28878 1931.316835 \nL 752.998253 1931.974952 \nL 753.707725 1931.737497 \nL 755.12667 1930.846964 \nL 757.964559 1930.462036 \nL 758.674031 1930.749584 \nL 759.383504 1930.252385 \nL 762.930865 1930.460099 \nL 763.640338 1929.823356 \nL 764.34981 1929.83408 \nL 765.059283 1929.967421 \nL 768.606644 1930.169536 \nL 769.316117 1930.11354 \nL 770.025589 1929.423054 \nL 772.863478 1929.324693 \nL 773.572951 1929.342975 \nL 774.282423 1929.10859 \nL 774.991895 1929.177309 \nL 777.120312 1929.638136 \nL 777.829785 1929.91284 \nL 778.539257 1929.806622 \nL 779.248729 1930.181934 \nL 779.958202 1929.913872 \nL 782.086619 1930.404456 \nL 782.796091 1929.818724 \nL 783.505564 1929.7466 \nL 784.215036 1930.185431 \nL 784.924508 1929.928858 \nL 787.052925 1930.256355 \nL 787.762398 1931.094641 \nL 788.47187 1931.721242 \nL 789.181342 1930.763537 \nL 789.890815 1930.865103 \nL 792.728704 1930.809847 \nL 793.438176 1930.991101 \nL 794.147649 1930.906525 \nL 794.857121 1930.973858 \nL 798.404483 1930.900591 \nL 799.113955 1930.597678 \nL 799.823427 1930.670777 \nL 801.951844 1931.259662 \nL 802.661317 1931.333471 \nL 803.370789 1930.952908 \nL 804.080262 1931.25368 \nL 804.789734 1931.208768 \nL 807.627623 1931.162369 \nL 808.337096 1932.769442 \nL 809.046568 1933.150782 \nL 809.75604 1932.560652 \nL 812.59393 1932.703776 \nL 813.303402 1932.563683 \nL 814.012874 1934.27379 \nL 814.722347 1939.055753 \nL 816.850764 1944.110777 \nL 817.560236 1944.885519 \nL 818.269708 1945.167235 \nL 819.688653 1945.14993 \nL 821.81707 1945.184353 \nL 822.526543 1944.89642 \nL 823.236015 1945.192765 \nL 823.945487 1945.192378 \nL 823.945487 1945.192378 \n\" clip-path=\"url(#p7d900ebc36)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_152\">\n    <path d=\"M 78.254578 1886.200271 \nL 859.454578 1886.200271 \n\" clip-path=\"url(#p7d900ebc36)\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n   </g>\n   <g id=\"line2d_153\">\n    <path d=\"M 78.254578 2028.428067 \nL 859.454578 2028.428067 \n\" clip-path=\"url(#p7d900ebc36)\" style=\"fill: none; stroke: #000000; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 78.254578 2037.584223 \nL 78.254578 1836.148795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 859.454578 2037.584223 \nL 859.454578 1836.148795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 78.254578 2037.584223 \nL 859.454578 2037.584223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 78.254578 1836.148795 \nL 859.454578 1836.148795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_61\">\n    <!-- Rolling volatility (6-month) -->\n    <g transform=\"translate(380.903391 1830.148795)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.164062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"153.947266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"181.730469\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"209.513672\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"272.892578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"336.369141\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"368.15625\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"427.335938\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"488.517578\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"516.300781\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"577.580078\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"616.789062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"644.572266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"672.355469\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"700.138672\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"739.347656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"798.527344\"/>\n     <use xlink:href=\"#DejaVuSans-28\" x=\"830.314453\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"869.328125\"/>\n     <use xlink:href=\"#DejaVuSans-2d\" x=\"932.951172\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"969.035156\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1066.447266\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1127.628906\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1191.007812\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1230.216797\"/>\n     <use xlink:href=\"#DejaVuSans-29\" x=\"1293.595703\"/>\n    </g>\n   </g>\n   <g id=\"legend_4\">\n    <g id=\"patch_35\">\n     <path d=\"M 687.424719 1899.110388 \nL 850.984578 1899.110388 \nQ 853.404578 1899.110388 853.404578 1896.690388 \nL 853.404578 1844.618795 \nQ 853.404578 1842.198795 850.984578 1842.198795 \nL 687.424719 1842.198795 \nQ 685.004719 1842.198795 685.004719 1844.618795 \nL 685.004719 1896.690388 \nQ 685.004719 1899.110388 687.424719 1899.110388 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_154\">\n     <path d=\"M 689.844719 1851.997904 \nL 701.944719 1851.997904 \nL 714.044719 1851.997904 \n\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_62\">\n     <!-- Volatility -->\n     <g transform=\"translate(723.724719 1856.232904)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.839844\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"149.623047\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"210.902344\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"250.111328\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"277.894531\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"305.677734\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"333.460938\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"372.669922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_155\">\n     <path d=\"M 689.844719 1869.758435 \nL 701.944719 1869.758435 \nL 714.044719 1869.758435 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_63\">\n     <!-- Benchmark volatility -->\n     <g transform=\"translate(723.724719 1873.993435)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-42\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"68.603516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"130.126953\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"193.505859\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"248.486328\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"311.865234\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"409.277344\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"470.556641\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"511.669922\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"569.580078\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"601.367188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"660.546875\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"721.728516\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"749.511719\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"810.791016\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"850\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"877.783203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"905.566406\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"933.349609\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"972.558594\"/>\n     </g>\n    </g>\n    <g id=\"line2d_156\">\n     <path d=\"M 689.844719 1887.518967 \nL 701.944719 1887.518967 \nL 714.044719 1887.518967 \n\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n    </g>\n    <g id=\"text_64\">\n     <!-- Average volatility -->\n     <g transform=\"translate(723.724719 1891.753967)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"62.533203\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"121.712891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"183.236328\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"224.349609\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"285.628906\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"349.105469\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"410.628906\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"442.416016\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"501.595703\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"562.777344\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"590.560547\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"651.839844\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"691.048828\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"718.832031\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"746.615234\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"774.398438\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"813.607422\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_7\">\n   <g id=\"patch_36\">\n    <path d=\"M 78.254578 2339.737366 \nL 859.454578 2339.737366 \nL 859.454578 2138.301937 \nL 78.254578 2138.301937 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_13\">\n    <g id=\"xtick_85\">\n     <g id=\"line2d_157\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_86\">\n     <g id=\"line2d_158\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_87\">\n     <g id=\"line2d_159\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_88\">\n     <g id=\"line2d_160\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_89\">\n     <g id=\"line2d_161\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_90\">\n     <g id=\"line2d_162\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_91\">\n     <g id=\"line2d_163\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_92\">\n     <g id=\"line2d_164\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_93\">\n     <g id=\"line2d_165\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"2339.737366\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_94\">\n     <g id=\"line2d_166\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_95\">\n     <g id=\"line2d_167\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_96\">\n     <g id=\"line2d_168\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_97\">\n     <g id=\"line2d_169\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_98\">\n     <g id=\"line2d_170\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"2339.737366\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_14\">\n    <g id=\"ytick_46\">\n     <g id=\"line2d_171\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2327.150559\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_65\">\n      <!-- -2.00 -->\n      <g transform=\"translate(37.447719 2331.747613)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_47\">\n     <g id=\"line2d_172\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2297.528301\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_66\">\n      <!-- -1.00 -->\n      <g transform=\"translate(37.447719 2302.125356)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"131.494141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"195.117188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_48\">\n     <g id=\"line2d_173\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2267.906043\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_67\">\n      <!-- 0.00 -->\n      <g transform=\"translate(41.813172 2272.503098)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_49\">\n     <g id=\"line2d_174\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2238.283786\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_68\">\n      <!-- 1.00 -->\n      <g transform=\"translate(41.813172 2242.88084)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_50\">\n     <g id=\"line2d_175\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2208.661528\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_69\">\n      <!-- 2.00 -->\n      <g transform=\"translate(41.813172 2213.258583)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_51\">\n     <g id=\"line2d_176\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2179.03927\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_70\">\n      <!-- 3.00 -->\n      <g transform=\"translate(41.813172 2183.636325)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_52\">\n     <g id=\"line2d_177\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2149.417013\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_71\">\n      <!-- 4.00 -->\n      <g transform=\"translate(41.813172 2154.014067)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_72\">\n     <!-- Sharpe ratio -->\n     <g transform=\"translate(30.702531 2279.715871)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"126.855469\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"188.134766\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"229.248047\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"292.724609\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"354.248047\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"386.035156\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"427.148438\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"488.427734\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"527.636719\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"555.419922\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_178\">\n    <path d=\"M 251.401304 2205.274209 \nL 252.110776 2203.698493 \nL 252.820249 2219.584922 \nL 253.529721 2216.987629 \nL 255.658138 2205.41869 \nL 257.077083 2202.089247 \nL 257.786555 2196.273538 \nL 258.496028 2207.227771 \nL 260.624445 2201.371209 \nL 261.333917 2202.485707 \nL 262.043389 2200.811632 \nL 262.752862 2195.51455 \nL 263.462334 2192.699065 \nL 265.590751 2191.063337 \nL 266.300223 2188.049813 \nL 267.009696 2167.795022 \nL 267.719168 2175.533654 \nL 268.42864 2178.657036 \nL 270.557057 2179.228528 \nL 271.976002 2195.585139 \nL 272.685475 2196.479293 \nL 273.394947 2196.254236 \nL 276.232836 2192.161149 \nL 276.942309 2200.628656 \nL 277.651781 2205.231273 \nL 278.361253 2200.151659 \nL 280.48967 2198.554554 \nL 281.199143 2200.653469 \nL 281.908615 2203.395766 \nL 282.618087 2201.966987 \nL 283.32756 2194.58094 \nL 285.455977 2191.812866 \nL 286.165449 2179.500138 \nL 286.874921 2180.961075 \nL 287.584394 2185.266349 \nL 288.293866 2191.549988 \nL 290.422283 2196.554501 \nL 291.131755 2191.555005 \nL 291.841228 2187.54214 \nL 292.5507 2191.259174 \nL 293.260173 2186.841389 \nL 295.38859 2180.367482 \nL 296.098062 2177.049838 \nL 296.807534 2166.555921 \nL 297.517007 2168.17252 \nL 298.226479 2162.186666 \nL 300.354896 2162.364385 \nL 301.064368 2168.421883 \nL 301.773841 2155.798164 \nL 302.483313 2169.871453 \nL 303.192785 2173.089589 \nL 305.321202 2167.218744 \nL 306.030675 2168.003943 \nL 306.740147 2167.390533 \nL 313.125398 2162.059567 \nL 315.253815 2154.637354 \nL 315.963288 2155.420082 \nL 316.67276 2155.177771 \nL 317.382232 2163.859324 \nL 318.091705 2165.342685 \nL 320.220122 2170.084679 \nL 320.929594 2164.702029 \nL 321.639066 2164.094831 \nL 322.348539 2169.733893 \nL 323.058011 2170.350881 \nL 325.186428 2169.905658 \nL 325.8959 2170.259161 \nL 326.605373 2168.451399 \nL 327.314845 2164.266473 \nL 328.024317 2165.733553 \nL 330.152735 2164.798385 \nL 330.862207 2160.370774 \nL 331.571679 2163.142034 \nL 332.281152 2159.757145 \nL 332.990624 2164.726147 \nL 335.119041 2162.141511 \nL 335.828513 2159.472158 \nL 336.537986 2164.305108 \nL 337.95693 2169.889572 \nL 340.79482 2168.073073 \nL 341.504292 2164.644316 \nL 342.923237 2155.491658 \nL 345.051654 2154.793651 \nL 345.761126 2155.901918 \nL 346.470598 2155.481525 \nL 347.180071 2148.794619 \nL 347.889543 2148.967097 \nL 350.01796 2152.383967 \nL 350.727433 2147.458093 \nL 351.436905 2148.599805 \nL 352.146377 2151.436696 \nL 352.85585 2155.964505 \nL 354.984267 2158.848202 \nL 355.693739 2160.996939 \nL 356.403211 2162.045295 \nL 357.112684 2160.327914 \nL 357.822156 2167.193515 \nL 359.950573 2167.795162 \nL 360.660045 2163.94561 \nL 361.369518 2161.01709 \nL 362.07899 2153.510958 \nL 362.788462 2148.281282 \nL 364.916879 2148.155449 \nL 365.626352 2155.544689 \nL 366.335824 2152.692564 \nL 367.045296 2154.291146 \nL 367.754769 2151.011005 \nL 369.883186 2148.153709 \nL 370.592658 2155.117487 \nL 371.302131 2153.285937 \nL 372.011603 2150.316478 \nL 374.849492 2149.759025 \nL 375.558965 2150.627224 \nL 376.977909 2155.558115 \nL 377.687382 2153.862046 \nL 379.815799 2159.510935 \nL 380.525271 2160.604418 \nL 381.234743 2149.758909 \nL 381.944216 2166.465058 \nL 382.653688 2169.393995 \nL 384.782105 2166.41401 \nL 385.491577 2160.864978 \nL 386.20105 2161.308373 \nL 386.910522 2164.819368 \nL 387.619995 2165.258872 \nL 389.748412 2166.365396 \nL 390.457884 2177.483157 \nL 391.167356 2162.4518 \nL 391.876829 2179.222466 \nL 392.586301 2184.308833 \nL 394.714718 2189.698551 \nL 395.42419 2188.817271 \nL 396.133663 2189.688255 \nL 396.843135 2196.264303 \nL 397.552607 2194.330801 \nL 399.681024 2193.690251 \nL 400.390497 2182.938868 \nL 401.099969 2179.681227 \nL 406.775748 2176.90056 \nL 407.48522 2172.258627 \nL 409.613637 2168.156334 \nL 410.32311 2169.891515 \nL 411.032582 2183.71324 \nL 411.742054 2186.62032 \nL 412.451527 2196.081219 \nL 414.579944 2189.096807 \nL 415.289416 2191.866854 \nL 415.998888 2193.065229 \nL 416.708361 2209.253716 \nL 417.417833 2211.151786 \nL 419.54625 2218.642875 \nL 420.255722 2223.647154 \nL 420.965195 2227.124462 \nL 421.674667 2223.634407 \nL 422.384139 2226.563272 \nL 424.512557 2230.697573 \nL 425.222029 2227.354053 \nL 425.931501 2220.620867 \nL 426.640974 2216.948183 \nL 427.350446 2223.566071 \nL 429.478863 2217.698982 \nL 430.188335 2222.332878 \nL 430.897808 2232.690661 \nL 431.60728 2231.476593 \nL 432.316752 2224.949336 \nL 434.445169 2225.641682 \nL 435.154642 2222.423894 \nL 435.864114 2222.435671 \nL 437.283059 2213.276949 \nL 440.120948 2214.681513 \nL 440.83042 2206.889984 \nL 441.539893 2207.0192 \nL 442.249365 2211.507326 \nL 445.087255 2220.541321 \nL 445.796727 2225.317714 \nL 446.506199 2232.227874 \nL 447.215672 2232.982461 \nL 449.344089 2229.772896 \nL 450.053561 2225.67162 \nL 451.472506 2211.811479 \nL 452.181978 2212.916241 \nL 454.310395 2211.868245 \nL 455.019867 2207.101343 \nL 455.72934 2205.034011 \nL 456.438812 2202.473248 \nL 457.148284 2206.145535 \nL 461.405118 2204.441132 \nL 462.114591 2206.101062 \nL 464.243008 2203.134483 \nL 464.95248 2209.983512 \nL 465.661953 2208.494693 \nL 466.371425 2209.473134 \nL 467.080897 2212.977269 \nL 469.209314 2203.308042 \nL 469.918787 2206.598323 \nL 470.628259 2207.207204 \nL 471.337731 2208.173466 \nL 472.047204 2203.517508 \nL 474.175621 2201.616431 \nL 474.885093 2200.16017 \nL 475.594565 2201.705259 \nL 476.304038 2202.054373 \nL 477.01351 2201.79468 \nL 479.851399 2207.60056 \nL 480.560872 2210.146017 \nL 481.270344 2209.456662 \nL 481.979817 2209.113558 \nL 484.108234 2207.202688 \nL 484.817706 2208.796034 \nL 485.527178 2209.262397 \nL 486.236651 2201.839826 \nL 486.946123 2198.056151 \nL 489.784012 2200.097339 \nL 490.493485 2204.597707 \nL 491.202957 2198.739902 \nL 491.912429 2195.385915 \nL 494.040846 2198.73273 \nL 494.750319 2193.339661 \nL 495.459791 2195.792455 \nL 496.169263 2197.546046 \nL 496.878736 2194.294015 \nL 499.007153 2197.643154 \nL 499.716625 2200.517803 \nL 500.426098 2200.285511 \nL 501.13557 2194.335195 \nL 501.845042 2201.145436 \nL 503.973459 2212.889914 \nL 504.682932 2219.113148 \nL 505.392404 2217.356252 \nL 506.101876 2216.657861 \nL 506.811349 2225.333065 \nL 508.939766 2227.407012 \nL 509.649238 2228.893698 \nL 510.35871 2251.716851 \nL 511.068183 2252.076205 \nL 511.777655 2258.429249 \nL 513.906072 2255.225781 \nL 514.615544 2255.630964 \nL 515.325017 2255.299092 \nL 516.034489 2258.334217 \nL 516.743961 2255.041696 \nL 518.872379 2256.105939 \nL 519.581851 2265.175124 \nL 520.291323 2259.255095 \nL 521.000796 2256.401285 \nL 521.710268 2258.482489 \nL 523.838685 2255.263059 \nL 524.548157 2252.203338 \nL 525.25763 2245.468513 \nL 525.967102 2247.910242 \nL 526.676574 2240.134902 \nL 528.804991 2236.242394 \nL 529.514464 2234.642634 \nL 530.223936 2239.832629 \nL 530.933408 2237.264673 \nL 531.642881 2235.670688 \nL 533.771298 2236.869338 \nL 535.190242 2246.756543 \nL 535.899715 2252.691538 \nL 536.609187 2262.733856 \nL 539.447077 2251.457166 \nL 540.156549 2247.338104 \nL 540.866021 2240.750607 \nL 541.575494 2240.376233 \nL 543.703911 2231.662325 \nL 544.413383 2235.352301 \nL 545.122855 2230.890526 \nL 545.832328 2232.302018 \nL 546.5418 2225.18476 \nL 548.670217 2220.979017 \nL 549.379689 2206.056906 \nL 550.089162 2203.043344 \nL 550.798634 2205.212704 \nL 551.508106 2205.927395 \nL 553.636523 2202.421035 \nL 554.345996 2203.128436 \nL 555.055468 2207.858229 \nL 555.76494 2213.679475 \nL 560.021775 2207.20193 \nL 560.731247 2207.880724 \nL 561.440719 2202.725098 \nL 563.569136 2202.322911 \nL 564.278609 2207.763955 \nL 564.988081 2220.607407 \nL 565.697553 2217.417175 \nL 571.373332 2219.323755 \nL 573.501749 2221.530128 \nL 574.211221 2225.056645 \nL 574.920694 2224.976144 \nL 575.630166 2229.011143 \nL 576.339639 2232.372233 \nL 578.468056 2232.591019 \nL 579.177528 2229.734126 \nL 579.887 2226.363756 \nL 580.596473 2222.384917 \nL 581.305945 2224.019645 \nL 583.434362 2221.536716 \nL 584.143834 2223.963881 \nL 584.853307 2228.995374 \nL 585.562779 2232.051596 \nL 586.272251 2233.837231 \nL 588.400668 2239.800408 \nL 589.110141 2244.121939 \nL 589.819613 2244.945659 \nL 591.238558 2250.894473 \nL 593.366975 2254.210524 \nL 594.076447 2253.35732 \nL 594.78592 2259.50827 \nL 595.495392 2258.570906 \nL 596.204864 2261.913889 \nL 598.333281 2259.324948 \nL 599.042754 2261.064917 \nL 599.752226 2257.679711 \nL 600.461698 2261.648662 \nL 601.171171 2268.61184 \nL 604.00906 2269.054982 \nL 604.718532 2264.993616 \nL 605.428005 2269.06043 \nL 606.137477 2267.340711 \nL 608.265894 2267.619574 \nL 608.975366 2262.789206 \nL 609.684839 2262.918806 \nL 610.394311 2264.714893 \nL 611.103783 2267.72646 \nL 613.232201 2267.771016 \nL 614.651145 2256.983111 \nL 615.360618 2256.192742 \nL 616.07009 2256.591081 \nL 618.198507 2254.20478 \nL 619.617452 2268.39467 \nL 620.326924 2269.607569 \nL 621.036396 2269.979693 \nL 623.164813 2263.623579 \nL 624.583758 2273.265602 \nL 625.29323 2270.017575 \nL 626.002703 2277.982586 \nL 628.13112 2276.331068 \nL 628.840592 2273.25983 \nL 629.550064 2282.925524 \nL 630.259537 2287.524411 \nL 630.969009 2282.932838 \nL 633.806899 2286.003688 \nL 634.516371 2289.019948 \nL 635.225843 2288.890939 \nL 635.935316 2277.655144 \nL 638.063733 2278.019403 \nL 638.773205 2286.667049 \nL 639.482677 2280.646265 \nL 640.19215 2276.478053 \nL 640.901622 2279.462697 \nL 643.030039 2289.568069 \nL 643.739511 2263.055918 \nL 644.448984 2267.769371 \nL 645.158456 2266.196095 \nL 645.867928 2275.825225 \nL 647.996345 2271.697421 \nL 648.705818 2283.116992 \nL 649.41529 2280.439034 \nL 650.124762 2278.986867 \nL 650.834235 2278.62085 \nL 657.928958 2261.231334 \nL 658.638431 2259.835635 \nL 659.347903 2265.753096 \nL 660.057375 2268.048724 \nL 660.766848 2279.186453 \nL 662.895265 2289.887189 \nL 663.604737 2294.761799 \nL 665.023682 2288.636289 \nL 665.733154 2286.472726 \nL 667.861571 2288.945017 \nL 668.571043 2288.493011 \nL 669.280516 2290.05077 \nL 669.989988 2291.94282 \nL 670.699461 2287.495137 \nL 672.827878 2275.979025 \nL 673.53735 2276.357188 \nL 674.246822 2273.049101 \nL 674.956295 2261.595824 \nL 675.665767 2275.107601 \nL 677.794184 2282.669763 \nL 678.503656 2293.305248 \nL 679.213129 2293.949069 \nL 679.922601 2291.853522 \nL 680.632073 2291.33056 \nL 682.76049 2298.184266 \nL 683.469963 2306.359755 \nL 684.179435 2293.888641 \nL 684.888907 2290.344453 \nL 685.59838 2289.596283 \nL 687.726797 2295.78762 \nL 688.436269 2296.441069 \nL 689.145742 2296.156586 \nL 689.855214 2306.208729 \nL 690.564686 2319.052353 \nL 692.693103 2312.932176 \nL 693.402576 2306.326861 \nL 694.112048 2297.310028 \nL 694.82152 2307.541614 \nL 695.530993 2298.997401 \nL 699.078354 2306.055554 \nL 699.787827 2310.717782 \nL 700.497299 2302.433421 \nL 702.625716 2305.455687 \nL 703.335188 2292.728982 \nL 704.044661 2295.235719 \nL 704.754133 2290.337707 \nL 705.463605 2295.121948 \nL 707.592022 2296.45306 \nL 708.301495 2300.05384 \nL 709.010967 2299.724584 \nL 709.72044 2303.880066 \nL 710.429912 2303.010875 \nL 712.558329 2318.260948 \nL 713.267801 2316.222845 \nL 713.977274 2307.605441 \nL 714.686746 2305.102939 \nL 715.396218 2303.413681 \nL 719.653052 2300.776254 \nL 720.362525 2306.653235 \nL 722.490942 2304.708368 \nL 723.200414 2309.10616 \nL 723.909886 2303.65388 \nL 724.619359 2301.195199 \nL 725.328831 2299.337137 \nL 727.457248 2302.315166 \nL 728.166721 2296.033752 \nL 728.876193 2298.087438 \nL 729.585665 2299.426919 \nL 730.295138 2289.24521 \nL 732.423555 2288.56305 \nL 733.133027 2292.63056 \nL 733.842499 2287.37419 \nL 734.551972 2289.101798 \nL 735.261444 2287.887037 \nL 737.389861 2287.408392 \nL 738.099333 2287.92417 \nL 738.808806 2290.762036 \nL 739.518278 2292.185911 \nL 742.356167 2287.033982 \nL 743.06564 2282.42907 \nL 743.775112 2282.181666 \nL 744.484584 2290.062482 \nL 745.194057 2292.659728 \nL 747.322474 2295.392896 \nL 748.031946 2295.750461 \nL 748.741419 2290.826668 \nL 749.450891 2295.061638 \nL 750.160363 2295.015311 \nL 752.28878 2299.489115 \nL 752.998253 2304.97082 \nL 753.707725 2308.950627 \nL 754.417197 2306.519006 \nL 755.12667 2299.222438 \nL 757.255087 2298.416041 \nL 757.964559 2297.976916 \nL 758.674031 2299.6414 \nL 759.383504 2296.092289 \nL 760.092976 2296.680972 \nL 762.221393 2292.168396 \nL 762.930865 2293.258779 \nL 763.640338 2292.819894 \nL 764.34981 2289.359908 \nL 765.059283 2294.450515 \nL 767.1877 2295.958135 \nL 767.897172 2295.840149 \nL 768.606644 2301.37792 \nL 769.316117 2303.044923 \nL 770.025589 2303.333934 \nL 772.154006 2295.540447 \nL 772.863478 2297.845017 \nL 773.572951 2296.7961 \nL 774.282423 2298.798319 \nL 774.991895 2301.867977 \nL 777.120312 2300.990996 \nL 777.829785 2297.894809 \nL 778.539257 2296.359648 \nL 779.248729 2301.056501 \nL 779.958202 2298.772731 \nL 782.086619 2299.664612 \nL 783.505564 2308.338716 \nL 784.215036 2300.476387 \nL 784.924508 2301.263955 \nL 787.052925 2295.897089 \nL 787.762398 2289.784672 \nL 788.47187 2300.76596 \nL 789.181342 2298.078116 \nL 789.890815 2299.701519 \nL 792.019232 2300.813097 \nL 792.728704 2300.578084 \nL 793.438176 2294.742059 \nL 794.147649 2299.188218 \nL 794.857121 2299.057192 \nL 796.985538 2299.948802 \nL 797.69501 2303.100728 \nL 798.404483 2305.394094 \nL 799.113955 2301.67303 \nL 799.823427 2306.079633 \nL 802.661317 2302.947364 \nL 803.370789 2310.465332 \nL 804.080262 2315.793229 \nL 804.789734 2320.22314 \nL 806.918151 2323.021684 \nL 808.337096 2312.073912 \nL 809.046568 2308.142527 \nL 809.75604 2303.094109 \nL 812.59393 2307.406525 \nL 813.303402 2314.798048 \nL 814.012874 2309.655957 \nL 814.722347 2305.621597 \nL 816.850764 2320.90246 \nL 817.560236 2319.20085 \nL 818.269708 2321.250317 \nL 818.979181 2323.862988 \nL 819.688653 2327.332884 \nL 821.81707 2330.58121 \nL 822.526543 2324.403998 \nL 823.236015 2323.657456 \nL 823.945487 2324.159595 \nL 823.945487 2324.159595 \n\" clip-path=\"url(#peb71f1c2ab)\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_179\">\n    <path d=\"M 78.254578 2236.449796 \nL 859.454578 2236.449796 \n\" clip-path=\"url(#peb71f1c2ab)\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n   </g>\n   <g id=\"line2d_180\">\n    <path d=\"M 78.254578 2267.906043 \nL 859.454578 2267.906043 \n\" clip-path=\"url(#peb71f1c2ab)\" style=\"fill: none; stroke: #000000; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_37\">\n    <path d=\"M 78.254578 2339.737366 \nL 78.254578 2138.301937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_38\">\n    <path d=\"M 859.454578 2339.737366 \nL 859.454578 2138.301937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 78.254578 2339.737366 \nL 859.454578 2339.737366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_40\">\n    <path d=\"M 78.254578 2138.301937 \nL 859.454578 2138.301937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_73\">\n    <!-- Rolling Sharpe ratio (6-month) -->\n    <g transform=\"translate(368.611922 2132.301937)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.164062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"153.947266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"181.730469\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"209.513672\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"272.892578\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"336.369141\"/>\n     <use xlink:href=\"#DejaVuSans-53\" x=\"368.15625\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"431.632812\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"495.011719\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"556.291016\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"597.404297\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"660.880859\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"722.404297\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"754.191406\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"795.304688\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"856.583984\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"895.792969\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"923.576172\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"984.757812\"/>\n     <use xlink:href=\"#DejaVuSans-28\" x=\"1016.544922\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"1055.558594\"/>\n     <use xlink:href=\"#DejaVuSans-2d\" x=\"1119.181641\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"1155.265625\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1252.677734\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1313.859375\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1377.238281\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1416.447266\"/>\n     <use xlink:href=\"#DejaVuSans-29\" x=\"1479.826172\"/>\n    </g>\n   </g>\n   <g id=\"legend_5\">\n    <g id=\"patch_41\">\n     <path d=\"M 762.575172 2183.503 \nL 850.984578 2183.503 \nQ 853.404578 2183.503 853.404578 2181.083 \nL 853.404578 2146.771937 \nQ 853.404578 2144.351937 850.984578 2144.351937 \nL 762.575172 2144.351937 \nQ 760.155172 2144.351937 760.155172 2146.771937 \nL 760.155172 2181.083 \nQ 760.155172 2183.503 762.575172 2183.503 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_181\">\n     <path d=\"M 764.995172 2154.151047 \nL 777.095172 2154.151047 \nL 789.195172 2154.151047 \n\" style=\"fill: none; stroke: #ff4500; stroke-opacity: 0.7; stroke-width: 3; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_74\">\n     <!-- Sharpe -->\n     <g transform=\"translate(798.875172 2158.386047)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"126.855469\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"188.134766\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"229.248047\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"292.724609\"/>\n     </g>\n    </g>\n    <g id=\"line2d_182\">\n     <path d=\"M 764.995172 2171.911578 \nL 777.095172 2171.911578 \nL 789.195172 2171.911578 \n\" style=\"fill: none; stroke-dasharray: 11.1,4.8; stroke-dashoffset: 0; stroke: #4682b4; stroke-width: 3\"/>\n    </g>\n    <g id=\"text_75\">\n     <!-- Average -->\n     <g transform=\"translate(798.875172 2176.146578)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"62.533203\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"121.712891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"183.236328\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"224.349609\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"285.628906\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"349.105469\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_8\">\n   <g id=\"patch_42\">\n    <path d=\"M 78.254578 2641.890509 \nL 859.454578 2641.890509 \nL 859.454578 2440.45508 \nL 78.254578 2440.45508 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"PolyCollection_1\">\n    <defs>\n     <path id=\"me962b10091\" d=\"M 500.426098 -1136.305388 \nL 500.426098 -934.86996 \nL 823.945487 -934.86996 \nL 823.945487 -1136.305388 \nL 823.945487 -1136.305388 \nL 500.426098 -1136.305388 \nz\n\" style=\"stroke: #2d1e3e; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p4ada1e5541)\">\n     <use xlink:href=\"#me962b10091\" x=\"0\" y=\"3576.760469\" style=\"fill: #2d1e3e; fill-opacity: 0.4; stroke: #2d1e3e; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_2\">\n    <defs>\n     <path id=\"mad3e731538\" d=\"M 406.775748 -1136.305388 \nL 406.775748 -934.86996 \nL 469.209314 -934.86996 \nL 469.209314 -1136.305388 \nL 469.209314 -1136.305388 \nL 406.775748 -1136.305388 \nz\n\" style=\"stroke: #6e4071; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p4ada1e5541)\">\n     <use xlink:href=\"#mad3e731538\" x=\"0\" y=\"3576.760469\" style=\"fill: #6e4071; fill-opacity: 0.4; stroke: #6e4071; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_3\">\n    <defs>\n     <path id=\"md75fba248b\" d=\"M 158.460427 -1136.305388 \nL 158.460427 -934.86996 \nL 236.502385 -934.86996 \nL 236.502385 -1136.305388 \nL 236.502385 -1136.305388 \nL 158.460427 -1136.305388 \nz\n\" style=\"stroke: #aa688f; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p4ada1e5541)\">\n     <use xlink:href=\"#md75fba248b\" x=\"0\" y=\"3576.760469\" style=\"fill: #aa688f; fill-opacity: 0.4; stroke: #aa688f; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_4\">\n    <defs>\n     <path id=\"m32410dd37e\" d=\"M 381.234743 -1136.305388 \nL 381.234743 -934.86996 \nL 406.775748 -934.86996 \nL 406.775748 -1136.305388 \nL 406.775748 -1136.305388 \nL 381.234743 -1136.305388 \nz\n\" style=\"stroke: #d499a7; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p4ada1e5541)\">\n     <use xlink:href=\"#m32410dd37e\" x=\"0\" y=\"3576.760469\" style=\"fill: #d499a7; fill-opacity: 0.4; stroke: #d499a7; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_5\">\n    <defs>\n     <path id=\"m11b759b967\" d=\"M 124.405754 -1136.305388 \nL 124.405754 -934.86996 \nL 146.399397 -934.86996 \nL 146.399397 -1136.305388 \nL 146.399397 -1136.305388 \nL 124.405754 -1136.305388 \nz\n\" style=\"stroke: #edd1cb; stroke-opacity: 0.4\"/>\n    </defs>\n    <g clip-path=\"url(#p4ada1e5541)\">\n     <use xlink:href=\"#m11b759b967\" x=\"0\" y=\"3576.760469\" style=\"fill: #edd1cb; fill-opacity: 0.4; stroke: #edd1cb; stroke-opacity: 0.4\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_15\">\n    <g id=\"xtick_99\">\n     <g id=\"line2d_183\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_100\">\n     <g id=\"line2d_184\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_101\">\n     <g id=\"line2d_185\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_102\">\n     <g id=\"line2d_186\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_103\">\n     <g id=\"line2d_187\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_104\">\n     <g id=\"line2d_188\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_105\">\n     <g id=\"line2d_189\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_106\">\n     <g id=\"line2d_190\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_107\">\n     <g id=\"line2d_191\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"2641.890509\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_108\">\n     <g id=\"line2d_192\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_109\">\n     <g id=\"line2d_193\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_110\">\n     <g id=\"line2d_194\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_111\">\n     <g id=\"line2d_195\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_112\">\n     <g id=\"line2d_196\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"2641.890509\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_16\">\n    <g id=\"ytick_53\">\n     <g id=\"line2d_197\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2622.351485\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_76\">\n      <!-- 1.00 -->\n      <g transform=\"translate(41.813172 2626.94854)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_54\">\n     <g id=\"line2d_198\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2598.38028\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_77\">\n      <!-- 1.25 -->\n      <g transform=\"translate(41.813172 2602.977335)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_55\">\n     <g id=\"line2d_199\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2574.409076\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_78\">\n      <!-- 1.50 -->\n      <g transform=\"translate(41.813172 2579.00613)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_56\">\n     <g id=\"line2d_200\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2550.437871\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_79\">\n      <!-- 1.75 -->\n      <g transform=\"translate(41.813172 2555.034926)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_57\">\n     <g id=\"line2d_201\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2526.466666\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_80\">\n      <!-- 2.00 -->\n      <g transform=\"translate(41.813172 2531.063721)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_58\">\n     <g id=\"line2d_202\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2502.495462\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_81\">\n      <!-- 2.25 -->\n      <g transform=\"translate(41.813172 2507.092516)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_59\">\n     <g id=\"line2d_203\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2478.524257\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_82\">\n      <!-- 2.50 -->\n      <g transform=\"translate(41.813172 2483.121312)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_60\">\n     <g id=\"line2d_204\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2454.553052\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_83\">\n      <!-- 2.75 -->\n      <g transform=\"translate(41.813172 2459.150107)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_84\">\n     <!-- Cumulative returns -->\n     <g transform=\"translate(35.067984 2604.554451)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n      <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"602.539062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"641.402344\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"702.925781\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"742.134766\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"805.513672\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"844.876953\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"908.255859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_205\">\n    <path d=\"M 113.763669 2622.351485 \nL 114.473141 2622.439719 \nL 116.601558 2622.444925 \nL 117.311031 2622.192329 \nL 118.020503 2623.076843 \nL 118.729975 2621.975993 \nL 119.439448 2622.109691 \nL 121.567865 2620.983785 \nL 122.277337 2621.279589 \nL 122.98681 2622.074185 \nL 123.696282 2622.338115 \nL 124.405754 2620.707938 \nL 126.534171 2620.902251 \nL 127.243644 2621.754674 \nL 127.953116 2621.47865 \nL 128.662588 2624.215074 \nL 136.466784 2630.48905 \nL 137.176256 2628.777257 \nL 137.885729 2626.185002 \nL 138.595201 2624.926234 \nL 141.433091 2624.102217 \nL 142.142563 2623.535096 \nL 142.852035 2622.009921 \nL 143.561508 2621.34228 \nL 144.27098 2621.019385 \nL 146.399397 2618.670861 \nL 147.108869 2618.68661 \nL 147.818342 2619.662938 \nL 148.527814 2618.154549 \nL 149.237286 2617.897591 \nL 151.365703 2618.507713 \nL 152.075176 2617.428383 \nL 152.784648 2618.781929 \nL 153.49412 2618.428334 \nL 154.203593 2622.044103 \nL 156.33201 2620.223966 \nL 157.041482 2619.221991 \nL 157.750954 2618.822879 \nL 158.460427 2617.234336 \nL 159.169899 2618.66939 \nL 161.298316 2622.664163 \nL 162.007789 2620.722608 \nL 162.717261 2621.084946 \nL 163.426733 2623.431033 \nL 164.136206 2624.603616 \nL 166.264623 2628.521281 \nL 166.974095 2628.485554 \nL 167.683567 2629.757228 \nL 168.39304 2630.597946 \nL 169.102512 2629.603429 \nL 171.230929 2632.734353 \nL 171.940401 2629.721945 \nL 172.649874 2628.039957 \nL 173.359346 2628.462989 \nL 174.068818 2627.585541 \nL 176.197235 2628.437852 \nL 176.906708 2627.912492 \nL 177.61618 2628.160941 \nL 178.325653 2626.415467 \nL 179.035125 2626.510033 \nL 181.873014 2624.556181 \nL 183.291959 2625.336977 \nL 184.001431 2626.486257 \nL 186.129848 2626.931627 \nL 186.839321 2624.580048 \nL 187.548793 2625.303049 \nL 188.258265 2624.76591 \nL 188.967738 2623.289391 \nL 191.096155 2623.038136 \nL 191.805627 2623.983004 \nL 192.515099 2623.054962 \nL 193.224572 2622.962072 \nL 193.934044 2624.218548 \nL 196.062461 2624.29235 \nL 196.771933 2622.479087 \nL 197.481406 2621.911675 \nL 198.190878 2620.278335 \nL 202.447712 2620.507265 \nL 203.157185 2621.007105 \nL 203.866657 2620.571368 \nL 205.995074 2621.35165 \nL 206.704546 2620.875055 \nL 207.414019 2621.268462 \nL 208.123491 2622.794617 \nL 208.832963 2623.657606 \nL 210.96138 2622.776638 \nL 211.670853 2621.138013 \nL 212.380325 2621.774339 \nL 213.089797 2623.591794 \nL 213.79927 2626.267491 \nL 215.927687 2625.735037 \nL 216.637159 2624.556114 \nL 217.346632 2625.282762 \nL 218.056104 2625.466877 \nL 218.765576 2625.03838 \nL 220.893993 2622.166138 \nL 221.603466 2622.008501 \nL 222.312938 2621.405462 \nL 223.02241 2621.966201 \nL 223.731883 2621.58629 \nL 226.569772 2619.007847 \nL 227.279244 2619.466092 \nL 227.988717 2619.757469 \nL 228.698189 2620.618262 \nL 230.826606 2621.688604 \nL 231.536078 2620.257035 \nL 232.245551 2620.455874 \nL 233.664495 2618.838097 \nL 236.502385 2617.151434 \nL 237.211857 2615.180612 \nL 240.759219 2615.11193 \nL 241.468691 2614.362021 \nL 242.178164 2610.192114 \nL 243.597108 2604.747788 \nL 245.725525 2598.587462 \nL 246.434998 2598.870622 \nL 247.853942 2592.50804 \nL 248.563415 2596.118448 \nL 250.691832 2592.71521 \nL 251.401304 2593.176154 \nL 252.110776 2592.395252 \nL 252.820249 2600.000068 \nL 253.529721 2598.154288 \nL 256.367611 2588.786558 \nL 257.077083 2587.842694 \nL 257.786555 2581.448429 \nL 258.496028 2588.23317 \nL 260.624445 2585.160383 \nL 261.333917 2586.261111 \nL 262.752862 2578.811045 \nL 263.462334 2578.022898 \nL 265.590751 2576.361486 \nL 266.300223 2578.508196 \nL 267.009696 2576.715479 \nL 267.719168 2579.259949 \nL 268.42864 2577.837081 \nL 270.557057 2576.355297 \nL 271.976002 2585.123223 \nL 272.685475 2584.933745 \nL 273.394947 2582.614284 \nL 276.232836 2578.073458 \nL 277.651781 2583.7622 \nL 278.361253 2581.525627 \nL 280.48967 2578.130385 \nL 281.199143 2579.238967 \nL 281.908615 2581.873571 \nL 282.618087 2579.281096 \nL 283.32756 2575.614086 \nL 285.455977 2572.881441 \nL 286.165449 2569.566986 \nL 286.874921 2568.017579 \nL 287.584394 2569.718373 \nL 288.293866 2573.464622 \nL 290.422283 2574.944594 \nL 291.131755 2573.364726 \nL 291.841228 2576.862583 \nL 292.5507 2576.876457 \nL 293.260173 2574.03233 \nL 295.38859 2573.224547 \nL 296.098062 2572.741864 \nL 296.807534 2572.764539 \nL 297.517007 2573.789785 \nL 298.226479 2571.713671 \nL 300.354896 2573.216777 \nL 301.064368 2575.638127 \nL 301.773841 2572.890313 \nL 302.483313 2577.56702 \nL 303.192785 2577.311903 \nL 305.321202 2573.505217 \nL 306.030675 2572.680687 \nL 306.740147 2573.6604 \nL 313.125398 2567.847766 \nL 315.963288 2558.83401 \nL 316.67276 2558.812352 \nL 317.382232 2562.161894 \nL 318.091705 2563.793604 \nL 320.220122 2567.636809 \nL 320.929594 2565.435005 \nL 321.639066 2565.735256 \nL 322.348539 2566.57038 \nL 323.058011 2568.163399 \nL 325.186428 2566.93979 \nL 326.605373 2562.969613 \nL 327.314845 2561.29553 \nL 330.152735 2560.057255 \nL 330.862207 2558.814659 \nL 331.571679 2560.941161 \nL 332.281152 2553.778987 \nL 332.990624 2556.64024 \nL 335.828513 2548.994417 \nL 336.537986 2553.401299 \nL 337.247458 2554.814219 \nL 337.95693 2558.291775 \nL 340.085347 2556.352128 \nL 340.79482 2556.569411 \nL 341.504292 2556.476995 \nL 342.213764 2553.672705 \nL 342.923237 2547.307497 \nL 345.051654 2543.589498 \nL 345.761126 2545.635392 \nL 346.470598 2548.576997 \nL 347.180071 2548.382234 \nL 347.889543 2547.556789 \nL 350.01796 2548.466099 \nL 350.727433 2545.255527 \nL 351.436905 2546.542052 \nL 352.146377 2548.150086 \nL 352.85585 2547.740956 \nL 355.693739 2550.627694 \nL 356.403211 2552.423929 \nL 357.112684 2550.157709 \nL 357.822156 2552.858477 \nL 359.950573 2552.310331 \nL 360.660045 2549.566728 \nL 361.369518 2547.381127 \nL 362.07899 2541.058846 \nL 362.788462 2538.086542 \nL 364.916879 2535.274042 \nL 365.626352 2541.44042 \nL 366.335824 2536.832362 \nL 367.045296 2536.836794 \nL 367.754769 2530.410118 \nL 369.883186 2526.131806 \nL 370.592658 2529.529641 \nL 371.302131 2527.443564 \nL 372.011603 2522.347037 \nL 374.849492 2513.357111 \nL 375.558965 2509.103442 \nL 376.268437 2507.792926 \nL 376.977909 2501.27291 \nL 377.687382 2499.809956 \nL 379.815799 2500.961105 \nL 380.525271 2497.343194 \nL 381.234743 2491.358657 \nL 381.944216 2502.790198 \nL 382.653688 2506.648389 \nL 384.782105 2501.310496 \nL 385.491577 2510.188981 \nL 386.20105 2507.51248 \nL 386.910522 2502.308194 \nL 387.619995 2498.535992 \nL 389.748412 2498.24863 \nL 390.457884 2502.306263 \nL 391.167356 2499.160156 \nL 391.876829 2510.248342 \nL 392.586301 2516.631253 \nL 394.714718 2517.414249 \nL 395.42419 2510.461886 \nL 396.133663 2510.258771 \nL 396.843135 2514.715345 \nL 397.552607 2515.874271 \nL 399.681024 2512.509702 \nL 400.390497 2503.02983 \nL 401.099969 2496.282432 \nL 406.775748 2489.956974 \nL 407.48522 2492.293794 \nL 409.613637 2495.574527 \nL 410.32311 2497.207453 \nL 411.032582 2507.600255 \nL 411.742054 2506.179942 \nL 412.451527 2514.171603 \nL 414.579944 2510.30419 \nL 415.289416 2517.427665 \nL 415.998888 2515.553977 \nL 416.708361 2527.145089 \nL 419.54625 2541.008997 \nL 420.255722 2542.962084 \nL 420.965195 2542.166646 \nL 421.674667 2534.641103 \nL 422.384139 2533.829645 \nL 424.512557 2536.398992 \nL 425.222029 2534.870904 \nL 426.640974 2530.262169 \nL 427.350446 2535.269688 \nL 429.478863 2533.561509 \nL 430.188335 2538.344845 \nL 430.897808 2545.448332 \nL 431.60728 2543.177697 \nL 432.316752 2534.96438 \nL 434.445169 2535.759748 \nL 435.864114 2530.782333 \nL 436.573586 2527.49423 \nL 437.283059 2525.346772 \nL 440.120948 2523.399424 \nL 440.83042 2520.996662 \nL 441.539893 2520.792455 \nL 442.249365 2521.140602 \nL 444.377782 2527.496013 \nL 445.087255 2531.279159 \nL 445.796727 2529.761671 \nL 446.506199 2529.821094 \nL 447.215672 2527.946271 \nL 449.344089 2524.162372 \nL 450.053561 2523.685338 \nL 450.763033 2517.480043 \nL 451.472506 2514.321008 \nL 452.181978 2512.746996 \nL 454.310395 2511.877872 \nL 455.019867 2506.914985 \nL 455.72934 2506.637442 \nL 456.438812 2501.37982 \nL 457.148284 2503.164012 \nL 461.405118 2498.094406 \nL 462.114591 2497.9515 \nL 464.243008 2493.340945 \nL 464.95248 2500.563335 \nL 465.661953 2496.769404 \nL 466.371425 2500.917875 \nL 467.080897 2496.528098 \nL 469.918787 2483.699425 \nL 470.628259 2481.818974 \nL 471.337731 2489.146214 \nL 472.047204 2484.539753 \nL 474.175621 2487.110551 \nL 474.885093 2482.07634 \nL 475.594565 2484.4852 \nL 476.304038 2484.835441 \nL 477.01351 2480.38339 \nL 479.141927 2478.075522 \nL 479.851399 2475.394324 \nL 480.560872 2481.554136 \nL 481.270344 2484.694496 \nL 481.979817 2483.945971 \nL 484.108234 2479.9824 \nL 484.817706 2483.386852 \nL 485.527178 2479.665184 \nL 486.236651 2469.722638 \nL 486.946123 2466.361515 \nL 489.784012 2468.757429 \nL 490.493485 2477.701036 \nL 491.202957 2469.480244 \nL 491.912429 2467.107277 \nL 494.040846 2468.877698 \nL 494.750319 2464.733747 \nL 495.459791 2467.556741 \nL 496.169263 2466.272923 \nL 496.878736 2457.082515 \nL 499.007153 2453.750608 \nL 499.716625 2454.147321 \nL 500.426098 2449.611236 \nL 501.13557 2450.032327 \nL 501.845042 2454.333104 \nL 503.973459 2470.514944 \nL 504.682932 2472.011937 \nL 505.392404 2463.316579 \nL 506.101876 2466.793811 \nL 506.811349 2476.877284 \nL 508.939766 2473.832832 \nL 509.649238 2465.282855 \nL 510.35871 2494.092231 \nL 511.068183 2493.243553 \nL 511.777655 2496.147887 \nL 513.906072 2489.698651 \nL 514.615544 2491.533977 \nL 515.325017 2487.233012 \nL 516.034489 2485.853184 \nL 516.743961 2492.546677 \nL 518.872379 2498.178742 \nL 519.581851 2506.142336 \nL 520.291323 2506.402381 \nL 521.000796 2499.512588 \nL 521.710268 2497.238032 \nL 523.838685 2488.421347 \nL 524.548157 2483.261146 \nL 525.25763 2476.712425 \nL 525.967102 2477.263406 \nL 526.676574 2477.413223 \nL 528.804991 2478.82426 \nL 529.514464 2477.197476 \nL 530.223936 2477.524783 \nL 530.933408 2473.098729 \nL 531.642881 2475.879221 \nL 533.771298 2479.128943 \nL 534.48077 2482.745523 \nL 535.190242 2480.278089 \nL 535.899715 2482.20988 \nL 536.609187 2490.901443 \nL 538.737604 2480.75436 \nL 539.447077 2479.427713 \nL 540.156549 2474.606714 \nL 540.866021 2476.079803 \nL 541.575494 2473.845379 \nL 543.703911 2469.657254 \nL 544.413383 2470.97257 \nL 545.122855 2472.809085 \nL 545.832328 2472.76007 \nL 546.5418 2477.086768 \nL 548.670217 2475.279104 \nL 549.379689 2467.953363 \nL 550.089162 2466.231804 \nL 550.798634 2468.336506 \nL 551.508106 2459.048487 \nL 553.636523 2451.876052 \nL 555.055468 2461.674873 \nL 555.76494 2467.098477 \nL 556.474413 2462.431594 \nL 560.021775 2461.337057 \nL 560.731247 2460.037261 \nL 561.440719 2459.201403 \nL 563.569136 2468.923834 \nL 564.278609 2473.654089 \nL 564.988081 2481.772676 \nL 565.697553 2478.136865 \nL 573.501749 2477.778284 \nL 574.211221 2478.812362 \nL 574.920694 2475.995121 \nL 575.630166 2479.400115 \nL 576.339639 2481.341766 \nL 578.468056 2481.41028 \nL 579.177528 2477.63304 \nL 579.887 2480.891816 \nL 580.596473 2480.135985 \nL 581.305945 2480.558045 \nL 583.434362 2476.995708 \nL 584.143834 2478.132734 \nL 584.853307 2480.712768 \nL 585.562779 2484.38003 \nL 586.272251 2479.658302 \nL 588.400668 2484.373022 \nL 589.110141 2488.56617 \nL 589.819613 2488.738239 \nL 590.529085 2487.476509 \nL 591.238558 2491.218603 \nL 593.366975 2490.198018 \nL 594.076447 2490.91743 \nL 594.78592 2493.972364 \nL 595.495392 2492.566443 \nL 596.204864 2492.382602 \nL 598.333281 2496.221116 \nL 599.042754 2494.658126 \nL 599.752226 2494.412232 \nL 600.461698 2495.153083 \nL 601.171171 2494.221945 \nL 603.299588 2491.925005 \nL 604.00906 2490.228053 \nL 604.718532 2491.977252 \nL 605.428005 2492.694531 \nL 606.137477 2492.961763 \nL 608.265894 2488.413526 \nL 608.975366 2484.418276 \nL 609.684839 2484.941464 \nL 610.394311 2482.894706 \nL 611.103783 2484.648237 \nL 613.232201 2482.099689 \nL 613.941673 2480.438563 \nL 614.651145 2476.765639 \nL 615.360618 2474.904067 \nL 616.07009 2471.346669 \nL 618.198507 2471.574979 \nL 618.907979 2477.976568 \nL 619.617452 2477.185885 \nL 620.326924 2475.556804 \nL 621.036396 2478.37045 \nL 623.164813 2478.524446 \nL 623.874286 2476.824999 \nL 624.583758 2480.761623 \nL 625.29323 2478.220095 \nL 626.002703 2484.747459 \nL 628.13112 2485.217185 \nL 628.840592 2480.125751 \nL 629.550064 2483.91819 \nL 630.259537 2486.793948 \nL 630.969009 2481.451623 \nL 633.806899 2481.298523 \nL 634.516371 2485.655891 \nL 635.225843 2489.215465 \nL 635.935316 2488.720857 \nL 638.063733 2490.552785 \nL 638.773205 2492.63372 \nL 639.482677 2488.649143 \nL 640.19215 2492.714711 \nL 640.901622 2493.317387 \nL 643.030039 2496.864504 \nL 643.739511 2493.031336 \nL 644.448984 2496.765567 \nL 645.158456 2498.115761 \nL 645.867928 2500.821253 \nL 647.996345 2498.724661 \nL 648.705818 2505.424821 \nL 649.41529 2501.739047 \nL 650.834235 2511.494096 \nL 657.928958 2503.44836 \nL 658.638431 2502.412166 \nL 659.347903 2500.952534 \nL 660.057375 2500.818625 \nL 660.766848 2502.184764 \nL 662.895265 2506.896918 \nL 663.604737 2504.987077 \nL 665.023682 2500.319664 \nL 665.733154 2499.654661 \nL 667.861571 2500.37464 \nL 668.571043 2500.266414 \nL 669.280516 2497.58667 \nL 669.989988 2501.886668 \nL 670.699461 2500.795544 \nL 673.53735 2491.914673 \nL 674.246822 2490.639104 \nL 674.956295 2488.320795 \nL 675.665767 2490.46047 \nL 677.794184 2496.090961 \nL 678.503656 2500.993871 \nL 679.213129 2502.876816 \nL 680.632073 2494.995568 \nL 682.76049 2502.845055 \nL 683.469963 2512.757371 \nL 684.179435 2502.795119 \nL 684.888907 2503.160281 \nL 685.59838 2500.865759 \nL 687.726797 2499.811002 \nL 688.436269 2498.907825 \nL 689.145742 2500.464326 \nL 689.855214 2500.954443 \nL 690.564686 2506.444236 \nL 692.693103 2504.691667 \nL 693.402576 2502.812006 \nL 694.112048 2499.25824 \nL 694.82152 2504.568043 \nL 695.530993 2496.704955 \nL 699.078354 2502.577732 \nL 699.787827 2506.343467 \nL 700.497299 2506.087459 \nL 702.625716 2513.214689 \nL 703.335188 2508.701851 \nL 704.044661 2507.617645 \nL 704.754133 2503.214461 \nL 705.463605 2507.623075 \nL 708.301495 2510.450688 \nL 709.010967 2513.062789 \nL 709.72044 2518.689829 \nL 710.429912 2518.008726 \nL 712.558329 2530.047715 \nL 713.267801 2530.785451 \nL 713.977274 2523.631105 \nL 714.686746 2521.78467 \nL 715.396218 2517.431716 \nL 719.653052 2515.94927 \nL 720.362525 2524.375972 \nL 722.490942 2525.50795 \nL 723.200414 2525.393917 \nL 723.909886 2524.153898 \nL 724.619359 2525.300385 \nL 725.328831 2523.803855 \nL 727.457248 2525.439382 \nL 728.166721 2522.90712 \nL 728.876193 2523.894816 \nL 729.585665 2525.747071 \nL 730.295138 2519.43258 \nL 732.423555 2517.558607 \nL 733.133027 2521.35471 \nL 733.842499 2519.74198 \nL 734.551972 2519.95469 \nL 735.261444 2518.608573 \nL 737.389861 2518.814881 \nL 738.099333 2518.465674 \nL 738.808806 2519.071239 \nL 739.518278 2518.899882 \nL 742.356167 2515.631857 \nL 743.06564 2511.912478 \nL 743.775112 2511.913742 \nL 744.484584 2515.448579 \nL 745.194057 2514.338061 \nL 747.322474 2517.505023 \nL 748.031946 2516.074784 \nL 748.741419 2512.920758 \nL 749.450891 2514.795757 \nL 750.160363 2513.32097 \nL 752.28878 2514.416654 \nL 752.998253 2518.245616 \nL 753.707725 2518.980333 \nL 755.12667 2514.996488 \nL 757.255087 2513.572016 \nL 757.964559 2511.777896 \nL 758.674031 2515.891547 \nL 759.383504 2512.716265 \nL 760.092976 2511.821273 \nL 762.221393 2510.701396 \nL 762.930865 2509.523988 \nL 763.640338 2514.730548 \nL 764.34981 2511.868834 \nL 765.059283 2512.169695 \nL 767.1877 2517.015131 \nL 767.897172 2519.368114 \nL 768.606644 2519.745968 \nL 769.316117 2521.183664 \nL 770.025589 2525.097198 \nL 772.154006 2521.075846 \nL 772.863478 2522.809704 \nL 773.572951 2523.387478 \nL 774.282423 2527.101924 \nL 774.991895 2526.37074 \nL 777.120312 2528.927356 \nL 777.829785 2526.732686 \nL 778.539257 2528.312871 \nL 779.248729 2529.090876 \nL 779.958202 2530.126359 \nL 782.086619 2532.078679 \nL 782.796091 2538.88429 \nL 783.505564 2540.540871 \nL 784.215036 2539.079258 \nL 784.924508 2536.595658 \nL 787.052925 2535.940454 \nL 787.762398 2534.888738 \nL 788.47187 2536.495529 \nL 789.181342 2533.499595 \nL 789.890815 2533.59209 \nL 792.019232 2534.414443 \nL 792.728704 2535.369272 \nL 793.438176 2534.38462 \nL 794.147649 2536.419283 \nL 794.857121 2534.359377 \nL 796.985538 2533.047862 \nL 797.69501 2535.155162 \nL 798.404483 2537.726316 \nL 799.113955 2534.714813 \nL 799.823427 2536.075898 \nL 801.951844 2537.505898 \nL 802.661317 2536.029817 \nL 803.370789 2535.93122 \nL 804.789734 2541.279129 \nL 806.918151 2541.599189 \nL 807.627623 2538.950026 \nL 808.337096 2538.829675 \nL 809.046568 2539.459459 \nL 809.75604 2537.08888 \nL 812.59393 2537.27701 \nL 813.303402 2539.542622 \nL 814.012874 2541.27334 \nL 814.722347 2545.69159 \nL 816.850764 2546.874567 \nL 817.560236 2546.013556 \nL 818.269708 2545.519073 \nL 818.979181 2546.483603 \nL 819.688653 2548.201387 \nL 821.81707 2551.917869 \nL 822.526543 2548.457418 \nL 823.236015 2552.121551 \nL 823.945487 2551.06517 \nL 823.945487 2551.06517 \n\" clip-path=\"url(#p4ada1e5541)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_43\">\n    <path d=\"M 78.254578 2641.890509 \nL 78.254578 2440.45508 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_44\">\n    <path d=\"M 859.454578 2641.890509 \nL 859.454578 2440.45508 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_45\">\n    <path d=\"M 78.254578 2641.890509 \nL 859.454578 2641.890509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_46\">\n    <path d=\"M 78.254578 2440.45508 \nL 859.454578 2440.45508 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_85\">\n    <!-- Top 5 drawdown periods -->\n    <g transform=\"translate(388.606828 2434.45508)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"44.083984\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"105.265625\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"168.742188\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"200.529297\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"264.152344\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"295.939453\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"359.416016\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"400.529297\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"461.808594\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"543.595703\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"607.072266\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"668.253906\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"750.041016\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"813.419922\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"845.207031\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"908.683594\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"970.207031\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1011.320312\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1039.103516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"1100.285156\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1163.761719\"/>\n    </g>\n   </g>\n   <g id=\"legend_6\">\n    <g id=\"patch_47\">\n     <path d=\"M 86.724578 2467.895612 \nL 175.213391 2467.895612 \nQ 177.633391 2467.895612 177.633391 2465.475612 \nL 177.633391 2448.92508 \nQ 177.633391 2446.50508 175.213391 2446.50508 \nL 86.724578 2446.50508 \nQ 84.304578 2446.50508 84.304578 2448.92508 \nL 84.304578 2465.475612 \nQ 84.304578 2467.895612 86.724578 2467.895612 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_206\">\n     <path d=\"M 89.144578 2456.30419 \nL 101.244578 2456.30419 \nL 113.344578 2456.30419 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_86\">\n     <!-- Portfolio -->\n     <g transform=\"translate(123.024578 2460.53919)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"56.677734\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"117.859375\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"158.972656\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"198.181641\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"233.386719\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"294.568359\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"322.351562\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"350.134766\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_9\">\n   <g id=\"patch_48\">\n    <path d=\"M 78.254578 2944.043652 \nL 859.454578 2944.043652 \nL 859.454578 2742.608223 \nL 78.254578 2742.608223 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"PolyCollection_6\">\n    <defs>\n     <path id=\"m790c90f785\" d=\"M 113.763669 -834.152246 \nL 113.763669 -834.152246 \nL 114.473141 -834.152246 \nL 116.601558 -834.152246 \nL 117.311031 -834.152246 \nL 118.020503 -834.152246 \nL 118.729975 -834.152246 \nL 119.439448 -834.152246 \nL 121.567865 -834.152246 \nL 122.277337 -834.152246 \nL 122.98681 -834.152246 \nL 123.696282 -834.152246 \nL 124.405754 -834.152246 \nL 126.534171 -834.152246 \nL 127.243644 -834.152246 \nL 127.953116 -834.152246 \nL 128.662588 -834.152246 \nL 136.466784 -834.152246 \nL 137.176256 -834.152246 \nL 137.885729 -834.152246 \nL 138.595201 -834.152246 \nL 139.304673 -834.152246 \nL 141.433091 -834.152246 \nL 142.142563 -834.152246 \nL 142.852035 -834.152246 \nL 143.561508 -834.152246 \nL 144.27098 -834.152246 \nL 146.399397 -834.152246 \nL 147.108869 -834.152246 \nL 147.818342 -834.152246 \nL 148.527814 -834.152246 \nL 149.237286 -834.152246 \nL 151.365703 -834.152246 \nL 152.075176 -834.152246 \nL 152.784648 -834.152246 \nL 153.49412 -834.152246 \nL 154.203593 -834.152246 \nL 156.33201 -834.152246 \nL 157.041482 -834.152246 \nL 157.750954 -834.152246 \nL 158.460427 -834.152246 \nL 159.169899 -834.152246 \nL 161.298316 -834.152246 \nL 162.007789 -834.152246 \nL 162.717261 -834.152246 \nL 163.426733 -834.152246 \nL 164.136206 -834.152246 \nL 166.264623 -834.152246 \nL 166.974095 -834.152246 \nL 167.683567 -834.152246 \nL 168.39304 -834.152246 \nL 169.102512 -834.152246 \nL 171.230929 -834.152246 \nL 171.940401 -834.152246 \nL 172.649874 -834.152246 \nL 173.359346 -834.152246 \nL 174.068818 -834.152246 \nL 176.197235 -834.152246 \nL 176.906708 -834.152246 \nL 177.61618 -834.152246 \nL 178.325653 -834.152246 \nL 179.035125 -834.152246 \nL 181.873014 -834.152246 \nL 182.582487 -834.152246 \nL 183.291959 -834.152246 \nL 184.001431 -834.152246 \nL 186.129848 -834.152246 \nL 186.839321 -834.152246 \nL 187.548793 -834.152246 \nL 188.258265 -834.152246 \nL 188.967738 -834.152246 \nL 191.096155 -834.152246 \nL 191.805627 -834.152246 \nL 192.515099 -834.152246 \nL 193.224572 -834.152246 \nL 193.934044 -834.152246 \nL 196.062461 -834.152246 \nL 196.771933 -834.152246 \nL 197.481406 -834.152246 \nL 198.190878 -834.152246 \nL 202.447712 -834.152246 \nL 203.157185 -834.152246 \nL 203.866657 -834.152246 \nL 205.995074 -834.152246 \nL 206.704546 -834.152246 \nL 207.414019 -834.152246 \nL 208.123491 -834.152246 \nL 208.832963 -834.152246 \nL 210.96138 -834.152246 \nL 211.670853 -834.152246 \nL 212.380325 -834.152246 \nL 213.089797 -834.152246 \nL 213.79927 -834.152246 \nL 215.927687 -834.152246 \nL 216.637159 -834.152246 \nL 217.346632 -834.152246 \nL 218.056104 -834.152246 \nL 218.765576 -834.152246 \nL 220.893993 -834.152246 \nL 221.603466 -834.152246 \nL 222.312938 -834.152246 \nL 223.02241 -834.152246 \nL 223.731883 -834.152246 \nL 225.8603 -834.152246 \nL 226.569772 -834.152246 \nL 227.279244 -834.152246 \nL 227.988717 -834.152246 \nL 228.698189 -834.152246 \nL 230.826606 -834.152246 \nL 231.536078 -834.152246 \nL 232.245551 -834.152246 \nL 232.955023 -834.152246 \nL 233.664495 -834.152246 \nL 235.792913 -834.152246 \nL 236.502385 -834.152246 \nL 237.211857 -834.152246 \nL 240.759219 -834.152246 \nL 241.468691 -834.152246 \nL 242.178164 -834.152246 \nL 242.887636 -834.152246 \nL 243.597108 -834.152246 \nL 245.725525 -834.152246 \nL 246.434998 -834.152246 \nL 247.14447 -834.152246 \nL 247.853942 -834.152246 \nL 248.563415 -834.152246 \nL 250.691832 -834.152246 \nL 251.401304 -834.152246 \nL 252.110776 -834.152246 \nL 252.820249 -834.152246 \nL 253.529721 -834.152246 \nL 255.658138 -834.152246 \nL 256.367611 -834.152246 \nL 257.077083 -834.152246 \nL 257.786555 -834.152246 \nL 258.496028 -834.152246 \nL 260.624445 -834.152246 \nL 261.333917 -834.152246 \nL 262.043389 -834.152246 \nL 262.752862 -834.152246 \nL 263.462334 -834.152246 \nL 265.590751 -834.152246 \nL 266.300223 -834.152246 \nL 267.009696 -834.152246 \nL 267.719168 -834.152246 \nL 268.42864 -834.152246 \nL 270.557057 -834.152246 \nL 271.26653 -834.152246 \nL 271.976002 -834.152246 \nL 272.685475 -834.152246 \nL 273.394947 -834.152246 \nL 275.523364 -834.152246 \nL 276.232836 -834.152246 \nL 276.942309 -834.152246 \nL 277.651781 -834.152246 \nL 278.361253 -834.152246 \nL 280.48967 -834.152246 \nL 281.199143 -834.152246 \nL 281.908615 -834.152246 \nL 282.618087 -834.152246 \nL 283.32756 -834.152246 \nL 285.455977 -834.152246 \nL 286.165449 -834.152246 \nL 286.874921 -834.152246 \nL 287.584394 -834.152246 \nL 288.293866 -834.152246 \nL 290.422283 -834.152246 \nL 291.131755 -834.152246 \nL 291.841228 -834.152246 \nL 292.5507 -834.152246 \nL 293.260173 -834.152246 \nL 295.38859 -834.152246 \nL 296.098062 -834.152246 \nL 296.807534 -834.152246 \nL 297.517007 -834.152246 \nL 298.226479 -834.152246 \nL 300.354896 -834.152246 \nL 301.064368 -834.152246 \nL 301.773841 -834.152246 \nL 302.483313 -834.152246 \nL 303.192785 -834.152246 \nL 305.321202 -834.152246 \nL 306.030675 -834.152246 \nL 306.740147 -834.152246 \nL 313.125398 -834.152246 \nL 315.253815 -834.152246 \nL 315.963288 -834.152246 \nL 316.67276 -834.152246 \nL 317.382232 -834.152246 \nL 318.091705 -834.152246 \nL 320.220122 -834.152246 \nL 320.929594 -834.152246 \nL 321.639066 -834.152246 \nL 322.348539 -834.152246 \nL 323.058011 -834.152246 \nL 325.186428 -834.152246 \nL 325.8959 -834.152246 \nL 326.605373 -834.152246 \nL 327.314845 -834.152246 \nL 328.024317 -834.152246 \nL 330.152735 -834.152246 \nL 330.862207 -834.152246 \nL 331.571679 -834.152246 \nL 332.281152 -834.152246 \nL 332.990624 -834.152246 \nL 335.119041 -834.152246 \nL 335.828513 -834.152246 \nL 336.537986 -834.152246 \nL 337.247458 -834.152246 \nL 337.95693 -834.152246 \nL 340.085347 -834.152246 \nL 340.79482 -834.152246 \nL 341.504292 -834.152246 \nL 342.213764 -834.152246 \nL 342.923237 -834.152246 \nL 345.051654 -834.152246 \nL 345.761126 -834.152246 \nL 346.470598 -834.152246 \nL 347.180071 -834.152246 \nL 347.889543 -834.152246 \nL 350.01796 -834.152246 \nL 350.727433 -834.152246 \nL 351.436905 -834.152246 \nL 352.146377 -834.152246 \nL 352.85585 -834.152246 \nL 354.984267 -834.152246 \nL 355.693739 -834.152246 \nL 356.403211 -834.152246 \nL 357.112684 -834.152246 \nL 357.822156 -834.152246 \nL 359.950573 -834.152246 \nL 360.660045 -834.152246 \nL 361.369518 -834.152246 \nL 362.07899 -834.152246 \nL 362.788462 -834.152246 \nL 364.916879 -834.152246 \nL 365.626352 -834.152246 \nL 366.335824 -834.152246 \nL 367.045296 -834.152246 \nL 367.754769 -834.152246 \nL 369.883186 -834.152246 \nL 370.592658 -834.152246 \nL 371.302131 -834.152246 \nL 372.011603 -834.152246 \nL 374.849492 -834.152246 \nL 375.558965 -834.152246 \nL 376.268437 -834.152246 \nL 376.977909 -834.152246 \nL 377.687382 -834.152246 \nL 379.815799 -834.152246 \nL 380.525271 -834.152246 \nL 381.234743 -834.152246 \nL 381.944216 -834.152246 \nL 382.653688 -834.152246 \nL 384.782105 -834.152246 \nL 385.491577 -834.152246 \nL 386.20105 -834.152246 \nL 386.910522 -834.152246 \nL 387.619995 -834.152246 \nL 389.748412 -834.152246 \nL 390.457884 -834.152246 \nL 391.167356 -834.152246 \nL 391.876829 -834.152246 \nL 392.586301 -834.152246 \nL 394.714718 -834.152246 \nL 395.42419 -834.152246 \nL 396.133663 -834.152246 \nL 396.843135 -834.152246 \nL 397.552607 -834.152246 \nL 399.681024 -834.152246 \nL 400.390497 -834.152246 \nL 401.099969 -834.152246 \nL 406.775748 -834.152246 \nL 407.48522 -834.152246 \nL 409.613637 -834.152246 \nL 410.32311 -834.152246 \nL 411.032582 -834.152246 \nL 411.742054 -834.152246 \nL 412.451527 -834.152246 \nL 414.579944 -834.152246 \nL 415.289416 -834.152246 \nL 415.998888 -834.152246 \nL 416.708361 -834.152246 \nL 417.417833 -834.152246 \nL 419.54625 -834.152246 \nL 420.255722 -834.152246 \nL 420.965195 -834.152246 \nL 421.674667 -834.152246 \nL 422.384139 -834.152246 \nL 424.512557 -834.152246 \nL 425.222029 -834.152246 \nL 425.931501 -834.152246 \nL 426.640974 -834.152246 \nL 427.350446 -834.152246 \nL 429.478863 -834.152246 \nL 430.188335 -834.152246 \nL 430.897808 -834.152246 \nL 431.60728 -834.152246 \nL 432.316752 -834.152246 \nL 434.445169 -834.152246 \nL 435.154642 -834.152246 \nL 435.864114 -834.152246 \nL 436.573586 -834.152246 \nL 437.283059 -834.152246 \nL 440.120948 -834.152246 \nL 440.83042 -834.152246 \nL 441.539893 -834.152246 \nL 442.249365 -834.152246 \nL 444.377782 -834.152246 \nL 445.087255 -834.152246 \nL 445.796727 -834.152246 \nL 446.506199 -834.152246 \nL 447.215672 -834.152246 \nL 449.344089 -834.152246 \nL 450.053561 -834.152246 \nL 450.763033 -834.152246 \nL 451.472506 -834.152246 \nL 452.181978 -834.152246 \nL 454.310395 -834.152246 \nL 455.019867 -834.152246 \nL 455.72934 -834.152246 \nL 456.438812 -834.152246 \nL 457.148284 -834.152246 \nL 461.405118 -834.152246 \nL 462.114591 -834.152246 \nL 464.243008 -834.152246 \nL 464.95248 -834.152246 \nL 465.661953 -834.152246 \nL 466.371425 -834.152246 \nL 467.080897 -834.152246 \nL 469.209314 -834.152246 \nL 469.918787 -834.152246 \nL 470.628259 -834.152246 \nL 471.337731 -834.152246 \nL 472.047204 -834.152246 \nL 474.175621 -834.152246 \nL 474.885093 -834.152246 \nL 475.594565 -834.152246 \nL 476.304038 -834.152246 \nL 477.01351 -834.152246 \nL 479.141927 -834.152246 \nL 479.851399 -834.152246 \nL 480.560872 -834.152246 \nL 481.270344 -834.152246 \nL 481.979817 -834.152246 \nL 484.108234 -834.152246 \nL 484.817706 -834.152246 \nL 485.527178 -834.152246 \nL 486.236651 -834.152246 \nL 486.946123 -834.152246 \nL 489.784012 -834.152246 \nL 490.493485 -834.152246 \nL 491.202957 -834.152246 \nL 491.912429 -834.152246 \nL 494.040846 -834.152246 \nL 494.750319 -834.152246 \nL 495.459791 -834.152246 \nL 496.169263 -834.152246 \nL 496.878736 -834.152246 \nL 499.007153 -834.152246 \nL 499.716625 -834.152246 \nL 500.426098 -834.152246 \nL 501.13557 -834.152246 \nL 501.845042 -834.152246 \nL 503.973459 -834.152246 \nL 504.682932 -834.152246 \nL 505.392404 -834.152246 \nL 506.101876 -834.152246 \nL 506.811349 -834.152246 \nL 508.939766 -834.152246 \nL 509.649238 -834.152246 \nL 510.35871 -834.152246 \nL 511.068183 -834.152246 \nL 511.777655 -834.152246 \nL 513.906072 -834.152246 \nL 514.615544 -834.152246 \nL 515.325017 -834.152246 \nL 516.034489 -834.152246 \nL 516.743961 -834.152246 \nL 518.872379 -834.152246 \nL 519.581851 -834.152246 \nL 520.291323 -834.152246 \nL 521.000796 -834.152246 \nL 521.710268 -834.152246 \nL 523.838685 -834.152246 \nL 524.548157 -834.152246 \nL 525.25763 -834.152246 \nL 525.967102 -834.152246 \nL 526.676574 -834.152246 \nL 528.804991 -834.152246 \nL 529.514464 -834.152246 \nL 530.223936 -834.152246 \nL 530.933408 -834.152246 \nL 531.642881 -834.152246 \nL 533.771298 -834.152246 \nL 534.48077 -834.152246 \nL 535.190242 -834.152246 \nL 535.899715 -834.152246 \nL 536.609187 -834.152246 \nL 538.737604 -834.152246 \nL 539.447077 -834.152246 \nL 540.156549 -834.152246 \nL 540.866021 -834.152246 \nL 541.575494 -834.152246 \nL 543.703911 -834.152246 \nL 544.413383 -834.152246 \nL 545.122855 -834.152246 \nL 545.832328 -834.152246 \nL 546.5418 -834.152246 \nL 548.670217 -834.152246 \nL 549.379689 -834.152246 \nL 550.089162 -834.152246 \nL 550.798634 -834.152246 \nL 551.508106 -834.152246 \nL 553.636523 -834.152246 \nL 554.345996 -834.152246 \nL 555.055468 -834.152246 \nL 555.76494 -834.152246 \nL 556.474413 -834.152246 \nL 560.021775 -834.152246 \nL 560.731247 -834.152246 \nL 561.440719 -834.152246 \nL 563.569136 -834.152246 \nL 564.278609 -834.152246 \nL 564.988081 -834.152246 \nL 565.697553 -834.152246 \nL 571.373332 -834.152246 \nL 573.501749 -834.152246 \nL 574.211221 -834.152246 \nL 574.920694 -834.152246 \nL 575.630166 -834.152246 \nL 576.339639 -834.152246 \nL 578.468056 -834.152246 \nL 579.177528 -834.152246 \nL 579.887 -834.152246 \nL 580.596473 -834.152246 \nL 581.305945 -834.152246 \nL 583.434362 -834.152246 \nL 584.143834 -834.152246 \nL 584.853307 -834.152246 \nL 585.562779 -834.152246 \nL 586.272251 -834.152246 \nL 588.400668 -834.152246 \nL 589.110141 -834.152246 \nL 589.819613 -834.152246 \nL 590.529085 -834.152246 \nL 591.238558 -834.152246 \nL 593.366975 -834.152246 \nL 594.076447 -834.152246 \nL 594.78592 -834.152246 \nL 595.495392 -834.152246 \nL 596.204864 -834.152246 \nL 598.333281 -834.152246 \nL 599.042754 -834.152246 \nL 599.752226 -834.152246 \nL 600.461698 -834.152246 \nL 601.171171 -834.152246 \nL 603.299588 -834.152246 \nL 604.00906 -834.152246 \nL 604.718532 -834.152246 \nL 605.428005 -834.152246 \nL 606.137477 -834.152246 \nL 608.265894 -834.152246 \nL 608.975366 -834.152246 \nL 609.684839 -834.152246 \nL 610.394311 -834.152246 \nL 611.103783 -834.152246 \nL 613.232201 -834.152246 \nL 613.941673 -834.152246 \nL 614.651145 -834.152246 \nL 615.360618 -834.152246 \nL 616.07009 -834.152246 \nL 618.198507 -834.152246 \nL 618.907979 -834.152246 \nL 619.617452 -834.152246 \nL 620.326924 -834.152246 \nL 621.036396 -834.152246 \nL 623.164813 -834.152246 \nL 623.874286 -834.152246 \nL 624.583758 -834.152246 \nL 625.29323 -834.152246 \nL 626.002703 -834.152246 \nL 628.13112 -834.152246 \nL 628.840592 -834.152246 \nL 629.550064 -834.152246 \nL 630.259537 -834.152246 \nL 630.969009 -834.152246 \nL 633.806899 -834.152246 \nL 634.516371 -834.152246 \nL 635.225843 -834.152246 \nL 635.935316 -834.152246 \nL 638.063733 -834.152246 \nL 638.773205 -834.152246 \nL 639.482677 -834.152246 \nL 640.19215 -834.152246 \nL 640.901622 -834.152246 \nL 643.030039 -834.152246 \nL 643.739511 -834.152246 \nL 644.448984 -834.152246 \nL 645.158456 -834.152246 \nL 645.867928 -834.152246 \nL 647.996345 -834.152246 \nL 648.705818 -834.152246 \nL 649.41529 -834.152246 \nL 650.124762 -834.152246 \nL 650.834235 -834.152246 \nL 657.928958 -834.152246 \nL 658.638431 -834.152246 \nL 659.347903 -834.152246 \nL 660.057375 -834.152246 \nL 660.766848 -834.152246 \nL 662.895265 -834.152246 \nL 663.604737 -834.152246 \nL 664.314209 -834.152246 \nL 665.023682 -834.152246 \nL 665.733154 -834.152246 \nL 667.861571 -834.152246 \nL 668.571043 -834.152246 \nL 669.280516 -834.152246 \nL 669.989988 -834.152246 \nL 670.699461 -834.152246 \nL 672.827878 -834.152246 \nL 673.53735 -834.152246 \nL 674.246822 -834.152246 \nL 674.956295 -834.152246 \nL 675.665767 -834.152246 \nL 677.794184 -834.152246 \nL 678.503656 -834.152246 \nL 679.213129 -834.152246 \nL 679.922601 -834.152246 \nL 680.632073 -834.152246 \nL 682.76049 -834.152246 \nL 683.469963 -834.152246 \nL 684.179435 -834.152246 \nL 684.888907 -834.152246 \nL 685.59838 -834.152246 \nL 687.726797 -834.152246 \nL 688.436269 -834.152246 \nL 689.145742 -834.152246 \nL 689.855214 -834.152246 \nL 690.564686 -834.152246 \nL 692.693103 -834.152246 \nL 693.402576 -834.152246 \nL 694.112048 -834.152246 \nL 694.82152 -834.152246 \nL 695.530993 -834.152246 \nL 699.078354 -834.152246 \nL 699.787827 -834.152246 \nL 700.497299 -834.152246 \nL 702.625716 -834.152246 \nL 703.335188 -834.152246 \nL 704.044661 -834.152246 \nL 704.754133 -834.152246 \nL 705.463605 -834.152246 \nL 707.592022 -834.152246 \nL 708.301495 -834.152246 \nL 709.010967 -834.152246 \nL 709.72044 -834.152246 \nL 710.429912 -834.152246 \nL 712.558329 -834.152246 \nL 713.267801 -834.152246 \nL 713.977274 -834.152246 \nL 714.686746 -834.152246 \nL 715.396218 -834.152246 \nL 719.653052 -834.152246 \nL 720.362525 -834.152246 \nL 722.490942 -834.152246 \nL 723.200414 -834.152246 \nL 723.909886 -834.152246 \nL 724.619359 -834.152246 \nL 725.328831 -834.152246 \nL 727.457248 -834.152246 \nL 728.166721 -834.152246 \nL 728.876193 -834.152246 \nL 729.585665 -834.152246 \nL 730.295138 -834.152246 \nL 732.423555 -834.152246 \nL 733.133027 -834.152246 \nL 733.842499 -834.152246 \nL 734.551972 -834.152246 \nL 735.261444 -834.152246 \nL 737.389861 -834.152246 \nL 738.099333 -834.152246 \nL 738.808806 -834.152246 \nL 739.518278 -834.152246 \nL 742.356167 -834.152246 \nL 743.06564 -834.152246 \nL 743.775112 -834.152246 \nL 744.484584 -834.152246 \nL 745.194057 -834.152246 \nL 747.322474 -834.152246 \nL 748.031946 -834.152246 \nL 748.741419 -834.152246 \nL 749.450891 -834.152246 \nL 750.160363 -834.152246 \nL 752.28878 -834.152246 \nL 752.998253 -834.152246 \nL 753.707725 -834.152246 \nL 754.417197 -834.152246 \nL 755.12667 -834.152246 \nL 757.255087 -834.152246 \nL 757.964559 -834.152246 \nL 758.674031 -834.152246 \nL 759.383504 -834.152246 \nL 760.092976 -834.152246 \nL 762.221393 -834.152246 \nL 762.930865 -834.152246 \nL 763.640338 -834.152246 \nL 764.34981 -834.152246 \nL 765.059283 -834.152246 \nL 767.1877 -834.152246 \nL 767.897172 -834.152246 \nL 768.606644 -834.152246 \nL 769.316117 -834.152246 \nL 770.025589 -834.152246 \nL 772.154006 -834.152246 \nL 772.863478 -834.152246 \nL 773.572951 -834.152246 \nL 774.282423 -834.152246 \nL 774.991895 -834.152246 \nL 777.120312 -834.152246 \nL 777.829785 -834.152246 \nL 778.539257 -834.152246 \nL 779.248729 -834.152246 \nL 779.958202 -834.152246 \nL 782.086619 -834.152246 \nL 782.796091 -834.152246 \nL 783.505564 -834.152246 \nL 784.215036 -834.152246 \nL 784.924508 -834.152246 \nL 787.052925 -834.152246 \nL 787.762398 -834.152246 \nL 788.47187 -834.152246 \nL 789.181342 -834.152246 \nL 789.890815 -834.152246 \nL 792.019232 -834.152246 \nL 792.728704 -834.152246 \nL 793.438176 -834.152246 \nL 794.147649 -834.152246 \nL 794.857121 -834.152246 \nL 796.985538 -834.152246 \nL 797.69501 -834.152246 \nL 798.404483 -834.152246 \nL 799.113955 -834.152246 \nL 799.823427 -834.152246 \nL 801.951844 -834.152246 \nL 802.661317 -834.152246 \nL 803.370789 -834.152246 \nL 804.080262 -834.152246 \nL 804.789734 -834.152246 \nL 806.918151 -834.152246 \nL 807.627623 -834.152246 \nL 808.337096 -834.152246 \nL 809.046568 -834.152246 \nL 809.75604 -834.152246 \nL 812.59393 -834.152246 \nL 813.303402 -834.152246 \nL 814.012874 -834.152246 \nL 814.722347 -834.152246 \nL 816.850764 -834.152246 \nL 817.560236 -834.152246 \nL 818.269708 -834.152246 \nL 818.979181 -834.152246 \nL 819.688653 -834.152246 \nL 821.81707 -834.152246 \nL 822.526543 -834.152246 \nL 823.236015 -834.152246 \nL 823.945487 -834.152246 \nL 823.945487 -644.285949 \nL 823.945487 -644.285949 \nL 823.236015 -642.30898 \nL 822.526543 -649.166235 \nL 821.81707 -642.690162 \nL 819.688653 -649.645384 \nL 818.979181 -652.860137 \nL 818.269708 -654.66521 \nL 817.560236 -653.739807 \nL 816.850764 -652.128467 \nL 814.722347 -654.342352 \nL 814.012874 -662.6109 \nL 813.303402 -665.849859 \nL 812.59393 -670.089846 \nL 809.75604 -670.441923 \nL 809.046568 -666.005495 \nL 808.337096 -667.184107 \nL 807.627623 -666.958874 \nL 806.918151 -662.001089 \nL 804.789734 -662.600067 \nL 804.080262 -667.472579 \nL 803.370789 -672.608429 \nL 802.661317 -672.42391 \nL 801.951844 -669.661493 \nL 799.823427 -672.33767 \nL 799.113955 -674.884877 \nL 798.404483 -669.24899 \nL 797.69501 -674.060784 \nL 796.985538 -678.004499 \nL 794.857121 -675.550059 \nL 794.147649 -671.695041 \nL 793.438176 -675.502818 \nL 792.728704 -673.660089 \nL 792.019232 -675.447007 \nL 789.890815 -676.986001 \nL 789.181342 -677.159102 \nL 788.47187 -671.552351 \nL 787.762398 -674.559385 \nL 787.052925 -672.591149 \nL 784.924508 -671.364964 \nL 784.215036 -666.717023 \nL 783.505564 -663.981682 \nL 782.796091 -667.081896 \nL 782.086619 -679.81828 \nL 779.958202 -683.471954 \nL 779.248729 -685.409814 \nL 778.539257 -686.865812 \nL 777.829785 -689.823056 \nL 777.120312 -685.715833 \nL 774.991895 -690.50042 \nL 774.282423 -689.132044 \nL 773.572951 -696.083456 \nL 772.863478 -697.164734 \nL 772.154006 -700.409568 \nL 770.025589 -692.883795 \nL 769.316117 -700.207792 \nL 768.606644 -702.898371 \nL 767.897172 -703.605508 \nL 767.1877 -708.009005 \nL 765.059283 -717.077013 \nL 764.34981 -717.640061 \nL 763.640338 -712.284495 \nL 762.930865 -722.028329 \nL 762.221393 -719.824866 \nL 760.092976 -717.729069 \nL 759.383504 -716.054133 \nL 758.674031 -710.11174 \nL 757.964559 -717.810247 \nL 757.255087 -714.452634 \nL 755.12667 -711.786801 \nL 754.417197 -708.163459 \nL 753.707725 -704.331222 \nL 752.998253 -705.70621 \nL 752.28878 -712.871933 \nL 750.160363 -714.922456 \nL 749.450891 -712.162461 \nL 748.741419 -715.671434 \nL 748.031946 -709.768821 \nL 747.322474 -707.092196 \nL 745.194057 -713.019017 \nL 744.484584 -710.940734 \nL 743.775112 -717.556017 \nL 743.06564 -717.558382 \nL 742.356167 -710.597739 \nL 739.518278 -704.481781 \nL 738.808806 -704.161095 \nL 738.099333 -705.294383 \nL 737.389861 -704.640857 \nL 735.261444 -705.026953 \nL 734.551972 -702.507758 \nL 733.842499 -702.905835 \nL 733.133027 -699.887686 \nL 732.423555 -706.991916 \nL 730.295138 -703.484863 \nL 729.585665 -691.667587 \nL 728.876193 -695.133996 \nL 728.166721 -696.982423 \nL 727.457248 -692.243413 \nL 725.328831 -695.304225 \nL 724.619359 -692.50354 \nL 723.909886 -694.649137 \nL 723.200414 -692.3285 \nL 722.490942 -692.115092 \nL 720.362525 -694.233536 \nL 719.653052 -710.003714 \nL 715.396218 -707.229387 \nL 714.686746 -699.083036 \nL 713.977274 -695.62752 \nL 713.267801 -682.238495 \nL 712.558329 -683.619134 \nL 710.429912 -706.149539 \nL 709.72044 -704.874887 \nL 709.010967 -715.405629 \nL 708.301495 -720.294054 \nL 707.592022 -721.589836 \nL 705.463605 -725.585799 \nL 704.754133 -733.836314 \nL 704.044661 -725.595962 \nL 703.335188 -723.566922 \nL 702.625716 -715.121356 \nL 700.497299 -728.459633 \nL 699.787827 -727.980526 \nL 699.078354 -735.027924 \nL 695.530993 -746.018551 \nL 694.82152 -731.303149 \nL 694.112048 -741.240198 \nL 693.402576 -734.589491 \nL 692.693103 -731.071793 \nL 690.564686 -727.791943 \nL 689.855214 -738.065833 \nL 689.145742 -738.983064 \nL 688.436269 -741.895982 \nL 687.726797 -740.20573 \nL 685.59838 -738.2318 \nL 684.888907 -733.93771 \nL 684.179435 -734.621095 \nL 683.469963 -715.977204 \nL 682.76049 -734.527642 \nL 680.632073 -749.21759 \nL 679.922601 -741.388075 \nL 679.213129 -734.468202 \nL 678.503656 -737.992045 \nL 677.794184 -747.167612 \nL 675.665767 -757.704814 \nL 674.956295 -761.709114 \nL 674.246822 -757.370507 \nL 673.53735 -754.983341 \nL 672.827878 -751.237031 \nL 670.699461 -738.363206 \nL 669.989988 -736.321217 \nL 669.280516 -744.368463 \nL 668.571043 -739.353448 \nL 667.861571 -739.150907 \nL 665.733154 -740.498314 \nL 665.023682 -739.253791 \nL 664.314209 -734.814814 \nL 663.604737 -730.518947 \nL 662.895265 -726.944769 \nL 660.766848 -735.763345 \nL 660.057375 -738.32001 \nL 659.347903 -738.069406 \nL 658.638431 -735.337773 \nL 657.928958 -733.398583 \nL 650.834235 -718.341365 \nL 650.124762 -727.578997 \nL 649.41529 -736.597484 \nL 648.705818 -729.69973 \nL 647.996345 -742.238767 \nL 645.867928 -738.315092 \nL 645.158456 -743.378294 \nL 644.448984 -745.905118 \nL 643.739511 -752.893557 \nL 643.030039 -745.719962 \nL 640.901622 -752.358226 \nL 640.19215 -753.486107 \nL 639.482677 -761.094627 \nL 638.773205 -753.637678 \nL 638.063733 -757.53205 \nL 635.935316 -760.960417 \nL 635.225843 -760.034782 \nL 634.516371 -766.696358 \nL 633.806899 -774.850969 \nL 630.969009 -774.564449 \nL 630.259537 -764.566537 \nL 629.550064 -769.948384 \nL 628.840592 -777.045757 \nL 628.13112 -767.517376 \nL 626.002703 -768.396446 \nL 625.29323 -780.612103 \nL 624.583758 -775.855751 \nL 623.874286 -783.22296 \nL 623.164813 -780.042525 \nL 621.036396 -780.330721 \nL 620.326924 -785.596328 \nL 619.617452 -782.547578 \nL 618.907979 -781.067852 \nL 618.198507 -793.048128 \nL 616.07009 -793.475398 \nL 615.360618 -786.817895 \nL 614.651145 -783.33405 \nL 613.941673 -776.460344 \nL 613.232201 -773.351624 \nL 611.103783 -768.582136 \nL 610.394311 -771.863788 \nL 609.684839 -768.033375 \nL 608.975366 -769.012497 \nL 608.265894 -761.535573 \nL 606.137477 -753.023761 \nL 605.428005 -753.523872 \nL 604.718532 -754.866227 \nL 604.00906 -758.13977 \nL 603.299588 -754.964005 \nL 601.171171 -750.665388 \nL 600.461698 -748.922807 \nL 599.752226 -750.309276 \nL 599.042754 -749.849096 \nL 598.333281 -746.924033 \nL 596.204864 -754.107633 \nL 595.495392 -753.763584 \nL 594.78592 -751.132468 \nL 594.076447 -756.849634 \nL 593.366975 -758.19598 \nL 591.238558 -756.286002 \nL 590.529085 -763.289157 \nL 589.819613 -760.927888 \nL 589.110141 -761.249907 \nL 588.400668 -769.097187 \nL 586.272251 -777.920565 \nL 585.562779 -769.084073 \nL 584.853307 -775.947182 \nL 584.143834 -780.775595 \nL 583.434362 -782.903486 \nL 581.305945 -776.236738 \nL 580.596473 -777.026605 \nL 579.887 -775.612103 \nL 579.177528 -781.710749 \nL 578.468056 -774.641822 \nL 576.339639 -774.770041 \nL 575.630166 -778.403751 \nL 574.920694 -784.776038 \nL 574.211221 -779.503702 \nL 573.501749 -781.438931 \nL 571.373332 -781.189174 \nL 565.697553 -780.767864 \nL 564.988081 -773.963613 \nL 564.278609 -789.157169 \nL 563.569136 -798.009622 \nL 561.440719 -816.204696 \nL 560.731247 -814.640427 \nL 560.021775 -812.207919 \nL 556.474413 -810.159545 \nL 555.76494 -801.425692 \nL 555.055468 -811.575713 \nL 554.345996 -821.030059 \nL 553.636523 -829.913748 \nL 551.508106 -816.490872 \nL 550.798634 -799.108778 \nL 550.089162 -803.047629 \nL 549.379689 -799.825812 \nL 548.670217 -786.11603 \nL 546.5418 -782.733071 \nL 545.832328 -790.830284 \nL 545.122855 -790.738555 \nL 544.413383 -794.175507 \nL 543.703911 -796.637059 \nL 541.575494 -788.799179 \nL 540.866021 -784.61756 \nL 540.156549 -787.374377 \nL 539.447077 -778.352102 \nL 538.737604 -775.869345 \nL 536.609187 -756.879554 \nL 535.899715 -773.145406 \nL 535.190242 -776.760664 \nL 534.48077 -772.142975 \nL 533.771298 -778.911236 \nL 531.642881 -784.992939 \nL 530.933408 -790.1965 \nL 530.223936 -781.913346 \nL 529.514464 -782.525887 \nL 528.804991 -779.481436 \nL 526.676574 -782.122126 \nL 525.967102 -782.402502 \nL 525.25763 -783.433637 \nL 524.548157 -771.178011 \nL 523.838685 -761.520936 \nL 521.710268 -745.020923 \nL 521.000796 -740.764197 \nL 520.291323 -727.870272 \nL 519.581851 -728.356933 \nL 518.872379 -743.260428 \nL 516.743961 -753.800573 \nL 516.034489 -766.327133 \nL 515.325017 -763.74485 \nL 514.615544 -755.695795 \nL 513.906072 -759.130523 \nL 511.777655 -747.061078 \nL 511.068183 -752.496403 \nL 510.35871 -750.908142 \nL 509.649238 -804.823543 \nL 508.939766 -788.822661 \nL 506.811349 -783.12511 \nL 506.101876 -801.995861 \nL 505.392404 -808.503337 \nL 504.682932 -792.23038 \nL 503.973459 -795.031934 \nL 501.845042 -825.315491 \nL 501.13557 -833.364194 \nL 500.426098 -834.152246 \nL 499.716625 -833.398195 \nL 499.007153 -834.152246 \nL 496.878736 -834.152246 \nL 496.169263 -831.099917 \nL 495.459791 -828.553985 \nL 494.750319 -834.152246 \nL 494.040846 -829.130171 \nL 491.912429 -832.663771 \nL 491.202957 -827.927544 \nL 490.493485 -811.519589 \nL 489.784012 -829.370217 \nL 486.946123 -834.152246 \nL 486.236651 -834.152246 \nL 485.527178 -825.310926 \nL 484.817706 -817.606516 \nL 484.108234 -824.654242 \nL 481.979817 -816.449055 \nL 481.270344 -814.899498 \nL 480.560872 -821.400513 \nL 479.851399 -834.152246 \nL 479.141927 -834.152246 \nL 477.01351 -834.152246 \nL 476.304038 -827.738011 \nL 475.594565 -828.482766 \nL 474.885093 -833.604982 \nL 474.175621 -822.900203 \nL 472.047204 -828.366765 \nL 471.337731 -818.571557 \nL 470.628259 -834.152246 \nL 469.918787 -834.152246 \nL 469.209314 -834.152246 \nL 467.080897 -819.681243 \nL 466.371425 -810.014027 \nL 465.661953 -819.149836 \nL 464.95248 -810.794799 \nL 464.243008 -826.700027 \nL 462.114591 -816.546611 \nL 461.405118 -816.231901 \nL 457.148284 -805.06756 \nL 456.438812 -808.996727 \nL 455.72934 -797.418334 \nL 455.019867 -796.807125 \nL 454.310395 -785.8778 \nL 452.181978 -783.963807 \nL 451.472506 -780.497501 \nL 450.763033 -773.540639 \nL 450.053561 -759.87527 \nL 449.344089 -758.82474 \nL 447.215672 -750.491795 \nL 446.506199 -746.363039 \nL 445.796727 -746.493901 \nL 445.087255 -743.152071 \nL 444.377782 -751.483358 \nL 442.249365 -765.479314 \nL 441.539893 -766.246007 \nL 440.83042 -765.796301 \nL 440.120948 -760.504912 \nL 437.283059 -756.21644 \nL 436.573586 -751.487285 \nL 435.864114 -744.246189 \nL 435.154642 -738.427575 \nL 434.445169 -733.284869 \nL 432.316752 -735.036437 \nL 431.60728 -716.94898 \nL 430.897808 -711.948563 \nL 430.188335 -727.591941 \nL 429.478863 -738.125856 \nL 427.350446 -734.364085 \nL 426.640974 -745.391698 \nL 425.931501 -740.722234 \nL 425.222029 -735.242291 \nL 424.512557 -731.877119 \nL 422.384139 -737.535363 \nL 421.674667 -735.748361 \nL 420.965195 -719.175528 \nL 420.255722 -717.423805 \nL 419.54625 -721.724915 \nL 417.417833 -744.668838 \nL 416.708361 -752.256167 \nL 415.998888 -777.782243 \nL 415.289416 -773.655986 \nL 414.579944 -789.343381 \nL 412.451527 -780.826521 \nL 411.742054 -798.425846 \nL 411.032582 -795.298017 \nL 410.32311 -818.185159 \nL 409.613637 -821.781208 \nL 407.48522 -829.006075 \nL 406.775748 -834.152246 \nL 401.099969 -823.242062 \nL 400.390497 -808.291065 \nL 399.681024 -787.285408 \nL 397.552607 -779.830141 \nL 396.843135 -782.398107 \nL 396.133663 -792.273059 \nL 395.42419 -791.822992 \nL 394.714718 -776.417831 \nL 392.586301 -778.152807 \nL 391.876829 -792.296166 \nL 391.167356 -816.865555 \nL 390.457884 -809.894358 \nL 389.748412 -818.885329 \nL 387.619995 -818.248588 \nL 386.910522 -809.890079 \nL 386.20105 -798.358336 \nL 385.491577 -792.427699 \nL 384.782105 -812.100794 \nL 382.653688 -800.273004 \nL 381.944216 -808.822048 \nL 381.234743 -834.152246 \nL 380.525271 -834.152246 \nL 379.815799 -831.502817 \nL 377.687382 -834.152246 \nL 376.977909 -834.152246 \nL 376.268437 -834.152246 \nL 375.558965 -834.152246 \nL 374.849492 -834.152246 \nL 372.011603 -834.152246 \nL 371.302131 -830.719498 \nL 370.592658 -825.260434 \nL 369.883186 -834.152246 \nL 367.754769 -834.152246 \nL 367.045296 -829.858325 \nL 366.335824 -829.870503 \nL 365.626352 -817.209098 \nL 364.916879 -834.152246 \nL 362.788462 -834.152246 \nL 362.07899 -834.152246 \nL 361.369518 -823.238074 \nL 360.660045 -816.946843 \nL 359.950573 -809.049405 \nL 357.822156 -807.471573 \nL 357.112684 -815.245708 \nL 356.403211 -808.722414 \nL 355.693739 -813.892859 \nL 354.984267 -816.215384 \nL 352.85585 -822.20231 \nL 352.146377 -821.024632 \nL 351.436905 -825.653345 \nL 350.727433 -829.356596 \nL 350.01796 -820.114991 \nL 347.889543 -822.732434 \nL 347.180071 -820.356396 \nL 346.470598 -819.795772 \nL 345.761126 -828.263158 \nL 345.051654 -834.152246 \nL 342.923237 -834.152246 \nL 342.213764 -820.25577 \nL 341.504292 -811.925856 \nL 340.79482 -811.65134 \nL 340.085347 -812.296761 \nL 337.95693 -806.535198 \nL 337.247458 -816.864996 \nL 336.537986 -821.061961 \nL 335.828513 -834.152246 \nL 335.119041 -834.152246 \nL 332.990624 -825.405859 \nL 332.281152 -834.152246 \nL 331.571679 -827.43937 \nL 330.862207 -834.144973 \nL 330.152735 -830.226633 \nL 328.024317 -827.376414 \nL 327.314845 -826.321922 \nL 326.605373 -821.042954 \nL 325.8959 -815.074565 \nL 325.186428 -808.523605 \nL 323.058011 -804.665137 \nL 322.348539 -809.688481 \nL 321.639066 -812.321917 \nL 320.929594 -813.268713 \nL 320.220122 -806.32566 \nL 318.091705 -818.444625 \nL 317.382232 -823.589975 \nL 316.67276 -834.152246 \nL 315.963288 -834.152246 \nL 315.253815 -834.152246 \nL 313.125398 -834.152246 \nL 306.740147 -815.268082 \nL 306.030675 -818.546772 \nL 305.321202 -815.787415 \nL 303.192785 -803.048028 \nL 302.483313 -802.194257 \nL 301.773841 -817.84524 \nL 301.064368 -808.649455 \nL 300.354896 -816.752702 \nL 298.226479 -821.78297 \nL 297.517007 -814.835084 \nL 296.807534 -818.266154 \nL 296.098062 -818.342039 \nL 295.38859 -816.7267 \nL 293.260173 -814.023386 \nL 292.5507 -804.505283 \nL 291.841228 -804.551715 \nL 291.131755 -816.257579 \nL 290.422283 -810.970422 \nL 288.293866 -815.923268 \nL 287.584394 -828.460399 \nL 286.874921 -834.152246 \nL 286.165449 -834.152246 \nL 285.455977 -834.152246 \nL 283.32756 -834.152246 \nL 282.618087 -823.785421 \nL 281.908615 -814.599644 \nL 281.199143 -823.934692 \nL 280.48967 -827.862672 \nL 278.361253 -815.832495 \nL 277.651781 -807.907766 \nL 276.942309 -818.514747 \nL 276.232836 -828.06438 \nL 275.523364 -823.85927 \nL 273.394947 -811.975115 \nL 272.685475 -803.756697 \nL 271.976002 -803.085328 \nL 271.26653 -818.65121 \nL 270.557057 -834.152246 \nL 268.42864 -828.923622 \nL 267.719168 -823.881833 \nL 267.009696 -832.897907 \nL 266.300223 -826.545595 \nL 265.590751 -834.152246 \nL 263.462334 -834.152246 \nL 262.752862 -834.152246 \nL 262.043389 -829.682465 \nL 261.333917 -816.464799 \nL 260.624445 -820.510166 \nL 258.496028 -809.217139 \nL 257.786555 -834.152246 \nL 257.077083 -834.152246 \nL 256.367611 -834.152246 \nL 255.658138 -834.152246 \nL 253.529721 -811.145616 \nL 252.820249 -803.771957 \nL 252.110776 -834.152246 \nL 251.401304 -831.480817 \nL 250.691832 -833.323885 \nL 248.563415 -819.716177 \nL 247.853942 -834.152246 \nL 247.14447 -834.152246 \nL 246.434998 -832.962515 \nL 245.725525 -834.152246 \nL 243.597108 -834.152246 \nL 242.887636 -834.152246 \nL 242.178164 -834.152246 \nL 241.468691 -834.152246 \nL 240.759219 -834.152246 \nL 237.211857 -834.152246 \nL 236.502385 -834.152246 \nL 235.792913 -832.098295 \nL 233.664495 -826.169814 \nL 232.955023 -821.870691 \nL 232.245551 -818.117617 \nL 231.536078 -819.107301 \nL 230.826606 -811.981922 \nL 228.698189 -817.30936 \nL 227.988717 -821.593801 \nL 227.279244 -823.044083 \nL 226.569772 -825.324914 \nL 225.8603 -822.093774 \nL 223.731883 -812.491172 \nL 223.02241 -810.600232 \nL 222.312938 -813.391214 \nL 221.603466 -810.389693 \nL 220.893993 -809.605086 \nL 218.765576 -795.309014 \nL 218.056104 -793.176247 \nL 217.346632 -794.092646 \nL 216.637159 -797.709405 \nL 215.927687 -791.841525 \nL 213.79927 -789.191333 \nL 213.089797 -802.509136 \nL 212.380325 -811.555192 \nL 211.670853 -814.722392 \nL 210.96138 -806.56643 \nL 208.832963 -802.18157 \nL 208.123491 -806.47694 \nL 207.414019 -814.073106 \nL 206.704546 -816.031221 \nL 205.995074 -813.659052 \nL 203.866657 -817.542766 \nL 203.157185 -815.373963 \nL 202.447712 -817.861826 \nL 198.190878 -819.001288 \nL 197.481406 -810.871627 \nL 196.771933 -808.047438 \nL 196.062461 -799.022244 \nL 193.934044 -799.38958 \nL 193.224572 -805.643464 \nL 192.515099 -805.18112 \nL 191.805627 -800.561958 \nL 191.096155 -805.264868 \nL 188.967738 -804.014295 \nL 188.258265 -796.665181 \nL 187.548793 -793.99167 \nL 186.839321 -797.590279 \nL 186.129848 -785.885715 \nL 184.001431 -788.102464 \nL 183.291959 -793.822798 \nL 182.582487 -795.97958 \nL 181.873014 -797.709071 \nL 179.035125 -787.984121 \nL 178.325653 -788.454806 \nL 177.61618 -779.767021 \nL 176.906708 -781.003632 \nL 176.197235 -778.388747 \nL 174.068818 -782.630972 \nL 173.359346 -778.26363 \nL 172.649874 -780.369197 \nL 171.940401 -771.997403 \nL 171.230929 -757.00368 \nL 169.102512 -772.587298 \nL 168.39304 -767.637266 \nL 167.683567 -771.82179 \nL 166.974095 -778.151317 \nL 166.264623 -777.973495 \nL 164.136206 -797.472973 \nL 163.426733 -803.309296 \nL 162.717261 -814.986526 \nL 162.007789 -816.789999 \nL 161.298316 -807.126254 \nL 159.169899 -827.009525 \nL 158.460427 -834.152246 \nL 157.750954 -827.198031 \nL 157.041482 -825.207695 \nL 156.33201 -820.210944 \nL 154.203593 -811.134102 \nL 153.49412 -829.165586 \nL 152.784648 -827.402242 \nL 152.075176 -834.152246 \nL 151.365703 -831.095397 \nL 149.237286 -834.152246 \nL 148.527814 -834.152246 \nL 147.818342 -829.143116 \nL 147.108869 -834.072728 \nL 146.399397 -834.152246 \nL 144.27098 -832.546864 \nL 143.561508 -830.882472 \nL 142.852035 -827.441049 \nL 142.142563 -819.57939 \nL 141.433091 -816.656114 \nL 139.304673 -813.348525 \nL 138.595201 -812.408639 \nL 137.885729 -805.920195 \nL 137.176256 -792.558173 \nL 136.466784 -783.734572 \nL 128.662588 -816.07438 \nL 127.953116 -830.179535 \nL 127.243644 -828.756747 \nL 126.534171 -833.150642 \nL 124.405754 -834.152246 \nL 123.696282 -827.151421 \nL 122.98681 -828.51573 \nL 122.277337 -832.623168 \nL 121.567865 -834.152246 \nL 119.439448 -833.45401 \nL 118.729975 -834.152246 \nL 118.020503 -829.522467 \nL 117.311031 -834.152246 \nL 116.601558 -833.662347 \nL 114.473141 -833.689638 \nL 113.763669 -834.152246 \nz\n\" style=\"stroke: #ff7f50; stroke-opacity: 0.7\"/>\n    </defs>\n    <g clip-path=\"url(#p1f7dc791f5)\">\n     <use xlink:href=\"#m790c90f785\" x=\"0\" y=\"3576.760469\" style=\"fill: #ff7f50; fill-opacity: 0.7; stroke: #ff7f50; stroke-opacity: 0.7\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_17\">\n    <g id=\"xtick_113\">\n     <g id=\"line2d_207\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"113.054197\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_114\">\n     <g id=\"line2d_208\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"198.900351\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_115\">\n     <g id=\"line2d_209\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"286.165449\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_116\">\n     <g id=\"line2d_210\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"372.721075\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_117\">\n     <g id=\"line2d_211\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"457.857757\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_118\">\n     <g id=\"line2d_212\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"545.122855\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_119\">\n     <g id=\"line2d_213\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"631.678481\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_120\">\n     <g id=\"line2d_214\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"716.815163\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_121\">\n     <g id=\"line2d_215\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"804.080262\" y=\"2944.043652\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_122\">\n     <g id=\"line2d_216\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"210.96138\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_123\">\n     <g id=\"line2d_217\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"352.85585\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_124\">\n     <g id=\"line2d_218\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"494.750319\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_125\">\n     <g id=\"line2d_219\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"636.644788\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_126\">\n     <g id=\"line2d_220\">\n      <g>\n       <use xlink:href=\"#m29b6c6ad8b\" x=\"778.539257\" y=\"2944.043652\" style=\"stroke: #000000\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_18\">\n    <g id=\"ytick_61\">\n     <g id=\"line2d_221\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2943.695928\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_87\">\n      <!-- -40% -->\n      <g transform=\"translate(37.494984 2948.292983)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-25\" d=\"M 4653 2053 \nQ 4381 2053 4226 1822 \nQ 4072 1591 4072 1178 \nQ 4072 772 4226 539 \nQ 4381 306 4653 306 \nQ 4919 306 5073 539 \nQ 5228 772 5228 1178 \nQ 5228 1588 5073 1820 \nQ 4919 2053 4653 2053 \nz\nM 4653 2450 \nQ 5147 2450 5437 2106 \nQ 5728 1763 5728 1178 \nQ 5728 594 5436 251 \nQ 5144 -91 4653 -91 \nQ 4153 -91 3862 251 \nQ 3572 594 3572 1178 \nQ 3572 1766 3864 2108 \nQ 4156 2450 4653 2450 \nz\nM 1428 4353 \nQ 1159 4353 1004 4120 \nQ 850 3888 850 3481 \nQ 850 3069 1003 2837 \nQ 1156 2606 1428 2606 \nQ 1700 2606 1854 2837 \nQ 2009 3069 2009 3481 \nQ 2009 3884 1853 4118 \nQ 1697 4353 1428 4353 \nz\nM 4250 4750 \nL 4750 4750 \nL 1831 -91 \nL 1331 -91 \nL 4250 4750 \nz\nM 1428 4750 \nQ 1922 4750 2215 4408 \nQ 2509 4066 2509 3481 \nQ 2509 2891 2217 2550 \nQ 1925 2209 1428 2209 \nQ 931 2209 642 2551 \nQ 353 2894 353 3481 \nQ 353 4063 643 4406 \nQ 934 4750 1428 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_62\">\n     <g id=\"line2d_222\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2918.559965\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_88\">\n      <!-- -35% -->\n      <g transform=\"translate(37.494984 2923.15702)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_63\">\n     <g id=\"line2d_223\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2893.424002\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_89\">\n      <!-- -30% -->\n      <g transform=\"translate(37.494984 2898.021057)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_64\">\n     <g id=\"line2d_224\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2868.288039\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_90\">\n      <!-- -25% -->\n      <g transform=\"translate(37.494984 2872.885094)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_65\">\n     <g id=\"line2d_225\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2843.152076\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_91\">\n      <!-- -20% -->\n      <g transform=\"translate(37.494984 2847.749131)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_66\">\n     <g id=\"line2d_226\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2818.016113\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_92\">\n      <!-- -15% -->\n      <g transform=\"translate(37.494984 2822.613167)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_67\">\n     <g id=\"line2d_227\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2792.88015\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_93\">\n      <!-- -10% -->\n      <g transform=\"translate(37.494984 2797.477204)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_68\">\n     <g id=\"line2d_228\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2767.744186\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_94\">\n      <!-- -5% -->\n      <g transform=\"translate(45.193609 2772.341241)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"99.707031\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_69\">\n     <g id=\"line2d_229\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"2742.608223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_95\">\n      <!-- 0% -->\n      <g transform=\"translate(49.559062 2747.205278)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_96\">\n     <!-- Drawdown -->\n     <g transform=\"translate(30.749797 2878.371937)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \nL 1259 519 \nL 2022 519 \nQ 2988 519 3436 956 \nQ 3884 1394 3884 2338 \nQ 3884 3275 3436 3711 \nQ 2988 4147 2022 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 1925 4666 \nQ 3281 4666 3915 4102 \nQ 4550 3538 4550 2338 \nQ 4550 1131 3912 565 \nQ 3275 0 1925 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-44\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"77.001953\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"118.115234\"/>\n      <use xlink:href=\"#DejaVuSans-77\" x=\"179.394531\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"261.181641\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"324.658203\"/>\n      <use xlink:href=\"#DejaVuSans-77\" x=\"385.839844\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"467.626953\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_230\">\n    <path d=\"M 113.763669 2742.608223 \nL 114.473141 2743.07083 \nL 116.601558 2743.098122 \nL 117.311031 2742.608223 \nL 118.020503 2747.238001 \nL 118.729975 2742.608223 \nL 119.439448 2743.306459 \nL 121.567865 2742.608223 \nL 122.277337 2744.1373 \nL 122.98681 2748.244739 \nL 123.696282 2749.609048 \nL 124.405754 2742.608223 \nL 126.534171 2743.609827 \nL 127.243644 2748.003722 \nL 127.953116 2746.580933 \nL 128.662588 2760.686089 \nL 136.466784 2793.025896 \nL 137.176256 2784.202295 \nL 137.885729 2770.840274 \nL 138.595201 2764.35183 \nL 139.304673 2763.411943 \nL 141.433091 2760.104355 \nL 142.142563 2757.181079 \nL 142.852035 2749.319419 \nL 143.561508 2745.877997 \nL 144.27098 2744.213605 \nL 146.399397 2742.608223 \nL 147.108869 2742.687741 \nL 147.818342 2747.617352 \nL 148.527814 2742.608223 \nL 149.237286 2742.608223 \nL 151.365703 2745.665071 \nL 152.075176 2742.608223 \nL 152.784648 2749.358227 \nL 153.49412 2747.594883 \nL 154.203593 2765.626367 \nL 156.33201 2756.549525 \nL 157.041482 2751.552774 \nL 157.750954 2749.562438 \nL 158.460427 2742.608223 \nL 159.169899 2749.750944 \nL 161.298316 2769.634214 \nL 162.007789 2759.97047 \nL 162.717261 2761.773942 \nL 163.426733 2773.451172 \nL 164.136206 2779.287496 \nL 166.264623 2798.786974 \nL 166.974095 2798.609152 \nL 167.683567 2804.938678 \nL 168.39304 2809.123203 \nL 169.102512 2804.173171 \nL 171.230929 2819.756789 \nL 171.940401 2804.763066 \nL 172.649874 2796.391272 \nL 173.359346 2798.496839 \nL 174.068818 2794.129496 \nL 176.197235 2798.371721 \nL 176.906708 2795.756837 \nL 177.61618 2796.993447 \nL 178.325653 2788.305663 \nL 179.035125 2788.776347 \nL 181.873014 2779.051398 \nL 182.582487 2780.780889 \nL 183.291959 2782.937671 \nL 184.001431 2788.658005 \nL 186.129848 2790.874754 \nL 186.839321 2779.17019 \nL 187.548793 2782.768799 \nL 188.258265 2780.095288 \nL 188.967738 2772.746174 \nL 191.096155 2771.495601 \nL 191.805627 2776.198511 \nL 192.515099 2771.579348 \nL 193.224572 2771.117005 \nL 193.934044 2777.370888 \nL 196.062461 2777.738225 \nL 196.771933 2768.71303 \nL 197.481406 2765.888842 \nL 198.190878 2757.759181 \nL 202.447712 2758.898643 \nL 203.157185 2761.386506 \nL 203.866657 2759.217703 \nL 205.995074 2763.101417 \nL 206.704546 2760.729248 \nL 207.414019 2762.687363 \nL 208.123491 2770.283529 \nL 208.832963 2774.578899 \nL 210.96138 2770.194038 \nL 211.670853 2762.038076 \nL 212.380325 2765.205276 \nL 213.089797 2774.251332 \nL 213.79927 2787.569135 \nL 215.927687 2784.918944 \nL 216.637159 2779.051064 \nL 217.346632 2782.667823 \nL 218.056104 2783.584222 \nL 218.765576 2781.451455 \nL 220.893993 2767.155383 \nL 221.603466 2766.370776 \nL 222.312938 2763.369255 \nL 223.02241 2766.160236 \nL 223.731883 2764.269296 \nL 226.569772 2751.435555 \nL 227.279244 2753.716386 \nL 227.988717 2755.166667 \nL 228.698189 2759.451109 \nL 230.826606 2764.778546 \nL 231.536078 2757.653168 \nL 232.245551 2758.642851 \nL 233.664495 2750.590655 \nL 236.502385 2742.608223 \nL 245.725525 2742.608223 \nL 246.434998 2743.797953 \nL 247.14447 2742.608223 \nL 247.853942 2742.608223 \nL 248.563415 2757.044291 \nL 250.691832 2743.436584 \nL 251.401304 2745.279652 \nL 252.110776 2742.608223 \nL 252.820249 2772.988512 \nL 255.658138 2742.608223 \nL 257.786555 2742.608223 \nL 258.496028 2767.543329 \nL 260.624445 2756.250303 \nL 261.333917 2760.29567 \nL 262.043389 2747.078004 \nL 262.752862 2742.608223 \nL 265.590751 2742.608223 \nL 266.300223 2750.214873 \nL 267.009696 2743.862562 \nL 267.719168 2752.878636 \nL 268.42864 2747.836847 \nL 270.557057 2742.608223 \nL 271.976002 2773.675141 \nL 272.685475 2773.003772 \nL 273.394947 2764.785354 \nL 276.232836 2748.696089 \nL 277.651781 2768.852702 \nL 278.361253 2760.927974 \nL 280.48967 2748.897796 \nL 281.199143 2752.825776 \nL 281.908615 2762.160825 \nL 283.32756 2742.608223 \nL 286.874921 2742.608223 \nL 287.584394 2748.30007 \nL 288.293866 2760.837201 \nL 290.422283 2765.790046 \nL 291.131755 2760.50289 \nL 291.841228 2772.208753 \nL 292.5507 2772.255186 \nL 293.260173 2762.737082 \nL 295.38859 2760.033768 \nL 296.098062 2758.418429 \nL 296.807534 2758.494315 \nL 297.517007 2761.925385 \nL 298.226479 2754.977498 \nL 300.354896 2760.007767 \nL 301.064368 2768.111014 \nL 301.773841 2758.915229 \nL 302.483313 2774.566212 \nL 303.192785 2773.712441 \nL 305.321202 2760.973054 \nL 306.030675 2758.213697 \nL 306.740147 2761.492387 \nL 313.125398 2742.608223 \nL 316.67276 2742.608223 \nL 317.382232 2753.170494 \nL 318.091705 2758.315844 \nL 320.220122 2770.434809 \nL 320.929594 2763.491755 \nL 321.639066 2764.438551 \nL 322.348539 2767.071988 \nL 323.058011 2772.095332 \nL 325.186428 2768.236864 \nL 326.605373 2755.717515 \nL 327.314845 2750.438546 \nL 328.024317 2749.384055 \nL 330.152735 2746.533835 \nL 330.862207 2742.615496 \nL 331.571679 2749.321098 \nL 332.281152 2742.608223 \nL 332.990624 2751.35461 \nL 335.119041 2742.608223 \nL 335.828513 2742.608223 \nL 336.537986 2755.698508 \nL 337.247458 2759.895473 \nL 337.95693 2770.225271 \nL 340.085347 2764.463708 \nL 340.79482 2765.109129 \nL 341.504292 2764.834613 \nL 342.213764 2756.504699 \nL 342.923237 2742.608223 \nL 345.051654 2742.608223 \nL 345.761126 2748.497311 \nL 346.470598 2756.964696 \nL 347.180071 2756.404072 \nL 347.889543 2754.028035 \nL 350.01796 2756.645477 \nL 350.727433 2747.403873 \nL 351.436905 2751.107124 \nL 352.146377 2755.735836 \nL 352.85585 2754.558159 \nL 355.693739 2762.867609 \nL 356.403211 2768.038055 \nL 357.112684 2761.514761 \nL 357.822156 2769.288896 \nL 359.950573 2767.711063 \nL 360.660045 2759.813626 \nL 361.369518 2753.522394 \nL 362.07899 2742.608223 \nL 364.916879 2742.608223 \nL 365.626352 2759.551371 \nL 366.335824 2746.889966 \nL 367.045296 2746.902144 \nL 367.754769 2742.608223 \nL 369.883186 2742.608223 \nL 370.592658 2751.500035 \nL 371.302131 2746.040971 \nL 372.011603 2742.608223 \nL 377.687382 2742.608223 \nL 379.815799 2745.257652 \nL 380.525271 2742.608223 \nL 381.234743 2742.608223 \nL 381.944216 2767.938421 \nL 382.653688 2776.487465 \nL 384.782105 2764.659675 \nL 385.491577 2784.332769 \nL 386.20105 2778.402133 \nL 386.910522 2766.87039 \nL 387.619995 2758.511881 \nL 389.748412 2757.875139 \nL 390.457884 2766.86611 \nL 391.167356 2759.894914 \nL 391.876829 2784.464302 \nL 392.586301 2798.607661 \nL 394.714718 2800.342638 \nL 395.42419 2784.937477 \nL 396.133663 2784.48741 \nL 396.843135 2794.362362 \nL 397.552607 2796.930328 \nL 399.681024 2789.475061 \nL 400.390497 2768.469404 \nL 401.099969 2753.518406 \nL 406.775748 2742.608223 \nL 407.48522 2747.754394 \nL 409.613637 2754.979261 \nL 410.32311 2758.57531 \nL 411.032582 2781.462452 \nL 411.742054 2778.334623 \nL 412.451527 2795.933948 \nL 414.579944 2787.417088 \nL 415.289416 2803.104483 \nL 415.998888 2798.978226 \nL 416.708361 2824.504302 \nL 419.54625 2855.035554 \nL 420.255722 2859.336664 \nL 420.965195 2857.584941 \nL 421.674667 2841.012107 \nL 422.384139 2839.225106 \nL 424.512557 2844.88335 \nL 425.222029 2841.518177 \nL 426.640974 2831.368771 \nL 427.350446 2842.396384 \nL 429.478863 2838.634613 \nL 430.188335 2849.168527 \nL 430.897808 2864.811906 \nL 431.60728 2859.811489 \nL 432.316752 2841.724031 \nL 434.445169 2843.4756 \nL 435.864114 2832.51428 \nL 436.573586 2825.273184 \nL 437.283059 2820.544029 \nL 440.120948 2816.255556 \nL 440.83042 2810.964168 \nL 441.539893 2810.514462 \nL 442.249365 2811.281155 \nL 444.377782 2825.277111 \nL 445.087255 2833.608397 \nL 445.796727 2830.266568 \nL 446.506199 2830.39743 \nL 447.215672 2826.268674 \nL 449.344089 2817.935729 \nL 450.053561 2816.885199 \nL 450.763033 2803.21983 \nL 451.472506 2796.262968 \nL 452.181978 2792.796661 \nL 454.310395 2790.882669 \nL 455.019867 2779.953344 \nL 455.72934 2779.342135 \nL 456.438812 2767.763742 \nL 457.148284 2771.692909 \nL 461.405118 2760.528568 \nL 462.114591 2760.213858 \nL 464.243008 2750.060442 \nL 464.95248 2765.96567 \nL 465.661953 2757.610633 \nL 466.371425 2766.746442 \nL 467.080897 2757.079226 \nL 469.209314 2742.608223 \nL 470.628259 2742.608223 \nL 471.337731 2758.188912 \nL 472.047204 2748.393704 \nL 474.175621 2753.860266 \nL 474.885093 2743.155487 \nL 475.594565 2748.277702 \nL 476.304038 2749.022457 \nL 477.01351 2742.608223 \nL 479.851399 2742.608223 \nL 480.560872 2755.359955 \nL 481.270344 2761.860971 \nL 481.979817 2760.311414 \nL 484.108234 2752.106227 \nL 484.817706 2759.153953 \nL 486.236651 2742.608223 \nL 486.946123 2742.608223 \nL 489.784012 2747.390251 \nL 490.493485 2765.24088 \nL 491.202957 2748.832925 \nL 491.912429 2744.096697 \nL 494.040846 2747.630298 \nL 494.750319 2742.608223 \nL 495.459791 2748.206484 \nL 496.169263 2745.660552 \nL 496.878736 2742.608223 \nL 499.007153 2742.608223 \nL 499.716625 2743.362273 \nL 500.426098 2742.608223 \nL 501.13557 2743.396275 \nL 501.845042 2751.444978 \nL 503.973459 2781.728535 \nL 504.682932 2784.530089 \nL 505.392404 2768.257132 \nL 506.101876 2774.764608 \nL 506.811349 2793.635359 \nL 508.939766 2787.937808 \nL 509.649238 2771.936926 \nL 510.35871 2825.852326 \nL 511.068183 2824.264066 \nL 511.777655 2829.699391 \nL 513.906072 2817.629946 \nL 514.615544 2821.064674 \nL 515.325017 2813.015619 \nL 516.034489 2810.433336 \nL 516.743961 2822.959895 \nL 518.872379 2833.50004 \nL 519.581851 2848.403535 \nL 520.291323 2848.890197 \nL 521.000796 2835.996271 \nL 521.710268 2831.739546 \nL 523.838685 2815.239533 \nL 524.548157 2805.582458 \nL 525.25763 2793.326832 \nL 525.967102 2794.357967 \nL 526.676574 2794.638342 \nL 528.804991 2797.279032 \nL 529.514464 2794.234582 \nL 530.223936 2794.847123 \nL 530.933408 2786.563969 \nL 531.642881 2791.76753 \nL 533.771298 2797.849232 \nL 534.48077 2804.617493 \nL 535.190242 2799.999805 \nL 535.899715 2803.615062 \nL 536.609187 2819.880915 \nL 538.737604 2800.891124 \nL 539.447077 2798.408367 \nL 540.156549 2789.386092 \nL 540.866021 2792.142909 \nL 541.575494 2787.96129 \nL 543.703911 2780.12341 \nL 544.413383 2782.584962 \nL 545.122855 2786.021914 \nL 545.832328 2785.930185 \nL 546.5418 2794.027398 \nL 548.670217 2790.644439 \nL 549.379689 2776.934657 \nL 550.089162 2773.71284 \nL 550.798634 2777.651691 \nL 551.508106 2760.269597 \nL 553.636523 2746.846721 \nL 555.055468 2765.184755 \nL 555.76494 2775.334777 \nL 556.474413 2766.600923 \nL 560.021775 2764.55255 \nL 560.731247 2762.120041 \nL 561.440719 2760.555773 \nL 563.569136 2778.750847 \nL 564.278609 2787.6033 \nL 564.988081 2802.796856 \nL 565.697553 2795.992605 \nL 573.501749 2795.321537 \nL 574.211221 2797.256766 \nL 574.920694 2791.98443 \nL 575.630166 2798.356718 \nL 576.339639 2801.990427 \nL 578.468056 2802.118647 \nL 579.177528 2795.04972 \nL 579.887 2801.148366 \nL 580.596473 2799.733864 \nL 581.305945 2800.523731 \nL 583.434362 2793.856982 \nL 584.143834 2795.984874 \nL 584.853307 2800.813286 \nL 585.562779 2807.676396 \nL 586.272251 2798.839904 \nL 588.400668 2807.663282 \nL 589.110141 2815.510562 \nL 589.819613 2815.832581 \nL 590.529085 2813.471312 \nL 591.238558 2820.474467 \nL 593.366975 2818.564489 \nL 594.076447 2819.910835 \nL 594.78592 2825.628001 \nL 595.495392 2822.996885 \nL 596.204864 2822.652836 \nL 598.333281 2829.836436 \nL 599.042754 2826.911373 \nL 599.752226 2826.451193 \nL 600.461698 2827.837662 \nL 601.171171 2826.095081 \nL 603.299588 2821.796464 \nL 604.00906 2818.620698 \nL 604.718532 2821.894242 \nL 605.428005 2823.236597 \nL 606.137477 2823.736708 \nL 608.265894 2815.224896 \nL 608.975366 2807.747971 \nL 609.684839 2808.727094 \nL 610.394311 2804.896681 \nL 611.103783 2808.178333 \nL 613.232201 2803.408845 \nL 613.941673 2800.300124 \nL 614.651145 2793.426419 \nL 615.360618 2789.942574 \nL 616.07009 2783.285071 \nL 618.198507 2783.712341 \nL 618.907979 2795.692617 \nL 619.617452 2794.21289 \nL 620.326924 2791.164141 \nL 621.036396 2796.429748 \nL 623.164813 2796.717944 \nL 623.874286 2793.537509 \nL 624.583758 2800.904717 \nL 625.29323 2796.148366 \nL 626.002703 2808.364023 \nL 628.13112 2809.243093 \nL 628.840592 2799.714712 \nL 629.550064 2806.812085 \nL 630.259537 2812.193932 \nL 630.969009 2802.19602 \nL 633.806899 2801.909499 \nL 634.516371 2810.064111 \nL 635.225843 2816.725687 \nL 635.935316 2815.800052 \nL 638.063733 2819.228419 \nL 638.773205 2823.122791 \nL 639.482677 2815.665841 \nL 640.19215 2823.274362 \nL 640.901622 2824.402243 \nL 643.030039 2831.040507 \nL 643.739511 2823.866912 \nL 644.448984 2830.855351 \nL 645.158456 2833.382175 \nL 645.867928 2838.445377 \nL 647.996345 2834.521702 \nL 648.705818 2847.060739 \nL 649.41529 2840.162985 \nL 650.834235 2858.419103 \nL 657.928958 2843.361886 \nL 658.638431 2841.422696 \nL 659.347903 2838.691063 \nL 660.057375 2838.440459 \nL 660.766848 2840.997123 \nL 662.895265 2849.815699 \nL 663.604737 2846.241522 \nL 665.023682 2837.506677 \nL 665.733154 2836.262155 \nL 667.861571 2837.609561 \nL 668.571043 2837.407021 \nL 669.280516 2832.392005 \nL 669.989988 2840.439251 \nL 670.699461 2838.397263 \nL 673.53735 2821.777128 \nL 674.246822 2819.389961 \nL 674.956295 2815.051354 \nL 675.665767 2819.055655 \nL 677.794184 2829.592857 \nL 678.503656 2838.768424 \nL 679.213129 2842.292266 \nL 680.632073 2827.542879 \nL 682.76049 2842.232827 \nL 683.469963 2860.783265 \nL 684.179435 2842.139374 \nL 684.888907 2842.822759 \nL 685.59838 2838.528669 \nL 687.726797 2836.554739 \nL 688.436269 2834.864486 \nL 689.145742 2837.777405 \nL 689.855214 2838.694635 \nL 690.564686 2848.968526 \nL 692.693103 2845.688676 \nL 693.402576 2842.170977 \nL 694.112048 2835.52027 \nL 694.82152 2845.45732 \nL 695.530993 2830.741918 \nL 699.078354 2841.732545 \nL 699.787827 2848.779943 \nL 700.497299 2848.300836 \nL 702.625716 2861.639113 \nL 703.335188 2853.193547 \nL 704.044661 2851.164507 \nL 704.754133 2842.924155 \nL 705.463605 2851.17467 \nL 708.301495 2856.466414 \nL 709.010967 2861.35484 \nL 709.72044 2871.885582 \nL 710.429912 2870.610929 \nL 712.558329 2893.141335 \nL 713.267801 2894.521974 \nL 713.977274 2881.132949 \nL 714.686746 2877.677433 \nL 715.396218 2869.531082 \nL 719.653052 2866.756755 \nL 720.362525 2882.526933 \nL 722.490942 2884.645377 \nL 723.200414 2884.431969 \nL 723.909886 2882.111332 \nL 724.619359 2884.256929 \nL 725.328831 2881.456244 \nL 727.457248 2884.517056 \nL 728.166721 2879.778045 \nL 728.876193 2881.626472 \nL 729.585665 2885.092882 \nL 730.295138 2873.275606 \nL 732.423555 2869.768553 \nL 733.133027 2876.872783 \nL 733.842499 2873.854633 \nL 734.551972 2874.252711 \nL 735.261444 2871.733516 \nL 737.389861 2872.119611 \nL 738.099333 2871.466086 \nL 738.808806 2872.599374 \nL 739.518278 2872.278687 \nL 742.356167 2866.16273 \nL 743.06564 2859.202086 \nL 743.775112 2859.204452 \nL 744.484584 2865.819735 \nL 745.194057 2863.741452 \nL 747.322474 2869.668273 \nL 748.031946 2866.991648 \nL 748.741419 2861.089035 \nL 749.450891 2864.598008 \nL 750.160363 2861.838013 \nL 752.28878 2863.888536 \nL 752.998253 2871.054259 \nL 753.707725 2872.429247 \nL 755.12667 2864.973667 \nL 757.255087 2862.307834 \nL 757.964559 2858.950222 \nL 758.674031 2866.648729 \nL 759.383504 2860.706335 \nL 760.092976 2859.0314 \nL 762.221393 2856.935603 \nL 762.930865 2854.73214 \nL 763.640338 2864.475973 \nL 764.34981 2859.120408 \nL 765.059283 2859.683456 \nL 767.1877 2868.751464 \nL 767.897172 2873.154961 \nL 768.606644 2873.862098 \nL 769.316117 2876.552677 \nL 770.025589 2883.876674 \nL 772.154006 2876.350901 \nL 772.863478 2879.595735 \nL 773.572951 2880.677013 \nL 774.282423 2887.628425 \nL 774.991895 2886.260049 \nL 777.120312 2891.044636 \nL 777.829785 2886.937412 \nL 778.539257 2889.894656 \nL 779.248729 2891.350655 \nL 779.958202 2893.288514 \nL 782.086619 2896.942189 \nL 782.796091 2909.678572 \nL 783.505564 2912.778787 \nL 784.215036 2910.043445 \nL 784.924508 2905.395504 \nL 787.052925 2904.16932 \nL 787.762398 2902.201084 \nL 788.47187 2905.208118 \nL 789.181342 2899.601367 \nL 789.890815 2899.774468 \nL 792.019232 2901.313462 \nL 792.728704 2903.10038 \nL 793.438176 2901.257651 \nL 794.147649 2905.065427 \nL 794.857121 2901.210409 \nL 796.985538 2898.75597 \nL 797.69501 2902.699684 \nL 798.404483 2907.511479 \nL 799.113955 2901.875591 \nL 799.823427 2904.422799 \nL 801.951844 2907.098976 \nL 802.661317 2904.336559 \nL 803.370789 2904.15204 \nL 804.789734 2914.160402 \nL 806.918151 2914.759379 \nL 807.627623 2909.801594 \nL 808.337096 2909.576362 \nL 809.046568 2910.754974 \nL 809.75604 2906.318546 \nL 812.59393 2906.670623 \nL 813.303402 2910.91061 \nL 814.012874 2914.149568 \nL 814.722347 2922.418117 \nL 816.850764 2924.632002 \nL 817.560236 2923.020661 \nL 818.269708 2922.095259 \nL 818.979181 2923.900331 \nL 819.688653 2927.115084 \nL 821.81707 2934.070307 \nL 822.526543 2927.594234 \nL 823.236015 2934.451489 \nL 823.945487 2932.47452 \nL 823.945487 2932.47452 \n\" clip-path=\"url(#p1f7dc791f5)\" style=\"fill: none; stroke: #ff7f50; stroke-opacity: 0.7; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_49\">\n    <path d=\"M 78.254578 2944.043652 \nL 78.254578 2742.608223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_50\">\n    <path d=\"M 859.454578 2944.043652 \nL 859.454578 2742.608223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_51\">\n    <path d=\"M 78.254578 2944.043652 \nL 859.454578 2944.043652 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_52\">\n    <path d=\"M 78.254578 2742.608223 \nL 859.454578 2742.608223 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_97\">\n    <!-- Underwater plot -->\n    <g transform=\"translate(415.326516 2736.608223)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-55\" d=\"M 556 4666 \nL 1191 4666 \nL 1191 1831 \nQ 1191 1081 1462 751 \nQ 1734 422 2344 422 \nQ 2950 422 3222 751 \nQ 3494 1081 3494 1831 \nL 3494 4666 \nL 4128 4666 \nL 4128 1753 \nQ 4128 841 3676 375 \nQ 3225 -91 2344 -91 \nQ 1459 -91 1007 375 \nQ 556 841 556 1753 \nL 556 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-55\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"73.193359\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"136.572266\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"200.048828\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"261.572266\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"302.685547\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"384.472656\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"445.751953\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"484.960938\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"546.484375\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"587.597656\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"619.384766\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"682.861328\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"710.644531\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"771.826172\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_10\">\n   <g id=\"patch_53\">\n    <path d=\"M 78.254578 3246.196795 \nL 273.554578 3246.196795 \nL 273.554578 3044.761366 \nL 78.254578 3044.761366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"QuadMesh_1\">\n    <path d=\"M 78.254578 3044.761366 \nL 94.529578 3044.761366 \nL 94.529578 3111.906509 \nL 78.254578 3111.906509 \nL 78.254578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fff6b0\"/>\n    <path d=\"M 94.529578 3044.761366 \nL 110.804578 3044.761366 \nL 110.804578 3111.906509 \nL 94.529578 3111.906509 \nL 94.529578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #f2faae\"/>\n    <path d=\"M 110.804578 3044.761366 \nL 127.079578 3044.761366 \nL 127.079578 3111.906509 \nL 110.804578 3111.906509 \nL 110.804578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fee491\"/>\n    <path d=\"M 127.079578 3044.761366 \nL 143.354578 3044.761366 \nL 143.354578 3111.906509 \nL 127.079578 3111.906509 \nL 127.079578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #cdea83\"/>\n    <path d=\"M 143.354578 3044.761366 \nL 159.629578 3044.761366 \nL 159.629578 3111.906509 \nL 143.354578 3111.906509 \nL 143.354578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #feea9b\"/>\n    <path d=\"M 159.629578 3044.761366 \nL 175.904578 3044.761366 \nL 175.904578 3111.906509 \nL 159.629578 3111.906509 \nL 159.629578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #b9e176\"/>\n    <path d=\"M 175.904578 3044.761366 \nL 192.179578 3044.761366 \nL 192.179578 3111.906509 \nL 175.904578 3111.906509 \nL 175.904578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #006837\"/>\n    <path d=\"M 192.179578 3044.761366 \nL 208.454578 3044.761366 \nL 208.454578 3111.906509 \nL 192.179578 3111.906509 \nL 192.179578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #ebf7a3\"/>\n    <path d=\"M 208.454578 3044.761366 \nL 224.729578 3044.761366 \nL 224.729578 3111.906509 \nL 208.454578 3111.906509 \nL 208.454578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fffdbc\"/>\n    <path d=\"M 224.729578 3044.761366 \nL 241.004578 3044.761366 \nL 241.004578 3111.906509 \nL 224.729578 3111.906509 \nL 224.729578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #cbe982\"/>\n    <path d=\"M 241.004578 3044.761366 \nL 257.279578 3044.761366 \nL 257.279578 3111.906509 \nL 241.004578 3111.906509 \nL 241.004578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #d3ec87\"/>\n    <path d=\"M 257.279578 3044.761366 \nL 273.554578 3044.761366 \nL 273.554578 3111.906509 \nL 257.279578 3111.906509 \nL 257.279578 3044.761366 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #98d368\"/>\n    <path d=\"M 78.254578 3111.906509 \nL 94.529578 3111.906509 \nL 94.529578 3179.051652 \nL 78.254578 3179.051652 \nL 78.254578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #eff8aa\"/>\n    <path d=\"M 94.529578 3111.906509 \nL 110.804578 3111.906509 \nL 110.804578 3179.051652 \nL 94.529578 3179.051652 \nL 94.529578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #f8fcb6\"/>\n    <path d=\"M 110.804578 3111.906509 \nL 127.079578 3111.906509 \nL 127.079578 3179.051652 \nL 110.804578 3179.051652 \nL 110.804578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fed884\"/>\n    <path d=\"M 127.079578 3111.906509 \nL 143.354578 3111.906509 \nL 143.354578 3179.051652 \nL 127.079578 3179.051652 \nL 127.079578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #a0d669\"/>\n    <path d=\"M 143.354578 3111.906509 \nL 159.629578 3111.906509 \nL 159.629578 3179.051652 \nL 143.354578 3179.051652 \nL 143.354578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #b7e075\"/>\n    <path d=\"M 159.629578 3111.906509 \nL 175.904578 3111.906509 \nL 175.904578 3179.051652 \nL 159.629578 3179.051652 \nL 159.629578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #b5df74\"/>\n    <path d=\"M 175.904578 3111.906509 \nL 192.179578 3111.906509 \nL 192.179578 3179.051652 \nL 175.904578 3179.051652 \nL 175.904578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #f88c51\"/>\n    <path d=\"M 192.179578 3111.906509 \nL 208.454578 3111.906509 \nL 208.454578 3179.051652 \nL 192.179578 3179.051652 \nL 192.179578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #b5df74\"/>\n    <path d=\"M 208.454578 3111.906509 \nL 224.729578 3111.906509 \nL 224.729578 3179.051652 \nL 208.454578 3179.051652 \nL 208.454578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fff1a8\"/>\n    <path d=\"M 224.729578 3111.906509 \nL 241.004578 3111.906509 \nL 241.004578 3179.051652 \nL 224.729578 3179.051652 \nL 224.729578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fffdbc\"/>\n    <path d=\"M 241.004578 3111.906509 \nL 257.279578 3111.906509 \nL 257.279578 3179.051652 \nL 241.004578 3179.051652 \nL 241.004578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fff6b0\"/>\n    <path d=\"M 257.279578 3111.906509 \nL 273.554578 3111.906509 \nL 273.554578 3179.051652 \nL 257.279578 3179.051652 \nL 257.279578 3111.906509 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #f8fcb6\"/>\n    <path d=\"M 78.254578 3179.051652 \nL 94.529578 3179.051652 \nL 94.529578 3246.196795 \nL 78.254578 3246.196795 \nL 78.254578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fdb768\"/>\n    <path d=\"M 94.529578 3179.051652 \nL 110.804578 3179.051652 \nL 110.804578 3246.196795 \nL 94.529578 3246.196795 \nL 94.529578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #cdea83\"/>\n    <path d=\"M 110.804578 3179.051652 \nL 127.079578 3179.051652 \nL 127.079578 3246.196795 \nL 110.804578 3246.196795 \nL 110.804578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #feea9b\"/>\n    <path d=\"M 127.079578 3179.051652 \nL 143.354578 3179.051652 \nL 143.354578 3246.196795 \nL 127.079578 3246.196795 \nL 127.079578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fee491\"/>\n    <path d=\"M 143.354578 3179.051652 \nL 159.629578 3179.051652 \nL 159.629578 3246.196795 \nL 143.354578 3246.196795 \nL 143.354578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fffdbc\"/>\n    <path d=\"M 159.629578 3179.051652 \nL 175.904578 3179.051652 \nL 175.904578 3246.196795 \nL 159.629578 3246.196795 \nL 159.629578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #eff8aa\"/>\n    <path d=\"M 175.904578 3179.051652 \nL 192.179578 3179.051652 \nL 192.179578 3246.196795 \nL 175.904578 3246.196795 \nL 175.904578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fed481\"/>\n    <path d=\"M 192.179578 3179.051652 \nL 208.454578 3179.051652 \nL 208.454578 3246.196795 \nL 192.179578 3246.196795 \nL 192.179578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fff1a8\"/>\n    <path d=\"M 208.454578 3179.051652 \nL 224.729578 3179.051652 \nL 224.729578 3246.196795 \nL 208.454578 3246.196795 \nL 208.454578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fed683\"/>\n    <path d=\"M 224.729578 3179.051652 \nL 241.004578 3179.051652 \nL 241.004578 3246.196795 \nL 224.729578 3246.196795 \nL 224.729578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fffebe\"/>\n    <path d=\"M 241.004578 3179.051652 \nL 257.279578 3179.051652 \nL 257.279578 3246.196795 \nL 241.004578 3246.196795 \nL 241.004578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fffebe\"/>\n    <path d=\"M 257.279578 3179.051652 \nL 273.554578 3179.051652 \nL 273.554578 3246.196795 \nL 257.279578 3246.196795 \nL 257.279578 3179.051652 \n\" clip-path=\"url(#pb4c3cad4a9)\" style=\"fill: #fffebe\"/>\n   </g>\n   <g id=\"matplotlib.axis_19\">\n    <g id=\"xtick_127\">\n     <g id=\"line2d_231\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"86.392078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_98\">\n      <!-- 1 -->\n      <g transform=\"translate(82.542766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_128\">\n     <g id=\"line2d_232\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"102.667078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_99\">\n      <!-- 2 -->\n      <g transform=\"translate(98.817766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_129\">\n     <g id=\"line2d_233\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"118.942078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_100\">\n      <!-- 3 -->\n      <g transform=\"translate(115.092766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_130\">\n     <g id=\"line2d_234\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"135.217078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_101\">\n      <!-- 4 -->\n      <g transform=\"translate(131.367766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_131\">\n     <g id=\"line2d_235\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"151.492078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_102\">\n      <!-- 5 -->\n      <g transform=\"translate(147.642766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_132\">\n     <g id=\"line2d_236\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"167.767078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_103\">\n      <!-- 6 -->\n      <g transform=\"translate(163.917766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_133\">\n     <g id=\"line2d_237\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"184.042078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_104\">\n      <!-- 7 -->\n      <g transform=\"translate(180.192766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-37\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_134\">\n     <g id=\"line2d_238\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"200.317078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_105\">\n      <!-- 8 -->\n      <g transform=\"translate(196.467766 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_135\">\n     <g id=\"line2d_239\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"216.592078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_106\">\n      <!-- 9 -->\n      <g transform=\"translate(212.742766 3264.890904)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-39\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_136\">\n     <g id=\"line2d_240\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"232.867078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_107\">\n      <!-- 10 -->\n      <g transform=\"translate(225.168453 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_137\">\n     <g id=\"line2d_241\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"249.142078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_108\">\n      <!-- 11 -->\n      <g transform=\"translate(241.443453 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_138\">\n     <g id=\"line2d_242\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"265.417078\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_109\">\n      <!-- 12 -->\n      <g transform=\"translate(257.718453 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_110\">\n     <!-- Month -->\n     <g transform=\"translate(155.218734 3281.437263)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-4d\" d=\"M 628 4666 \nL 1569 4666 \nL 2759 1491 \nL 3956 4666 \nL 4897 4666 \nL 4897 0 \nL 4281 0 \nL 4281 4097 \nL 3078 897 \nL 2444 897 \nL 1241 4097 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4d\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"86.279297\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"147.460938\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"210.839844\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"250.048828\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_20\">\n    <g id=\"ytick_70\">\n     <g id=\"line2d_243\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3078.333937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_111\">\n      <!-- 2020 -->\n      <g transform=\"translate(66.238156 3093.731187)rotate(-90)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_71\">\n     <g id=\"line2d_244\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3145.47908\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_112\">\n      <!-- 2021 -->\n      <g transform=\"translate(66.238156 3160.87633)rotate(-90)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_72\">\n     <g id=\"line2d_245\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3212.624223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_113\">\n      <!-- 2022 -->\n      <g transform=\"translate(66.238156 3228.021473)rotate(-90)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_114\">\n     <!-- Year -->\n     <g transform=\"translate(50.298859 3159.45458)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-59\" d=\"M -13 4666 \nL 666 4666 \nL 1959 2747 \nL 3244 4666 \nL 3922 4666 \nL 2272 2222 \nL 2272 0 \nL 1638 0 \nL 1638 2222 \nL -13 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-59\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"47.833984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"109.357422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"170.636719\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_115\">\n    <!-- -1.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(77.612156 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_116\">\n    <!-- 2.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(95.510672 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-32\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_117\">\n    <!-- -6.1 -->\n    <g style=\"fill: #262626\" transform=\"translate(110.162156 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_118\">\n    <!-- 8.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(128.060672 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-38\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_119\">\n    <!-- -4.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(142.712156 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_120\">\n    <!-- 12 -->\n    <g style=\"fill: #262626\" transform=\"translate(162.040828 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_121\">\n    <!-- 35 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(178.315828 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-33\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_122\">\n    <!-- 3.7 -->\n    <g style=\"fill: #262626\" transform=\"translate(193.160672 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-33\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_123\">\n    <!-- -0.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(207.812156 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_124\">\n    <!-- 8.8 -->\n    <g style=\"fill: #262626\" transform=\"translate(225.710672 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-38\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_125\">\n    <!-- 7.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(241.985672 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-37\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_126\">\n    <!-- 15 -->\n    <g style=\"fill: #262626\" transform=\"translate(259.690828 3080.817375)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_127\">\n    <!-- 2.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(79.235672 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-32\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_128\">\n    <!-- 1.2 -->\n    <g style=\"fill: #262626\" transform=\"translate(95.510672 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_129\">\n    <!-- -8.1 -->\n    <g style=\"fill: #262626\" transform=\"translate(110.162156 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_130\">\n    <!-- 15 -->\n    <g style=\"fill: #262626\" transform=\"translate(129.490828 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_131\">\n    <!-- 12 -->\n    <g style=\"fill: #262626\" transform=\"translate(145.765828 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_132\">\n    <!-- 12 -->\n    <g style=\"fill: #262626\" transform=\"translate(162.040828 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_133\">\n    <!-- -18 -->\n    <g style=\"fill: #ffffff\" transform=\"translate(176.692312 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"99.707031\"/>\n    </g>\n   </g>\n   <g id=\"text_134\">\n    <!-- 12 -->\n    <g style=\"fill: #262626\" transform=\"translate(194.590828 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n    </g>\n   </g>\n   <g id=\"text_135\">\n    <!-- -2.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(207.812156 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_136\">\n    <!-- -0.6 -->\n    <g style=\"fill: #262626\" transform=\"translate(224.087156 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_137\">\n    <!-- -2 -->\n    <g style=\"fill: #262626\" transform=\"translate(244.655437 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n    </g>\n   </g>\n   <g id=\"text_138\">\n    <!-- 1.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(258.260672 3147.962518)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-31\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_139\">\n    <!-- -13 -->\n    <g style=\"fill: #262626\" transform=\"translate(79.042312 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"99.707031\"/>\n    </g>\n   </g>\n   <g id=\"text_140\">\n    <!-- 8.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(95.510672 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-38\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_141\">\n    <!-- -4.7 -->\n    <g style=\"fill: #262626\" transform=\"translate(110.162156 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-34\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-37\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_142\">\n    <!-- -6 -->\n    <g style=\"fill: #262626\" transform=\"translate(130.730437 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-36\" x=\"36.083984\"/>\n    </g>\n   </g>\n   <g id=\"text_143\">\n    <!-- -0.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(142.712156 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-30\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_144\">\n    <!-- 2.9 -->\n    <g style=\"fill: #262626\" transform=\"translate(160.610672 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-32\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n     <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n    </g>\n   </g>\n   <g id=\"text_145\">\n    <!-- -8.5 -->\n    <g style=\"fill: #262626\" transform=\"translate(175.262156 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-35\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_146\">\n    <!-- -3.1 -->\n    <g style=\"fill: #262626\" transform=\"translate(191.537156 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-31\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_147\">\n    <!-- -8.3 -->\n    <g style=\"fill: #262626\" transform=\"translate(207.812156 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-2d\"/>\n     <use xlink:href=\"#DejaVuSans-38\" x=\"36.083984\"/>\n     <use xlink:href=\"#DejaVuSans-2e\" x=\"99.707031\"/>\n     <use xlink:href=\"#DejaVuSans-33\" x=\"131.494141\"/>\n    </g>\n   </g>\n   <g id=\"text_148\">\n    <!-- 0 -->\n    <g style=\"fill: #262626\" transform=\"translate(230.003953 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-30\"/>\n    </g>\n   </g>\n   <g id=\"text_149\">\n    <!-- 0 -->\n    <g style=\"fill: #262626\" transform=\"translate(246.278953 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-30\"/>\n    </g>\n   </g>\n   <g id=\"text_150\">\n    <!-- 0 -->\n    <g style=\"fill: #262626\" transform=\"translate(262.553953 3215.107661)scale(0.09 -0.09)\">\n     <use xlink:href=\"#DejaVuSans-30\"/>\n    </g>\n   </g>\n   <g id=\"text_151\">\n    <!-- Monthly returns (%) -->\n    <g transform=\"translate(110.247984 3038.761366)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-4d\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"86.279297\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"147.460938\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"210.839844\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"250.048828\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"313.427734\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"341.210938\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"400.390625\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"432.177734\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"471.041016\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"532.564453\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"571.773438\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"635.152344\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"674.515625\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"737.894531\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"789.994141\"/>\n     <use xlink:href=\"#DejaVuSans-28\" x=\"821.78125\"/>\n     <use xlink:href=\"#DejaVuSans-25\" x=\"860.794922\"/>\n     <use xlink:href=\"#DejaVuSans-29\" x=\"955.814453\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_11\">\n   <g id=\"patch_54\">\n    <path d=\"M 371.204578 3246.196795 \nL 566.504578 3246.196795 \nL 566.504578 3044.761366 \nL 371.204578 3044.761366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_55\">\n    <path d=\"M 419.123798 3229.410509 \nL 380.081851 3229.410509 \nL 380.081851 3195.837937 \nL 419.123798 3195.837937 \nz\n\" clip-path=\"url(#pddd7f82052)\" style=\"fill: #1f77b4; opacity: 0.7\"/>\n   </g>\n   <g id=\"patch_56\">\n    <path d=\"M 419.123798 3162.265366 \nL 446.847758 3162.265366 \nL 446.847758 3128.692795 \nL 419.123798 3128.692795 \nz\n\" clip-path=\"url(#pddd7f82052)\" style=\"fill: #1f77b4; opacity: 0.7\"/>\n   </g>\n   <g id=\"patch_57\">\n    <path d=\"M 419.123798 3095.120223 \nL 557.627305 3095.120223 \nL 557.627305 3061.547652 \nL 419.123798 3061.547652 \nz\n\" clip-path=\"url(#pddd7f82052)\" style=\"fill: #1f77b4; opacity: 0.7\"/>\n   </g>\n   <g id=\"matplotlib.axis_21\">\n    <g id=\"xtick_139\">\n     <g id=\"line2d_246\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"385.924315\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_152\">\n      <!-- -25% -->\n      <g transform=\"translate(370.294518 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_140\">\n     <g id=\"line2d_247\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"419.123798\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_153\">\n      <!-- 0% -->\n      <g transform=\"translate(409.52604 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_141\">\n     <g id=\"line2d_248\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"452.32328\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_154\">\n      <!-- 25% -->\n      <g transform=\"translate(438.87621 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_142\">\n     <g id=\"line2d_249\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"485.522763\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_155\">\n      <!-- 50% -->\n      <g transform=\"translate(472.075692 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_143\">\n     <g id=\"line2d_250\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"518.722245\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_156\">\n      <!-- 75% -->\n      <g transform=\"translate(505.275175 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_144\">\n     <g id=\"line2d_251\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"551.921728\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_157\">\n      <!-- 100% -->\n      <g transform=\"translate(534.625345 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_158\">\n     <!-- Returns -->\n     <g transform=\"translate(443.515734 3281.437263)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_22\">\n    <g id=\"ytick_73\">\n     <g id=\"line2d_252\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"371.204578\" y=\"3212.624223\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_159\">\n      <!-- 2022 -->\n      <g transform=\"translate(330.910078 3217.221278)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_74\">\n     <g id=\"line2d_253\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"371.204578\" y=\"3145.47908\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_160\">\n      <!-- 2021 -->\n      <g transform=\"translate(330.910078 3150.076135)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_75\">\n     <g id=\"line2d_254\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"371.204578\" y=\"3078.333937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_161\">\n      <!-- 2020 -->\n      <g transform=\"translate(330.910078 3082.930992)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_162\">\n     <!-- Year -->\n     <g transform=\"translate(324.164891 3159.45458)rotate(-90)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-59\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"47.833984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"109.357422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"170.636719\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_255\">\n    <path d=\"M 461.518971 3246.196795 \nL 461.518971 3044.761366 \n\" clip-path=\"url(#pddd7f82052)\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #4682b4; stroke-opacity: 0.7; stroke-width: 4\"/>\n   </g>\n   <g id=\"line2d_256\">\n    <path d=\"M 419.123798 3246.196795 \nL 419.123798 3044.761366 \n\" clip-path=\"url(#pddd7f82052)\" style=\"fill: none; stroke: #000000; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_58\">\n    <path d=\"M 371.204578 3246.196795 \nL 371.204578 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_59\">\n    <path d=\"M 566.504578 3246.196795 \nL 566.504578 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_60\">\n    <path d=\"M 371.204578 3246.196795 \nL 566.504578 3246.196795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_61\">\n    <path d=\"M 371.204578 3044.761366 \nL 566.504578 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_163\">\n    <!-- Annual returns -->\n    <g transform=\"translate(420.201234 3038.761366)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-41\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"68.408203\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"131.787109\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"195.166016\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"258.544922\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"319.824219\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"347.607422\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"379.394531\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"418.257812\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"479.78125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"518.990234\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"582.369141\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"621.732422\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"685.111328\"/>\n    </g>\n   </g>\n   <g id=\"legend_7\">\n    <g id=\"patch_62\">\n     <path d=\"M 486.345859 3240.146795 \nL 558.034578 3240.146795 \nQ 560.454578 3240.146795 560.454578 3237.726795 \nL 560.454578 3221.176263 \nQ 560.454578 3218.756263 558.034578 3218.756263 \nL 486.345859 3218.756263 \nQ 483.925859 3218.756263 483.925859 3221.176263 \nL 483.925859 3237.726795 \nQ 483.925859 3240.146795 486.345859 3240.146795 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_257\">\n     <path d=\"M 488.765859 3228.555373 \nL 500.865859 3228.555373 \nL 512.965859 3228.555373 \n\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #4682b4; stroke-opacity: 0.7; stroke-width: 4\"/>\n    </g>\n    <g id=\"text_164\">\n     <!-- Mean -->\n     <g transform=\"translate(522.645859 3232.790373)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-4d\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"86.279297\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"147.802734\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"209.082031\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_12\">\n   <g id=\"patch_63\">\n    <path d=\"M 664.154578 3246.196795 \nL 859.454578 3246.196795 \nL 859.454578 3044.761366 \nL 664.154578 3044.761366 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_64\">\n    <path d=\"M 673.031851 3246.196795 \nL 681.909124 3246.196795 \nL 681.909124 3207.828142 \nL 673.031851 3207.828142 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_65\">\n    <path d=\"M 681.909124 3246.196795 \nL 690.786396 3246.196795 \nL 690.786396 3207.828142 \nL 681.909124 3207.828142 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_66\">\n    <path d=\"M 690.786396 3246.196795 \nL 699.663669 3246.196795 \nL 699.663669 3246.196795 \nL 690.786396 3246.196795 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_67\">\n    <path d=\"M 699.663669 3246.196795 \nL 708.540942 3246.196795 \nL 708.540942 3131.090835 \nL 699.663669 3131.090835 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_68\">\n    <path d=\"M 708.540942 3246.196795 \nL 717.418214 3246.196795 \nL 717.418214 3092.722182 \nL 708.540942 3092.722182 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_69\">\n    <path d=\"M 717.418214 3246.196795 \nL 726.295487 3246.196795 \nL 726.295487 3092.722182 \nL 717.418214 3092.722182 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_70\">\n    <path d=\"M 726.295487 3246.196795 \nL 735.17276 3246.196795 \nL 735.17276 3131.090835 \nL 726.295487 3131.090835 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_71\">\n    <path d=\"M 735.17276 3246.196795 \nL 744.050033 3246.196795 \nL 744.050033 3054.353529 \nL 735.17276 3054.353529 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_72\">\n    <path d=\"M 744.050033 3246.196795 \nL 752.927305 3246.196795 \nL 752.927305 3207.828142 \nL 744.050033 3207.828142 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_73\">\n    <path d=\"M 752.927305 3246.196795 \nL 761.804578 3246.196795 \nL 761.804578 3131.090835 \nL 752.927305 3131.090835 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_74\">\n    <path d=\"M 761.804578 3246.196795 \nL 770.681851 3246.196795 \nL 770.681851 3207.828142 \nL 761.804578 3207.828142 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_75\">\n    <path d=\"M 770.681851 3246.196795 \nL 779.559124 3246.196795 \nL 779.559124 3092.722182 \nL 770.681851 3092.722182 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_76\">\n    <path d=\"M 779.559124 3246.196795 \nL 788.436396 3246.196795 \nL 788.436396 3169.459489 \nL 779.559124 3169.459489 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_77\">\n    <path d=\"M 788.436396 3246.196795 \nL 797.313669 3246.196795 \nL 797.313669 3246.196795 \nL 788.436396 3246.196795 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_78\">\n    <path d=\"M 797.313669 3246.196795 \nL 806.190942 3246.196795 \nL 806.190942 3246.196795 \nL 797.313669 3246.196795 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_79\">\n    <path d=\"M 806.190942 3246.196795 \nL 815.068214 3246.196795 \nL 815.068214 3246.196795 \nL 806.190942 3246.196795 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_80\">\n    <path d=\"M 815.068214 3246.196795 \nL 823.945487 3246.196795 \nL 823.945487 3246.196795 \nL 815.068214 3246.196795 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_81\">\n    <path d=\"M 823.945487 3246.196795 \nL 832.82276 3246.196795 \nL 832.82276 3246.196795 \nL 823.945487 3246.196795 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_82\">\n    <path d=\"M 832.82276 3246.196795 \nL 841.700033 3246.196795 \nL 841.700033 3246.196795 \nL 832.82276 3246.196795 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"patch_83\">\n    <path d=\"M 841.700033 3246.196795 \nL 850.577305 3246.196795 \nL 850.577305 3207.828142 \nL 841.700033 3207.828142 \nz\n\" clip-path=\"url(#pec9462000e)\" style=\"fill: #ff4500; opacity: 0.8\"/>\n   </g>\n   <g id=\"matplotlib.axis_23\">\n    <g id=\"xtick_145\">\n     <g id=\"line2d_258\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"665.385691\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_165\">\n      <!-- -20% -->\n      <g transform=\"translate(649.755895 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_146\">\n     <g id=\"line2d_259\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"699.066843\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_166\">\n      <!-- -10% -->\n      <g transform=\"translate(683.437046 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2d\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"36.083984\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"99.707031\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"163.330078\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_147\">\n     <g id=\"line2d_260\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"732.747994\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_167\">\n      <!-- 0% -->\n      <g transform=\"translate(723.150236 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_148\">\n     <g id=\"line2d_261\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"766.429146\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_168\">\n      <!-- 10% -->\n      <g transform=\"translate(752.982075 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_149\">\n     <g id=\"line2d_262\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"800.110297\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_169\">\n      <!-- 20% -->\n      <g transform=\"translate(786.663227 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_150\">\n     <g id=\"line2d_263\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"833.791448\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_170\">\n      <!-- 30% -->\n      <g transform=\"translate(820.344378 3264.890904)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-25\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_171\">\n     <!-- Returns -->\n     <g transform=\"translate(736.465734 3281.437263)scale(0.132 -0.132)\">\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_24\">\n    <g id=\"ytick_76\">\n     <g id=\"line2d_264\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"664.154578\" y=\"3246.196795\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_172\">\n      <!-- 0 -->\n      <g transform=\"translate(646.955953 3250.793849)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_77\">\n     <g id=\"line2d_265\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"664.154578\" y=\"3207.828142\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_173\">\n      <!-- 1 -->\n      <g transform=\"translate(646.955953 3212.425196)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_78\">\n     <g id=\"line2d_266\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"664.154578\" y=\"3169.459489\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_174\">\n      <!-- 2 -->\n      <g transform=\"translate(646.955953 3174.056543)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_79\">\n     <g id=\"line2d_267\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"664.154578\" y=\"3131.090835\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_175\">\n      <!-- 3 -->\n      <g transform=\"translate(646.955953 3135.68789)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_80\">\n     <g id=\"line2d_268\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"664.154578\" y=\"3092.722182\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_176\">\n      <!-- 4 -->\n      <g transform=\"translate(646.955953 3097.319237)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_81\">\n     <g id=\"line2d_269\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"664.154578\" y=\"3054.353529\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_177\">\n      <!-- 5 -->\n      <g transform=\"translate(646.955953 3058.950584)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_178\">\n     <!-- Number of months -->\n     <g transform=\"translate(640.210766 3207.407705)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4e\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"74.804688\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"138.183594\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"235.595703\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"299.072266\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"360.595703\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"401.708984\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"433.496094\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"494.677734\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"529.882812\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"561.669922\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"659.082031\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"720.263672\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"783.642578\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"822.851562\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"886.230469\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_270\">\n    <path d=\"M 740.018815 3246.196795 \nL 740.018815 3044.761366 \n\" clip-path=\"url(#pec9462000e)\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #ffd700; stroke-width: 4\"/>\n   </g>\n   <g id=\"line2d_271\">\n    <path d=\"M 732.747994 3246.196795 \nL 732.747994 3044.761366 \n\" clip-path=\"url(#pec9462000e)\" style=\"fill: none; stroke: #000000; stroke-opacity: 0.75; stroke-width: 3; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_84\">\n    <path d=\"M 664.154578 3246.196795 \nL 664.154578 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_85\">\n    <path d=\"M 859.454578 3246.196795 \nL 859.454578 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_86\">\n    <path d=\"M 664.154578 3246.196795 \nL 859.454578 3246.196795 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_87\">\n    <path d=\"M 664.154578 3044.761366 \nL 859.454578 3044.761366 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_179\">\n    <!-- Distribution of monthly returns -->\n    <g transform=\"translate(659.872734 3038.761366)scale(0.132 -0.132)\">\n     <use xlink:href=\"#DejaVuSans-44\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"77.001953\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"104.785156\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"156.884766\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"196.09375\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"237.207031\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"264.990234\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"328.466797\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"391.845703\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"431.054688\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"458.837891\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"520.019531\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"583.398438\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"615.185547\"/>\n     <use xlink:href=\"#DejaVuSans-66\" x=\"676.367188\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"711.572266\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"743.359375\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"840.771484\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"901.953125\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"965.332031\"/>\n     <use xlink:href=\"#DejaVuSans-68\" x=\"1004.541016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1067.919922\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1095.703125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1154.882812\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1186.669922\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"1225.533203\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1287.056641\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"1326.265625\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1389.644531\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1429.007812\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1492.386719\"/>\n    </g>\n   </g>\n   <g id=\"legend_8\">\n    <g id=\"patch_88\">\n     <path d=\"M 779.295859 3072.201897 \nL 850.984578 3072.201897 \nQ 853.404578 3072.201897 853.404578 3069.781897 \nL 853.404578 3053.231366 \nQ 853.404578 3050.811366 850.984578 3050.811366 \nL 779.295859 3050.811366 \nQ 776.875859 3050.811366 776.875859 3053.231366 \nL 776.875859 3069.781897 \nQ 776.875859 3072.201897 779.295859 3072.201897 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_272\">\n     <path d=\"M 781.715859 3060.610475 \nL 793.815859 3060.610475 \nL 805.915859 3060.610475 \n\" style=\"fill: none; stroke-dasharray: 14.8,6.4; stroke-dashoffset: 0; stroke: #ffd700; stroke-width: 4\"/>\n    </g>\n    <g id=\"text_180\">\n     <!-- Mean -->\n     <g transform=\"translate(815.595859 3064.845475)scale(0.121 -0.121)\">\n      <use xlink:href=\"#DejaVuSans-4d\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"86.279297\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"147.802734\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"209.082031\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_13\">\n   <g id=\"patch_89\">\n    <path d=\"M 78.254578 3548.349937 \nL 859.454578 3548.349937 \nL 859.454578 3346.914509 \nL 78.254578 3346.914509 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_90\">\n    <path d=\"M 104.294578 3480.998065 \nL 312.614578 3480.998065 \nL 312.614578 3473.135497 \nL 104.294578 3473.135497 \nL 104.294578 3480.998065 \nz\n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: #5875a4; stroke: #4c4c4c; stroke-width: 1.5; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_91\">\n    <path d=\"M 364.694578 3484.54876 \nL 573.014578 3484.54876 \nL 573.014578 3468.102342 \nL 364.694578 3468.102342 \nL 364.694578 3484.54876 \nz\n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: #5f9e6e; stroke: #4c4c4c; stroke-width: 1.5; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_92\">\n    <path d=\"M 625.094578 3494.097144 \nL 833.414578 3494.097144 \nL 833.414578 3448.065672 \nL 625.094578 3448.065672 \nL 625.094578 3494.097144 \nz\n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: #c1b37f; stroke: #4c4c4c; stroke-width: 1.5; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"matplotlib.axis_25\">\n    <g id=\"xtick_151\">\n     <g id=\"line2d_273\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"208.454578\" y=\"3548.349937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_181\">\n      <!-- Daily -->\n      <g transform=\"translate(193.146187 3567.044047)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-44\"/>\n       <use xlink:href=\"#DejaVuSans-61\" x=\"77.001953\"/>\n       <use xlink:href=\"#DejaVuSans-69\" x=\"138.28125\"/>\n       <use xlink:href=\"#DejaVuSans-6c\" x=\"166.064453\"/>\n       <use xlink:href=\"#DejaVuSans-79\" x=\"193.847656\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_152\">\n     <g id=\"line2d_274\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"468.854578\" y=\"3548.349937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_182\">\n      <!-- Weekly -->\n      <g transform=\"translate(447.017859 3567.044047)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-57\" d=\"M 213 4666 \nL 850 4666 \nL 1831 722 \nL 2809 4666 \nL 3519 4666 \nL 4500 722 \nL 5478 4666 \nL 6119 4666 \nL 4947 0 \nL 4153 0 \nL 3169 4050 \nL 2175 0 \nL 1381 0 \nL 213 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-57\"/>\n       <use xlink:href=\"#DejaVuSans-65\" x=\"93.001953\"/>\n       <use xlink:href=\"#DejaVuSans-65\" x=\"154.525391\"/>\n       <use xlink:href=\"#DejaVuSans-6b\" x=\"216.048828\"/>\n       <use xlink:href=\"#DejaVuSans-6c\" x=\"273.958984\"/>\n       <use xlink:href=\"#DejaVuSans-79\" x=\"301.742188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_153\">\n     <g id=\"line2d_275\">\n      <g>\n       <use xlink:href=\"#m9cb947725a\" x=\"729.254578\" y=\"3548.349937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_183\">\n      <!-- Monthly -->\n      <g transform=\"translate(705.030945 3567.044047)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-4d\"/>\n       <use xlink:href=\"#DejaVuSans-6f\" x=\"86.279297\"/>\n       <use xlink:href=\"#DejaVuSans-6e\" x=\"147.460938\"/>\n       <use xlink:href=\"#DejaVuSans-74\" x=\"210.839844\"/>\n       <use xlink:href=\"#DejaVuSans-68\" x=\"250.048828\"/>\n       <use xlink:href=\"#DejaVuSans-6c\" x=\"313.427734\"/>\n       <use xlink:href=\"#DejaVuSans-79\" x=\"341.210938\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_26\">\n    <g id=\"ytick_82\">\n     <g id=\"line2d_276\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3547.080148\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_184\">\n      <!-- −0.2 -->\n      <g transform=\"translate(39.372375 3551.677203)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_83\">\n     <g id=\"line2d_277\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3512.34089\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_185\">\n      <!-- −0.1 -->\n      <g transform=\"translate(39.372375 3516.937945)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_84\">\n     <g id=\"line2d_278\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3477.601632\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_186\">\n      <!-- 0.0 -->\n      <g transform=\"translate(49.511797 3482.198686)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_85\">\n     <g id=\"line2d_279\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3442.862373\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_187\">\n      <!-- 0.1 -->\n      <g transform=\"translate(49.511797 3447.459428)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_86\">\n     <g id=\"line2d_280\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3408.123115\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_188\">\n      <!-- 0.2 -->\n      <g transform=\"translate(49.511797 3412.72017)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_87\">\n     <g id=\"line2d_281\">\n      <g>\n       <use xlink:href=\"#ma8bca00fb6\" x=\"78.254578\" y=\"3373.383856\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_189\">\n      <!-- 0.3 -->\n      <g transform=\"translate(49.511797 3377.980911)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_282\">\n    <path d=\"M 208.454578 3480.998065 \nL 208.454578 3492.136809 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_283\">\n    <path d=\"M 208.454578 3473.135497 \nL 208.454578 3461.593799 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_284\">\n    <path d=\"M 156.374578 3492.136809 \nL 260.534578 3492.136809 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_285\">\n    <path d=\"M 156.374578 3461.593799 \nL 260.534578 3461.593799 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_286\">\n    <defs>\n     <path id=\"mb43c6c830f\" d=\"M -0 3.535534 \nL 2.12132 0 \nL -0 -3.535534 \nL -2.12132 -0 \nz\n\" style=\"stroke: #4c4c4c; stroke-linejoin: miter\"/>\n    </defs>\n    <g clip-path=\"url(#p1e7b755c4c)\">\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3500.782914\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3498.595231\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3494.832463\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3495.105482\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3495.184348\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3493.93607\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3497.468517\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3496.889766\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3498.902817\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3517.16687\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3493.588657\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3498.489141\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3458.744644\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3457.950434\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3460.566132\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3461.30283\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"208.454578\" y=\"3460.758967\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n    </g>\n   </g>\n   <g id=\"line2d_287\">\n    <path d=\"M 468.854578 3484.54876 \nL 468.854578 3507.277972 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_288\">\n    <path d=\"M 468.854578 3468.102342 \nL 468.854578 3443.968547 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_289\">\n    <path d=\"M 416.774578 3507.277972 \nL 520.934578 3507.277972 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_290\">\n    <path d=\"M 416.774578 3443.968547 \nL 520.934578 3443.968547 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_291\">\n    <g clip-path=\"url(#p1e7b755c4c)\">\n     <use xlink:href=\"#mb43c6c830f\" x=\"468.854578\" y=\"3511.239342\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"468.854578\" y=\"3442.433404\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n     <use xlink:href=\"#mb43c6c830f\" x=\"468.854578\" y=\"3437.634078\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n    </g>\n   </g>\n   <g id=\"line2d_292\">\n    <path d=\"M 729.254578 3494.097144 \nL 729.254578 3539.193782 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_293\">\n    <path d=\"M 729.254578 3448.065672 \nL 729.254578 3424.155453 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_294\">\n    <path d=\"M 677.174578 3539.193782 \nL 781.334578 3539.193782 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_295\">\n    <path d=\"M 677.174578 3424.155453 \nL 781.334578 3424.155453 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_296\">\n    <g clip-path=\"url(#p1e7b755c4c)\">\n     <use xlink:href=\"#mb43c6c830f\" x=\"729.254578\" y=\"3356.070665\" style=\"fill: #4c4c4c; stroke: #4c4c4c; stroke-linejoin: miter\"/>\n    </g>\n   </g>\n   <g id=\"line2d_297\">\n    <path d=\"M 104.294578 3476.982457 \nL 312.614578 3476.982457 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_298\">\n    <path d=\"M 364.694578 3476.58847 \nL 573.014578 3476.58847 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_299\">\n    <path d=\"M 625.094578 3473.363325 \nL 833.414578 3473.363325 \n\" clip-path=\"url(#p1e7b755c4c)\" style=\"fill: none; stroke: #4c4c4c; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_93\">\n    <path d=\"M 78.254578 3548.349937 \nL 78.254578 3346.914509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_94\">\n    <path d=\"M 859.454578 3548.349937 \nL 859.454578 3346.914509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_95\">\n    <path d=\"M 78.254578 3548.349937 \nL 859.454578 3548.349937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_96\">\n    <path d=\"M 78.254578 3346.914509 \nL 859.454578 3346.914509 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_190\">\n    <!-- Return quantiles -->\n    <g transform=\"translate(414.502547 3340.914509)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-71\" d=\"M 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\nM 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 -1331 \nL 2906 -1331 \nL 2906 525 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-52\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"331.835938\"/>\n     <use xlink:href=\"#DejaVuSans-71\" x=\"363.623047\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"427.099609\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"490.478516\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"551.757812\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"615.136719\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"654.345703\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"682.128906\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"709.912109\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"771.435547\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9b8c24c311\">\n   <rect x=\"78.254578\" y=\"23.229937\" width=\"781.2\" height=\"503.588571\"/>\n  </clipPath>\n  <clipPath id=\"pd7898e59a1\">\n   <rect x=\"78.254578\" y=\"627.536223\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pbcac90addc\">\n   <rect x=\"78.254578\" y=\"929.689366\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p4a26e2549c\">\n   <rect x=\"78.254578\" y=\"1231.842509\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p7972b0b8e2\">\n   <rect x=\"78.254578\" y=\"1533.995652\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p7d900ebc36\">\n   <rect x=\"78.254578\" y=\"1836.148795\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"peb71f1c2ab\">\n   <rect x=\"78.254578\" y=\"2138.301937\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p4ada1e5541\">\n   <rect x=\"78.254578\" y=\"2440.45508\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p1f7dc791f5\">\n   <rect x=\"78.254578\" y=\"2742.608223\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pb4c3cad4a9\">\n   <rect x=\"78.254578\" y=\"3044.761366\" width=\"195.3\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pddd7f82052\">\n   <rect x=\"371.204578\" y=\"3044.761366\" width=\"195.3\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"pec9462000e\">\n   <rect x=\"664.154578\" y=\"3044.761366\" width=\"195.3\" height=\"201.435429\"/>\n  </clipPath>\n  <clipPath id=\"p1e7b755c4c\">\n   <rect x=\"78.254578\" y=\"3346.914509\" width=\"781.2\" height=\"201.435429\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 1400x7200 with 13 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"390.235953pt\" height=\"369.110157pt\" viewBox=\"0 0 390.235953 369.110157\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-10-19T17:02:52.798569</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 369.110157 \nL 390.235953 369.110157 \nL 390.235953 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 70.555953 316.989937 \nL 383.035953 316.989937 \nL 383.035953 23.229937 \nL 70.555953 23.229937 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m33a8da1a03\" d=\"M 0 0 \nL 0 6 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"84.475801\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2020-01 -->\n      <g transform=\"translate(39.433767 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"118.814262\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2020-05 -->\n      <g transform=\"translate(73.772229 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"153.720302\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2020-09 -->\n      <g transform=\"translate(108.678268 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"188.342552\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2021-01 -->\n      <g transform=\"translate(143.300519 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"222.397225\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2021-05 -->\n      <g transform=\"translate(177.355191 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"257.303264\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2021-09 -->\n      <g transform=\"translate(212.261231 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"291.925514\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2022-01 -->\n      <g transform=\"translate(246.883481 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"325.980187\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2022-05 -->\n      <g transform=\"translate(280.938154 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m33a8da1a03\" x=\"360.886226\" y=\"316.989937\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2022-09 -->\n      <g transform=\"translate(315.844193 359.730871)rotate(-30)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-2d\" x=\"254.492188\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"290.576172\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"354.199219\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m1239092789\" d=\"M 0 0 \nL -6 0 \n\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"314.210615\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −0.25 -->\n      <g transform=\"translate(23.975125 318.80767)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"280.378948\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.00 -->\n      <g transform=\"translate(34.114547 284.976003)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"246.547281\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.25 -->\n      <g transform=\"translate(34.114547 251.144335)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"212.715614\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.50 -->\n      <g transform=\"translate(34.114547 217.312668)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"178.883946\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.75 -->\n      <g transform=\"translate(34.114547 183.481001)scale(0.121 -0.121)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"145.052279\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.00 -->\n      <g transform=\"translate(34.114547 149.649334)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"111.220612\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.25 -->\n      <g transform=\"translate(34.114547 115.817667)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"77.388945\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1.50 -->\n      <g transform=\"translate(34.114547 81.986)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m1239092789\" x=\"70.555953\" y=\"43.557278\" style=\"stroke: #000000; stroke-width: 1.25\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 1.75 -->\n      <g transform=\"translate(34.114547 48.154333)scale(0.121 -0.121)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- Returns -->\n     <g transform=\"translate(17.229938 195.448781)rotate(-90)scale(0.132 -0.132)\">\n      <defs>\n       <path id=\"DejaVuSans-52\" d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-52\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"126.505859\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"165.714844\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"229.09375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"268.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"331.835938\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 84.759589 280.378948 \nL 85.043378 280.503477 \nL 85.894745 280.510823 \nL 86.178534 280.154324 \nL 86.462323 281.402679 \nL 86.746112 279.848999 \nL 87.029901 280.037692 \nL 87.881268 278.448649 \nL 88.165057 278.866132 \nL 88.448846 279.987582 \nL 88.732635 280.360078 \nL 89.016424 278.059334 \nL 89.86779 278.333577 \nL 90.151579 279.53664 \nL 90.435368 279.147076 \nL 90.719157 283.009117 \nL 93.840836 291.863868 \nL 94.124624 289.447936 \nL 94.408413 285.789368 \nL 94.692202 284.012809 \nL 95.827358 282.849836 \nL 96.111147 282.049433 \nL 96.394936 279.896883 \nL 96.678725 278.95461 \nL 96.962514 278.498893 \nL 97.813881 275.184313 \nL 98.09767 275.20654 \nL 98.381459 276.584477 \nL 98.665247 274.455618 \nL 98.949036 274.092962 \nL 99.800403 274.954055 \nL 100.084192 273.430747 \nL 100.367981 275.341069 \nL 100.65177 274.842024 \nL 100.935559 279.945125 \nL 101.786926 277.376283 \nL 102.070715 275.962149 \nL 102.354504 275.398863 \nL 102.638293 273.15688 \nL 103.773448 280.820244 \nL 104.057237 278.080038 \nL 104.341026 278.591422 \nL 104.624815 281.902563 \nL 105.759971 289.086665 \nL 106.04376 289.036243 \nL 106.611338 292.017558 \nL 106.895127 290.61395 \nL 107.746493 295.032769 \nL 108.030282 290.781218 \nL 108.314071 288.407351 \nL 108.59786 289.004396 \nL 108.881649 287.766013 \nL 109.733016 288.968918 \nL 110.016805 288.227454 \nL 110.300594 288.578101 \nL 110.584383 286.114633 \nL 110.868172 286.248098 \nL 112.003328 283.490537 \nL 112.570905 284.59251 \nL 112.854694 286.214542 \nL 113.706061 286.843113 \nL 113.98985 283.524221 \nL 114.273639 284.544626 \nL 114.557428 283.786538 \nL 114.841217 281.702657 \nL 115.692584 281.34805 \nL 115.976373 282.681586 \nL 116.260162 281.371797 \nL 116.543951 281.240697 \nL 116.82774 283.01402 \nL 117.679106 283.11818 \nL 117.962895 280.559038 \nL 118.246684 279.758224 \nL 118.530473 277.453015 \nL 120.233207 277.776116 \nL 120.516996 278.481562 \nL 120.800785 277.866587 \nL 121.652151 278.967835 \nL 121.93594 278.295193 \nL 122.219729 278.850427 \nL 122.503518 281.004361 \nL 122.787307 282.222336 \nL 123.638674 280.978985 \nL 123.922463 278.666319 \nL 124.206252 279.564395 \nL 124.490041 282.129453 \nL 124.77383 285.905787 \nL 125.625197 285.154311 \nL 125.908986 283.490442 \nL 126.192774 284.515994 \nL 126.476563 284.775844 \nL 126.760352 284.171086 \nL 127.611719 280.117358 \nL 127.895508 279.894879 \nL 128.179297 279.043782 \nL 128.463086 279.835179 \nL 128.746875 279.298993 \nL 129.882031 275.659917 \nL 130.449609 276.717894 \nL 130.733397 277.93277 \nL 131.584764 279.443394 \nL 131.868553 277.422954 \nL 132.152342 277.703585 \nL 132.71992 275.420341 \nL 133.855076 273.039875 \nL 134.138865 270.258364 \nL 135.557809 270.16143 \nL 135.841598 269.103049 \nL 136.409176 259.088098 \nL 136.692965 255.534037 \nL 137.544332 246.839685 \nL 137.828121 247.239322 \nL 138.395699 238.259516 \nL 138.679488 243.355052 \nL 139.530855 238.551905 \nL 139.814644 239.202457 \nL 140.098432 238.100334 \nL 140.382221 248.833362 \nL 140.66601 246.228328 \nL 141.801166 233.007218 \nL 142.084955 231.675098 \nL 142.368744 222.650577 \nL 142.652533 232.226196 \nL 143.5039 227.88943 \nL 143.787689 229.442938 \nL 144.355267 218.928317 \nL 144.639055 217.815967 \nL 145.490422 215.471141 \nL 145.774211 218.500891 \nL 146.058 215.970747 \nL 146.341789 219.561875 \nL 146.625578 217.553716 \nL 147.476945 215.462405 \nL 148.044523 227.836985 \nL 148.328312 227.569565 \nL 148.612101 224.296003 \nL 149.747256 217.887325 \nL 150.314834 225.91611 \nL 150.598623 222.759531 \nL 151.44999 217.967669 \nL 151.733779 219.532263 \nL 152.017568 223.250601 \nL 152.301357 219.59172 \nL 152.585146 214.4163 \nL 153.436513 210.559592 \nL 153.720302 205.881749 \nL 154.00409 203.694999 \nL 154.287879 206.095408 \nL 154.571668 211.382663 \nL 155.423035 213.471415 \nL 155.706824 211.241675 \nL 155.990613 216.178361 \nL 156.274402 216.197943 \nL 156.558191 212.183895 \nL 157.409558 211.043833 \nL 157.693347 210.3626 \nL 157.977136 210.394603 \nL 158.260925 211.84158 \nL 158.544713 208.911464 \nL 159.39608 211.032868 \nL 159.679869 214.450231 \nL 159.963658 210.572114 \nL 160.247447 217.172567 \nL 160.531236 216.812508 \nL 161.666392 210.276259 \nL 161.950181 211.658973 \nL 164.504281 203.455335 \nL 165.639437 190.733805 \nL 165.923226 190.703238 \nL 166.207015 195.430601 \nL 166.490804 197.733508 \nL 167.342171 203.157601 \nL 167.625959 200.050094 \nL 167.909748 200.473852 \nL 168.193537 201.652501 \nL 168.477326 203.900802 \nL 169.328693 202.173865 \nL 170.18006 194.207861 \nL 171.315216 192.460227 \nL 171.599005 190.706494 \nL 171.882794 193.707724 \nL 172.166582 183.599417 \nL 172.450371 187.637636 \nL 173.585527 176.846733 \nL 173.869316 183.066368 \nL 174.153105 185.060488 \nL 174.436894 189.968524 \nL 175.288261 187.231011 \nL 175.57205 187.537672 \nL 175.855839 187.40724 \nL 176.139628 183.449417 \nL 176.423417 174.465906 \nL 177.274783 169.218521 \nL 177.558572 172.105986 \nL 177.842361 176.257609 \nL 178.12615 175.982731 \nL 178.409939 174.817742 \nL 179.261306 176.101094 \nL 179.545095 171.569864 \nL 180.112673 175.65509 \nL 180.396462 175.077666 \nL 181.531617 179.151853 \nL 181.815406 181.686962 \nL 182.099195 178.488541 \nL 182.382984 182.300259 \nL 183.234351 181.526635 \nL 183.801929 174.569822 \nL 184.085718 165.646895 \nL 184.369507 161.451946 \nL 185.220874 157.482535 \nL 185.504663 166.185428 \nL 185.788452 159.681864 \nL 186.07224 159.688119 \nL 186.356029 150.617855 \nL 187.207396 144.579675 \nL 187.491185 149.375196 \nL 187.774974 146.43102 \nL 188.058763 139.238056 \nL 189.193919 126.55016 \nL 189.477708 120.54676 \nL 189.761497 118.697167 \nL 190.045286 109.495168 \nL 190.329075 107.430434 \nL 191.180441 109.055104 \nL 191.46423 103.948978 \nL 191.748019 95.502726 \nL 192.031808 111.636587 \nL 192.315597 117.08183 \nL 193.166964 109.548216 \nL 193.450753 122.078831 \nL 193.734542 118.301361 \nL 194.30212 105.632429 \nL 195.153487 105.226862 \nL 195.437275 110.953587 \nL 195.721064 106.513341 \nL 196.004853 122.16261 \nL 196.288642 131.171106 \nL 197.140009 132.276185 \nL 197.423798 122.463995 \nL 197.707587 122.177328 \nL 197.991376 128.467098 \nL 198.275165 130.102743 \nL 199.126532 125.354172 \nL 199.69411 102.451877 \nL 201.964421 93.524465 \nL 202.24821 96.822527 \nL 203.099577 101.452777 \nL 203.383366 103.757402 \nL 203.667155 118.425242 \nL 203.950944 116.420689 \nL 204.234733 127.699689 \nL 205.086099 122.241431 \nL 205.369888 132.295119 \nL 205.653677 129.650697 \nL 205.937466 146.009769 \nL 207.072622 165.576542 \nL 207.356411 168.333024 \nL 207.6402 167.210385 \nL 207.923989 156.589239 \nL 208.207778 155.443991 \nL 209.059144 159.070229 \nL 209.342933 156.913568 \nL 209.910511 150.409048 \nL 210.1943 157.47639 \nL 211.045667 155.065558 \nL 211.329456 161.8165 \nL 211.613245 171.84198 \nL 211.897034 168.637328 \nL 212.180823 157.045495 \nL 213.03219 158.168035 \nL 213.599767 151.143178 \nL 214.167345 143.471721 \nL 215.302501 140.723338 \nL 215.58629 137.33221 \nL 215.870079 137.044004 \nL 216.153868 137.53536 \nL 217.005235 146.505044 \nL 217.289024 151.844373 \nL 217.572813 149.702672 \nL 217.856602 149.786538 \nL 218.140391 147.140514 \nL 218.991757 141.800122 \nL 219.275546 141.126862 \nL 219.559335 132.369043 \nL 219.843124 127.910551 \nL 220.126913 125.689075 \nL 220.97828 124.462441 \nL 221.262069 117.45809 \nL 221.545858 117.06638 \nL 221.829647 109.646056 \nL 222.113436 112.164168 \nL 223.816169 105.0092 \nL 224.099958 104.80751 \nL 224.951325 98.30042 \nL 225.235114 108.493713 \nL 225.518903 103.139163 \nL 225.802692 108.994092 \nL 226.086481 102.798596 \nL 227.221637 84.692898 \nL 227.505425 82.038931 \nL 227.789214 92.380203 \nL 228.073003 85.878892 \nL 228.92437 89.507178 \nL 229.208159 82.402163 \nL 229.491948 85.801899 \nL 229.775737 86.29621 \nL 230.059526 80.012825 \nL 230.910893 76.755624 \nL 231.194682 72.971526 \nL 231.478471 81.665153 \nL 231.76226 86.097287 \nL 232.046048 85.040861 \nL 232.897415 79.44689 \nL 233.181204 84.25175 \nL 233.464993 78.999188 \nL 233.748782 64.966814 \nL 234.032571 60.223106 \nL 235.167727 63.60457 \nL 235.451516 76.227095 \nL 235.735305 64.624712 \nL 236.019094 61.275634 \nL 236.87046 63.774312 \nL 237.154249 57.925763 \nL 237.438038 61.909984 \nL 237.721827 60.098072 \nL 238.005616 47.127225 \nL 238.856983 42.424751 \nL 239.140772 42.984651 \nL 239.424561 36.582665 \nL 239.70835 37.17697 \nL 239.992139 43.246855 \nL 240.843506 66.085032 \nL 241.127295 68.197808 \nL 241.411083 55.925648 \nL 241.694872 60.833225 \nL 241.978661 75.064497 \nL 242.830028 70.767721 \nL 243.113817 58.700744 \nL 243.397606 99.360745 \nL 243.681395 98.162967 \nL 243.965184 102.261987 \nL 244.816551 93.159882 \nL 245.10034 95.750163 \nL 245.384129 89.680013 \nL 245.667918 87.732598 \nL 245.951706 97.179434 \nL 246.803073 105.128226 \nL 247.086862 116.367614 \nL 247.370651 116.734627 \nL 247.65444 107.010745 \nL 247.938229 103.800558 \nL 248.789596 91.357165 \nL 249.357174 74.831823 \nL 249.640963 75.609448 \nL 249.924752 75.820891 \nL 250.776118 77.812353 \nL 251.059907 75.516398 \nL 251.343696 75.978342 \nL 251.627485 69.731647 \nL 251.911274 73.655884 \nL 252.762641 78.242366 \nL 253.04643 83.346613 \nL 253.330219 79.864208 \nL 253.614008 82.590635 \nL 253.897797 94.857438 \nL 254.749164 80.536392 \nL 255.032952 78.664034 \nL 255.316741 71.859936 \nL 255.60053 73.938974 \nL 255.884319 70.785429 \nL 256.735686 64.874535 \nL 257.019475 66.730901 \nL 257.303264 69.322859 \nL 257.587053 69.253683 \nL 257.870842 75.360151 \nL 258.722209 72.808911 \nL 259.005998 62.469755 \nL 259.289787 60.040039 \nL 259.573576 63.010502 \nL 259.857364 49.901892 \nL 260.708731 39.779104 \nL 261.560098 61.263214 \nL 261.843887 54.676627 \nL 263.262832 53.131857 \nL 263.83041 50.11771 \nL 264.681776 63.839425 \nL 264.965565 70.515453 \nL 265.249354 81.973589 \nL 265.533143 76.842201 \nL 268.654822 76.336119 \nL 268.93861 77.795561 \nL 269.222399 73.819458 \nL 269.506188 78.625084 \nL 269.789977 81.365425 \nL 270.641344 81.462122 \nL 270.925133 76.131129 \nL 271.208922 80.73039 \nL 271.492711 79.663651 \nL 271.7765 80.259324 \nL 272.627867 75.231633 \nL 272.911656 76.83637 \nL 273.195445 80.477691 \nL 273.479233 85.653467 \nL 273.763022 78.989476 \nL 274.614389 85.643578 \nL 274.898178 91.56156 \nL 275.181967 91.804409 \nL 275.465756 90.023671 \nL 275.749545 95.305062 \nL 276.600912 93.864662 \nL 276.884701 94.880002 \nL 277.16849 99.191571 \nL 277.452279 97.20733 \nL 277.736068 96.947867 \nL 278.587434 102.365339 \nL 278.871223 100.159419 \nL 279.155012 99.812377 \nL 279.438801 100.857975 \nL 279.72259 99.543817 \nL 280.573957 96.302038 \nL 280.857746 93.907052 \nL 281.141535 96.375777 \nL 281.425324 97.388107 \nL 281.709113 97.765263 \nL 282.56048 91.346127 \nL 282.844268 85.707446 \nL 283.128057 86.445845 \nL 283.411846 83.557161 \nL 283.695635 86.032 \nL 284.547002 82.435117 \nL 284.830791 80.090693 \nL 285.11458 74.906926 \nL 285.398369 72.279604 \nL 285.682158 67.258884 \nL 286.533525 67.581108 \nL 286.817314 76.615966 \nL 287.101103 75.500039 \nL 287.384891 73.200841 \nL 287.66868 77.17187 \nL 288.520047 77.389211 \nL 288.803836 74.990704 \nL 289.087625 80.546643 \nL 289.371414 76.959667 \nL 289.655203 86.172038 \nL 290.50657 86.834983 \nL 290.790359 79.649207 \nL 291.357937 89.060342 \nL 291.641726 81.520472 \nL 292.776881 81.304394 \nL 293.344459 92.47794 \nL 293.628248 91.779878 \nL 294.479615 94.365361 \nL 294.763404 97.302281 \nL 295.047193 91.678663 \nL 295.330982 97.416587 \nL 295.614771 98.267172 \nL 296.466137 103.273382 \nL 296.749926 97.863456 \nL 297.033715 103.133748 \nL 297.317504 105.039338 \nL 297.601293 108.857724 \nL 298.45266 105.898707 \nL 298.736449 115.354952 \nL 299.020238 110.153049 \nL 299.587816 123.920799 \nL 302.709494 111.103053 \nL 302.993283 109.043007 \nL 303.277072 108.854015 \nL 303.560861 110.78211 \nL 304.412228 117.43259 \nL 304.979806 111.49744 \nL 305.263595 108.149809 \nL 305.547384 107.211259 \nL 306.39875 108.227398 \nL 306.682539 108.074654 \nL 306.966328 104.292607 \nL 307.250117 110.361394 \nL 307.533906 108.821439 \nL 308.669062 96.287456 \nL 308.952851 94.487188 \nL 309.23664 91.215251 \nL 310.371795 102.181645 \nL 310.655584 109.101348 \nL 310.939373 111.758835 \nL 311.506951 100.635666 \nL 312.358318 111.714009 \nL 312.642107 125.703719 \nL 312.925896 111.643532 \nL 313.209685 112.158903 \nL 313.493474 108.920538 \nL 314.344841 107.43191 \nL 314.62863 106.157215 \nL 314.912418 108.353977 \nL 315.196207 109.045701 \nL 315.479996 116.793699 \nL 316.331363 114.320218 \nL 316.615152 111.667365 \nL 316.898941 106.651771 \nL 317.18273 114.145742 \nL 317.466519 103.048203 \nL 318.885464 111.336724 \nL 319.169253 116.65148 \nL 319.453041 116.290164 \nL 320.304408 126.349152 \nL 320.588197 119.979975 \nL 320.871986 118.449786 \nL 321.155775 112.23537 \nL 321.439564 118.45745 \nL 322.57472 122.44819 \nL 322.858509 126.134769 \nL 323.142298 134.07647 \nL 323.426087 133.115198 \nL 324.277453 150.106378 \nL 324.561242 151.147579 \nL 324.845031 141.05032 \nL 325.12882 138.444362 \nL 325.412609 132.300837 \nL 327.115343 130.208593 \nL 327.399132 142.101586 \nL 328.250499 143.699198 \nL 328.534288 143.538258 \nL 328.818076 141.788163 \nL 329.101865 143.406253 \nL 329.385654 141.294131 \nL 330.237021 143.602426 \nL 330.52081 140.028527 \nL 330.804599 141.422508 \nL 331.088388 144.036682 \nL 331.372177 135.124749 \nL 332.223544 132.479924 \nL 332.507333 137.83754 \nL 332.791122 135.561419 \nL 333.074911 135.861627 \nL 333.358699 133.96179 \nL 334.210066 134.252962 \nL 334.493855 133.760109 \nL 334.777644 134.614772 \nL 335.061433 134.372928 \nL 336.196589 129.760613 \nL 336.480378 124.511282 \nL 336.764167 124.513066 \nL 337.047956 129.501945 \nL 337.331745 127.934619 \nL 338.183111 132.404298 \nL 338.4669 130.385736 \nL 338.750689 125.934313 \nL 339.034478 128.580586 \nL 339.318267 126.499151 \nL 340.169634 128.045541 \nL 340.453423 133.449532 \nL 340.737212 134.486471 \nL 341.30479 128.863888 \nL 342.156157 126.853464 \nL 342.439945 124.32134 \nL 342.723734 130.127126 \nL 343.007523 125.645703 \nL 343.291312 124.382559 \nL 344.142679 122.802025 \nL 344.426468 121.140296 \nL 344.710257 128.488554 \nL 344.994046 124.449684 \nL 345.277835 124.874304 \nL 346.129202 131.712892 \nL 346.412991 135.033765 \nL 346.69678 135.567048 \nL 346.980569 137.596134 \nL 347.264357 143.119485 \nL 348.115724 137.443965 \nL 348.399513 139.891039 \nL 348.683302 140.706479 \nL 348.967091 145.948848 \nL 349.25088 144.916894 \nL 350.102247 148.525164 \nL 350.386036 145.427724 \nL 350.669825 147.657914 \nL 352.088769 152.972771 \nL 352.372558 162.577844 \nL 352.656347 164.915854 \nL 352.940136 162.853011 \nL 353.223925 159.347792 \nL 354.075292 158.423072 \nL 354.359081 156.938738 \nL 354.64287 159.206476 \nL 354.926659 154.978176 \nL 355.210448 155.108719 \nL 356.061815 156.269342 \nL 356.345603 157.616937 \nL 356.629392 156.227253 \nL 356.913181 159.098867 \nL 357.19697 156.191626 \nL 358.048337 154.340624 \nL 358.615915 160.943543 \nL 358.899704 156.693269 \nL 359.183493 158.614232 \nL 360.03486 160.632456 \nL 360.318649 158.549195 \nL 360.602438 158.410041 \nL 361.170015 165.957792 \nL 362.021382 166.409507 \nL 362.305171 162.670621 \nL 362.58896 162.500763 \nL 362.872749 163.389606 \nL 363.156538 160.043899 \nL 364.291694 160.309416 \nL 364.859272 165.949621 \nL 365.143061 172.185301 \nL 365.994427 173.85489 \nL 366.278216 172.639707 \nL 366.562005 171.94182 \nL 366.845794 173.303105 \nL 367.129583 175.727493 \nL 367.98095 180.972736 \nL 368.264739 176.088842 \nL 368.548528 181.260202 \nL 368.832317 179.769282 \nL 368.832317 179.769282 \n\" clip-path=\"url(#p501b49471e)\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.7; stroke-width: 2; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 84.759589 280.378948 \nL 85.043378 280.928594 \nL 85.894745 281.867455 \nL 86.178534 281.11529 \nL 86.462323 282.69861 \nL 86.746112 281.39855 \nL 87.029901 281.383865 \nL 87.881268 280.409802 \nL 88.165057 280.826916 \nL 88.732635 282.469159 \nL 89.016424 282.027833 \nL 89.86779 281.466633 \nL 90.151579 283.825599 \nL 90.435368 283.573136 \nL 90.719157 287.311581 \nL 93.840836 296.304661 \nL 94.124624 293.346338 \nL 94.408413 292.547788 \nL 94.692202 290.709396 \nL 94.975991 290.848509 \nL 95.827358 290.920589 \nL 96.111147 289.616142 \nL 96.394936 288.927502 \nL 96.678725 289.807829 \nL 97.813881 286.542016 \nL 98.09767 287.66601 \nL 98.381459 287.693804 \nL 98.665247 285.311138 \nL 98.949036 285.750932 \nL 99.800403 287.419287 \nL 100.084192 288.326003 \nL 100.367981 288.660971 \nL 100.65177 288.207246 \nL 100.935559 292.191279 \nL 101.786926 288.38895 \nL 102.070715 287.795372 \nL 102.354504 286.651618 \nL 102.638293 283.564747 \nL 102.922082 285.895561 \nL 103.773448 290.098975 \nL 104.057237 287.673961 \nL 104.624815 291.274436 \nL 104.908604 293.166437 \nL 105.759971 297.752582 \nL 106.04376 298.121771 \nL 106.611338 303.191939 \nL 106.895127 300.625059 \nL 107.746493 303.63721 \nL 108.314071 297.482719 \nL 108.59786 297.960228 \nL 108.881649 297.427631 \nL 109.733016 297.926878 \nL 110.016805 297.955907 \nL 110.300594 298.275502 \nL 110.584383 296.620194 \nL 110.868172 297.104515 \nL 112.003328 294.977447 \nL 112.287117 295.569392 \nL 112.570905 295.188412 \nL 113.706061 295.776044 \nL 113.98985 293.737786 \nL 114.273639 294.667379 \nL 114.557428 294.502171 \nL 114.841217 292.715198 \nL 115.692584 292.245925 \nL 115.976373 293.789765 \nL 116.260162 292.927039 \nL 116.543951 293.214962 \nL 116.82774 294.162286 \nL 117.679106 292.884004 \nL 118.530473 290.402042 \nL 120.233207 290.317212 \nL 120.516996 290.729747 \nL 120.800785 289.915838 \nL 121.93594 290.065367 \nL 122.219729 290.147898 \nL 122.503518 291.600604 \nL 122.787307 292.250421 \nL 123.638674 291.485047 \nL 123.922463 290.456311 \nL 124.206252 290.654579 \nL 124.490041 291.06246 \nL 124.77383 294.171695 \nL 125.625197 293.563113 \nL 125.908986 292.725434 \nL 126.192774 293.310431 \nL 126.476563 292.689405 \nL 126.760352 292.820777 \nL 127.895508 289.350671 \nL 128.179297 289.211099 \nL 128.463086 289.462647 \nL 128.746875 288.894069 \nL 129.598242 288.314501 \nL 129.882031 287.494984 \nL 130.16582 288.363162 \nL 130.449609 289.762575 \nL 130.733397 289.429704 \nL 131.584764 291.422205 \nL 131.868553 289.654019 \nL 132.152342 289.560336 \nL 132.436131 289.217714 \nL 132.71992 287.598694 \nL 133.571287 287.775757 \nL 133.855076 287.621443 \nL 134.138865 286.830836 \nL 135.557809 287.618492 \nL 135.841598 286.892098 \nL 137.544332 267.975022 \nL 137.828121 267.641192 \nL 138.11191 265.531537 \nL 138.395699 265.002828 \nL 138.679488 268.953849 \nL 139.530855 267.275418 \nL 140.098432 270.618286 \nL 140.382221 277.261932 \nL 140.66601 276.21701 \nL 141.517377 271.750065 \nL 141.801166 271.798244 \nL 142.084955 271.59921 \nL 142.368744 271.916647 \nL 142.652533 277.425668 \nL 143.5039 277.209151 \nL 143.787689 276.217032 \nL 144.071478 273.699737 \nL 144.355267 274.219251 \nL 144.639055 273.439113 \nL 145.490422 272.048395 \nL 145.774211 270.689696 \nL 146.058 271.557664 \nL 146.341789 271.562441 \nL 146.625578 272.808284 \nL 147.476945 271.844409 \nL 147.760734 272.848613 \nL 148.328312 273.767176 \nL 148.612101 271.723834 \nL 149.463467 268.206521 \nL 149.747256 268.272962 \nL 150.314834 272.773809 \nL 150.598623 271.889659 \nL 151.44999 271.276965 \nL 151.733779 270.746382 \nL 152.017568 272.188987 \nL 152.301357 271.624385 \nL 152.585146 268.22449 \nL 153.436513 269.299382 \nL 153.720302 268.808663 \nL 154.00409 269.149814 \nL 154.287879 269.71428 \nL 154.571668 270.817718 \nL 155.423035 273.260109 \nL 155.706824 271.662533 \nL 155.990613 274.036066 \nL 156.274402 273.607056 \nL 156.558191 272.731615 \nL 157.409558 271.477046 \nL 157.693347 270.4486 \nL 158.260925 272.767088 \nL 158.544713 269.129052 \nL 159.39608 270.713339 \nL 159.679869 272.511718 \nL 159.963658 272.283183 \nL 160.247447 274.779821 \nL 160.531236 274.295539 \nL 161.382603 273.388136 \nL 161.950181 274.17989 \nL 164.504281 271.796379 \nL 165.355648 267.373064 \nL 165.639437 267.416488 \nL 165.923226 268.178106 \nL 166.207015 268.09476 \nL 166.490804 267.710891 \nL 167.342171 268.843187 \nL 167.625959 268.440578 \nL 167.909748 267.831045 \nL 168.193537 268.176696 \nL 168.477326 269.180296 \nL 169.612482 271.479787 \nL 169.896271 270.641631 \nL 170.18006 270.150895 \nL 170.463849 272.079818 \nL 171.315216 272.714115 \nL 171.599005 270.893245 \nL 171.882794 269.811558 \nL 172.166582 268.177883 \nL 172.450371 268.63251 \nL 173.301738 266.042469 \nL 173.585527 266.135925 \nL 173.869316 266.350957 \nL 174.153105 266.958454 \nL 174.436894 269.543604 \nL 175.288261 267.844819 \nL 175.57205 267.750064 \nL 175.855839 267.409846 \nL 176.139628 266.400686 \nL 176.423417 266.320186 \nL 177.274783 263.78635 \nL 177.842361 265.954189 \nL 178.12615 264.840029 \nL 178.409939 262.523015 \nL 179.261306 263.803285 \nL 179.545095 260.099395 \nL 180.112673 260.852444 \nL 180.396462 260.646378 \nL 181.531617 262.505577 \nL 181.815406 263.842292 \nL 182.099195 264.257895 \nL 182.382984 265.622973 \nL 183.234351 263.875567 \nL 183.51814 263.829082 \nL 183.801929 263.103318 \nL 184.085718 260.733104 \nL 184.369507 262.115157 \nL 185.220874 261.489595 \nL 185.504663 263.738285 \nL 185.788452 262.701305 \nL 186.07224 262.933908 \nL 186.356029 261.917612 \nL 187.207396 261.420641 \nL 187.491185 261.704659 \nL 188.058763 256.306672 \nL 189.193919 256.187568 \nL 189.761497 252.103083 \nL 190.045286 248.976019 \nL 190.329075 249.840755 \nL 191.180441 250.356951 \nL 191.46423 244.682941 \nL 191.748019 246.123147 \nL 192.031808 248.837896 \nL 192.315597 248.544097 \nL 193.166964 247.166515 \nL 193.450753 248.948676 \nL 193.734542 248.687741 \nL 194.018331 247.137718 \nL 194.30212 247.298026 \nL 195.153487 245.032121 \nL 195.437275 248.74744 \nL 195.721064 248.529487 \nL 196.004853 252.173762 \nL 196.288642 253.12765 \nL 197.140009 251.677348 \nL 197.423798 250.578463 \nL 197.707587 250.392279 \nL 197.991376 249.258495 \nL 198.275165 247.544447 \nL 199.126532 245.36846 \nL 199.69411 239.323593 \nL 202.24821 239.939733 \nL 203.099577 245.744877 \nL 203.383366 245.050988 \nL 203.667155 249.08975 \nL 203.950944 247.095113 \nL 204.234733 251.218149 \nL 205.086099 249.86044 \nL 205.369888 252.885669 \nL 205.653677 248.566939 \nL 205.937466 253.328462 \nL 206.221255 254.203198 \nL 207.072622 259.249251 \nL 207.356411 262.043379 \nL 207.6402 261.060944 \nL 207.923989 256.978031 \nL 208.207778 256.659587 \nL 209.059144 259.536193 \nL 209.342933 258.122551 \nL 209.626722 258.487296 \nL 209.910511 257.840582 \nL 210.1943 261.93801 \nL 211.045667 260.781835 \nL 211.329456 261.74789 \nL 211.613245 263.95108 \nL 211.897034 264.046068 \nL 212.180823 261.162701 \nL 213.03219 260.813188 \nL 213.315979 259.082332 \nL 213.599767 260.740569 \nL 214.167345 257.35201 \nL 215.302501 258.317618 \nL 215.58629 259.904345 \nL 215.870079 259.266502 \nL 216.153868 261.84649 \nL 217.289024 264.151739 \nL 217.572813 263.814017 \nL 217.856602 265.463751 \nL 218.140391 264.736464 \nL 218.991757 261.877808 \nL 219.275546 262.021041 \nL 219.559335 261.759493 \nL 219.843124 263.01478 \nL 220.126913 261.412554 \nL 220.97828 263.880226 \nL 221.262069 263.501882 \nL 221.545858 263.644742 \nL 221.829647 261.710771 \nL 222.113436 262.850129 \nL 223.816169 264.656152 \nL 224.099958 266.566336 \nL 224.951325 266.843282 \nL 225.235114 265.191402 \nL 225.518903 264.747081 \nL 225.802692 266.234533 \nL 226.086481 262.331328 \nL 226.937848 260.716799 \nL 227.221637 260.813832 \nL 227.505425 261.962218 \nL 227.789214 261.481312 \nL 228.073003 263.258442 \nL 228.92437 262.562946 \nL 229.208159 256.278086 \nL 229.491948 255.58202 \nL 229.775737 255.242617 \nL 230.059526 255.489817 \nL 230.910893 255.886983 \nL 231.194682 255.857259 \nL 231.76226 258.473189 \nL 232.046048 257.529866 \nL 232.897415 258.037414 \nL 233.181204 258.949222 \nL 233.464993 258.631859 \nL 233.748782 257.749754 \nL 234.032571 259.102739 \nL 235.167727 261.209107 \nL 235.451516 263.064671 \nL 235.735305 263.269892 \nL 236.019094 264.45256 \nL 236.87046 265.474299 \nL 237.154249 264.009596 \nL 237.438038 263.719077 \nL 237.721827 263.168801 \nL 238.005616 260.931075 \nL 238.856983 261.556085 \nL 239.140772 263.22029 \nL 239.424561 262.523471 \nL 239.70835 260.920983 \nL 239.992139 266.481983 \nL 241.127295 266.611498 \nL 241.411083 265.774761 \nL 241.694872 268.013582 \nL 241.978661 268.524134 \nL 243.113817 267.204183 \nL 243.397606 269.496717 \nL 243.681395 266.348361 \nL 243.965184 268.160523 \nL 244.816551 267.483327 \nL 245.10034 267.778304 \nL 245.384129 267.345248 \nL 245.667918 267.161516 \nL 245.951706 268.705729 \nL 246.803073 274.357146 \nL 247.086862 278.822778 \nL 247.65444 276.352515 \nL 247.938229 278.540604 \nL 248.789596 275.111343 \nL 249.357174 274.149912 \nL 249.640963 274.401394 \nL 249.924752 275.787711 \nL 250.776118 274.057818 \nL 251.059907 271.717827 \nL 251.911274 274.818324 \nL 252.762641 274.608795 \nL 253.04643 277.793758 \nL 253.330219 276.012941 \nL 253.614008 278.034728 \nL 253.897797 281.170487 \nL 254.749164 279.982552 \nL 255.032952 277.886132 \nL 255.316741 277.359205 \nL 255.60053 280.466589 \nL 255.884319 278.968432 \nL 256.735686 279.421448 \nL 257.019475 280.106384 \nL 257.303264 277.130057 \nL 257.587053 277.039859 \nL 257.870842 276.655359 \nL 258.722209 275.108983 \nL 259.005998 273.495378 \nL 259.289787 275.018847 \nL 259.573576 275.411954 \nL 259.857364 273.308328 \nL 260.708731 273.758778 \nL 261.276309 277.935817 \nL 261.560098 278.72589 \nL 261.843887 277.266442 \nL 263.262832 278.999601 \nL 263.546621 278.759511 \nL 264.965565 275.110918 \nL 265.249354 275.633161 \nL 265.533143 275.731034 \nL 268.654822 272.253918 \nL 268.93861 272.999437 \nL 269.222399 271.53783 \nL 269.506188 272.504144 \nL 269.789977 271.447159 \nL 270.641344 274.301914 \nL 270.925133 273.11816 \nL 271.208922 273.191273 \nL 271.492711 272.16045 \nL 271.7765 270.427264 \nL 272.627867 270.682275 \nL 272.911656 271.657188 \nL 273.195445 273.537226 \nL 273.479233 273.864996 \nL 273.763022 272.654885 \nL 274.614389 273.370045 \nL 275.181967 276.411425 \nL 275.465756 275.281231 \nL 275.749545 275.53157 \nL 276.600912 275.762575 \nL 276.884701 276.170302 \nL 277.16849 276.89505 \nL 277.452279 274.138213 \nL 277.736068 274.699606 \nL 278.871223 274.628458 \nL 279.155012 275.215031 \nL 279.438801 276.764961 \nL 279.72259 275.034127 \nL 280.573957 275.06724 \nL 281.141535 274.205411 \nL 281.425324 274.808919 \nL 281.709113 276.15278 \nL 282.56048 276.166326 \nL 282.844268 277.116374 \nL 283.411846 275.99893 \nL 283.695635 274.66133 \nL 284.547002 274.367111 \nL 284.830791 273.213108 \nL 285.398369 268.585912 \nL 285.682158 268.872841 \nL 286.533525 268.328283 \nL 286.817314 269.010009 \nL 287.101103 270.389934 \nL 287.384891 269.869965 \nL 287.66868 272.144836 \nL 288.520047 273.1758 \nL 288.803836 272.401721 \nL 289.087625 272.947269 \nL 289.371414 271.781908 \nL 289.655203 271.648457 \nL 290.50657 272.165064 \nL 290.790359 271.072073 \nL 291.074148 273.810933 \nL 291.641726 272.345259 \nL 292.776881 272.794264 \nL 293.06067 273.222745 \nL 293.344459 275.144566 \nL 293.628248 274.580563 \nL 294.479615 274.017979 \nL 294.763404 274.963154 \nL 295.047193 274.009582 \nL 295.614771 278.268062 \nL 296.466137 277.889188 \nL 296.749926 276.14549 \nL 297.033715 276.160039 \nL 297.317504 274.123725 \nL 297.601293 274.77898 \nL 298.45266 275.172622 \nL 298.736449 278.009579 \nL 299.020238 277.189725 \nL 299.304027 279.135263 \nL 299.587816 281.990705 \nL 302.425705 279.353229 \nL 302.709494 279.254958 \nL 302.993283 278.245369 \nL 303.277072 278.002416 \nL 303.560861 278.098778 \nL 304.412228 279.80259 \nL 304.979806 278.3978 \nL 305.263595 278.262291 \nL 305.547384 277.227063 \nL 306.39875 278.013261 \nL 306.682539 279.8758 \nL 306.966328 279.187847 \nL 307.250117 281.744643 \nL 307.533906 281.046463 \nL 308.385273 280.819219 \nL 308.669062 278.852778 \nL 308.952851 279.660579 \nL 309.23664 280.105057 \nL 309.520429 281.624611 \nL 310.371795 285.464673 \nL 310.939373 288.419958 \nL 311.223162 287.269203 \nL 311.506951 287.171877 \nL 312.358318 290.841223 \nL 312.642107 297.365963 \nL 312.925896 291.89759 \nL 313.493474 288.156939 \nL 314.344841 289.079824 \nL 314.62863 288.70063 \nL 314.912418 288.01146 \nL 315.196207 288.575874 \nL 315.479996 290.641974 \nL 316.331363 290.784086 \nL 316.615152 291.266962 \nL 316.898941 288.056009 \nL 317.18273 288.785635 \nL 317.466519 286.840889 \nL 318.885464 287.368276 \nL 319.169253 288.625577 \nL 319.453041 287.618147 \nL 320.304408 291.081895 \nL 320.588197 288.985628 \nL 320.871986 289.51013 \nL 321.155775 287.482204 \nL 321.439564 287.395417 \nL 322.290931 289.271861 \nL 322.858509 291.56475 \nL 323.142298 293.220737 \nL 323.426087 292.494023 \nL 324.277453 298.21713 \nL 324.561242 298.321536 \nL 325.12882 294.438659 \nL 325.412609 292.878938 \nL 327.115343 293.071882 \nL 327.399132 296.62568 \nL 328.250499 297.704 \nL 328.818076 295.685597 \nL 329.101865 296.537728 \nL 329.385654 295.378917 \nL 330.237021 296.597466 \nL 330.52081 295.006624 \nL 330.804599 295.497526 \nL 331.088388 295.540561 \nL 331.372177 292.764835 \nL 332.223544 293.876675 \nL 332.507333 295.993835 \nL 332.791122 295.589966 \nL 333.074911 295.525088 \nL 333.358699 294.729402 \nL 334.210066 294.056059 \nL 334.493855 292.5338 \nL 334.777644 293.197146 \nL 335.061433 293.536541 \nL 336.196589 291.9895 \nL 336.480378 291.063077 \nL 336.764167 289.640056 \nL 337.047956 290.116755 \nL 337.331745 288.752693 \nL 338.183111 291.154418 \nL 338.750689 287.683926 \nL 339.034478 289.113602 \nL 339.318267 287.149289 \nL 340.169634 287.643374 \nL 340.453423 287.575077 \nL 340.737212 289.071978 \nL 341.30479 285.461279 \nL 342.156157 283.745226 \nL 342.439945 282.630273 \nL 342.723734 283.951537 \nL 343.007523 281.799079 \nL 343.291312 282.373905 \nL 344.426468 282.074313 \nL 344.710257 284.499178 \nL 344.994046 284.828419 \nL 345.277835 284.648987 \nL 346.980569 288.940063 \nL 347.264357 291.387782 \nL 348.115724 289.669479 \nL 348.399513 290.240254 \nL 348.683302 289.869209 \nL 348.967091 291.507402 \nL 349.25088 290.991877 \nL 350.102247 291.481216 \nL 350.386036 290.720302 \nL 350.669825 291.802493 \nL 350.953614 291.925742 \nL 351.237403 293.448436 \nL 352.088769 293.914574 \nL 352.372558 296.144318 \nL 352.656347 297.021362 \nL 353.223925 294.236254 \nL 354.075292 294.813229 \nL 354.359081 294.685781 \nL 354.64287 296.135321 \nL 354.926659 293.678981 \nL 355.210448 293.248784 \nL 356.061815 293.8715 \nL 356.345603 294.458419 \nL 356.629392 293.731967 \nL 356.913181 294.894784 \nL 357.19697 295.274118 \nL 358.048337 295.022876 \nL 358.615915 297.13667 \nL 358.899704 295.189813 \nL 359.183493 295.232134 \nL 360.318649 296.323615 \nL 360.602438 294.785821 \nL 361.170015 296.997702 \nL 362.021382 297.588675 \nL 362.305171 296.418283 \nL 362.58896 297.023008 \nL 362.872749 297.128438 \nL 363.156538 294.970464 \nL 364.291694 294.459561 \nL 364.575483 295.501883 \nL 364.859272 295.573678 \nL 365.143061 298.452667 \nL 365.994427 298.384689 \nL 366.278216 298.634485 \nL 366.845794 300.58329 \nL 367.129583 300.564078 \nL 367.98095 301.216847 \nL 368.264739 299.989979 \nL 368.548528 301.344619 \nL 368.832317 301.344619 \nL 368.832317 301.344619 \n\" clip-path=\"url(#p501b49471e)\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 70.555953 316.989937 \nL 70.555953 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 383.035953 316.989937 \nL 383.035953 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 70.555953 316.989937 \nL 383.035953 316.989937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 70.555953 23.229937 \nL 383.035953 23.229937 \n\" style=\"fill: none; stroke: #000000; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- New Normal -->\n    <g transform=\"translate(186.421484 17.229937)scale(0.132 -0.132)\">\n     <defs>\n      <path id=\"DejaVuSans-4e\" d=\"M 628 4666 \nL 1478 4666 \nL 3547 763 \nL 3547 4666 \nL 4159 4666 \nL 4159 0 \nL 3309 0 \nL 1241 3903 \nL 1241 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-4e\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"74.804688\"/>\n     <use xlink:href=\"#DejaVuSans-77\" x=\"136.328125\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"218.115234\"/>\n     <use xlink:href=\"#DejaVuSans-4e\" x=\"249.902344\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"324.707031\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"385.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"425.251953\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"522.664062\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"583.943359\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 79.025953 68.431 \nL 186.044781 68.431 \nQ 188.464781 68.431 188.464781 66.011 \nL 188.464781 31.699937 \nQ 188.464781 29.279937 186.044781 29.279937 \nL 79.025953 29.279937 \nQ 76.605953 29.279937 76.605953 31.699937 \nL 76.605953 66.011 \nQ 76.605953 68.431 79.025953 68.431 \nz\n\" style=\"fill: #ffffff; opacity: 0.5; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 81.445953 39.079047 \nL 93.545953 39.079047 \nL 105.645953 39.079047 \n\" style=\"fill: none; stroke: #228b22; stroke-opacity: 0.7; stroke-width: 2; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_21\">\n     <!-- Algo -->\n     <g transform=\"translate(115.325953 43.314047)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-41\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"68.408203\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"96.191406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"159.667969\"/>\n     </g>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 81.445953 56.839578 \nL 93.545953 56.839578 \nL 105.645953 56.839578 \n\" style=\"fill: none; stroke: #808080; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_22\">\n     <!-- benchmark -->\n     <g transform=\"translate(115.325953 61.074578)scale(0.121 -0.121)\">\n      <defs>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-62\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"188.378906\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"243.359375\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"306.738281\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"404.150391\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"465.429688\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"506.542969\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p501b49471e\">\n   <rect x=\"70.555953\" y=\"23.229937\" width=\"312.48\" height=\"293.76\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyfolio\n",
    "from pyfolio import timeseries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "daily_return = get_daily_return(df_account_value)\n",
    "daily_return_base = get_daily_return(baseline_df, value_col_name='close')\n",
    "\n",
    "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "        pyfolio.create_full_tear_sheet(returns = daily_return,\n",
    "                                       benchmark_rets = daily_return_base, set_context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Demo_China_A_share_market.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "7a792fcb311f9eb9f3c1b942a8c87ada8484712b89b670347c16a1088e0a1f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
