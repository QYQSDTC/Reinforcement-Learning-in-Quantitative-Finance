{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bed929-ebbb-42e6-92ea-2d3db0635523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from meta.env_fx_trading.env_fx import tgym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d16e13-67dc-403a-96db-91bf3d3f52b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_0.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_1.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_2.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_3.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_4.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_5.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_6.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_7.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_8.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_9.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_10.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_11.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_12.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_13.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_14.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_15.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_16.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_17.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_18.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_19.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_20.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_21.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_22.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_23.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_24.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_25.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_26.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_27.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_28.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_29.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_30.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_31.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_32.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_33.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_34.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_35.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_36.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_37.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_38.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_39.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_40.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_41.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_42.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_43.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_44.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_45.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_46.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_47.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_48.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_49.csv\n",
      "not exist: ./data/split/GBPUSD/weekly/GBPUSD_2017_50.csv\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files=[]\n",
    "for i in range(51):\n",
    "    file = f\"./data/split/GBPUSD/weekly/GBPUSD_2017_{i}.csv\"\n",
    "    if os.path.isfile(file):\n",
    "        files.append(file)\n",
    "    else:\n",
    "        print(f'not exist: {file}')\n",
    "print(files)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecd1fc11-0018-46c9-a1c5-d2d7d0eeb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agent, files, if_vix = True,**kwargs):\n",
    "    learning_rate = kwargs.get('learning_rate', 2 ** -15)\n",
    "    batch_size = kwargs.get('batch_size', 2 ** 11 )\n",
    "    gamma = kwargs.get('gamma', 0.99)\n",
    "    seed = kwargs.get('seed', 312)\n",
    "    total_timesteps = kwargs.get('total_timesteps', 1e6)\n",
    "    net_dimension = kwargs.get('net_dimension', 2**9)\n",
    "    cwd = kwargs.get('cwd','./'+str(agent))\n",
    "\n",
    "    # env_instance = map(env, [pd.read_csv(f) for f in files])\n",
    "    if agent == 'ppo':\n",
    "        from stable_baselines3 import PPO\n",
    "        from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "\n",
    "        # env_train = [x.get_sb_env for x in env_instance ]\n",
    "        vector_env = [lambda:env(df=pd.read_csv(f)) for f in files]\n",
    "        env_train = SubprocVecEnv(vector_env)\n",
    "        model = PPO(\"MlpPolicy\", env_train, learning_rate=learning_rate, \n",
    "                    n_steps=2048, batch_size=batch_size, ent_coef=0.0, \n",
    "                    gamma=gamma, seed=seed)\n",
    "        start_time = time.time()\n",
    "        s = datetime.datetime.now()\n",
    "        print(f'Training start: {s}')\n",
    "        model.learn(total_timesteps=total_timesteps, tb_log_name = 'ppo')\n",
    "        print('Training finished!')\n",
    "        model_name = \"./data/models/GBPUSD-week-\" + s.strftime('%Y%m%d%H%M%S')\n",
    "        model.save(model_name)\n",
    "        print(f'Trained model saved in {model_name}')\n",
    "        print(f\"trainning time: {(time.time() - start_time)}\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError('DRL library input is NOT supported. Please check.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5b6cfe4-2bec-4135-b31b-60c8ac71d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start: 2021-10-25 22:40:25.516039\n",
      "Training finished!\n",
      "Trained model saved in ./ppo\n",
      "trainning time: 359.4131119251251\n"
     ]
    }
   ],
   "source": [
    "train(env=tgym,agent=\"ppo\",files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429675ae-949e-4013-8302-e724700a3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "run at 10:36 to check loading time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df8d7c-5f86-42bd-be09-c8317231c16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5cbf5f3919493e81ecc3b85d0c032848d05d998b2f24661b916bdd5d1cc3a5e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
